2025-11-24 22:21:42,759 - 
============================================================
2025-11-24 22:21:42,759 - VIGNet Single-Target Training
2025-11-24 22:21:42,759 - Target: miss_rate
2025-11-24 22:21:42,759 - Started: 2025-11-24 22:21:42
2025-11-24 22:21:42,759 - ============================================================
2025-11-24 22:21:42,759 - 
============================================================
2025-11-24 22:21:42,759 - Loading data for target: miss_rate
2025-11-24 22:21:42,759 - ============================================================
2025-11-24 22:21:42,846 - Applied StandardScaler normalization
2025-11-24 22:21:43,181 - 
============================================================
2025-11-24 22:21:43,181 - Training VIGNet for target: miss_rate
2025-11-24 22:21:43,181 - ============================================================
2025-11-24 22:21:43,181 - Learning rate: 0.005
2025-11-24 22:21:43,181 - Epochs: 200
2025-11-24 22:21:43,181 - Batch size: 8
2025-11-24 22:21:43,181 - Early stopping patience: 20
2025-11-24 22:21:47,188 - Epoch   1: train_loss=0.048979, val_loss=0.053637, val_corr=-0.0017
2025-11-24 22:21:47,194 -   -> New best validation loss: 0.053637
2025-11-24 22:21:49,231 - Epoch   2: train_loss=0.048477, val_loss=0.037681, val_corr=0.6835
2025-11-24 22:21:49,232 -   -> New best validation loss: 0.037681
2025-11-24 22:21:52,609 - Epoch   3: train_loss=0.037925, val_loss=0.036618, val_corr=0.4114
2025-11-24 22:21:52,611 -   -> New best validation loss: 0.036618
2025-11-24 22:21:55,843 - Epoch   4: train_loss=0.036155, val_loss=0.035949, val_corr=0.7250
2025-11-24 22:21:55,844 -   -> New best validation loss: 0.035949
2025-11-24 22:21:57,865 - Epoch   5: train_loss=0.030937, val_loss=0.035235, val_corr=0.7024
2025-11-24 22:21:57,866 -   -> New best validation loss: 0.035235
2025-11-24 22:21:59,384 - Epoch   6: train_loss=0.023890, val_loss=0.035013, val_corr=0.6596
2025-11-24 22:21:59,385 -   -> New best validation loss: 0.035013
2025-11-24 22:22:03,040 - Epoch   7: train_loss=0.021482, val_loss=0.035826, val_corr=0.5112
2025-11-24 22:22:06,504 - Epoch   8: train_loss=0.024772, val_loss=0.035199, val_corr=0.6810
2025-11-24 22:22:08,020 - Epoch   9: train_loss=0.019145, val_loss=0.034894, val_corr=0.6112
2025-11-24 22:22:08,021 -   -> New best validation loss: 0.034894
2025-11-24 22:22:11,243 - Epoch  10: train_loss=0.021389, val_loss=0.034909, val_corr=0.6460
2025-11-24 22:22:14,252 - Epoch  11: train_loss=0.016093, val_loss=0.035152, val_corr=0.7616
2025-11-24 22:22:15,815 - Epoch  12: train_loss=0.014771, val_loss=0.035312, val_corr=0.6489
2025-11-24 22:22:17,392 - Epoch  13: train_loss=0.017194, val_loss=0.034900, val_corr=0.6225
2025-11-24 22:22:20,346 - Epoch  14: train_loss=0.016879, val_loss=0.036947, val_corr=0.5808
2025-11-24 22:22:22,396 - Epoch  15: train_loss=0.017014, val_loss=0.033808, val_corr=0.6699
2025-11-24 22:22:22,397 -   -> New best validation loss: 0.033808
2025-11-24 22:22:24,659 - Epoch  16: train_loss=0.015203, val_loss=0.039371, val_corr=0.6423
2025-11-24 22:22:26,672 - Epoch  17: train_loss=0.015974, val_loss=0.043463, val_corr=0.6202
2025-11-24 22:22:28,740 - Epoch  18: train_loss=0.017245, val_loss=0.034667, val_corr=0.6199
2025-11-24 22:22:31,427 - Epoch  19: train_loss=0.012998, val_loss=0.037688, val_corr=0.5759
2025-11-24 22:22:34,245 - Epoch  20: train_loss=0.011318, val_loss=0.041681, val_corr=0.5631
2025-11-24 22:22:36,408 - Epoch  21: train_loss=0.012032, val_loss=0.030621, val_corr=0.6859
2025-11-24 22:22:36,409 -   -> New best validation loss: 0.030621
2025-11-24 22:22:37,940 - Epoch  22: train_loss=0.015506, val_loss=0.045346, val_corr=0.7048
2025-11-24 22:22:39,653 - Epoch  23: train_loss=0.014979, val_loss=0.031542, val_corr=0.6815
2025-11-24 22:22:43,172 - Epoch  24: train_loss=0.009436, val_loss=0.027949, val_corr=0.6774
2025-11-24 22:22:43,179 -   -> New best validation loss: 0.027949
2025-11-24 22:22:46,016 - Epoch  25: train_loss=0.019604, val_loss=0.026506, val_corr=0.6841
2025-11-24 22:22:46,017 -   -> New best validation loss: 0.026506
2025-11-24 22:22:48,943 - Epoch  26: train_loss=0.012760, val_loss=0.023688, val_corr=0.6909
2025-11-24 22:22:48,945 -   -> New best validation loss: 0.023688
2025-11-24 22:22:53,313 - Epoch  27: train_loss=0.013733, val_loss=0.021891, val_corr=0.6955
2025-11-24 22:22:53,314 -   -> New best validation loss: 0.021891
2025-11-24 22:22:55,783 - Epoch  28: train_loss=0.008921, val_loss=0.020434, val_corr=0.7208
2025-11-24 22:22:55,784 -   -> New best validation loss: 0.020434
2025-11-24 22:22:57,415 - Epoch  29: train_loss=0.014413, val_loss=0.020482, val_corr=0.7086
2025-11-24 22:23:00,285 - Epoch  30: train_loss=0.010760, val_loss=0.018491, val_corr=0.7048
2025-11-24 22:23:00,289 -   -> New best validation loss: 0.018491
2025-11-24 22:23:05,086 - Epoch  31: train_loss=0.012038, val_loss=0.019556, val_corr=0.6914
2025-11-24 22:23:07,565 - Epoch  32: train_loss=0.010061, val_loss=0.021658, val_corr=0.6198
2025-11-24 22:23:09,202 - Epoch  33: train_loss=0.011501, val_loss=0.020214, val_corr=0.6636
2025-11-24 22:23:11,988 - Epoch  34: train_loss=0.009609, val_loss=0.017020, val_corr=0.7196
2025-11-24 22:23:11,989 -   -> New best validation loss: 0.017020
2025-11-24 22:23:15,461 - Epoch  35: train_loss=0.009153, val_loss=0.014206, val_corr=0.7753
2025-11-24 22:23:15,462 -   -> New best validation loss: 0.014206
2025-11-24 22:23:19,500 - Epoch  36: train_loss=0.010626, val_loss=0.015349, val_corr=0.7639
2025-11-24 22:23:23,528 - Epoch  37: train_loss=0.010774, val_loss=0.016486, val_corr=0.7291
2025-11-24 22:23:26,580 - Epoch  38: train_loss=0.008120, val_loss=0.016832, val_corr=0.7318
2025-11-24 22:23:30,467 - Epoch  39: train_loss=0.010817, val_loss=0.019748, val_corr=0.6949
2025-11-24 22:23:33,211 - Epoch  40: train_loss=0.012318, val_loss=0.019153, val_corr=0.7214
2025-11-24 22:23:37,358 - Epoch  41: train_loss=0.010192, val_loss=0.017940, val_corr=0.7135
2025-11-24 22:23:41,534 - Epoch  42: train_loss=0.009883, val_loss=0.017776, val_corr=0.7198
2025-11-24 22:23:45,497 - Epoch  43: train_loss=0.010789, val_loss=0.018402, val_corr=0.7031
2025-11-24 22:23:47,980 - Epoch  44: train_loss=0.010770, val_loss=0.018085, val_corr=0.7430
2025-11-24 22:23:50,064 - Epoch  45: train_loss=0.008491, val_loss=0.018775, val_corr=0.7344
2025-11-24 22:23:52,864 - Epoch  46: train_loss=0.011585, val_loss=0.015655, val_corr=0.7656
2025-11-24 22:23:55,882 - Epoch  47: train_loss=0.015262, val_loss=0.014628, val_corr=0.7779
2025-11-24 22:23:58,462 - Epoch  48: train_loss=0.011552, val_loss=0.015443, val_corr=0.7505
2025-11-24 22:24:01,986 - Epoch  49: train_loss=0.013814, val_loss=0.018596, val_corr=0.7309
2025-11-24 22:24:04,263 - Epoch  50: train_loss=0.012655, val_loss=0.015361, val_corr=0.7504
2025-11-24 22:24:06,673 - Epoch  51: train_loss=0.008660, val_loss=0.017371, val_corr=0.7491
2025-11-24 22:24:09,869 - Epoch  52: train_loss=0.009064, val_loss=0.019490, val_corr=0.6980
2025-11-24 22:24:12,762 - Epoch  53: train_loss=0.011549, val_loss=0.019893, val_corr=0.7135
2025-11-24 22:24:15,215 - Epoch  54: train_loss=0.007513, val_loss=0.014920, val_corr=0.7911
2025-11-24 22:24:18,027 - Epoch  55: train_loss=0.011470, val_loss=0.016687, val_corr=0.7489
2025-11-24 22:24:18,027 - 
Early stopping at epoch 55
2025-11-24 22:24:18,051 - Restored best model weights
2025-11-24 22:24:18,052 - 
============================================================
2025-11-24 22:24:18,052 - Evaluation Results
2025-11-24 22:24:18,052 - ============================================================
2025-11-24 22:24:18,582 - 
Validation Set:
2025-11-24 22:24:18,583 -   MSE:  0.014496
2025-11-24 22:24:18,583 -   MAE:  0.077136
2025-11-24 22:24:18,583 -   RMSE: 0.120401
2025-11-24 22:24:18,583 -   Pearson r:  0.768112 (p=7.36e-06)
2025-11-24 22:24:18,583 -   Spearman r: 0.782248 (p=3.85e-06)
2025-11-24 22:24:18,583 -   Pred mean: 0.1384, std: 0.1462
2025-11-24 22:24:18,583 -   True mean: 0.1490, std: 0.1873
2025-11-24 22:24:18,585 - 
Test Set:
2025-11-24 22:24:18,585 -   MSE:  0.018637
2025-11-24 22:24:18,585 -   MAE:  0.091322
2025-11-24 22:24:18,585 -   RMSE: 0.136517
2025-11-24 22:24:18,585 -   Pearson r:  0.846659 (p=1.94e-09)
2025-11-24 22:24:18,586 -   Spearman r: 0.815892 (p=2.23e-08)
2025-11-24 22:24:18,586 -   Pred mean: 0.1992, std: 0.1509
2025-11-24 22:24:18,586 -   True mean: 0.2415, std: 0.2298
2025-11-24 22:24:18,586 - 
============================================================
2025-11-24 22:24:18,586 - Saving Results
2025-11-24 22:24:18,586 - ============================================================
2025-11-24 22:24:18,611 - Saved model weights: ./logs_experiment/miss_rate/model_weights.h5
2025-11-24 22:24:18,612 - Saved predictions: ./logs_experiment/miss_rate/predictions.npy
2025-11-24 22:24:18,615 - Saved training history: ./logs_experiment/miss_rate/training_history.csv
2025-11-24 22:24:18,615 - Saved metrics: ./logs_experiment/miss_rate/metrics.json
2025-11-24 22:24:18,616 - Saved config: ./logs_experiment/miss_rate/config.json
2025-11-24 22:24:18,616 - 
============================================================
2025-11-24 22:24:18,616 - Training Complete
2025-11-24 22:24:18,616 - Duration: 155.9 seconds
2025-11-24 22:24:18,616 - Results saved to: ./logs_experiment/miss_rate
2025-11-24 22:24:18,616 - ============================================================
