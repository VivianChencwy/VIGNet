2026-01-02 19:08:18,846 - ======================================================================
2026-01-02 19:08:18,846 - WEIYU DATA PROCESSING AND MODELING PIPELINE
2026-01-02 19:08:18,846 - ======================================================================
2026-01-02 19:08:18,846 - Start time: 2026-01-02 19:08:18
2026-01-02 19:08:18,846 - Log file: logs/pipeline_20260102_190818.log
2026-01-02 19:08:18,846 - 
2026-01-02 19:08:18,846 - ============================================================
2026-01-02 19:08:18,846 - STEP 1: Loading and Trimming Data
2026-01-02 19:08:18,846 - ============================================================
2026-01-02 19:08:18,846 - Loading data from: merged_data.csv
2026-01-02 19:08:20,274 - Loaded 1104038 samples
2026-01-02 19:08:20,274 - Original duration: 2212.86s (36.88 min)
2026-01-02 19:08:20,281 - Original sampling rate: 967.12 Hz
2026-01-02 19:08:20,281 - Trimming: first 300.0s, last 0.0s
2026-01-02 19:08:20,384 - After trimming: 1912.86s (31.88 min)
2026-01-02 19:08:20,384 - Samples after trimming: 954348
2026-01-02 19:08:20,386 - ============================================================
2026-01-02 19:08:20,386 - STEP 2: Resampling
2026-01-02 19:08:20,386 - ============================================================
2026-01-02 19:08:20,386 - Resampling from 967.12 Hz to 200 Hz
2026-01-02 19:08:20,386 - Samples: 954348 -> 197359
2026-01-02 19:08:20,585 - ============================================================
2026-01-02 19:08:20,585 - STEP 3: Segmentation
2026-01-02 19:08:20,585 - ============================================================
2026-01-02 19:08:20,585 - Created 245 windows
2026-01-02 19:08:20,585 - Window shape: 1600 samples x 2 channels
2026-01-02 19:08:20,585 - ============================================================
2026-01-02 19:08:20,585 - STEP 4: Extracting DE Features
2026-01-02 19:08:20,585 - ============================================================
2026-01-02 19:08:20,585 - Extracting DE for 245 windows, 2 channels, 25 bands
2026-01-02 19:08:21,248 -   Processing window 100/245
2026-01-02 19:08:21,912 -   Processing window 200/245
2026-01-02 19:08:22,210 -   Processing window 245/245
2026-01-02 19:08:22,217 - DE features shape: (2, 245, 25)
2026-01-02 19:08:22,217 - ============================================================
2026-01-02 19:08:22,217 - STEP 5: Applying Smoothing
2026-01-02 19:08:22,217 - ============================================================
2026-01-02 19:08:22,217 - Applying moving average (window=5)...
2026-01-02 19:08:22,217 - Applying LDS (Kalman filter) smoothing...
2026-01-02 19:08:23,147 - Smoothing completed
2026-01-02 19:08:23,148 - ============================================================
2026-01-02 19:08:23,148 - STEP 6: Computing PERCLOS Labels
2026-01-02 19:08:23,148 - ============================================================
2026-01-02 19:08:23,344 - Unique eye states in data: ['close' 'open']
2026-01-02 19:08:23,353 - Eye closed samples: 34125.0 / 954348 (3.58%)
2026-01-02 19:08:23,353 - Computing PERCLOS with 60.0s window...
2026-01-02 19:08:23,479 - PERCLOS range: [0.0000, 0.1261]
2026-01-02 19:08:23,479 - PERCLOS mean: 0.0344, std: 0.0339
2026-01-02 19:08:23,479 - Distribution: Awake=245 (100.0%), Tired=0 (0.0%), Drowsy=0 (0.0%)
2026-01-02 19:08:23,479 - ============================================================
2026-01-02 19:08:23,479 - STEP 7: Saving Preprocessed Data
2026-01-02 19:08:23,479 - ============================================================
2026-01-02 19:08:23,480 - Saved DE features: processed/de_features.npy
2026-01-02 19:08:23,480 -   Shape: (245, 2, 25)
2026-01-02 19:08:23,480 - Saved PERCLOS labels: processed/perclos_labels.npy
2026-01-02 19:08:23,480 - Saved timestamps: processed/timestamps.npy
2026-01-02 19:08:23,480 - Saved metadata: processed/metadata.npy
2026-01-02 19:08:23,480 - ============================================================
2026-01-02 19:08:23,480 - STEP 8: Data Splitting (Block-wise Random)
2026-01-02 19:08:23,480 - ============================================================
2026-01-02 19:08:23,480 - Created 24 blocks (block_size=8, gap=2)
2026-01-02 19:08:23,480 - Split results:
2026-01-02 19:08:23,480 -   Train: 128 samples (66.7%)
2026-01-02 19:08:23,480 -   Valid: 24 samples (12.5%)
2026-01-02 19:08:23,480 -   Test:  40 samples (20.8%)
2026-01-02 19:08:23,480 -   Discarded (gaps): 53 samples
2026-01-02 19:08:23,480 - ============================================================
2026-01-02 19:08:23,480 - STEP 9-10: Model Training
2026-01-02 19:08:23,480 - ============================================================
2026-01-02 19:08:23,510 - Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
2026-01-02 19:08:23,510 - Train: (128, 2, 25), Val: (24, 2, 25), Test: (40, 2, 25)
2026-01-02 19:08:23,510 - Applied StandardScaler normalization
2026-01-02 19:08:23,837 - Learning rate: 0.005
2026-01-02 19:08:23,837 - Max epochs: 500
2026-01-02 19:08:23,837 - Batch size: 8
2026-01-02 19:08:23,837 - Early stopping patience: 50
2026-01-02 19:08:25,568 - Epoch   1: Train Loss = 0.003481, Val Loss = 0.000458
2026-01-02 19:08:25,569 -   -> New best validation loss: 0.000458
2026-01-02 19:08:26,800 - Epoch   2: Train Loss = 0.001434, Val Loss = 0.000549
2026-01-02 19:08:27,952 - Epoch   3: Train Loss = 0.000945, Val Loss = 0.000460
2026-01-02 19:08:29,227 - Epoch   4: Train Loss = 0.000665, Val Loss = 0.000363
2026-01-02 19:08:29,228 -   -> New best validation loss: 0.000363
2026-01-02 19:08:30,484 - Epoch   5: Train Loss = 0.000580, Val Loss = 0.000432
2026-01-02 19:08:31,632 - Epoch   6: Train Loss = 0.000484, Val Loss = 0.000362
2026-01-02 19:08:31,632 -   -> New best validation loss: 0.000362
2026-01-02 19:08:32,754 - Epoch   7: Train Loss = 0.000589, Val Loss = 0.000381
2026-01-02 19:08:33,886 - Epoch   8: Train Loss = 0.000503, Val Loss = 0.000376
2026-01-02 19:08:35,038 - Epoch   9: Train Loss = 0.000388, Val Loss = 0.000409
2026-01-02 19:08:36,170 - Epoch  10: Train Loss = 0.000347, Val Loss = 0.000371
2026-01-02 19:08:37,332 - Epoch  11: Train Loss = 0.000347, Val Loss = 0.000381
2026-01-02 19:08:38,496 - Epoch  12: Train Loss = 0.000371, Val Loss = 0.000363
2026-01-02 19:08:39,620 - Epoch  13: Train Loss = 0.000317, Val Loss = 0.000385
2026-01-02 19:08:40,759 - Epoch  14: Train Loss = 0.000193, Val Loss = 0.000350
2026-01-02 19:08:40,760 -   -> New best validation loss: 0.000350
2026-01-02 19:08:41,978 - Epoch  15: Train Loss = 0.000278, Val Loss = 0.000372
2026-01-02 19:08:43,207 - Epoch  16: Train Loss = 0.000320, Val Loss = 0.000346
2026-01-02 19:08:43,208 -   -> New best validation loss: 0.000346
2026-01-02 19:08:44,448 - Epoch  17: Train Loss = 0.000231, Val Loss = 0.000379
2026-01-02 19:08:45,619 - Epoch  18: Train Loss = 0.000283, Val Loss = 0.000392
2026-01-02 19:08:46,829 - Epoch  19: Train Loss = 0.000268, Val Loss = 0.000329
2026-01-02 19:08:46,830 -   -> New best validation loss: 0.000329
2026-01-02 19:08:47,968 - Epoch  20: Train Loss = 0.000261, Val Loss = 0.000409
2026-01-02 19:08:49,191 - Epoch  21: Train Loss = 0.000315, Val Loss = 0.000435
2026-01-02 19:08:50,418 - Epoch  22: Train Loss = 0.000264, Val Loss = 0.000316
2026-01-02 19:08:50,419 -   -> New best validation loss: 0.000316
2026-01-02 19:08:51,597 - Epoch  23: Train Loss = 0.000264, Val Loss = 0.000359
2026-01-02 19:08:52,723 - Epoch  24: Train Loss = 0.000267, Val Loss = 0.000312
2026-01-02 19:08:52,724 -   -> New best validation loss: 0.000312
2026-01-02 19:08:53,853 - Epoch  25: Train Loss = 0.000241, Val Loss = 0.000319
2026-01-02 19:08:54,975 - Epoch  26: Train Loss = 0.000380, Val Loss = 0.000680
2026-01-02 19:08:56,103 - Epoch  27: Train Loss = 0.000238, Val Loss = 0.000868
2026-01-02 19:08:57,263 - Epoch  28: Train Loss = 0.000269, Val Loss = 0.000401
2026-01-02 19:08:58,449 - Epoch  29: Train Loss = 0.000195, Val Loss = 0.000577
2026-01-02 19:08:59,668 - Epoch  30: Train Loss = 0.000326, Val Loss = 0.000304
2026-01-02 19:08:59,668 -   -> New best validation loss: 0.000304
2026-01-02 19:09:00,807 - Epoch  31: Train Loss = 0.000278, Val Loss = 0.000370
2026-01-02 19:09:01,967 - Epoch  32: Train Loss = 0.000204, Val Loss = 0.000513
2026-01-02 19:09:03,213 - Epoch  33: Train Loss = 0.000205, Val Loss = 0.000389
2026-01-02 19:09:04,427 - Epoch  34: Train Loss = 0.000366, Val Loss = 0.000362
2026-01-02 19:09:05,628 - Epoch  35: Train Loss = 0.000277, Val Loss = 0.000406
2026-01-02 19:09:06,755 - Epoch  36: Train Loss = 0.000174, Val Loss = 0.000420
2026-01-02 19:09:07,894 - Epoch  37: Train Loss = 0.000168, Val Loss = 0.000376
2026-01-02 19:09:09,031 - Epoch  38: Train Loss = 0.000227, Val Loss = 0.000479
2026-01-02 19:09:10,228 - Epoch  39: Train Loss = 0.000176, Val Loss = 0.000812
2026-01-02 19:09:11,363 - Epoch  40: Train Loss = 0.000211, Val Loss = 0.000667
2026-01-02 19:09:12,554 - Epoch  41: Train Loss = 0.000212, Val Loss = 0.000581
2026-01-02 19:09:13,758 - Epoch  42: Train Loss = 0.000173, Val Loss = 0.000553
2026-01-02 19:09:14,891 - Epoch  43: Train Loss = 0.000168, Val Loss = 0.000534
2026-01-02 19:09:16,017 - Epoch  44: Train Loss = 0.000192, Val Loss = 0.000687
2026-01-02 19:09:17,147 - Epoch  45: Train Loss = 0.000238, Val Loss = 0.000564
2026-01-02 19:09:18,349 - Epoch  46: Train Loss = 0.000302, Val Loss = 0.000436
2026-01-02 19:09:19,530 - Epoch  47: Train Loss = 0.000177, Val Loss = 0.000461
2026-01-02 19:09:20,778 - Epoch  48: Train Loss = 0.000188, Val Loss = 0.000480
2026-01-02 19:09:21,964 - Epoch  49: Train Loss = 0.000197, Val Loss = 0.000557
2026-01-02 19:09:23,203 - Epoch  50: Train Loss = 0.000206, Val Loss = 0.000581
2026-01-02 19:09:24,455 - Epoch  51: Train Loss = 0.000196, Val Loss = 0.000932
2026-01-02 19:09:25,736 - Epoch  52: Train Loss = 0.000302, Val Loss = 0.000563
2026-01-02 19:09:26,948 - Epoch  53: Train Loss = 0.000192, Val Loss = 0.000565
2026-01-02 19:09:28,188 - Epoch  54: Train Loss = 0.000180, Val Loss = 0.000763
2026-01-02 19:09:29,423 - Epoch  55: Train Loss = 0.000182, Val Loss = 0.000414
2026-01-02 19:09:30,584 - Epoch  56: Train Loss = 0.000182, Val Loss = 0.000749
2026-01-02 19:09:31,762 - Epoch  57: Train Loss = 0.000160, Val Loss = 0.000397
2026-01-02 19:09:32,992 - Epoch  58: Train Loss = 0.000167, Val Loss = 0.000434
2026-01-02 19:09:34,134 - Epoch  59: Train Loss = 0.000148, Val Loss = 0.000632
2026-01-02 19:09:35,317 - Epoch  60: Train Loss = 0.000162, Val Loss = 0.000584
2026-01-02 19:09:36,516 - Epoch  61: Train Loss = 0.000168, Val Loss = 0.000526
2026-01-02 19:09:37,661 - Epoch  62: Train Loss = 0.000220, Val Loss = 0.000307
2026-01-02 19:09:38,803 - Epoch  63: Train Loss = 0.000202, Val Loss = 0.000650
2026-01-02 19:09:39,948 - Epoch  64: Train Loss = 0.000167, Val Loss = 0.000409
2026-01-02 19:09:41,085 - Epoch  65: Train Loss = 0.000154, Val Loss = 0.000540
2026-01-02 19:09:42,219 - Epoch  66: Train Loss = 0.000162, Val Loss = 0.000549
2026-01-02 19:09:43,407 - Epoch  67: Train Loss = 0.000132, Val Loss = 0.000519
2026-01-02 19:09:44,609 - Epoch  68: Train Loss = 0.000187, Val Loss = 0.000425
2026-01-02 19:09:45,777 - Epoch  69: Train Loss = 0.000153, Val Loss = 0.000552
2026-01-02 19:09:46,909 - Epoch  70: Train Loss = 0.000157, Val Loss = 0.000710
2026-01-02 19:09:48,059 - Epoch  71: Train Loss = 0.000212, Val Loss = 0.000734
2026-01-02 19:09:49,247 - Epoch  72: Train Loss = 0.000192, Val Loss = 0.000882
2026-01-02 19:09:50,435 - Epoch  73: Train Loss = 0.000190, Val Loss = 0.000709
2026-01-02 19:09:51,602 - Epoch  74: Train Loss = 0.000200, Val Loss = 0.000855
2026-01-02 19:09:52,732 - Epoch  75: Train Loss = 0.000255, Val Loss = 0.000708
2026-01-02 19:09:53,946 - Epoch  76: Train Loss = 0.000164, Val Loss = 0.000654
2026-01-02 19:09:55,230 - Epoch  77: Train Loss = 0.000164, Val Loss = 0.000656
2026-01-02 19:09:56,469 - Epoch  78: Train Loss = 0.000176, Val Loss = 0.000665
2026-01-02 19:09:57,748 - Epoch  79: Train Loss = 0.000159, Val Loss = 0.000868
2026-01-02 19:09:58,939 - Epoch  80: Train Loss = 0.000138, Val Loss = 0.000800
2026-01-02 19:09:58,939 - Early stopping at epoch 80
2026-01-02 19:09:58,943 - Restored best model weights
2026-01-02 19:09:58,943 - 
============================================================
2026-01-02 19:09:58,943 - EVALUATION RESULTS
2026-01-02 19:09:58,943 - ============================================================
2026-01-02 19:09:58,987 - Validation: MSE=0.000346, MAE=0.015575, RMSE=0.018598, Corr=0.404940
2026-01-02 19:09:59,033 - Test:       MSE=0.000299, MAE=0.014537, RMSE=0.017277, Corr=0.844469
2026-01-02 19:09:59,033 - 
Saving model and results...
2026-01-02 19:09:59,242 - Saved weights to: logs/models/best_weights.h5
2026-01-02 19:09:59,242 - Saved scaler to: logs/models/scaler.pkl
2026-01-02 19:09:59,242 - Saved predictions to: logs/models/predictions.npy
2026-01-02 19:09:59,243 - 
2026-01-02 19:09:59,243 - ======================================================================
2026-01-02 19:09:59,243 - PIPELINE COMPLETED SUCCESSFULLY
2026-01-02 19:09:59,243 - ======================================================================
2026-01-02 19:09:59,243 - End time: 2026-01-02 19:09:59
2026-01-02 19:09:59,243 - Duration: 0:01:40.396621
2026-01-02 19:09:59,243 - 
2026-01-02 19:09:59,243 - Output files:
2026-01-02 19:09:59,243 -   - Preprocessed data: processed/
2026-01-02 19:09:59,243 -   - Model and results: logs/models/
2026-01-02 19:09:59,243 -   - Log file: logs/pipeline_20260102_190818.log
