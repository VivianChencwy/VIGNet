2025-12-28 23:17:14,001 - ======================================================================
2025-12-28 23:17:14,001 - WEIYU DATA PROCESSING AND MODELING PIPELINE
2025-12-28 23:17:14,001 - ======================================================================
2025-12-28 23:17:14,001 - Start time: 2025-12-28 23:17:14
2025-12-28 23:17:14,001 - Log file: logs/pipeline_20251228_231714.log
2025-12-28 23:17:14,001 - 
2025-12-28 23:17:14,001 - ============================================================
2025-12-28 23:17:14,001 - STEP 1: Loading and Trimming Data
2025-12-28 23:17:14,001 - ============================================================
2025-12-28 23:17:14,001 - Loading data from: merged_data.csv
2025-12-28 23:17:15,429 - Loaded 1104038 samples
2025-12-28 23:17:15,429 - Original duration: 2212.86s (36.88 min)
2025-12-28 23:17:15,435 - Original sampling rate: 967.12 Hz
2025-12-28 23:17:15,435 - Trimming: first 300.0s, last 0.0s
2025-12-28 23:17:15,536 - After trimming: 1912.86s (31.88 min)
2025-12-28 23:17:15,536 - Samples after trimming: 954348
2025-12-28 23:17:15,538 - ============================================================
2025-12-28 23:17:15,538 - STEP 2: Resampling
2025-12-28 23:17:15,538 - ============================================================
2025-12-28 23:17:15,538 - Resampling from 967.12 Hz to 200 Hz
2025-12-28 23:17:15,538 - Samples: 954348 -> 197359
2025-12-28 23:17:15,734 - ============================================================
2025-12-28 23:17:15,734 - STEP 3: Segmentation
2025-12-28 23:17:15,734 - ============================================================
2025-12-28 23:17:15,735 - Created 245 windows
2025-12-28 23:17:15,735 - Window shape: 1600 samples x 2 channels
2025-12-28 23:17:15,735 - ============================================================
2025-12-28 23:17:15,735 - STEP 4: Extracting DE Features
2025-12-28 23:17:15,735 - ============================================================
2025-12-28 23:17:15,735 - Extracting DE for 245 windows, 2 channels, 25 bands
2025-12-28 23:17:16,402 -   Processing window 100/245
2025-12-28 23:17:17,076 -   Processing window 200/245
2025-12-28 23:17:17,378 -   Processing window 245/245
2025-12-28 23:17:17,385 - DE features shape: (2, 245, 25)
2025-12-28 23:17:17,385 - ============================================================
2025-12-28 23:17:17,385 - STEP 5: Applying Smoothing
2025-12-28 23:17:17,385 - ============================================================
2025-12-28 23:17:17,385 - Applying moving average (window=5)...
2025-12-28 23:17:17,385 - Applying LDS (Kalman filter) smoothing...
2025-12-28 23:17:18,304 - Smoothing completed
2025-12-28 23:17:18,305 - ============================================================
2025-12-28 23:17:18,305 - STEP 6: Computing PERCLOS Labels
2025-12-28 23:17:18,305 - ============================================================
2025-12-28 23:17:18,496 - Unique eye states in data: ['close' 'open']
2025-12-28 23:17:18,504 - Eye closed samples: 34125.0 / 954348 (3.58%)
2025-12-28 23:17:18,504 - Computing PERCLOS with 60.0s window...
2025-12-28 23:17:18,641 - PERCLOS range: [0.0000, 0.1261]
2025-12-28 23:17:18,641 - PERCLOS mean: 0.0344, std: 0.0339
2025-12-28 23:17:18,641 - Distribution: Awake=245 (100.0%), Tired=0 (0.0%), Drowsy=0 (0.0%)
2025-12-28 23:17:18,641 - ============================================================
2025-12-28 23:17:18,641 - STEP 7: Saving Preprocessed Data
2025-12-28 23:17:18,641 - ============================================================
2025-12-28 23:17:18,642 - Saved DE features: processed/de_features.npy
2025-12-28 23:17:18,642 -   Shape: (245, 2, 25)
2025-12-28 23:17:18,642 - Saved PERCLOS labels: processed/perclos_labels.npy
2025-12-28 23:17:18,642 - Saved timestamps: processed/timestamps.npy
2025-12-28 23:17:18,642 - Saved metadata: processed/metadata.npy
2025-12-28 23:17:18,642 - ============================================================
2025-12-28 23:17:18,642 - STEP 8: Data Splitting (Block-wise Random)
2025-12-28 23:17:18,642 - ============================================================
2025-12-28 23:17:18,642 - Created 24 blocks (block_size=8, gap=2)
2025-12-28 23:17:18,642 - Split results:
2025-12-28 23:17:18,642 -   Train: 128 samples (66.7%)
2025-12-28 23:17:18,642 -   Valid: 24 samples (12.5%)
2025-12-28 23:17:18,642 -   Test:  40 samples (20.8%)
2025-12-28 23:17:18,642 -   Discarded (gaps): 53 samples
2025-12-28 23:17:18,642 - ============================================================
2025-12-28 23:17:18,642 - STEP 9-10: Model Training
2025-12-28 23:17:18,642 - ============================================================
2025-12-28 23:17:18,676 - Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
2025-12-28 23:17:18,676 - Train: (128, 2, 25), Val: (24, 2, 25), Test: (40, 2, 25)
2025-12-28 23:17:18,676 - Applied StandardScaler normalization
2025-12-28 23:17:19,003 - Learning rate: 0.005
2025-12-28 23:17:19,003 - Max epochs: 500
2025-12-28 23:17:19,003 - Batch size: 8
2025-12-28 23:17:19,003 - Early stopping patience: 50
2025-12-28 23:17:20,826 - Epoch   1: Train Loss = 0.003616, Val Loss = 0.000527
2025-12-28 23:17:20,827 -   -> New best validation loss: 0.000527
2025-12-28 23:17:22,139 - Epoch   2: Train Loss = 0.001437, Val Loss = 0.000787
2025-12-28 23:17:23,285 - Epoch   3: Train Loss = 0.001213, Val Loss = 0.000376
2025-12-28 23:17:23,286 -   -> New best validation loss: 0.000376
2025-12-28 23:17:24,517 - Epoch   4: Train Loss = 0.000768, Val Loss = 0.000375
2025-12-28 23:17:24,518 -   -> New best validation loss: 0.000375
2025-12-28 23:17:25,693 - Epoch   5: Train Loss = 0.000509, Val Loss = 0.000362
2025-12-28 23:17:25,694 -   -> New best validation loss: 0.000362
2025-12-28 23:17:26,840 - Epoch   6: Train Loss = 0.000560, Val Loss = 0.000381
2025-12-28 23:17:27,977 - Epoch   7: Train Loss = 0.000465, Val Loss = 0.000390
2025-12-28 23:17:29,155 - Epoch   8: Train Loss = 0.000472, Val Loss = 0.000371
2025-12-28 23:17:30,270 - Epoch   9: Train Loss = 0.000352, Val Loss = 0.000352
2025-12-28 23:17:30,271 -   -> New best validation loss: 0.000352
2025-12-28 23:17:31,410 - Epoch  10: Train Loss = 0.000468, Val Loss = 0.000346
2025-12-28 23:17:31,411 -   -> New best validation loss: 0.000346
2025-12-28 23:17:32,529 - Epoch  11: Train Loss = 0.000418, Val Loss = 0.000513
2025-12-28 23:17:33,672 - Epoch  12: Train Loss = 0.000453, Val Loss = 0.000355
2025-12-28 23:17:34,900 - Epoch  13: Train Loss = 0.000325, Val Loss = 0.000560
2025-12-28 23:17:36,035 - Epoch  14: Train Loss = 0.000455, Val Loss = 0.000473
2025-12-28 23:17:37,209 - Epoch  15: Train Loss = 0.000257, Val Loss = 0.000352
2025-12-28 23:17:38,356 - Epoch  16: Train Loss = 0.000275, Val Loss = 0.000352
2025-12-28 23:17:39,503 - Epoch  17: Train Loss = 0.000259, Val Loss = 0.000381
2025-12-28 23:17:40,664 - Epoch  18: Train Loss = 0.000261, Val Loss = 0.000384
2025-12-28 23:17:41,855 - Epoch  19: Train Loss = 0.000246, Val Loss = 0.000344
2025-12-28 23:17:41,856 -   -> New best validation loss: 0.000344
2025-12-28 23:17:43,023 - Epoch  20: Train Loss = 0.000243, Val Loss = 0.000530
2025-12-28 23:17:44,427 - Epoch  21: Train Loss = 0.000246, Val Loss = 0.000514
2025-12-28 23:17:45,647 - Epoch  22: Train Loss = 0.000322, Val Loss = 0.000312
2025-12-28 23:17:45,648 -   -> New best validation loss: 0.000312
2025-12-28 23:17:46,896 - Epoch  23: Train Loss = 0.000275, Val Loss = 0.000306
2025-12-28 23:17:46,897 -   -> New best validation loss: 0.000306
2025-12-28 23:17:48,045 - Epoch  24: Train Loss = 0.000330, Val Loss = 0.000310
2025-12-28 23:17:49,177 - Epoch  25: Train Loss = 0.000312, Val Loss = 0.000283
2025-12-28 23:17:49,178 -   -> New best validation loss: 0.000283
2025-12-28 23:17:50,326 - Epoch  26: Train Loss = 0.000356, Val Loss = 0.000570
2025-12-28 23:17:51,479 - Epoch  27: Train Loss = 0.000284, Val Loss = 0.000812
2025-12-28 23:17:52,638 - Epoch  28: Train Loss = 0.000295, Val Loss = 0.000505
2025-12-28 23:17:53,776 - Epoch  29: Train Loss = 0.000176, Val Loss = 0.000404
2025-12-28 23:17:54,901 - Epoch  30: Train Loss = 0.000253, Val Loss = 0.000370
2025-12-28 23:17:56,032 - Epoch  31: Train Loss = 0.000234, Val Loss = 0.000284
2025-12-28 23:17:57,165 - Epoch  32: Train Loss = 0.000208, Val Loss = 0.000399
2025-12-28 23:17:58,382 - Epoch  33: Train Loss = 0.000201, Val Loss = 0.000388
2025-12-28 23:17:59,522 - Epoch  34: Train Loss = 0.000380, Val Loss = 0.000327
2025-12-28 23:18:00,713 - Epoch  35: Train Loss = 0.000280, Val Loss = 0.000422
2025-12-28 23:18:01,888 - Epoch  36: Train Loss = 0.000187, Val Loss = 0.000630
2025-12-28 23:18:03,083 - Epoch  37: Train Loss = 0.000221, Val Loss = 0.000421
2025-12-28 23:18:04,233 - Epoch  38: Train Loss = 0.000247, Val Loss = 0.000481
2025-12-28 23:18:05,420 - Epoch  39: Train Loss = 0.000214, Val Loss = 0.000659
2025-12-28 23:18:06,636 - Epoch  40: Train Loss = 0.000211, Val Loss = 0.000599
2025-12-28 23:18:07,920 - Epoch  41: Train Loss = 0.000250, Val Loss = 0.000560
2025-12-28 23:18:09,085 - Epoch  42: Train Loss = 0.000275, Val Loss = 0.000940
2025-12-28 23:18:10,292 - Epoch  43: Train Loss = 0.000213, Val Loss = 0.000764
2025-12-28 23:18:11,435 - Epoch  44: Train Loss = 0.000177, Val Loss = 0.000870
2025-12-28 23:18:12,618 - Epoch  45: Train Loss = 0.000201, Val Loss = 0.000617
2025-12-28 23:18:13,793 - Epoch  46: Train Loss = 0.000178, Val Loss = 0.000685
2025-12-28 23:18:14,987 - Epoch  47: Train Loss = 0.000238, Val Loss = 0.000414
2025-12-28 23:18:16,222 - Epoch  48: Train Loss = 0.000180, Val Loss = 0.000530
2025-12-28 23:18:17,381 - Epoch  49: Train Loss = 0.000207, Val Loss = 0.000757
2025-12-28 23:18:18,507 - Epoch  50: Train Loss = 0.000195, Val Loss = 0.000749
2025-12-28 23:18:19,760 - Epoch  51: Train Loss = 0.000227, Val Loss = 0.000858
2025-12-28 23:18:21,066 - Epoch  52: Train Loss = 0.000226, Val Loss = 0.000814
2025-12-28 23:18:22,266 - Epoch  53: Train Loss = 0.000214, Val Loss = 0.000678
2025-12-28 23:18:23,474 - Epoch  54: Train Loss = 0.000245, Val Loss = 0.000737
2025-12-28 23:18:24,627 - Epoch  55: Train Loss = 0.000189, Val Loss = 0.000492
2025-12-28 23:18:25,779 - Epoch  56: Train Loss = 0.000149, Val Loss = 0.000587
2025-12-28 23:18:26,970 - Epoch  57: Train Loss = 0.000191, Val Loss = 0.000649
2025-12-28 23:18:28,232 - Epoch  58: Train Loss = 0.000193, Val Loss = 0.000964
2025-12-28 23:18:29,457 - Epoch  59: Train Loss = 0.000183, Val Loss = 0.000679
2025-12-28 23:18:30,593 - Epoch  60: Train Loss = 0.000164, Val Loss = 0.000802
2025-12-28 23:18:31,747 - Epoch  61: Train Loss = 0.000189, Val Loss = 0.000814
2025-12-28 23:18:33,019 - Epoch  62: Train Loss = 0.000237, Val Loss = 0.000429
2025-12-28 23:18:34,179 - Epoch  63: Train Loss = 0.000205, Val Loss = 0.000838
2025-12-28 23:18:35,362 - Epoch  64: Train Loss = 0.000183, Val Loss = 0.000513
2025-12-28 23:18:36,511 - Epoch  65: Train Loss = 0.000163, Val Loss = 0.000621
2025-12-28 23:18:37,655 - Epoch  66: Train Loss = 0.000151, Val Loss = 0.000411
2025-12-28 23:18:38,848 - Epoch  67: Train Loss = 0.000173, Val Loss = 0.000467
2025-12-28 23:18:40,136 - Epoch  68: Train Loss = 0.000195, Val Loss = 0.000821
2025-12-28 23:18:41,305 - Epoch  69: Train Loss = 0.000143, Val Loss = 0.000577
2025-12-28 23:18:42,492 - Epoch  70: Train Loss = 0.000156, Val Loss = 0.000519
2025-12-28 23:18:43,714 - Epoch  71: Train Loss = 0.000214, Val Loss = 0.000822
2025-12-28 23:18:44,884 - Epoch  72: Train Loss = 0.000177, Val Loss = 0.000649
2025-12-28 23:18:46,045 - Epoch  73: Train Loss = 0.000208, Val Loss = 0.000639
2025-12-28 23:18:47,209 - Epoch  74: Train Loss = 0.000237, Val Loss = 0.000800
2025-12-28 23:18:48,353 - Epoch  75: Train Loss = 0.000228, Val Loss = 0.000542
2025-12-28 23:18:48,353 - Early stopping at epoch 75
2025-12-28 23:18:48,357 - Restored best model weights
2025-12-28 23:18:48,357 - 
============================================================
2025-12-28 23:18:48,357 - EVALUATION RESULTS
2025-12-28 23:18:48,357 - ============================================================
2025-12-28 23:18:48,420 - Validation: MSE=0.000279, MAE=0.014080, RMSE=0.016701, Corr=0.511869
2025-12-28 23:18:48,473 - Test:       MSE=0.000379, MAE=0.014089, RMSE=0.019459, Corr=0.885421
2025-12-28 23:18:48,473 - 
Saving model and results...
2025-12-28 23:18:48,698 - Saved weights to: logs/models/best_weights.h5
2025-12-28 23:18:48,698 - Saved scaler to: logs/models/scaler.pkl
2025-12-28 23:18:48,698 - Saved predictions to: logs/models/predictions.npy
2025-12-28 23:18:48,698 - 
2025-12-28 23:18:48,698 - ======================================================================
2025-12-28 23:18:48,698 - PIPELINE COMPLETED SUCCESSFULLY
2025-12-28 23:18:48,698 - ======================================================================
2025-12-28 23:18:48,698 - End time: 2025-12-28 23:18:48
2025-12-28 23:18:48,698 - Duration: 0:01:34.697712
2025-12-28 23:18:48,698 - 
2025-12-28 23:18:48,698 - Output files:
2025-12-28 23:18:48,698 -   - Preprocessed data: processed/
2025-12-28 23:18:48,698 -   - Model and results: logs/models/
2025-12-28 23:18:48,698 -   - Log file: logs/pipeline_20251228_231714.log
