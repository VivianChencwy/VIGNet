2025-11-17 10:42:18,162 - INFO - ================================================================================
2025-11-17 10:42:18,162 - INFO - TRIAL 5 - Task: RGS (FP1/FP2 only, no CV)
2025-11-17 10:42:18,162 - INFO - Log file: ./logs_fp_no_cv/trial5_RGS_20251117_093635.log
2025-11-17 10:42:18,162 - INFO - Start time: 2025-11-17 10:42:18
2025-11-17 10:42:18,162 - INFO - ================================================================================
2025-11-17 10:42:18,164 - INFO - START TRAINING - Task: RGS (FP1/FP2 only, no CV)
2025-11-17 10:42:18,164 - INFO - Learning rate: 0.005, Epochs: 200, Batches: 8
2025-11-17 10:42:18,164 - INFO - Data split: 70% train / 15% validation / 15% test
2025-11-17 10:42:18,164 - INFO - Loading dataset (FP1/FP2 channels only, fixed split)...
2025-11-17 10:42:18,176 - INFO - Dataset shapes - Train: (617, 2, 25, 1), Valid: (130, 2, 25, 1), Test: (138, 2, 25, 1)
2025-11-17 10:42:18,177 - INFO - Applied feature normalization (StandardScaler)
2025-11-17 10:42:18,177 - INFO - Initializing VIGNet-FP model (2 channels)...
2025-11-17 10:42:18,182 - INFO - Number of batch iterations per epoch: 77
2025-11-17 10:42:24,468 - INFO - Epoch: 1, Training Loss: 0.0749, Validation Loss: 0.0361
2025-11-17 10:42:24,471 - INFO -   → New best validation loss: 0.0361
2025-11-17 10:42:31,636 - INFO - Epoch: 2, Training Loss: 0.0303, Validation Loss: 0.0326
2025-11-17 10:42:31,637 - INFO -   → New best validation loss: 0.0326
2025-11-17 10:42:40,186 - INFO - Epoch: 3, Training Loss: 0.0258, Validation Loss: 0.0275
2025-11-17 10:42:40,187 - INFO -   → New best validation loss: 0.0275
2025-11-17 10:42:49,828 - INFO - Epoch: 4, Training Loss: 0.0264, Validation Loss: 0.0345
2025-11-17 10:42:58,061 - INFO - Epoch: 5, Training Loss: 0.0244, Validation Loss: 0.0267
2025-11-17 10:42:58,062 - INFO -   → New best validation loss: 0.0267
2025-11-17 10:43:07,781 - INFO - Epoch: 6, Training Loss: 0.0234, Validation Loss: 0.0326
2025-11-17 10:43:16,575 - INFO - Epoch: 7, Training Loss: 0.0237, Validation Loss: 0.0271
2025-11-17 10:43:26,786 - INFO - Epoch: 8, Training Loss: 0.0234, Validation Loss: 0.0223
2025-11-17 10:43:26,787 - INFO -   → New best validation loss: 0.0223
2025-11-17 10:43:34,513 - INFO - Epoch: 9, Training Loss: 0.0200, Validation Loss: 0.0205
2025-11-17 10:43:34,514 - INFO -   → New best validation loss: 0.0205
2025-11-17 10:43:40,954 - INFO - Epoch: 10, Training Loss: 0.0200, Validation Loss: 0.0214
2025-11-17 10:43:52,522 - INFO - Epoch: 11, Training Loss: 0.0188, Validation Loss: 0.0192
2025-11-17 10:43:52,523 - INFO -   → New best validation loss: 0.0192
2025-11-17 10:44:01,964 - INFO - Epoch: 12, Training Loss: 0.0189, Validation Loss: 0.0190
2025-11-17 10:44:01,967 - INFO -   → New best validation loss: 0.0190
2025-11-17 10:44:11,328 - INFO - Epoch: 13, Training Loss: 0.0222, Validation Loss: 0.0226
2025-11-17 10:44:18,718 - INFO - Epoch: 14, Training Loss: 0.0183, Validation Loss: 0.0189
2025-11-17 10:44:18,719 - INFO -   → New best validation loss: 0.0189
2025-11-17 10:44:27,233 - INFO - Epoch: 15, Training Loss: 0.0178, Validation Loss: 0.0208
2025-11-17 10:44:34,985 - INFO - Epoch: 16, Training Loss: 0.0180, Validation Loss: 0.0186
2025-11-17 10:44:34,986 - INFO -   → New best validation loss: 0.0186
2025-11-17 10:44:44,345 - INFO - Epoch: 17, Training Loss: 0.0168, Validation Loss: 0.0223
2025-11-17 10:44:54,354 - INFO - Epoch: 18, Training Loss: 0.0169, Validation Loss: 0.0201
2025-11-17 10:45:01,632 - INFO - Epoch: 19, Training Loss: 0.0187, Validation Loss: 0.0203
2025-11-17 10:45:08,765 - INFO - Epoch: 20, Training Loss: 0.0165, Validation Loss: 0.0203
2025-11-17 10:45:15,880 - INFO - Epoch: 21, Training Loss: 0.0172, Validation Loss: 0.0185
2025-11-17 10:45:15,886 - INFO -   → New best validation loss: 0.0185
2025-11-17 10:45:24,391 - INFO - Epoch: 22, Training Loss: 0.0162, Validation Loss: 0.0198
2025-11-17 10:45:33,791 - INFO - Epoch: 23, Training Loss: 0.0164, Validation Loss: 0.0169
2025-11-17 10:45:33,791 - INFO -   → New best validation loss: 0.0169
2025-11-17 10:45:40,717 - INFO - Epoch: 24, Training Loss: 0.0148, Validation Loss: 0.0174
2025-11-17 10:45:50,733 - INFO - Epoch: 25, Training Loss: 0.0153, Validation Loss: 0.0150
2025-11-17 10:45:50,734 - INFO -   → New best validation loss: 0.0150
2025-11-17 10:45:58,683 - INFO - Epoch: 26, Training Loss: 0.0146, Validation Loss: 0.0161
2025-11-17 10:46:06,476 - INFO - Epoch: 27, Training Loss: 0.0139, Validation Loss: 0.0172
2025-11-17 10:46:15,074 - INFO - Epoch: 28, Training Loss: 0.0149, Validation Loss: 0.0164
2025-11-17 10:46:24,794 - INFO - Epoch: 29, Training Loss: 0.0128, Validation Loss: 0.0249
2025-11-17 10:46:37,029 - INFO - Epoch: 30, Training Loss: 0.0130, Validation Loss: 0.0143
2025-11-17 10:46:37,030 - INFO -   → New best validation loss: 0.0143
2025-11-17 10:46:47,794 - INFO - Epoch: 31, Training Loss: 0.0115, Validation Loss: 0.0136
2025-11-17 10:46:47,797 - INFO -   → New best validation loss: 0.0136
2025-11-17 10:46:56,496 - INFO - Epoch: 32, Training Loss: 0.0110, Validation Loss: 0.0145
2025-11-17 10:47:05,692 - INFO - Epoch: 33, Training Loss: 0.0111, Validation Loss: 0.0130
2025-11-17 10:47:05,693 - INFO -   → New best validation loss: 0.0130
2025-11-17 10:47:17,039 - INFO - Epoch: 34, Training Loss: 0.0099, Validation Loss: 0.0131
2025-11-17 10:47:27,946 - INFO - Epoch: 35, Training Loss: 0.0104, Validation Loss: 0.0092
2025-11-17 10:47:27,948 - INFO -   → New best validation loss: 0.0092
2025-11-17 10:47:37,801 - INFO - Epoch: 36, Training Loss: 0.0093, Validation Loss: 0.0110
2025-11-17 10:47:45,300 - INFO - Epoch: 37, Training Loss: 0.0088, Validation Loss: 0.0151
2025-11-17 10:47:51,456 - INFO - Epoch: 38, Training Loss: 0.0087, Validation Loss: 0.0103
2025-11-17 10:48:00,149 - INFO - Epoch: 39, Training Loss: 0.0099, Validation Loss: 0.0094
2025-11-17 10:48:10,152 - INFO - Epoch: 40, Training Loss: 0.0081, Validation Loss: 0.0126
2025-11-17 10:48:20,466 - INFO - Epoch: 41, Training Loss: 0.0085, Validation Loss: 0.0102
2025-11-17 10:48:30,590 - INFO - Epoch: 42, Training Loss: 0.0086, Validation Loss: 0.0080
2025-11-17 10:48:30,591 - INFO -   → New best validation loss: 0.0080
2025-11-17 10:48:37,168 - INFO - Epoch: 43, Training Loss: 0.0074, Validation Loss: 0.0094
2025-11-17 10:48:45,080 - INFO - Epoch: 44, Training Loss: 0.0073, Validation Loss: 0.0083
2025-11-17 10:48:53,406 - INFO - Epoch: 45, Training Loss: 0.0076, Validation Loss: 0.0105
2025-11-17 10:49:04,003 - INFO - Epoch: 46, Training Loss: 0.0077, Validation Loss: 0.0089
2025-11-17 10:49:13,311 - INFO - Epoch: 47, Training Loss: 0.0066, Validation Loss: 0.0074
2025-11-17 10:49:13,317 - INFO -   → New best validation loss: 0.0074
2025-11-17 10:49:21,262 - INFO - Epoch: 48, Training Loss: 0.0070, Validation Loss: 0.0085
2025-11-17 10:49:31,076 - INFO - Epoch: 49, Training Loss: 0.0063, Validation Loss: 0.0098
2025-11-17 10:49:38,042 - INFO - Epoch: 50, Training Loss: 0.0060, Validation Loss: 0.0073
2025-11-17 10:49:38,043 - INFO -   → New best validation loss: 0.0073
2025-11-17 10:49:44,507 - INFO - Epoch: 51, Training Loss: 0.0068, Validation Loss: 0.0090
2025-11-17 10:49:54,760 - INFO - Epoch: 52, Training Loss: 0.0064, Validation Loss: 0.0089
2025-11-17 10:50:01,727 - INFO - Epoch: 53, Training Loss: 0.0060, Validation Loss: 0.0089
2025-11-17 10:50:10,265 - INFO - Epoch: 54, Training Loss: 0.0081, Validation Loss: 0.0103
2025-11-17 10:50:20,546 - INFO - Epoch: 55, Training Loss: 0.0061, Validation Loss: 0.0062
2025-11-17 10:50:20,549 - INFO -   → New best validation loss: 0.0062
2025-11-17 10:50:29,563 - INFO - Epoch: 56, Training Loss: 0.0062, Validation Loss: 0.0097
2025-11-17 10:50:39,687 - INFO - Epoch: 57, Training Loss: 0.0064, Validation Loss: 0.0081
2025-11-17 10:50:50,975 - INFO - Epoch: 58, Training Loss: 0.0062, Validation Loss: 0.0114
2025-11-17 10:51:00,217 - INFO - Epoch: 59, Training Loss: 0.0062, Validation Loss: 0.0083
2025-11-17 10:51:10,198 - INFO - Epoch: 60, Training Loss: 0.0069, Validation Loss: 0.0093
2025-11-17 10:51:21,849 - INFO - Epoch: 61, Training Loss: 0.0056, Validation Loss: 0.0082
2025-11-17 10:51:30,622 - INFO - Epoch: 62, Training Loss: 0.0062, Validation Loss: 0.0078
2025-11-17 10:51:39,920 - INFO - Epoch: 63, Training Loss: 0.0059, Validation Loss: 0.0084
2025-11-17 10:51:47,490 - INFO - Epoch: 64, Training Loss: 0.0055, Validation Loss: 0.0062
2025-11-17 10:51:47,492 - INFO -   → New best validation loss: 0.0062
2025-11-17 10:51:55,257 - INFO - Epoch: 65, Training Loss: 0.0052, Validation Loss: 0.0076
2025-11-17 10:52:03,974 - INFO - Epoch: 66, Training Loss: 0.0054, Validation Loss: 0.0065
2025-11-17 10:52:13,500 - INFO - Epoch: 67, Training Loss: 0.0056, Validation Loss: 0.0084
2025-11-17 10:52:22,006 - INFO - Epoch: 68, Training Loss: 0.0060, Validation Loss: 0.0093
2025-11-17 10:52:30,452 - INFO - Epoch: 69, Training Loss: 0.0054, Validation Loss: 0.0101
2025-11-17 10:52:38,478 - INFO - Epoch: 70, Training Loss: 0.0060, Validation Loss: 0.0072
2025-11-17 10:52:52,157 - INFO - Epoch: 71, Training Loss: 0.0062, Validation Loss: 0.0076
2025-11-17 10:53:02,690 - INFO - Epoch: 72, Training Loss: 0.0056, Validation Loss: 0.0078
2025-11-17 10:53:11,034 - INFO - Epoch: 73, Training Loss: 0.0066, Validation Loss: 0.0068
2025-11-17 10:53:18,758 - INFO - Epoch: 74, Training Loss: 0.0061, Validation Loss: 0.0076
2025-11-17 10:53:26,820 - INFO - Epoch: 75, Training Loss: 0.0060, Validation Loss: 0.0064
2025-11-17 10:53:36,937 - INFO - Epoch: 76, Training Loss: 0.0049, Validation Loss: 0.0074
2025-11-17 10:53:45,820 - INFO - Epoch: 77, Training Loss: 0.0056, Validation Loss: 0.0089
2025-11-17 10:53:52,297 - INFO - Epoch: 78, Training Loss: 0.0055, Validation Loss: 0.0069
2025-11-17 10:54:02,937 - INFO - Epoch: 79, Training Loss: 0.0045, Validation Loss: 0.0077
2025-11-17 10:54:10,701 - INFO - Epoch: 80, Training Loss: 0.0052, Validation Loss: 0.0101
2025-11-17 10:54:18,434 - INFO - Epoch: 81, Training Loss: 0.0056, Validation Loss: 0.0063
2025-11-17 10:54:27,426 - INFO - Epoch: 82, Training Loss: 0.0061, Validation Loss: 0.0061
2025-11-17 10:54:27,431 - INFO -   → New best validation loss: 0.0061
2025-11-17 10:54:37,473 - INFO - Epoch: 83, Training Loss: 0.0055, Validation Loss: 0.0060
2025-11-17 10:54:37,474 - INFO -   → New best validation loss: 0.0060
2025-11-17 10:54:43,944 - INFO - Epoch: 84, Training Loss: 0.0050, Validation Loss: 0.0070
2025-11-17 10:54:51,400 - INFO - Epoch: 85, Training Loss: 0.0044, Validation Loss: 0.0058
2025-11-17 10:54:51,401 - INFO -   → New best validation loss: 0.0058
2025-11-17 10:54:59,949 - INFO - Epoch: 86, Training Loss: 0.0047, Validation Loss: 0.0069
2025-11-17 10:55:10,378 - INFO - Epoch: 87, Training Loss: 0.0058, Validation Loss: 0.0065
2025-11-17 10:55:17,174 - INFO - Epoch: 88, Training Loss: 0.0054, Validation Loss: 0.0077
2025-11-17 10:55:25,899 - INFO - Epoch: 89, Training Loss: 0.0046, Validation Loss: 0.0078
2025-11-17 10:55:38,200 - INFO - Epoch: 90, Training Loss: 0.0049, Validation Loss: 0.0099
2025-11-17 10:55:46,434 - INFO - Epoch: 91, Training Loss: 0.0049, Validation Loss: 0.0055
2025-11-17 10:55:46,438 - INFO -   → New best validation loss: 0.0055
2025-11-17 10:55:54,963 - INFO - Epoch: 92, Training Loss: 0.0048, Validation Loss: 0.0074
2025-11-17 10:56:03,960 - INFO - Epoch: 93, Training Loss: 0.0046, Validation Loss: 0.0060
2025-11-17 10:56:12,848 - INFO - Epoch: 94, Training Loss: 0.0045, Validation Loss: 0.0057
2025-11-17 10:56:22,723 - INFO - Epoch: 95, Training Loss: 0.0048, Validation Loss: 0.0062
2025-11-17 10:56:35,656 - INFO - Epoch: 96, Training Loss: 0.0045, Validation Loss: 0.0059
2025-11-17 10:56:43,698 - INFO - Epoch: 97, Training Loss: 0.0045, Validation Loss: 0.0071
2025-11-17 10:56:51,515 - INFO - Epoch: 98, Training Loss: 0.0050, Validation Loss: 0.0081
2025-11-17 10:56:58,538 - INFO - Epoch: 99, Training Loss: 0.0048, Validation Loss: 0.0060
2025-11-17 10:57:07,267 - INFO - Epoch: 100, Training Loss: 0.0043, Validation Loss: 0.0068
2025-11-17 10:57:18,491 - INFO - Epoch: 101, Training Loss: 0.0051, Validation Loss: 0.0063
2025-11-17 10:57:28,915 - INFO - Epoch: 102, Training Loss: 0.0045, Validation Loss: 0.0067
2025-11-17 10:57:37,963 - INFO - Epoch: 103, Training Loss: 0.0061, Validation Loss: 0.0061
2025-11-17 10:57:44,134 - INFO - Epoch: 104, Training Loss: 0.0043, Validation Loss: 0.0066
2025-11-17 10:57:50,774 - INFO - Epoch: 105, Training Loss: 0.0049, Validation Loss: 0.0063
2025-11-17 10:58:00,863 - INFO - Epoch: 106, Training Loss: 0.0042, Validation Loss: 0.0075
2025-11-17 10:58:09,504 - INFO - Epoch: 107, Training Loss: 0.0047, Validation Loss: 0.0061
2025-11-17 10:58:21,930 - INFO - Epoch: 108, Training Loss: 0.0046, Validation Loss: 0.0068
2025-11-17 10:58:29,694 - INFO - Epoch: 109, Training Loss: 0.0046, Validation Loss: 0.0064
2025-11-17 10:58:39,339 - INFO - Epoch: 110, Training Loss: 0.0044, Validation Loss: 0.0056
2025-11-17 10:58:48,921 - INFO - Epoch: 111, Training Loss: 0.0042, Validation Loss: 0.0048
2025-11-17 10:58:48,923 - INFO -   → New best validation loss: 0.0048
2025-11-17 10:58:56,428 - INFO - Epoch: 112, Training Loss: 0.0039, Validation Loss: 0.0055
2025-11-17 10:59:07,169 - INFO - Epoch: 113, Training Loss: 0.0045, Validation Loss: 0.0086
2025-11-17 10:59:19,687 - INFO - Epoch: 114, Training Loss: 0.0045, Validation Loss: 0.0092
2025-11-17 10:59:28,536 - INFO - Epoch: 115, Training Loss: 0.0045, Validation Loss: 0.0055
2025-11-17 10:59:36,415 - INFO - Epoch: 116, Training Loss: 0.0043, Validation Loss: 0.0072
2025-11-17 10:59:46,347 - INFO - Epoch: 117, Training Loss: 0.0047, Validation Loss: 0.0058
2025-11-17 10:59:57,018 - INFO - Epoch: 118, Training Loss: 0.0038, Validation Loss: 0.0057
2025-11-17 11:00:06,031 - INFO - Epoch: 119, Training Loss: 0.0041, Validation Loss: 0.0061
2025-11-17 11:00:14,437 - INFO - Epoch: 120, Training Loss: 0.0041, Validation Loss: 0.0064
2025-11-17 11:00:22,862 - INFO - Epoch: 121, Training Loss: 0.0044, Validation Loss: 0.0071
2025-11-17 11:00:31,435 - INFO - Epoch: 122, Training Loss: 0.0045, Validation Loss: 0.0065
2025-11-17 11:00:41,499 - INFO - Epoch: 123, Training Loss: 0.0049, Validation Loss: 0.0064
2025-11-17 11:00:53,624 - INFO - Epoch: 124, Training Loss: 0.0045, Validation Loss: 0.0067
2025-11-17 11:01:02,526 - INFO - Epoch: 125, Training Loss: 0.0044, Validation Loss: 0.0062
2025-11-17 11:01:11,888 - INFO - Epoch: 126, Training Loss: 0.0041, Validation Loss: 0.0098
2025-11-17 11:01:20,897 - INFO - Epoch: 127, Training Loss: 0.0043, Validation Loss: 0.0060
2025-11-17 11:01:31,067 - INFO - Epoch: 128, Training Loss: 0.0046, Validation Loss: 0.0053
2025-11-17 11:01:41,013 - INFO - Epoch: 129, Training Loss: 0.0044, Validation Loss: 0.0065
2025-11-17 11:01:49,792 - INFO - Epoch: 130, Training Loss: 0.0043, Validation Loss: 0.0063
2025-11-17 11:01:58,063 - INFO - Epoch: 131, Training Loss: 0.0039, Validation Loss: 0.0064
2025-11-17 11:01:58,063 - INFO - Early stopping triggered at epoch 131
2025-11-17 11:01:58,063 - INFO - Best validation loss: 0.0048
2025-11-17 11:01:58,071 - INFO - Restored best model weights
2025-11-17 11:01:58,072 - INFO - 
============================================================
2025-11-17 11:01:58,072 - INFO - EVALUATION RESULTS
2025-11-17 11:01:58,072 - INFO - ============================================================
2025-11-17 11:01:58,228 - INFO - Validation Prediction Stats:
2025-11-17 11:01:58,229 - INFO -   Std: 0.321030, Range: 1.059087, Unique ratio: 0.7385
2025-11-17 11:01:58,230 - INFO - Validation Set - MSE: 0.004951, MAE: 0.051951, RMSE: 0.070366, Pearson Correlation: 0.977430 (p=0.000000)
2025-11-17 11:01:58,406 - INFO - Test Prediction Stats:
2025-11-17 11:01:58,406 - INFO -   Std: 0.318495, Range: 0.973017, Unique ratio: 0.7681
2025-11-17 11:01:58,408 - INFO - Test Set - MSE: 0.003965, MAE: 0.047244, RMSE: 0.062968, Pearson Correlation: 0.983379 (p=0.000000)
2025-11-17 11:01:58,408 - INFO - ============================================================

2025-11-17 11:01:58,409 - INFO - Trial completed successfully
2025-11-17 11:01:58,409 - INFO - ================================================================================
2025-11-17 11:01:58,409 - INFO - Trial 5 completed. End time: 2025-11-17 11:01:58
2025-11-17 11:01:58,409 - INFO - ================================================================================
