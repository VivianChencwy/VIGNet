2025-11-12 08:43:16,547 - INFO - Log file: ./logs/trial7_cv3_RGS_20251112_084316.log
2025-11-12 08:43:16,547 - INFO - START TRAINING TRIAL 7 CV 3 - Task: RGS
2025-11-12 08:43:16,547 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 08:43:16,547 - INFO - Loading dataset...
2025-11-12 08:43:16,730 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 08:43:16,730 - INFO - Initializing VIGNet model...
2025-11-12 08:43:16,733 - INFO - Number of batch iterations per epoch: 113
2025-11-12 08:43:25,041 - INFO - Epoch: 1, Training Loss: 1.7117
2025-11-12 08:43:33,822 - INFO - Epoch: 2, Training Loss: 0.7021
2025-11-12 08:43:41,825 - INFO - Epoch: 3, Training Loss: 0.6954
2025-11-12 08:43:49,391 - INFO - Epoch: 4, Training Loss: 0.6935
2025-11-12 08:43:57,111 - INFO - Epoch: 5, Training Loss: 0.6902
2025-11-12 08:44:05,150 - INFO - Epoch: 6, Training Loss: 0.6908
2025-11-12 08:44:13,290 - INFO - Epoch: 7, Training Loss: 0.6904
2025-11-12 08:44:21,157 - INFO - Epoch: 8, Training Loss: 0.6896
2025-11-12 08:44:28,775 - INFO - Epoch: 9, Training Loss: 0.6893
2025-11-12 08:44:37,171 - INFO - Epoch: 10, Training Loss: 0.6892
2025-11-12 08:44:44,276 - INFO - Epoch: 11, Training Loss: 0.6888
2025-11-12 08:44:51,582 - INFO - Epoch: 12, Training Loss: 0.6890
2025-11-12 08:44:59,804 - INFO - Epoch: 13, Training Loss: 0.6888
2025-11-12 08:45:07,738 - INFO - Epoch: 14, Training Loss: 0.6882
2025-11-12 08:45:15,608 - INFO - Epoch: 15, Training Loss: 0.6890
2025-11-12 08:45:24,210 - INFO - Epoch: 16, Training Loss: 0.6886
2025-11-12 08:45:32,120 - INFO - Epoch: 17, Training Loss: 0.6888
2025-11-12 08:45:40,162 - INFO - Epoch: 18, Training Loss: 0.6889
2025-11-12 08:45:47,921 - INFO - Epoch: 19, Training Loss: 0.6887
2025-11-12 08:45:56,354 - INFO - Epoch: 20, Training Loss: 0.6891
2025-11-12 08:46:03,855 - INFO - Epoch: 21, Training Loss: 0.6884
2025-11-12 08:46:12,263 - INFO - Epoch: 22, Training Loss: 0.6882
2025-11-12 08:46:19,932 - INFO - Epoch: 23, Training Loss: 0.6888
2025-11-12 08:46:27,451 - INFO - Epoch: 24, Training Loss: 0.6885
2025-11-12 08:46:35,578 - INFO - Epoch: 25, Training Loss: 0.6884
2025-11-12 08:46:43,419 - INFO - Epoch: 26, Training Loss: 0.6888
2025-11-12 08:46:50,681 - INFO - Epoch: 27, Training Loss: 0.6887
2025-11-12 08:46:58,916 - INFO - Epoch: 28, Training Loss: 0.6891
2025-11-12 08:47:06,542 - INFO - Epoch: 29, Training Loss: 0.6885
2025-11-12 08:47:13,792 - INFO - Epoch: 30, Training Loss: 0.6887
2025-11-12 08:47:21,831 - INFO - Epoch: 31, Training Loss: 0.6885
2025-11-12 08:47:29,424 - INFO - Epoch: 32, Training Loss: 0.6888
2025-11-12 08:47:37,862 - INFO - Epoch: 33, Training Loss: 0.6881
2025-11-12 08:47:46,450 - INFO - Epoch: 34, Training Loss: 0.6885
2025-11-12 08:47:54,577 - INFO - Epoch: 35, Training Loss: 0.6888
2025-11-12 08:48:02,455 - INFO - Epoch: 36, Training Loss: 0.6889
2025-11-12 08:48:10,818 - INFO - Epoch: 37, Training Loss: 0.6885
2025-11-12 08:48:18,524 - INFO - Epoch: 38, Training Loss: 0.6880
2025-11-12 08:48:26,550 - INFO - Epoch: 39, Training Loss: 0.6883
2025-11-12 08:48:34,390 - INFO - Epoch: 40, Training Loss: 0.6883
2025-11-12 08:48:42,664 - INFO - Epoch: 41, Training Loss: 0.6895
2025-11-12 08:48:50,779 - INFO - Epoch: 42, Training Loss: 0.6883
2025-11-12 08:48:59,076 - INFO - Epoch: 43, Training Loss: 0.6886
2025-11-12 08:49:07,186 - INFO - Epoch: 44, Training Loss: 0.6882
2025-11-12 08:49:15,028 - INFO - Epoch: 45, Training Loss: 0.6888
2025-11-12 08:49:22,923 - INFO - Epoch: 46, Training Loss: 0.6886
2025-11-12 08:49:30,050 - INFO - Epoch: 47, Training Loss: 0.6889
2025-11-12 08:49:38,397 - INFO - Epoch: 48, Training Loss: 0.6884
2025-11-12 08:49:46,259 - INFO - Epoch: 49, Training Loss: 0.6888
2025-11-12 08:49:53,894 - INFO - Epoch: 50, Training Loss: 0.6883
2025-11-12 08:50:01,865 - INFO - Epoch: 51, Training Loss: 0.6881
2025-11-12 08:50:09,821 - INFO - Epoch: 52, Training Loss: 0.6884
2025-11-12 08:50:17,570 - INFO - Epoch: 53, Training Loss: 0.6887
2025-11-12 08:50:25,863 - INFO - Epoch: 54, Training Loss: 0.6882
2025-11-12 08:50:33,783 - INFO - Epoch: 55, Training Loss: 0.6881
2025-11-12 08:50:41,774 - INFO - Epoch: 56, Training Loss: 0.6878
2025-11-12 08:50:50,815 - INFO - Epoch: 57, Training Loss: 0.6886
2025-11-12 08:50:58,824 - INFO - Epoch: 58, Training Loss: 0.6885
2025-11-12 08:51:06,235 - INFO - Epoch: 59, Training Loss: 0.6887
2025-11-12 08:51:14,863 - INFO - Epoch: 60, Training Loss: 0.6884
2025-11-12 08:51:24,820 - INFO - Epoch: 61, Training Loss: 0.6887
2025-11-12 08:51:32,563 - INFO - Epoch: 62, Training Loss: 0.6882
2025-11-12 08:51:40,318 - INFO - Epoch: 63, Training Loss: 0.6886
2025-11-12 08:51:48,830 - INFO - Epoch: 64, Training Loss: 0.6886
2025-11-12 08:51:57,219 - INFO - Epoch: 65, Training Loss: 0.6884
2025-11-12 08:52:05,598 - INFO - Epoch: 66, Training Loss: 0.6887
2025-11-12 08:52:13,411 - INFO - Epoch: 67, Training Loss: 0.6887
2025-11-12 08:52:21,039 - INFO - Epoch: 68, Training Loss: 0.6884
2025-11-12 08:52:28,661 - INFO - Epoch: 69, Training Loss: 0.6878
2025-11-12 08:52:36,795 - INFO - Epoch: 70, Training Loss: 0.6880
2025-11-12 08:52:44,383 - INFO - Epoch: 71, Training Loss: 0.6882
2025-11-12 08:52:52,481 - INFO - Epoch: 72, Training Loss: 0.6877
2025-11-12 08:52:59,628 - INFO - Epoch: 73, Training Loss: 0.6865
2025-11-12 08:53:07,425 - INFO - Epoch: 74, Training Loss: 0.6842
2025-11-12 08:53:15,194 - INFO - Epoch: 75, Training Loss: 0.6808
2025-11-12 08:53:22,689 - INFO - Epoch: 76, Training Loss: 0.6898
2025-11-12 08:53:30,315 - INFO - Epoch: 77, Training Loss: 0.6833
2025-11-12 08:53:37,817 - INFO - Epoch: 78, Training Loss: 0.6797
2025-11-12 08:53:45,789 - INFO - Epoch: 79, Training Loss: 0.6797
2025-11-12 08:53:53,688 - INFO - Epoch: 80, Training Loss: 0.6766
2025-11-12 08:54:01,685 - INFO - Epoch: 81, Training Loss: 0.6773
2025-11-12 08:54:09,906 - INFO - Epoch: 82, Training Loss: 0.6762
2025-11-12 08:54:17,859 - INFO - Epoch: 83, Training Loss: 0.6804
2025-11-12 08:54:25,802 - INFO - Epoch: 84, Training Loss: 0.6766
2025-11-12 08:54:34,500 - INFO - Epoch: 85, Training Loss: 0.6783
2025-11-12 08:54:42,474 - INFO - Epoch: 86, Training Loss: 0.6785
2025-11-12 08:54:50,890 - INFO - Epoch: 87, Training Loss: 0.6800
2025-11-12 08:54:58,801 - INFO - Epoch: 88, Training Loss: 0.6783
2025-11-12 08:55:06,553 - INFO - Epoch: 89, Training Loss: 0.6762
2025-11-12 08:55:14,778 - INFO - Epoch: 90, Training Loss: 0.6765
2025-11-12 08:55:22,812 - INFO - Epoch: 91, Training Loss: 0.6842
2025-11-12 08:55:30,399 - INFO - Epoch: 92, Training Loss: 0.6803
2025-11-12 08:55:38,323 - INFO - Epoch: 93, Training Loss: 0.6804
2025-11-12 08:55:46,091 - INFO - Epoch: 94, Training Loss: 0.6798
2025-11-12 08:55:53,987 - INFO - Epoch: 95, Training Loss: 0.6800
2025-11-12 08:56:01,922 - INFO - Epoch: 96, Training Loss: 0.6730
2025-11-12 08:56:09,653 - INFO - Epoch: 97, Training Loss: 0.6775
2025-11-12 08:56:17,955 - INFO - Epoch: 98, Training Loss: 0.6772
2025-11-12 08:56:25,502 - INFO - Epoch: 99, Training Loss: 0.6738
2025-11-12 08:56:33,232 - INFO - Epoch: 100, Training Loss: 0.6737
2025-11-12 08:56:33,232 - INFO - Training completed for Trial 7 CV 3

