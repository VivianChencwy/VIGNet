2025-11-13 17:32:36,151 - INFO - Log file: ./logs/trial18_cv0_RGS_20251113_173236.log
2025-11-13 17:32:36,151 - INFO - START TRAINING TRIAL 18 CV 0 - Task: RGS
2025-11-13 17:32:36,151 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 17:32:36,151 - INFO - Loading dataset...
2025-11-13 17:32:36,246 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 17:32:36,246 - INFO - Initializing VIGNet model...
2025-11-13 17:32:36,249 - INFO - Number of batch iterations per epoch: 113
2025-11-13 17:32:43,378 - INFO - Epoch: 1, Training Loss: 1.1651
2025-11-13 17:32:52,044 - INFO - Epoch: 2, Training Loss: 0.7079
2025-11-13 17:33:00,458 - INFO - Epoch: 3, Training Loss: 0.6995
2025-11-13 17:33:08,913 - INFO - Epoch: 4, Training Loss: 0.6988
2025-11-13 17:33:16,971 - INFO - Epoch: 5, Training Loss: 0.6931
2025-11-13 17:33:24,817 - INFO - Epoch: 6, Training Loss: 0.6883
2025-11-13 17:33:33,191 - INFO - Epoch: 7, Training Loss: 0.6952
2025-11-13 17:33:41,253 - INFO - Epoch: 8, Training Loss: 0.6898
2025-11-13 17:33:49,136 - INFO - Epoch: 9, Training Loss: 0.6873
2025-11-13 17:33:57,676 - INFO - Epoch: 10, Training Loss: 0.6893
2025-11-13 17:34:05,369 - INFO - Epoch: 11, Training Loss: 0.6885
2025-11-13 17:34:12,868 - INFO - Epoch: 12, Training Loss: 0.6869
2025-11-13 17:34:21,101 - INFO - Epoch: 13, Training Loss: 0.6880
2025-11-13 17:34:28,821 - INFO - Epoch: 14, Training Loss: 0.6896
2025-11-13 17:34:37,372 - INFO - Epoch: 15, Training Loss: 0.6806
2025-11-13 17:34:46,374 - INFO - Epoch: 16, Training Loss: 0.6805
2025-11-13 17:34:55,116 - INFO - Epoch: 17, Training Loss: 0.6781
2025-11-13 17:35:03,010 - INFO - Epoch: 18, Training Loss: 0.6835
2025-11-13 17:35:10,554 - INFO - Epoch: 19, Training Loss: 0.6762
2025-11-13 17:35:18,593 - INFO - Epoch: 20, Training Loss: 0.6732
2025-11-13 17:35:26,837 - INFO - Epoch: 21, Training Loss: 0.6681
2025-11-13 17:35:35,304 - INFO - Epoch: 22, Training Loss: 0.6612
2025-11-13 17:35:43,188 - INFO - Epoch: 23, Training Loss: 0.6391
2025-11-13 17:35:51,107 - INFO - Epoch: 24, Training Loss: 0.6479
2025-11-13 17:35:58,287 - INFO - Epoch: 25, Training Loss: 0.5984
2025-11-13 17:36:06,512 - INFO - Epoch: 26, Training Loss: 0.5825
2025-11-13 17:36:14,349 - INFO - Epoch: 27, Training Loss: 0.5385
2025-11-13 17:36:22,749 - INFO - Epoch: 28, Training Loss: 3.4205
2025-11-13 17:36:31,205 - INFO - Epoch: 29, Training Loss: 6.8060
2025-11-13 17:36:39,320 - INFO - Epoch: 30, Training Loss: 6.8063
2025-11-13 17:36:47,057 - INFO - Epoch: 31, Training Loss: 6.8015
2025-11-13 17:36:55,204 - INFO - Epoch: 32, Training Loss: 6.8415
2025-11-13 17:37:03,799 - INFO - Epoch: 33, Training Loss: 6.8108
2025-11-13 17:37:12,342 - INFO - Epoch: 34, Training Loss: 6.8273
2025-11-13 17:37:20,591 - INFO - Epoch: 35, Training Loss: 6.8424
2025-11-13 17:37:28,925 - INFO - Epoch: 36, Training Loss: 6.8018
2025-11-13 17:37:37,522 - INFO - Epoch: 37, Training Loss: 6.8027
2025-11-13 17:37:45,178 - INFO - Epoch: 38, Training Loss: 6.8465
2025-11-13 17:37:52,657 - INFO - Epoch: 39, Training Loss: 6.8298
2025-11-13 17:38:00,263 - INFO - Epoch: 40, Training Loss: 6.8258
2025-11-13 17:38:08,176 - INFO - Epoch: 41, Training Loss: 6.8465
2025-11-13 17:38:16,728 - INFO - Epoch: 42, Training Loss: 6.8171
2025-11-13 17:38:24,972 - INFO - Epoch: 43, Training Loss: 6.8465
2025-11-13 17:38:32,381 - INFO - Epoch: 44, Training Loss: 6.8277
2025-11-13 17:38:39,998 - INFO - Epoch: 45, Training Loss: 6.8452
2025-11-13 17:38:47,516 - INFO - Epoch: 46, Training Loss: 6.8279
2025-11-13 17:38:55,116 - INFO - Epoch: 47, Training Loss: 6.8075
2025-11-13 17:39:03,155 - INFO - Epoch: 48, Training Loss: 6.8248
2025-11-13 17:39:11,356 - INFO - Epoch: 49, Training Loss: 6.8381
2025-11-13 17:39:19,145 - INFO - Epoch: 50, Training Loss: 6.8071
2025-11-13 17:39:27,008 - INFO - Epoch: 51, Training Loss: 6.8298
2025-11-13 17:39:35,393 - INFO - Epoch: 52, Training Loss: 6.8047
2025-11-13 17:39:42,824 - INFO - Epoch: 53, Training Loss: 6.8212
2025-11-13 17:39:50,817 - INFO - Epoch: 54, Training Loss: 6.8276
2025-11-13 17:39:59,201 - INFO - Epoch: 55, Training Loss: 6.8254
2025-11-13 17:40:07,076 - INFO - Epoch: 56, Training Loss: 6.8201
2025-11-13 17:40:14,523 - INFO - Epoch: 57, Training Loss: 6.8257
2025-11-13 17:40:22,626 - INFO - Epoch: 58, Training Loss: 6.8161
2025-11-13 17:40:30,065 - INFO - Epoch: 59, Training Loss: 6.8086
2025-11-13 17:40:38,271 - INFO - Epoch: 60, Training Loss: 6.8093
2025-11-13 17:40:45,852 - INFO - Epoch: 61, Training Loss: 6.8120
2025-11-13 17:40:54,108 - INFO - Epoch: 62, Training Loss: 6.8055
2025-11-13 17:41:02,121 - INFO - Epoch: 63, Training Loss: 6.8355
2025-11-13 17:41:11,075 - INFO - Epoch: 64, Training Loss: 6.8254
2025-11-13 17:41:19,948 - INFO - Epoch: 65, Training Loss: 6.8264
2025-11-13 17:41:27,397 - INFO - Epoch: 66, Training Loss: 6.8278
2025-11-13 17:41:35,875 - INFO - Epoch: 67, Training Loss: 6.8039
2025-11-13 17:41:43,447 - INFO - Epoch: 68, Training Loss: 6.8464
2025-11-13 17:41:51,114 - INFO - Epoch: 69, Training Loss: 6.8045
2025-11-13 17:42:00,811 - INFO - Epoch: 70, Training Loss: 6.8258
2025-11-13 17:42:08,707 - INFO - Epoch: 71, Training Loss: 6.8210
2025-11-13 17:42:17,619 - INFO - Epoch: 72, Training Loss: 6.8202
2025-11-13 17:42:26,253 - INFO - Epoch: 73, Training Loss: 6.8032
2025-11-13 17:42:34,564 - INFO - Epoch: 74, Training Loss: 6.8075
2025-11-13 17:42:42,986 - INFO - Epoch: 75, Training Loss: 6.8107
2025-11-13 17:42:50,937 - INFO - Epoch: 76, Training Loss: 6.8269
2025-11-13 17:42:58,323 - INFO - Epoch: 77, Training Loss: 6.8072
2025-11-13 17:43:05,846 - INFO - Epoch: 78, Training Loss: 6.8230
2025-11-13 17:43:13,281 - INFO - Epoch: 79, Training Loss: 6.8027
2025-11-13 17:43:20,777 - INFO - Epoch: 80, Training Loss: 6.8216
2025-11-13 17:43:29,141 - INFO - Epoch: 81, Training Loss: 6.8361
2025-11-13 17:43:37,534 - INFO - Epoch: 82, Training Loss: 6.8443
2025-11-13 17:43:45,269 - INFO - Epoch: 83, Training Loss: 6.8366
2025-11-13 17:43:52,442 - INFO - Epoch: 84, Training Loss: 6.8074
2025-11-13 17:44:00,588 - INFO - Epoch: 85, Training Loss: 6.8272
2025-11-13 17:44:08,320 - INFO - Epoch: 86, Training Loss: 6.8274
2025-11-13 17:44:16,296 - INFO - Epoch: 87, Training Loss: 6.8268
2025-11-13 17:44:24,101 - INFO - Epoch: 88, Training Loss: 6.8338
2025-11-13 17:44:31,783 - INFO - Epoch: 89, Training Loss: 6.8220
2025-11-13 17:44:39,417 - INFO - Epoch: 90, Training Loss: 6.8202
2025-11-13 17:44:47,189 - INFO - Epoch: 91, Training Loss: 6.8305
2025-11-13 17:44:55,794 - INFO - Epoch: 92, Training Loss: 6.8207
2025-11-13 17:45:03,060 - INFO - Epoch: 93, Training Loss: 6.8250
2025-11-13 17:45:11,454 - INFO - Epoch: 94, Training Loss: 6.8236
2025-11-13 17:45:19,203 - INFO - Epoch: 95, Training Loss: 6.8054
2025-11-13 17:45:27,328 - INFO - Epoch: 96, Training Loss: 6.8465
2025-11-13 17:45:35,560 - INFO - Epoch: 97, Training Loss: 6.8235
2025-11-13 17:45:44,176 - INFO - Epoch: 98, Training Loss: 6.8247
2025-11-13 17:45:51,633 - INFO - Epoch: 99, Training Loss: 6.8264
2025-11-13 17:45:59,424 - INFO - Epoch: 100, Training Loss: 6.8193
2025-11-13 17:45:59,424 - INFO - Training completed for Trial 18 CV 0

