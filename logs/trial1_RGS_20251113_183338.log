2025-11-13 18:33:38,922 - INFO - ================================================================================
2025-11-13 18:33:38,922 - INFO - TRIAL 1 - Task: RGS
2025-11-13 18:33:38,922 - INFO - Log file: ./logs/trial1_RGS_20251113_183338.log
2025-11-13 18:33:38,923 - INFO - Start time: 2025-11-13 18:33:38
2025-11-13 18:33:38,923 - INFO - ================================================================================
2025-11-13 18:33:38,923 - INFO - 
--------------------------------------------------------------------------------
2025-11-13 18:33:38,923 - INFO - CV Fold 0
2025-11-13 18:33:38,923 - INFO - --------------------------------------------------------------------------------
2025-11-13 18:33:39,342 - INFO - START TRAINING CV 0 - Task: RGS
2025-11-13 18:33:39,342 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 18:33:39,342 - INFO - Loading dataset...
2025-11-13 18:33:39,432 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 18:33:39,432 - INFO - Initializing VIGNet model...
2025-11-13 18:33:39,438 - INFO - Number of batch iterations per epoch: 113
2025-11-13 18:33:47,516 - INFO - Epoch: 1, Training Loss: 1.8019
2025-11-13 18:33:54,910 - INFO - Epoch: 2, Training Loss: 0.8637
2025-11-13 18:34:02,274 - INFO - Epoch: 3, Training Loss: 0.6820
2025-11-13 18:34:09,871 - INFO - Epoch: 4, Training Loss: 0.6738
2025-11-13 18:34:17,393 - INFO - Epoch: 5, Training Loss: 0.6741
2025-11-13 18:34:24,894 - INFO - Epoch: 6, Training Loss: 0.6803
2025-11-13 18:34:32,372 - INFO - Epoch: 7, Training Loss: 0.6578
2025-11-13 18:34:39,820 - INFO - Epoch: 8, Training Loss: 0.6554
2025-11-13 18:34:47,183 - INFO - Epoch: 9, Training Loss: 0.6519
2025-11-13 18:34:54,831 - INFO - Epoch: 10, Training Loss: 0.6538
2025-11-13 18:35:02,198 - INFO - Epoch: 11, Training Loss: 0.6483
2025-11-13 18:35:09,811 - INFO - Epoch: 12, Training Loss: 0.6489
2025-11-13 18:35:17,444 - INFO - Epoch: 13, Training Loss: 0.6430
2025-11-13 18:35:25,304 - INFO - Epoch: 14, Training Loss: 0.6471
2025-11-13 18:35:32,746 - INFO - Epoch: 15, Training Loss: 0.6458
2025-11-13 18:35:40,313 - INFO - Epoch: 16, Training Loss: 0.6505
2025-11-13 18:35:47,903 - INFO - Epoch: 17, Training Loss: 0.6430
2025-11-13 18:35:55,720 - INFO - Epoch: 18, Training Loss: 0.6437
2025-11-13 18:36:03,324 - INFO - Epoch: 19, Training Loss: 0.6400
2025-11-13 18:36:11,009 - INFO - Epoch: 20, Training Loss: 0.6434
2025-11-13 18:36:18,440 - INFO - Epoch: 21, Training Loss: 0.6401
2025-11-13 18:36:25,785 - INFO - Epoch: 22, Training Loss: 0.6382
2025-11-13 18:36:33,128 - INFO - Epoch: 23, Training Loss: 0.6387
2025-11-13 18:36:40,579 - INFO - Epoch: 24, Training Loss: 0.6380
2025-11-13 18:36:48,324 - INFO - Epoch: 25, Training Loss: 0.6399
2025-11-13 18:36:55,949 - INFO - Epoch: 26, Training Loss: 0.6347
2025-11-13 18:37:03,384 - INFO - Epoch: 27, Training Loss: 0.6345
2025-11-13 18:37:10,904 - INFO - Epoch: 28, Training Loss: 0.6314
2025-11-13 18:37:18,501 - INFO - Epoch: 29, Training Loss: 0.6338
2025-11-13 18:37:27,056 - INFO - Epoch: 30, Training Loss: 0.6282
2025-11-13 18:37:34,943 - INFO - Epoch: 31, Training Loss: 0.6323
2025-11-13 18:37:43,877 - INFO - Epoch: 32, Training Loss: 0.6237
2025-11-13 18:37:52,486 - INFO - Epoch: 33, Training Loss: 0.6296
2025-11-13 18:37:59,859 - INFO - Epoch: 34, Training Loss: 0.6136
2025-11-13 18:38:07,213 - INFO - Epoch: 35, Training Loss: 0.5961
2025-11-13 18:38:14,586 - INFO - Epoch: 36, Training Loss: 0.5657
2025-11-13 18:38:22,620 - INFO - Epoch: 37, Training Loss: 0.5318
2025-11-13 18:38:30,100 - INFO - Epoch: 38, Training Loss: 0.4733
2025-11-13 18:38:37,521 - INFO - Epoch: 39, Training Loss: 0.4856
2025-11-13 18:38:46,015 - INFO - Epoch: 40, Training Loss: 0.4873
2025-11-13 18:38:54,376 - INFO - Epoch: 41, Training Loss: 0.5852
2025-11-13 18:39:02,756 - INFO - Epoch: 42, Training Loss: 0.5230
2025-11-13 18:39:10,480 - INFO - Epoch: 43, Training Loss: 0.4833
2025-11-13 18:39:18,249 - INFO - Epoch: 44, Training Loss: 0.4714
2025-11-13 18:39:26,372 - INFO - Epoch: 45, Training Loss: 0.5756
2025-11-13 18:39:34,212 - INFO - Epoch: 46, Training Loss: 0.4903
2025-11-13 18:39:42,501 - INFO - Epoch: 47, Training Loss: 0.4658
2025-11-13 18:39:49,877 - INFO - Epoch: 48, Training Loss: 0.4706
2025-11-13 18:39:57,345 - INFO - Epoch: 49, Training Loss: 0.4694
2025-11-13 18:40:05,015 - INFO - Epoch: 50, Training Loss: 0.4631
2025-11-13 18:40:12,918 - INFO - Epoch: 51, Training Loss: 0.7256
2025-11-13 18:40:20,668 - INFO - Epoch: 52, Training Loss: 0.5601
2025-11-13 18:40:28,588 - INFO - Epoch: 53, Training Loss: 0.4985
2025-11-13 18:40:36,638 - INFO - Epoch: 54, Training Loss: 0.4751
2025-11-13 18:40:44,167 - INFO - Epoch: 55, Training Loss: 0.4810
2025-11-13 18:40:52,979 - INFO - Epoch: 56, Training Loss: 0.4705
2025-11-13 18:41:00,421 - INFO - Epoch: 57, Training Loss: 0.4818
2025-11-13 18:41:08,695 - INFO - Epoch: 58, Training Loss: 0.4870
2025-11-13 18:41:17,122 - INFO - Epoch: 59, Training Loss: 0.4754
2025-11-13 18:41:24,704 - INFO - Epoch: 60, Training Loss: 0.4633
2025-11-13 18:41:32,920 - INFO - Epoch: 61, Training Loss: 0.4670
2025-11-13 18:41:40,008 - INFO - Epoch: 62, Training Loss: 0.4702
2025-11-13 18:41:47,939 - INFO - Epoch: 63, Training Loss: 0.4745
2025-11-13 18:41:56,715 - INFO - Epoch: 64, Training Loss: 0.4691
2025-11-13 18:42:04,616 - INFO - Epoch: 65, Training Loss: 0.4576
2025-11-13 18:42:12,754 - INFO - Epoch: 66, Training Loss: 0.4588
2025-11-13 18:42:19,955 - INFO - Epoch: 67, Training Loss: 0.4604
2025-11-13 18:42:28,312 - INFO - Epoch: 68, Training Loss: 0.4772
2025-11-13 18:42:36,053 - INFO - Epoch: 69, Training Loss: 0.4676
2025-11-13 18:42:43,351 - INFO - Epoch: 70, Training Loss: 0.4775
2025-11-13 18:42:50,565 - INFO - Epoch: 71, Training Loss: 0.4739
2025-11-13 18:42:58,455 - INFO - Epoch: 72, Training Loss: 0.4773
2025-11-13 18:43:06,139 - INFO - Epoch: 73, Training Loss: 0.4934
2025-11-13 18:43:14,261 - INFO - Epoch: 74, Training Loss: 0.4715
2025-11-13 18:43:21,516 - INFO - Epoch: 75, Training Loss: 0.4659
2025-11-13 18:43:29,139 - INFO - Epoch: 76, Training Loss: 0.4717
2025-11-13 18:43:37,509 - INFO - Epoch: 77, Training Loss: 0.4668
2025-11-13 18:43:45,305 - INFO - Epoch: 78, Training Loss: 0.5022
2025-11-13 18:43:53,224 - INFO - Epoch: 79, Training Loss: 0.4572
2025-11-13 18:44:01,254 - INFO - Epoch: 80, Training Loss: 0.4477
2025-11-13 18:44:09,069 - INFO - Epoch: 81, Training Loss: 0.4604
2025-11-13 18:44:17,643 - INFO - Epoch: 82, Training Loss: 0.4552
2025-11-13 18:44:25,490 - INFO - Epoch: 83, Training Loss: 0.4577
2025-11-13 18:44:33,465 - INFO - Epoch: 84, Training Loss: 0.4646
2025-11-13 18:44:41,909 - INFO - Epoch: 85, Training Loss: 0.4666
2025-11-13 18:44:49,694 - INFO - Epoch: 86, Training Loss: 0.7969
2025-11-13 18:44:57,892 - INFO - Epoch: 87, Training Loss: 0.4794
2025-11-13 18:45:06,464 - INFO - Epoch: 88, Training Loss: 0.4723
2025-11-13 18:45:14,537 - INFO - Epoch: 89, Training Loss: 0.5981
2025-11-13 18:45:22,459 - INFO - Epoch: 90, Training Loss: 0.5494
2025-11-13 18:45:30,678 - INFO - Epoch: 91, Training Loss: 0.5200
2025-11-13 18:45:38,819 - INFO - Epoch: 92, Training Loss: 0.4825
2025-11-13 18:45:47,183 - INFO - Epoch: 93, Training Loss: 0.4729
2025-11-13 18:45:55,105 - INFO - Epoch: 94, Training Loss: 0.4738
2025-11-13 18:46:04,114 - INFO - Epoch: 95, Training Loss: 0.4643
2025-11-13 18:46:12,572 - INFO - Epoch: 96, Training Loss: 0.4638
2025-11-13 18:46:20,507 - INFO - Epoch: 97, Training Loss: 0.4565
2025-11-13 18:46:28,697 - INFO - Epoch: 98, Training Loss: 0.4613
2025-11-13 18:46:37,280 - INFO - Epoch: 99, Training Loss: 0.4585
2025-11-13 18:46:45,893 - INFO - Epoch: 100, Training Loss: 0.4603
2025-11-13 18:46:45,893 - INFO - 
============================================================
2025-11-13 18:46:45,893 - INFO - EVALUATION RESULTS
2025-11-13 18:46:45,893 - INFO - ============================================================
2025-11-13 18:46:45,947 - INFO - Validation Set - MSE: 0.026856, MAE: 0.125410, RMSE: 0.163878, Pearson Correlation: 0.912557 (p=0.000000)
2025-11-13 18:46:46,002 - INFO - Test Set - MSE: 0.026233, MAE: 0.145858, RMSE: 0.161967, Pearson Correlation: 0.908119 (p=0.000000)
2025-11-13 18:46:46,002 - INFO - ============================================================

2025-11-13 18:46:46,002 - INFO - CV Fold 0 completed successfully
2025-11-13 18:46:46,002 - INFO - 
--------------------------------------------------------------------------------
2025-11-13 18:46:46,002 - INFO - CV Fold 1
2025-11-13 18:46:46,002 - INFO - --------------------------------------------------------------------------------
2025-11-13 18:46:46,003 - INFO - START TRAINING CV 1 - Task: RGS
2025-11-13 18:46:46,003 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 18:46:46,004 - INFO - Loading dataset...
2025-11-13 18:46:46,118 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 18:46:46,118 - INFO - Initializing VIGNet model...
2025-11-13 18:46:46,121 - INFO - Number of batch iterations per epoch: 113
2025-11-13 18:46:54,117 - INFO - Epoch: 1, Training Loss: 1.1153
2025-11-13 18:47:02,292 - INFO - Epoch: 2, Training Loss: 0.6546
2025-11-13 18:47:09,974 - INFO - Epoch: 3, Training Loss: 0.6495
2025-11-13 18:47:17,126 - INFO - Epoch: 4, Training Loss: 0.6469
2025-11-13 18:47:24,658 - INFO - Epoch: 5, Training Loss: 0.6488
2025-11-13 18:47:32,586 - INFO - Epoch: 6, Training Loss: 0.6429
2025-11-13 18:47:40,537 - INFO - Epoch: 7, Training Loss: 0.6429
2025-11-13 18:47:48,761 - INFO - Epoch: 8, Training Loss: 0.6466
2025-11-13 18:47:56,649 - INFO - Epoch: 9, Training Loss: 0.6408
2025-11-13 18:48:04,231 - INFO - Epoch: 10, Training Loss: 0.6431
2025-11-13 18:48:11,662 - INFO - Epoch: 11, Training Loss: 0.6401
2025-11-13 18:48:19,824 - INFO - Epoch: 12, Training Loss: 0.6395
2025-11-13 18:48:27,751 - INFO - Epoch: 13, Training Loss: 0.6367
2025-11-13 18:48:36,134 - INFO - Epoch: 14, Training Loss: 0.6385
2025-11-13 18:48:44,243 - INFO - Epoch: 15, Training Loss: 0.6414
2025-11-13 18:48:52,475 - INFO - Epoch: 16, Training Loss: 0.6401
2025-11-13 18:48:59,939 - INFO - Epoch: 17, Training Loss: 0.6351
2025-11-13 18:49:07,301 - INFO - Epoch: 18, Training Loss: 0.6311
2025-11-13 18:49:15,126 - INFO - Epoch: 19, Training Loss: 0.6319
2025-11-13 18:49:22,563 - INFO - Epoch: 20, Training Loss: 0.6220
2025-11-13 18:49:30,165 - INFO - Epoch: 21, Training Loss: 0.6235
2025-11-13 18:49:37,671 - INFO - Epoch: 22, Training Loss: 0.6241
2025-11-13 18:49:46,220 - INFO - Epoch: 23, Training Loss: 0.5968
2025-11-13 18:49:54,391 - INFO - Epoch: 24, Training Loss: 0.6149
2025-11-13 18:50:01,917 - INFO - Epoch: 25, Training Loss: 0.5621
2025-11-13 18:50:09,398 - INFO - Epoch: 26, Training Loss: 0.5496
2025-11-13 18:50:16,963 - INFO - Epoch: 27, Training Loss: 0.5314
2025-11-13 18:50:24,919 - INFO - Epoch: 28, Training Loss: 0.4877
2025-11-13 18:50:33,403 - INFO - Epoch: 29, Training Loss: 0.5196
2025-11-13 18:50:41,363 - INFO - Epoch: 30, Training Loss: 0.4898
2025-11-13 18:50:48,849 - INFO - Epoch: 31, Training Loss: 0.4967
2025-11-13 18:50:56,432 - INFO - Epoch: 32, Training Loss: 0.5152
2025-11-13 18:51:04,365 - INFO - Epoch: 33, Training Loss: 0.4943
2025-11-13 18:51:12,296 - INFO - Epoch: 34, Training Loss: 0.5074
2025-11-13 18:51:20,119 - INFO - Epoch: 35, Training Loss: 0.5247
2025-11-13 18:51:28,103 - INFO - Epoch: 36, Training Loss: 0.5178
2025-11-13 18:51:37,197 - INFO - Epoch: 37, Training Loss: 0.4824
2025-11-13 18:51:44,952 - INFO - Epoch: 38, Training Loss: 0.4868
2025-11-13 18:51:52,425 - INFO - Epoch: 39, Training Loss: 0.4980
2025-11-13 18:52:00,649 - INFO - Epoch: 40, Training Loss: 0.4842
2025-11-13 18:52:08,092 - INFO - Epoch: 41, Training Loss: 0.4654
2025-11-13 18:52:15,944 - INFO - Epoch: 42, Training Loss: 0.4932
2025-11-13 18:52:23,405 - INFO - Epoch: 43, Training Loss: 0.5016
2025-11-13 18:52:32,221 - INFO - Epoch: 44, Training Loss: 0.4968
2025-11-13 18:52:40,382 - INFO - Epoch: 45, Training Loss: 0.4972
2025-11-13 18:52:48,888 - INFO - Epoch: 46, Training Loss: 0.4966
2025-11-13 18:52:56,967 - INFO - Epoch: 47, Training Loss: 0.4850
2025-11-13 18:53:04,571 - INFO - Epoch: 48, Training Loss: 0.4867
2025-11-13 18:53:13,153 - INFO - Epoch: 49, Training Loss: 0.4807
2025-11-13 18:53:20,958 - INFO - Epoch: 50, Training Loss: 0.4922
2025-11-13 18:53:29,271 - INFO - Epoch: 51, Training Loss: 0.4888
2025-11-13 18:53:38,202 - INFO - Epoch: 52, Training Loss: 0.4863
2025-11-13 18:53:45,299 - INFO - Epoch: 53, Training Loss: 0.4821
2025-11-13 18:53:53,174 - INFO - Epoch: 54, Training Loss: 0.4849
2025-11-13 18:54:01,784 - INFO - Epoch: 55, Training Loss: 0.5014
2025-11-13 18:54:09,077 - INFO - Epoch: 56, Training Loss: 0.4918
2025-11-13 18:54:16,593 - INFO - Epoch: 57, Training Loss: 0.5033
2025-11-13 18:54:24,452 - INFO - Epoch: 58, Training Loss: 0.4723
2025-11-13 18:54:32,179 - INFO - Epoch: 59, Training Loss: 0.4846
2025-11-13 18:54:40,646 - INFO - Epoch: 60, Training Loss: 0.4817
2025-11-13 18:54:48,436 - INFO - Epoch: 61, Training Loss: 0.4662
2025-11-13 18:54:57,256 - INFO - Epoch: 62, Training Loss: 0.4904
2025-11-13 18:55:05,041 - INFO - Epoch: 63, Training Loss: 0.4811
2025-11-13 18:55:13,535 - INFO - Epoch: 64, Training Loss: 0.4791
2025-11-13 18:55:20,954 - INFO - Epoch: 65, Training Loss: 0.4797
2025-11-13 18:55:28,240 - INFO - Epoch: 66, Training Loss: 0.4675
2025-11-13 18:55:35,842 - INFO - Epoch: 67, Training Loss: 0.4845
2025-11-13 18:55:43,771 - INFO - Epoch: 68, Training Loss: 0.4635
2025-11-13 18:55:51,917 - INFO - Epoch: 69, Training Loss: 0.4724
2025-11-13 18:55:59,193 - INFO - Epoch: 70, Training Loss: 0.4611
2025-11-13 18:56:07,417 - INFO - Epoch: 71, Training Loss: 0.4932
2025-11-13 18:56:15,652 - INFO - Epoch: 72, Training Loss: 0.4888
2025-11-13 18:56:23,154 - INFO - Epoch: 73, Training Loss: 0.4760
2025-11-13 18:56:30,653 - INFO - Epoch: 74, Training Loss: 0.4627
2025-11-13 18:56:37,758 - INFO - Epoch: 75, Training Loss: 0.4795
2025-11-13 18:56:46,454 - INFO - Epoch: 76, Training Loss: 1.1105
2025-11-13 18:56:54,515 - INFO - Epoch: 77, Training Loss: 0.5025
2025-11-13 18:57:02,470 - INFO - Epoch: 78, Training Loss: 0.4667
2025-11-13 18:57:10,232 - INFO - Epoch: 79, Training Loss: 0.4786
2025-11-13 18:57:18,895 - INFO - Epoch: 80, Training Loss: 0.4808
2025-11-13 18:57:26,654 - INFO - Epoch: 81, Training Loss: 0.4603
2025-11-13 18:57:34,322 - INFO - Epoch: 82, Training Loss: 0.4862
2025-11-13 18:57:41,816 - INFO - Epoch: 83, Training Loss: 0.4768
2025-11-13 18:57:50,014 - INFO - Epoch: 84, Training Loss: 0.5338
2025-11-13 18:57:58,069 - INFO - Epoch: 85, Training Loss: 0.5499
2025-11-13 18:58:05,689 - INFO - Epoch: 86, Training Loss: 0.4836
2025-11-13 18:58:13,735 - INFO - Epoch: 87, Training Loss: 0.4679
2025-11-13 18:58:21,945 - INFO - Epoch: 88, Training Loss: 0.4718
2025-11-13 18:58:30,270 - INFO - Epoch: 89, Training Loss: 0.4603
2025-11-13 18:58:37,934 - INFO - Epoch: 90, Training Loss: 0.4574
2025-11-13 18:58:45,663 - INFO - Epoch: 91, Training Loss: 0.4630
2025-11-13 18:58:54,192 - INFO - Epoch: 92, Training Loss: 0.4727
2025-11-13 18:59:02,614 - INFO - Epoch: 93, Training Loss: 0.4715
2025-11-13 18:59:10,210 - INFO - Epoch: 94, Training Loss: 0.4527
2025-11-13 18:59:19,191 - INFO - Epoch: 95, Training Loss: 0.4662
2025-11-13 18:59:26,980 - INFO - Epoch: 96, Training Loss: 0.4640
2025-11-13 18:59:34,778 - INFO - Epoch: 97, Training Loss: 0.4664
2025-11-13 18:59:42,303 - INFO - Epoch: 98, Training Loss: 0.4554
2025-11-13 18:59:50,507 - INFO - Epoch: 99, Training Loss: 0.4723
2025-11-13 18:59:59,233 - INFO - Epoch: 100, Training Loss: 0.4487
2025-11-13 18:59:59,234 - INFO - 
============================================================
2025-11-13 18:59:59,234 - INFO - EVALUATION RESULTS
2025-11-13 18:59:59,234 - INFO - ============================================================
2025-11-13 18:59:59,283 - INFO - Validation Set - MSE: 0.014810, MAE: 0.098837, RMSE: 0.121696, Pearson Correlation: 0.921870 (p=0.000000)
2025-11-13 18:59:59,329 - INFO - Test Set - MSE: 0.013770, MAE: 0.094859, RMSE: 0.117345, Pearson Correlation: 0.913283 (p=0.000000)
2025-11-13 18:59:59,329 - INFO - ============================================================

2025-11-13 18:59:59,329 - INFO - CV Fold 1 completed successfully
2025-11-13 18:59:59,329 - INFO - 
--------------------------------------------------------------------------------
2025-11-13 18:59:59,329 - INFO - CV Fold 2
2025-11-13 18:59:59,329 - INFO - --------------------------------------------------------------------------------
2025-11-13 18:59:59,329 - INFO - START TRAINING CV 2 - Task: RGS
2025-11-13 18:59:59,329 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 18:59:59,329 - INFO - Loading dataset...
2025-11-13 18:59:59,420 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 18:59:59,420 - INFO - Initializing VIGNet model...
2025-11-13 18:59:59,423 - INFO - Number of batch iterations per epoch: 113
2025-11-13 19:00:08,151 - INFO - Epoch: 1, Training Loss: 8.1075
2025-11-13 19:00:15,918 - INFO - Epoch: 2, Training Loss: 0.7251
2025-11-13 19:00:23,552 - INFO - Epoch: 3, Training Loss: 0.6595
2025-11-13 19:00:31,421 - INFO - Epoch: 4, Training Loss: 0.6629
2025-11-13 19:00:38,907 - INFO - Epoch: 5, Training Loss: 0.6489
2025-11-13 19:00:47,296 - INFO - Epoch: 6, Training Loss: 0.6527
2025-11-13 19:00:55,014 - INFO - Epoch: 7, Training Loss: 0.6530
2025-11-13 19:01:02,871 - INFO - Epoch: 8, Training Loss: 0.6494
2025-11-13 19:01:10,873 - INFO - Epoch: 9, Training Loss: 0.6484
2025-11-13 19:01:19,256 - INFO - Epoch: 10, Training Loss: 0.6466
2025-11-13 19:01:27,334 - INFO - Epoch: 11, Training Loss: 0.6464
2025-11-13 19:01:34,910 - INFO - Epoch: 12, Training Loss: 0.6488
2025-11-13 19:01:43,120 - INFO - Epoch: 13, Training Loss: 0.6475
2025-11-13 19:01:51,163 - INFO - Epoch: 14, Training Loss: 0.6441
2025-11-13 19:01:58,906 - INFO - Epoch: 15, Training Loss: 0.6474
2025-11-13 19:02:07,779 - INFO - Epoch: 16, Training Loss: 0.6453
2025-11-13 19:02:15,577 - INFO - Epoch: 17, Training Loss: 0.6453
2025-11-13 19:02:23,031 - INFO - Epoch: 18, Training Loss: 0.6440
2025-11-13 19:02:31,115 - INFO - Epoch: 19, Training Loss: 0.6453
2025-11-13 19:02:38,476 - INFO - Epoch: 20, Training Loss: 0.6483
2025-11-13 19:02:46,355 - INFO - Epoch: 21, Training Loss: 0.6462
2025-11-13 19:02:53,778 - INFO - Epoch: 22, Training Loss: 0.6427
2025-11-13 19:03:02,215 - INFO - Epoch: 23, Training Loss: 0.6456
2025-11-13 19:03:09,903 - INFO - Epoch: 24, Training Loss: 0.6459
2025-11-13 19:03:17,477 - INFO - Epoch: 25, Training Loss: 0.6473
2025-11-13 19:03:25,644 - INFO - Epoch: 26, Training Loss: 0.6421
2025-11-13 19:03:34,088 - INFO - Epoch: 27, Training Loss: 0.6402
2025-11-13 19:03:41,854 - INFO - Epoch: 28, Training Loss: 0.6384
2025-11-13 19:03:50,277 - INFO - Epoch: 29, Training Loss: 0.6351
2025-11-13 19:03:58,569 - INFO - Epoch: 30, Training Loss: 0.6349
2025-11-13 19:04:05,823 - INFO - Epoch: 31, Training Loss: 0.6296
2025-11-13 19:04:13,541 - INFO - Epoch: 32, Training Loss: 0.5960
2025-11-13 19:04:20,907 - INFO - Epoch: 33, Training Loss: 0.5485
2025-11-13 19:04:28,651 - INFO - Epoch: 34, Training Loss: 0.5126
2025-11-13 19:04:37,118 - INFO - Epoch: 35, Training Loss: 0.5008
2025-11-13 19:04:45,250 - INFO - Epoch: 36, Training Loss: 0.4952
2025-11-13 19:04:52,992 - INFO - Epoch: 37, Training Loss: 0.4977
2025-11-13 19:05:00,761 - INFO - Epoch: 38, Training Loss: 0.4949
2025-11-13 19:05:08,446 - INFO - Epoch: 39, Training Loss: 0.4896
2025-11-13 19:05:16,659 - INFO - Epoch: 40, Training Loss: 0.4758
2025-11-13 19:05:24,615 - INFO - Epoch: 41, Training Loss: 0.4724
2025-11-13 19:05:32,684 - INFO - Epoch: 42, Training Loss: 0.4770
2025-11-13 19:05:40,851 - INFO - Epoch: 43, Training Loss: 0.5654
2025-11-13 19:05:48,648 - INFO - Epoch: 44, Training Loss: 0.4952
2025-11-13 19:05:55,866 - INFO - Epoch: 45, Training Loss: 0.4766
2025-11-13 19:06:03,335 - INFO - Epoch: 46, Training Loss: 0.4816
2025-11-13 19:06:11,149 - INFO - Epoch: 47, Training Loss: 0.4925
2025-11-13 19:06:18,977 - INFO - Epoch: 48, Training Loss: 0.4866
2025-11-13 19:06:27,011 - INFO - Epoch: 49, Training Loss: 0.4895
2025-11-13 19:06:34,534 - INFO - Epoch: 50, Training Loss: 0.4672
2025-11-13 19:06:42,382 - INFO - Epoch: 51, Training Loss: 1.3473
2025-11-13 19:06:50,037 - INFO - Epoch: 52, Training Loss: 0.6103
2025-11-13 19:06:57,385 - INFO - Epoch: 53, Training Loss: 0.5300
2025-11-13 19:07:05,418 - INFO - Epoch: 54, Training Loss: 0.5031
2025-11-13 19:07:12,999 - INFO - Epoch: 55, Training Loss: 0.4906
2025-11-13 19:07:21,206 - INFO - Epoch: 56, Training Loss: 0.4756
2025-11-13 19:07:29,837 - INFO - Epoch: 57, Training Loss: 0.4890
2025-11-13 19:07:38,462 - INFO - Epoch: 58, Training Loss: 0.5460
2025-11-13 19:07:45,836 - INFO - Epoch: 59, Training Loss: 0.4999
2025-11-13 19:07:54,416 - INFO - Epoch: 60, Training Loss: 0.4866
2025-11-13 19:08:02,362 - INFO - Epoch: 61, Training Loss: 0.4824
2025-11-13 19:08:10,845 - INFO - Epoch: 62, Training Loss: 0.4650
2025-11-13 19:08:18,813 - INFO - Epoch: 63, Training Loss: 0.4647
2025-11-13 19:08:27,155 - INFO - Epoch: 64, Training Loss: 0.4619
2025-11-13 19:08:35,109 - INFO - Epoch: 65, Training Loss: 0.4679
2025-11-13 19:08:42,639 - INFO - Epoch: 66, Training Loss: 0.4532
2025-11-13 19:08:50,817 - INFO - Epoch: 67, Training Loss: 0.4696
2025-11-13 19:08:57,951 - INFO - Epoch: 68, Training Loss: 0.4637
2025-11-13 19:09:07,080 - INFO - Epoch: 69, Training Loss: 0.5333
2025-11-13 19:09:15,259 - INFO - Epoch: 70, Training Loss: 0.4898
2025-11-13 19:09:23,124 - INFO - Epoch: 71, Training Loss: 0.4604
2025-11-13 19:09:32,248 - INFO - Epoch: 72, Training Loss: 0.4696
2025-11-13 19:09:40,445 - INFO - Epoch: 73, Training Loss: 0.4583
2025-11-13 19:09:48,341 - INFO - Epoch: 74, Training Loss: 0.4576
2025-11-13 19:09:56,180 - INFO - Epoch: 75, Training Loss: 0.4572
2025-11-13 19:10:03,498 - INFO - Epoch: 76, Training Loss: 0.4720
2025-11-13 19:10:11,408 - INFO - Epoch: 77, Training Loss: 0.4619
2025-11-13 19:10:18,880 - INFO - Epoch: 78, Training Loss: 0.4713
2025-11-13 19:10:27,588 - INFO - Epoch: 79, Training Loss: 0.4605
2025-11-13 19:10:34,993 - INFO - Epoch: 80, Training Loss: 0.5028
2025-11-13 19:10:42,376 - INFO - Epoch: 81, Training Loss: 0.4563
2025-11-13 19:10:50,182 - INFO - Epoch: 82, Training Loss: 0.4519
2025-11-13 19:10:57,413 - INFO - Epoch: 83, Training Loss: 0.5270
2025-11-13 19:11:05,351 - INFO - Epoch: 84, Training Loss: 0.4625
2025-11-13 19:11:12,825 - INFO - Epoch: 85, Training Loss: 0.4661
2025-11-13 19:11:20,669 - INFO - Epoch: 86, Training Loss: 0.4581
2025-11-13 19:11:28,029 - INFO - Epoch: 87, Training Loss: 0.4819
2025-11-13 19:11:35,577 - INFO - Epoch: 88, Training Loss: 0.4559
2025-11-13 19:11:43,980 - INFO - Epoch: 89, Training Loss: 0.4549
2025-11-13 19:11:51,210 - INFO - Epoch: 90, Training Loss: 0.4577
2025-11-13 19:11:58,430 - INFO - Epoch: 91, Training Loss: 0.4657
2025-11-13 19:12:06,392 - INFO - Epoch: 92, Training Loss: 0.4651
2025-11-13 19:12:13,936 - INFO - Epoch: 93, Training Loss: 0.4700
2025-11-13 19:12:22,179 - INFO - Epoch: 94, Training Loss: 0.4590
2025-11-13 19:12:30,490 - INFO - Epoch: 95, Training Loss: 0.4539
2025-11-13 19:12:38,720 - INFO - Epoch: 96, Training Loss: 0.4644
2025-11-13 19:12:46,225 - INFO - Epoch: 97, Training Loss: 0.4648
2025-11-13 19:12:53,561 - INFO - Epoch: 98, Training Loss: 0.4544
2025-11-13 19:13:01,241 - INFO - Epoch: 99, Training Loss: 0.4691
2025-11-13 19:13:09,173 - INFO - Epoch: 100, Training Loss: 0.4883
2025-11-13 19:13:09,173 - INFO - 
============================================================
2025-11-13 19:13:09,173 - INFO - EVALUATION RESULTS
2025-11-13 19:13:09,173 - INFO - ============================================================
2025-11-13 19:13:09,222 - INFO - Validation Set - MSE: 0.056145, MAE: 0.170090, RMSE: 0.236949, Pearson Correlation: 0.904826 (p=0.000000)
2025-11-13 19:13:09,276 - INFO - Test Set - MSE: 0.023551, MAE: 0.118069, RMSE: 0.153463, Pearson Correlation: 0.899484 (p=0.000000)
2025-11-13 19:13:09,276 - INFO - ============================================================

2025-11-13 19:13:09,276 - INFO - CV Fold 2 completed successfully
2025-11-13 19:13:09,276 - INFO - 
--------------------------------------------------------------------------------
2025-11-13 19:13:09,276 - INFO - CV Fold 3
2025-11-13 19:13:09,276 - INFO - --------------------------------------------------------------------------------
2025-11-13 19:13:09,276 - INFO - START TRAINING CV 3 - Task: RGS
2025-11-13 19:13:09,277 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 19:13:09,277 - INFO - Loading dataset...
2025-11-13 19:13:09,367 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 19:13:09,367 - INFO - Initializing VIGNet model...
2025-11-13 19:13:09,370 - INFO - Number of batch iterations per epoch: 113
2025-11-13 19:13:17,678 - INFO - Epoch: 1, Training Loss: 1.2047
2025-11-13 19:13:25,694 - INFO - Epoch: 2, Training Loss: 0.9014
2025-11-13 19:13:33,408 - INFO - Epoch: 3, Training Loss: 0.7075
2025-11-13 19:13:40,924 - INFO - Epoch: 4, Training Loss: 0.6710
2025-11-13 19:13:48,528 - INFO - Epoch: 5, Training Loss: 0.6593
2025-11-13 19:13:56,450 - INFO - Epoch: 6, Training Loss: 0.6579
2025-11-13 19:14:04,680 - INFO - Epoch: 7, Training Loss: 0.6578
2025-11-13 19:14:12,837 - INFO - Epoch: 8, Training Loss: 0.6594
2025-11-13 19:14:20,425 - INFO - Epoch: 9, Training Loss: 0.6559
2025-11-13 19:14:29,983 - INFO - Epoch: 10, Training Loss: 0.6575
2025-11-13 19:14:38,149 - INFO - Epoch: 11, Training Loss: 0.6521
2025-11-13 19:14:45,439 - INFO - Epoch: 12, Training Loss: 0.6564
2025-11-13 19:14:53,116 - INFO - Epoch: 13, Training Loss: 0.6523
2025-11-13 19:15:00,834 - INFO - Epoch: 14, Training Loss: 0.6521
2025-11-13 19:15:08,107 - INFO - Epoch: 15, Training Loss: 0.6508
2025-11-13 19:15:15,619 - INFO - Epoch: 16, Training Loss: 0.6519
2025-11-13 19:15:23,236 - INFO - Epoch: 17, Training Loss: 0.6482
2025-11-13 19:15:31,947 - INFO - Epoch: 18, Training Loss: 0.6543
2025-11-13 19:15:39,835 - INFO - Epoch: 19, Training Loss: 0.6435
2025-11-13 19:15:48,302 - INFO - Epoch: 20, Training Loss: 0.6460
2025-11-13 19:15:55,933 - INFO - Epoch: 21, Training Loss: 0.6534
2025-11-13 19:16:03,556 - INFO - Epoch: 22, Training Loss: 0.6435
2025-11-13 19:16:11,201 - INFO - Epoch: 23, Training Loss: 0.6429
2025-11-13 19:16:19,675 - INFO - Epoch: 24, Training Loss: 0.6386
2025-11-13 19:16:27,029 - INFO - Epoch: 25, Training Loss: 0.6297
2025-11-13 19:16:35,159 - INFO - Epoch: 26, Training Loss: 0.6111
2025-11-13 19:16:42,712 - INFO - Epoch: 27, Training Loss: 0.6167
2025-11-13 19:16:50,800 - INFO - Epoch: 28, Training Loss: 0.5779
2025-11-13 19:16:58,565 - INFO - Epoch: 29, Training Loss: 0.5259
2025-11-13 19:17:07,301 - INFO - Epoch: 30, Training Loss: 0.5090
2025-11-13 19:17:15,156 - INFO - Epoch: 31, Training Loss: 0.5111
2025-11-13 19:17:23,612 - INFO - Epoch: 32, Training Loss: 0.5567
2025-11-13 19:17:31,919 - INFO - Epoch: 33, Training Loss: 0.5003
2025-11-13 19:17:39,747 - INFO - Epoch: 34, Training Loss: 0.6203
2025-11-13 19:17:46,978 - INFO - Epoch: 35, Training Loss: 0.5463
2025-11-13 19:17:55,710 - INFO - Epoch: 36, Training Loss: 0.5005
2025-11-13 19:18:03,281 - INFO - Epoch: 37, Training Loss: 0.4957
2025-11-13 19:18:11,176 - INFO - Epoch: 38, Training Loss: 0.4887
2025-11-13 19:18:18,738 - INFO - Epoch: 39, Training Loss: 0.4993
2025-11-13 19:18:26,873 - INFO - Epoch: 40, Training Loss: 0.5007
2025-11-13 19:18:34,843 - INFO - Epoch: 41, Training Loss: 0.4938
2025-11-13 19:18:42,811 - INFO - Epoch: 42, Training Loss: 0.4796
2025-11-13 19:18:50,584 - INFO - Epoch: 43, Training Loss: 0.4980
2025-11-13 19:18:58,246 - INFO - Epoch: 44, Training Loss: 0.5879
2025-11-13 19:19:06,314 - INFO - Epoch: 45, Training Loss: 0.6244
2025-11-13 19:19:14,063 - INFO - Epoch: 46, Training Loss: 0.5946
2025-11-13 19:19:21,357 - INFO - Epoch: 47, Training Loss: 0.5234
2025-11-13 19:19:29,161 - INFO - Epoch: 48, Training Loss: 0.4950
2025-11-13 19:19:36,846 - INFO - Epoch: 49, Training Loss: 0.4803
2025-11-13 19:19:44,773 - INFO - Epoch: 50, Training Loss: 0.4965
2025-11-13 19:19:52,381 - INFO - Epoch: 51, Training Loss: 0.4831
2025-11-13 19:20:00,115 - INFO - Epoch: 52, Training Loss: 0.4729
2025-11-13 19:20:07,389 - INFO - Epoch: 53, Training Loss: 0.4978
2025-11-13 19:20:15,964 - INFO - Epoch: 54, Training Loss: 0.4731
2025-11-13 19:20:23,231 - INFO - Epoch: 55, Training Loss: 0.4731
2025-11-13 19:20:31,010 - INFO - Epoch: 56, Training Loss: 0.5004
2025-11-13 19:20:38,423 - INFO - Epoch: 57, Training Loss: 0.4707
2025-11-13 19:20:46,079 - INFO - Epoch: 58, Training Loss: 0.4769
2025-11-13 19:20:53,966 - INFO - Epoch: 59, Training Loss: 0.4983
2025-11-13 19:21:01,246 - INFO - Epoch: 60, Training Loss: 0.7018
2025-11-13 19:21:09,418 - INFO - Epoch: 61, Training Loss: 0.5543
2025-11-13 19:21:17,584 - INFO - Epoch: 62, Training Loss: 0.5231
2025-11-13 19:21:25,407 - INFO - Epoch: 63, Training Loss: 0.4994
2025-11-13 19:21:33,346 - INFO - Epoch: 64, Training Loss: 0.4862
2025-11-13 19:21:41,141 - INFO - Epoch: 65, Training Loss: 0.4788
2025-11-13 19:21:48,530 - INFO - Epoch: 66, Training Loss: 0.4730
2025-11-13 19:21:57,708 - INFO - Epoch: 67, Training Loss: 0.4746
2025-11-13 19:22:05,878 - INFO - Epoch: 68, Training Loss: 0.4781
2025-11-13 19:22:13,678 - INFO - Epoch: 69, Training Loss: 0.4874
2025-11-13 19:22:21,910 - INFO - Epoch: 70, Training Loss: 0.4742
2025-11-13 19:22:31,739 - INFO - Epoch: 71, Training Loss: 0.5496
2025-11-13 19:22:45,592 - INFO - Epoch: 72, Training Loss: 0.5129
2025-11-13 19:22:59,409 - INFO - Epoch: 73, Training Loss: 0.4946
2025-11-13 19:23:09,595 - INFO - Epoch: 74, Training Loss: 0.4964
2025-11-13 19:23:19,443 - INFO - Epoch: 75, Training Loss: 0.5015
2025-11-13 19:23:32,473 - INFO - Epoch: 76, Training Loss: 0.4899
2025-11-13 19:23:42,341 - INFO - Epoch: 77, Training Loss: 0.5039
2025-11-13 19:23:53,700 - INFO - Epoch: 78, Training Loss: 0.4775
2025-11-13 19:24:06,629 - INFO - Epoch: 79, Training Loss: 0.4978
2025-11-13 19:24:18,114 - INFO - Epoch: 80, Training Loss: 0.4927
2025-11-13 19:24:32,680 - INFO - Epoch: 81, Training Loss: 0.4826
2025-11-13 19:24:44,178 - INFO - Epoch: 82, Training Loss: 0.4798
2025-11-13 19:24:54,465 - INFO - Epoch: 83, Training Loss: 0.4649
2025-11-13 19:25:07,816 - INFO - Epoch: 84, Training Loss: 0.4736
2025-11-13 19:25:20,652 - INFO - Epoch: 85, Training Loss: 0.5141
2025-11-13 19:25:32,116 - INFO - Epoch: 86, Training Loss: 0.5036
2025-11-13 19:25:43,824 - INFO - Epoch: 87, Training Loss: 0.5090
2025-11-13 19:26:00,342 - INFO - Epoch: 88, Training Loss: 0.4640
2025-11-13 19:26:13,964 - INFO - Epoch: 89, Training Loss: 0.4750
2025-11-13 19:26:24,055 - INFO - Epoch: 90, Training Loss: 0.4660
2025-11-13 19:26:34,775 - INFO - Epoch: 91, Training Loss: 0.4695
2025-11-13 19:26:47,263 - INFO - Epoch: 92, Training Loss: 0.4712
2025-11-13 19:26:59,094 - INFO - Epoch: 93, Training Loss: 0.4663
2025-11-13 19:27:11,906 - INFO - Epoch: 94, Training Loss: 0.4570
2025-11-13 19:27:20,381 - INFO - Epoch: 95, Training Loss: 0.4715
2025-11-13 19:27:32,768 - INFO - Epoch: 96, Training Loss: 0.4574
2025-11-13 19:27:44,351 - INFO - Epoch: 97, Training Loss: 0.4670
2025-11-13 19:27:54,444 - INFO - Epoch: 98, Training Loss: 0.4777
2025-11-13 19:28:07,993 - INFO - Epoch: 99, Training Loss: 0.4557
2025-11-13 19:28:20,320 - INFO - Epoch: 100, Training Loss: 0.4623
2025-11-13 19:28:20,320 - INFO - 
============================================================
2025-11-13 19:28:20,320 - INFO - EVALUATION RESULTS
2025-11-13 19:28:20,320 - INFO - ============================================================
2025-11-13 19:28:20,363 - INFO - Validation Set - MSE: 0.024366, MAE: 0.118223, RMSE: 0.156095, Pearson Correlation: 0.895916 (p=0.000000)
2025-11-13 19:28:20,408 - INFO - Test Set - MSE: 0.023211, MAE: 0.103241, RMSE: 0.152352, Pearson Correlation: 0.911903 (p=0.000000)
2025-11-13 19:28:20,408 - INFO - ============================================================

2025-11-13 19:28:20,408 - INFO - CV Fold 3 completed successfully
2025-11-13 19:28:20,408 - INFO - 
--------------------------------------------------------------------------------
2025-11-13 19:28:20,408 - INFO - CV Fold 4
2025-11-13 19:28:20,408 - INFO - --------------------------------------------------------------------------------
2025-11-13 19:28:20,409 - INFO - START TRAINING CV 4 - Task: RGS
2025-11-13 19:28:20,409 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 19:28:20,409 - INFO - Loading dataset...
2025-11-13 19:28:20,496 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 19:28:20,496 - INFO - Initializing VIGNet model...
2025-11-13 19:28:20,499 - INFO - Number of batch iterations per epoch: 113
2025-11-13 19:28:32,706 - INFO - Epoch: 1, Training Loss: 1.6446
2025-11-13 19:28:46,318 - INFO - Epoch: 2, Training Loss: 0.6597
2025-11-13 19:28:58,751 - INFO - Epoch: 3, Training Loss: 0.6523
2025-11-13 19:29:10,294 - INFO - Epoch: 4, Training Loss: 0.6501
2025-11-13 19:29:25,496 - INFO - Epoch: 5, Training Loss: 0.6513
2025-11-13 19:29:35,162 - INFO - Epoch: 6, Training Loss: 0.6469
2025-11-13 19:29:44,621 - INFO - Epoch: 7, Training Loss: 0.6450
2025-11-13 19:29:56,515 - INFO - Epoch: 8, Training Loss: 0.6421
2025-11-13 19:30:08,930 - INFO - Epoch: 9, Training Loss: 0.6428
2025-11-13 19:30:22,880 - INFO - Epoch: 10, Training Loss: 0.6382
2025-11-13 19:30:36,538 - INFO - Epoch: 11, Training Loss: 0.6398
2025-11-13 19:30:46,643 - INFO - Epoch: 12, Training Loss: 0.6368
2025-11-13 19:30:58,220 - INFO - Epoch: 13, Training Loss: 0.6385
2025-11-13 19:31:09,140 - INFO - Epoch: 14, Training Loss: 0.6360
2025-11-13 19:31:19,752 - INFO - Epoch: 15, Training Loss: 0.6386
2025-11-13 19:31:29,669 - INFO - Epoch: 16, Training Loss: 0.6384
2025-11-13 19:31:42,440 - INFO - Epoch: 17, Training Loss: 0.6365
2025-11-13 19:31:54,294 - INFO - Epoch: 18, Training Loss: 0.6350
2025-11-13 19:32:06,410 - INFO - Epoch: 19, Training Loss: 0.6340
2025-11-13 19:32:19,330 - INFO - Epoch: 20, Training Loss: 0.6343
2025-11-13 19:32:31,599 - INFO - Epoch: 21, Training Loss: 0.6353
2025-11-13 19:32:48,306 - INFO - Epoch: 22, Training Loss: 0.6305
2025-11-13 19:32:59,418 - INFO - Epoch: 23, Training Loss: 0.6334
2025-11-13 19:33:08,288 - INFO - Epoch: 24, Training Loss: 0.6344
2025-11-13 19:33:18,141 - INFO - Epoch: 25, Training Loss: 0.6257
2025-11-13 19:33:29,943 - INFO - Epoch: 26, Training Loss: 0.6319
2025-11-13 19:33:39,952 - INFO - Epoch: 27, Training Loss: 0.6186
2025-11-13 19:33:51,240 - INFO - Epoch: 28, Training Loss: 0.6215
2025-11-13 19:34:03,445 - INFO - Epoch: 29, Training Loss: 0.5989
2025-11-13 19:34:16,819 - INFO - Epoch: 30, Training Loss: 0.5694
2025-11-13 19:34:28,212 - INFO - Epoch: 31, Training Loss: 0.6197
2025-11-13 19:34:40,814 - INFO - Epoch: 32, Training Loss: 0.6153
2025-11-13 19:34:53,760 - INFO - Epoch: 33, Training Loss: 0.5987
2025-11-13 19:35:09,094 - INFO - Epoch: 34, Training Loss: 0.5947
2025-11-13 19:35:20,779 - INFO - Epoch: 35, Training Loss: 0.5728
2025-11-13 19:35:37,389 - INFO - Epoch: 36, Training Loss: 0.5456
2025-11-13 19:35:50,057 - INFO - Epoch: 37, Training Loss: 0.5178
2025-11-13 19:36:03,802 - INFO - Epoch: 38, Training Loss: 0.5181
2025-11-13 19:36:13,953 - INFO - Epoch: 39, Training Loss: 0.5163
2025-11-13 19:36:28,419 - INFO - Epoch: 40, Training Loss: 0.5045
2025-11-13 19:36:39,947 - INFO - Epoch: 41, Training Loss: 0.4856
2025-11-13 19:36:51,190 - INFO - Epoch: 42, Training Loss: 0.4873
2025-11-13 19:37:01,913 - INFO - Epoch: 43, Training Loss: 0.4801
2025-11-13 19:37:16,234 - INFO - Epoch: 44, Training Loss: 4.2879
2025-11-13 19:37:30,518 - INFO - Epoch: 45, Training Loss: 5.1609
2025-11-13 19:37:40,549 - INFO - Epoch: 46, Training Loss: 5.1708
2025-11-13 19:37:49,097 - INFO - Epoch: 47, Training Loss: 5.1408
2025-11-13 19:38:01,136 - INFO - Epoch: 48, Training Loss: 5.1408
2025-11-13 19:38:15,358 - INFO - Epoch: 49, Training Loss: 5.1638
2025-11-13 19:38:29,723 - INFO - Epoch: 50, Training Loss: 5.1483
2025-11-13 19:38:41,193 - INFO - Epoch: 51, Training Loss: 5.1536
2025-11-13 19:38:53,201 - INFO - Epoch: 52, Training Loss: 5.1798
2025-11-13 19:39:07,244 - INFO - Epoch: 53, Training Loss: 5.1610
2025-11-13 19:39:20,545 - INFO - Epoch: 54, Training Loss: 5.1599
2025-11-13 19:39:32,188 - INFO - Epoch: 55, Training Loss: 5.1633
2025-11-13 19:39:43,345 - INFO - Epoch: 56, Training Loss: 5.1798
2025-11-13 19:39:56,644 - INFO - Epoch: 57, Training Loss: 5.1627
2025-11-13 19:40:10,934 - INFO - Epoch: 58, Training Loss: 5.1458
2025-11-13 19:40:19,338 - INFO - Epoch: 59, Training Loss: 5.1539
2025-11-13 19:40:29,896 - INFO - Epoch: 60, Training Loss: 5.1472
2025-11-13 19:40:42,595 - INFO - Epoch: 61, Training Loss: 5.1798
2025-11-13 19:40:56,374 - INFO - Epoch: 62, Training Loss: 5.1657
2025-11-13 19:41:08,119 - INFO - Epoch: 63, Training Loss: 5.1798
2025-11-13 19:41:19,865 - INFO - Epoch: 64, Training Loss: 5.1658
2025-11-13 19:41:30,720 - INFO - Epoch: 65, Training Loss: 5.1635
2025-11-13 19:41:38,902 - INFO - Epoch: 66, Training Loss: 5.1798
2025-11-13 19:41:50,444 - INFO - Epoch: 67, Training Loss: 5.1517
2025-11-13 19:41:59,801 - INFO - Epoch: 68, Training Loss: 5.1627
2025-11-13 19:42:11,637 - INFO - Epoch: 69, Training Loss: 5.1699
2025-11-13 19:42:22,620 - INFO - Epoch: 70, Training Loss: 5.1434
2025-11-13 19:42:34,449 - INFO - Epoch: 71, Training Loss: 5.1504
2025-11-13 19:42:46,098 - INFO - Epoch: 72, Training Loss: 5.1622
2025-11-13 19:42:55,909 - INFO - Epoch: 73, Training Loss: 5.1431
2025-11-13 19:43:09,559 - INFO - Epoch: 74, Training Loss: 5.1450
2025-11-13 19:43:20,879 - INFO - Epoch: 75, Training Loss: 5.1618
2025-11-13 19:43:31,247 - INFO - Epoch: 76, Training Loss: 5.1598
2025-11-13 19:43:46,081 - INFO - Epoch: 77, Training Loss: 5.1466
2025-11-13 19:43:55,760 - INFO - Epoch: 78, Training Loss: 5.1715
2025-11-13 19:44:04,306 - INFO - Epoch: 79, Training Loss: 5.1661
2025-11-13 19:44:14,886 - INFO - Epoch: 80, Training Loss: 5.1603
2025-11-13 19:44:24,263 - INFO - Epoch: 81, Training Loss: 5.1627
2025-11-13 19:44:38,727 - INFO - Epoch: 82, Training Loss: 5.1794
2025-11-13 19:44:50,141 - INFO - Epoch: 83, Training Loss: 5.1798
2025-11-13 19:45:01,421 - INFO - Epoch: 84, Training Loss: 5.1486
2025-11-13 19:45:12,067 - INFO - Epoch: 85, Training Loss: 5.1616
2025-11-13 19:45:27,013 - INFO - Epoch: 86, Training Loss: 5.1477
2025-11-13 19:45:40,085 - INFO - Epoch: 87, Training Loss: 5.1618
2025-11-13 19:45:51,862 - INFO - Epoch: 88, Training Loss: 5.1798
2025-11-13 19:46:05,603 - INFO - Epoch: 89, Training Loss: 5.1633
2025-11-13 19:46:17,517 - INFO - Epoch: 90, Training Loss: 5.1798
2025-11-13 19:46:28,148 - INFO - Epoch: 91, Training Loss: 5.1677
2025-11-13 19:46:40,627 - INFO - Epoch: 92, Training Loss: 5.1664
2025-11-13 19:46:51,584 - INFO - Epoch: 93, Training Loss: 5.1610
2025-11-13 19:47:02,268 - INFO - Epoch: 94, Training Loss: 5.1621
2025-11-13 19:47:16,266 - INFO - Epoch: 95, Training Loss: 5.1631
2025-11-13 19:47:25,961 - INFO - Epoch: 96, Training Loss: 5.1476
2025-11-13 19:47:39,236 - INFO - Epoch: 97, Training Loss: 5.1665
2025-11-13 19:47:47,867 - INFO - Epoch: 98, Training Loss: 5.1614
2025-11-13 19:48:03,466 - INFO - Epoch: 99, Training Loss: 5.1531
2025-11-13 19:48:13,080 - INFO - Epoch: 100, Training Loss: 5.1596
2025-11-13 19:48:13,080 - INFO - 
============================================================
2025-11-13 19:48:13,080 - INFO - EVALUATION RESULTS
2025-11-13 19:48:13,080 - INFO - ============================================================
2025-11-13 19:48:13,125 - INFO - Validation Set - MSE: 1.218462, MAE: 1.094051, RMSE: 1.103840, Pearson Correlation: 0.894993 (p=0.000000)
2025-11-13 19:48:13,168 - INFO - Test Set - MSE: 0.971373, MAE: 0.977757, RMSE: 0.985582, Pearson Correlation: 0.930106 (p=0.000000)
2025-11-13 19:48:13,168 - INFO - ============================================================

2025-11-13 19:48:13,168 - INFO - CV Fold 4 completed successfully
2025-11-13 19:48:13,168 - INFO - 
================================================================================
2025-11-13 19:48:13,168 - INFO - CROSS-VALIDATION SUMMARY - TRIAL 1
2025-11-13 19:48:13,168 - INFO - ================================================================================
2025-11-13 19:48:13,168 - INFO - Validation Set (Average across 5 CV folds):
2025-11-13 19:48:13,168 - INFO -   MSE: 0.268128 ± 0.475368
2025-11-13 19:48:13,168 - INFO -   MAE: 0.321322 ± 0.387069
2025-11-13 19:48:13,169 - INFO -   RMSE: 0.356492 ± 0.375555
2025-11-13 19:48:13,169 - INFO -   Pearson Correlation: 0.906033 ± 0.010189
2025-11-13 19:48:13,169 - INFO - 
Test Set (Average across 5 CV folds):
2025-11-13 19:48:13,169 - INFO -   MSE: 0.211628 ± 0.379896
2025-11-13 19:48:13,169 - INFO -   MAE: 0.287957 ± 0.345336
2025-11-13 19:48:13,169 - INFO -   RMSE: 0.314142 ± 0.336069
2025-11-13 19:48:13,169 - INFO -   Pearson Correlation: 0.912579 ± 0.009995
2025-11-13 19:48:13,169 - INFO - ================================================================================
2025-11-13 19:48:13,169 - INFO - ================================================================================
2025-11-13 19:48:13,169 - INFO - Trial 1 completed. End time: 2025-11-13 19:48:13
2025-11-13 19:48:13,169 - INFO - ================================================================================
