2025-11-12 01:50:32,935 - INFO - Log file: ./logs/trial1_cv2_RGS_20251112_015032.log
2025-11-12 01:50:32,935 - INFO - START TRAINING TRIAL 1 CV 2 - Task: RGS
2025-11-12 01:50:32,935 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 01:50:32,935 - INFO - Loading dataset...
2025-11-12 01:50:33,024 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 01:50:33,024 - INFO - Initializing VIGNet model...
2025-11-12 01:50:33,027 - INFO - Number of batch iterations per epoch: 113
2025-11-12 01:50:41,054 - INFO - Epoch: 1, Training Loss: 1.0090
2025-11-12 01:50:49,512 - INFO - Epoch: 2, Training Loss: 0.7689
2025-11-12 01:50:57,747 - INFO - Epoch: 3, Training Loss: 0.6639
2025-11-12 01:51:05,813 - INFO - Epoch: 4, Training Loss: 0.6591
2025-11-12 01:51:14,378 - INFO - Epoch: 5, Training Loss: 0.6505
2025-11-12 01:51:22,200 - INFO - Epoch: 6, Training Loss: 0.6590
2025-11-12 01:51:30,635 - INFO - Epoch: 7, Training Loss: 0.6508
2025-11-12 01:51:39,484 - INFO - Epoch: 8, Training Loss: 0.6532
2025-11-12 01:51:46,896 - INFO - Epoch: 9, Training Loss: 0.6466
2025-11-12 01:51:54,824 - INFO - Epoch: 10, Training Loss: 0.6464
2025-11-12 01:52:03,075 - INFO - Epoch: 11, Training Loss: 0.6454
2025-11-12 01:52:11,270 - INFO - Epoch: 12, Training Loss: 0.6394
2025-11-12 01:52:20,025 - INFO - Epoch: 13, Training Loss: 0.6338
2025-11-12 01:52:28,666 - INFO - Epoch: 14, Training Loss: 0.6215
2025-11-12 01:52:36,532 - INFO - Epoch: 15, Training Loss: 0.5878
2025-11-12 01:52:44,079 - INFO - Epoch: 16, Training Loss: 0.5990
2025-11-12 01:52:51,707 - INFO - Epoch: 17, Training Loss: 0.5347
2025-11-12 01:52:59,366 - INFO - Epoch: 18, Training Loss: 0.5624
2025-11-12 01:53:07,420 - INFO - Epoch: 19, Training Loss: 0.5065
2025-11-12 01:53:14,797 - INFO - Epoch: 20, Training Loss: 0.4813
2025-11-12 01:53:22,245 - INFO - Epoch: 21, Training Loss: 0.5780
2025-11-12 01:53:30,015 - INFO - Epoch: 22, Training Loss: 0.4834
2025-11-12 01:53:38,455 - INFO - Epoch: 23, Training Loss: 0.4706
2025-11-12 01:53:46,145 - INFO - Epoch: 24, Training Loss: 0.4965
2025-11-12 01:53:53,503 - INFO - Epoch: 25, Training Loss: 0.4786
2025-11-12 01:54:01,593 - INFO - Epoch: 26, Training Loss: 1.7083
2025-11-12 01:54:10,350 - INFO - Epoch: 27, Training Loss: 0.6384
2025-11-12 01:54:17,974 - INFO - Epoch: 28, Training Loss: 0.6343
2025-11-12 01:54:26,493 - INFO - Epoch: 29, Training Loss: 0.6296
2025-11-12 01:54:34,515 - INFO - Epoch: 30, Training Loss: 0.6033
2025-11-12 01:54:43,185 - INFO - Epoch: 31, Training Loss: 0.5552
2025-11-12 01:54:51,116 - INFO - Epoch: 32, Training Loss: 0.5140
2025-11-12 01:54:58,857 - INFO - Epoch: 33, Training Loss: 0.4790
2025-11-12 01:55:06,666 - INFO - Epoch: 34, Training Loss: 0.4812
2025-11-12 01:55:14,785 - INFO - Epoch: 35, Training Loss: 0.6089
2025-11-12 01:55:22,623 - INFO - Epoch: 36, Training Loss: 0.5853
2025-11-12 01:55:30,665 - INFO - Epoch: 37, Training Loss: 0.5244
2025-11-12 01:55:38,382 - INFO - Epoch: 38, Training Loss: 0.4938
2025-11-12 01:55:45,976 - INFO - Epoch: 39, Training Loss: 0.4926
2025-11-12 01:55:53,519 - INFO - Epoch: 40, Training Loss: 0.4921
2025-11-12 01:56:01,797 - INFO - Epoch: 41, Training Loss: 0.4839
2025-11-12 01:56:10,601 - INFO - Epoch: 42, Training Loss: 0.4786
2025-11-12 01:56:19,235 - INFO - Epoch: 43, Training Loss: 0.4792
2025-11-12 01:56:27,169 - INFO - Epoch: 44, Training Loss: 0.4955
2025-11-12 01:56:34,872 - INFO - Epoch: 45, Training Loss: 0.4755
2025-11-12 01:56:43,830 - INFO - Epoch: 46, Training Loss: 0.4696
2025-11-12 01:56:51,815 - INFO - Epoch: 47, Training Loss: 0.4919
2025-11-12 01:56:59,279 - INFO - Epoch: 48, Training Loss: 0.5188
2025-11-12 01:57:07,273 - INFO - Epoch: 49, Training Loss: 0.5390
2025-11-12 01:57:14,479 - INFO - Epoch: 50, Training Loss: 0.5082
2025-11-12 01:57:21,988 - INFO - Epoch: 51, Training Loss: 0.4826
2025-11-12 01:57:30,186 - INFO - Epoch: 52, Training Loss: 0.4824
2025-11-12 01:57:37,019 - INFO - Epoch: 53, Training Loss: 0.4857
2025-11-12 01:57:45,081 - INFO - Epoch: 54, Training Loss: 0.4883
2025-11-12 01:57:53,411 - INFO - Epoch: 55, Training Loss: 0.6073
2025-11-12 01:58:01,154 - INFO - Epoch: 56, Training Loss: 0.4867
2025-11-12 01:58:08,833 - INFO - Epoch: 57, Training Loss: 0.4791
2025-11-12 01:58:16,536 - INFO - Epoch: 58, Training Loss: 0.4797
2025-11-12 01:58:25,279 - INFO - Epoch: 59, Training Loss: 0.4736
2025-11-12 01:58:33,083 - INFO - Epoch: 60, Training Loss: 0.4869
2025-11-12 01:58:41,782 - INFO - Epoch: 61, Training Loss: 0.4923
2025-11-12 01:58:49,433 - INFO - Epoch: 62, Training Loss: 0.4852
2025-11-12 01:58:57,979 - INFO - Epoch: 63, Training Loss: 0.4698
2025-11-12 01:59:05,329 - INFO - Epoch: 64, Training Loss: 0.4762
2025-11-12 01:59:12,661 - INFO - Epoch: 65, Training Loss: 0.4875
2025-11-12 01:59:20,811 - INFO - Epoch: 66, Training Loss: 0.4768
2025-11-12 01:59:28,470 - INFO - Epoch: 67, Training Loss: 0.4587
2025-11-12 01:59:36,277 - INFO - Epoch: 68, Training Loss: 0.4669
2025-11-12 01:59:45,392 - INFO - Epoch: 69, Training Loss: 0.4757
2025-11-12 01:59:53,907 - INFO - Epoch: 70, Training Loss: 0.4842
2025-11-12 02:00:01,447 - INFO - Epoch: 71, Training Loss: 0.4550
2025-11-12 02:00:09,497 - INFO - Epoch: 72, Training Loss: 0.4716
2025-11-12 02:00:17,192 - INFO - Epoch: 73, Training Loss: 0.4514
2025-11-12 02:00:25,265 - INFO - Epoch: 74, Training Loss: 0.4784
2025-11-12 02:00:33,375 - INFO - Epoch: 75, Training Loss: 0.5186
2025-11-12 02:00:41,322 - INFO - Epoch: 76, Training Loss: 0.4583
2025-11-12 02:00:49,135 - INFO - Epoch: 77, Training Loss: 0.4483
2025-11-12 02:00:57,273 - INFO - Epoch: 78, Training Loss: 0.4609
2025-11-12 02:01:05,478 - INFO - Epoch: 79, Training Loss: 0.4675
2025-11-12 02:01:13,828 - INFO - Epoch: 80, Training Loss: 0.4796
2025-11-12 02:01:21,697 - INFO - Epoch: 81, Training Loss: 0.4604
2025-11-12 02:01:30,057 - INFO - Epoch: 82, Training Loss: 0.4802
2025-11-12 02:01:37,285 - INFO - Epoch: 83, Training Loss: 0.4929
2025-11-12 02:01:44,853 - INFO - Epoch: 84, Training Loss: 0.4890
2025-11-12 02:01:52,823 - INFO - Epoch: 85, Training Loss: 0.4749
2025-11-12 02:02:01,077 - INFO - Epoch: 86, Training Loss: 0.4874
2025-11-12 02:02:08,874 - INFO - Epoch: 87, Training Loss: 0.4662
2025-11-12 02:02:16,985 - INFO - Epoch: 88, Training Loss: 0.5494
2025-11-12 02:02:25,655 - INFO - Epoch: 89, Training Loss: 0.5415
2025-11-12 02:02:33,723 - INFO - Epoch: 90, Training Loss: 0.4601
2025-11-12 02:02:42,076 - INFO - Epoch: 91, Training Loss: 0.4638
2025-11-12 02:02:51,064 - INFO - Epoch: 92, Training Loss: 0.4604
2025-11-12 02:02:58,890 - INFO - Epoch: 93, Training Loss: 0.5029
2025-11-12 02:03:06,844 - INFO - Epoch: 94, Training Loss: 0.4677
2025-11-12 02:03:14,404 - INFO - Epoch: 95, Training Loss: 0.4799
2025-11-12 02:03:22,045 - INFO - Epoch: 96, Training Loss: 0.4671
2025-11-12 02:03:30,669 - INFO - Epoch: 97, Training Loss: 0.4890
2025-11-12 02:03:39,232 - INFO - Epoch: 98, Training Loss: 0.4846
2025-11-12 02:03:47,034 - INFO - Epoch: 99, Training Loss: 0.4699
2025-11-12 02:03:54,421 - INFO - Epoch: 100, Training Loss: 0.4563
2025-11-12 02:03:54,422 - INFO - Training completed for Trial 1 CV 2

