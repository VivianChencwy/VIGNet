2025-11-12 13:23:13,275 - INFO - Log file: ./logs/trial11_cv4_RGS_20251112_132313.log
2025-11-12 13:23:13,275 - INFO - START TRAINING TRIAL 11 CV 4 - Task: RGS
2025-11-12 13:23:13,275 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 13:23:13,275 - INFO - Loading dataset...
2025-11-12 13:23:13,530 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 13:23:13,530 - INFO - Initializing VIGNet model...
2025-11-12 13:23:13,533 - INFO - Number of batch iterations per epoch: 113
2025-11-12 13:23:21,867 - INFO - Epoch: 1, Training Loss: 1.0528
2025-11-12 13:23:30,715 - INFO - Epoch: 2, Training Loss: 0.7965
2025-11-12 13:23:38,631 - INFO - Epoch: 3, Training Loss: 0.6976
2025-11-12 13:23:46,231 - INFO - Epoch: 4, Training Loss: 0.6866
2025-11-12 13:23:53,914 - INFO - Epoch: 5, Training Loss: 0.6838
2025-11-12 13:24:02,624 - INFO - Epoch: 6, Training Loss: 0.6865
2025-11-12 13:24:09,724 - INFO - Epoch: 7, Training Loss: 0.6806
2025-11-12 13:24:17,485 - INFO - Epoch: 8, Training Loss: 0.6791
2025-11-12 13:24:25,720 - INFO - Epoch: 9, Training Loss: 0.6799
2025-11-12 13:24:33,380 - INFO - Epoch: 10, Training Loss: 0.6804
2025-11-12 13:24:40,907 - INFO - Epoch: 11, Training Loss: 0.6791
2025-11-12 13:24:48,083 - INFO - Epoch: 12, Training Loss: 0.6785
2025-11-12 13:24:56,883 - INFO - Epoch: 13, Training Loss: 0.6767
2025-11-12 13:25:04,958 - INFO - Epoch: 14, Training Loss: 0.6775
2025-11-12 13:25:12,739 - INFO - Epoch: 15, Training Loss: 0.6766
2025-11-12 13:25:20,311 - INFO - Epoch: 16, Training Loss: 0.6760
2025-11-12 13:25:28,916 - INFO - Epoch: 17, Training Loss: 0.6766
2025-11-12 13:25:36,403 - INFO - Epoch: 18, Training Loss: 0.6759
2025-11-12 13:25:43,883 - INFO - Epoch: 19, Training Loss: 0.6766
2025-11-12 13:25:51,618 - INFO - Epoch: 20, Training Loss: 0.6770
2025-11-12 13:25:59,493 - INFO - Epoch: 21, Training Loss: 0.6772
2025-11-12 13:26:07,829 - INFO - Epoch: 22, Training Loss: 0.6760
2025-11-12 13:26:15,386 - INFO - Epoch: 23, Training Loss: 0.6760
2025-11-12 13:26:23,852 - INFO - Epoch: 24, Training Loss: 0.6768
2025-11-12 13:26:31,775 - INFO - Epoch: 25, Training Loss: 0.6760
2025-11-12 13:26:39,612 - INFO - Epoch: 26, Training Loss: 0.6765
2025-11-12 13:26:47,386 - INFO - Epoch: 27, Training Loss: 0.6757
2025-11-12 13:26:55,082 - INFO - Epoch: 28, Training Loss: 0.6757
2025-11-12 13:27:02,934 - INFO - Epoch: 29, Training Loss: 0.6757
2025-11-12 13:27:10,644 - INFO - Epoch: 30, Training Loss: 0.6762
2025-11-12 13:27:18,858 - INFO - Epoch: 31, Training Loss: 0.6759
2025-11-12 13:27:26,503 - INFO - Epoch: 32, Training Loss: 0.6762
2025-11-12 13:27:34,342 - INFO - Epoch: 33, Training Loss: 0.6764
2025-11-12 13:27:43,051 - INFO - Epoch: 34, Training Loss: 0.6763
2025-11-12 13:27:51,043 - INFO - Epoch: 35, Training Loss: 0.6756
2025-11-12 13:27:59,357 - INFO - Epoch: 36, Training Loss: 0.6758
2025-11-12 13:28:06,702 - INFO - Epoch: 37, Training Loss: 0.6752
2025-11-12 13:28:14,023 - INFO - Epoch: 38, Training Loss: 0.6760
2025-11-12 13:28:21,950 - INFO - Epoch: 39, Training Loss: 0.6755
2025-11-12 13:28:29,410 - INFO - Epoch: 40, Training Loss: 0.6757
2025-11-12 13:28:38,993 - INFO - Epoch: 41, Training Loss: 0.6761
2025-11-12 13:28:46,570 - INFO - Epoch: 42, Training Loss: 0.6758
2025-11-12 13:28:54,314 - INFO - Epoch: 43, Training Loss: 0.6766
2025-11-12 13:29:02,184 - INFO - Epoch: 44, Training Loss: 0.6752
2025-11-12 13:29:10,225 - INFO - Epoch: 45, Training Loss: 0.6757
2025-11-12 13:29:18,703 - INFO - Epoch: 46, Training Loss: 0.6755
2025-11-12 13:29:28,119 - INFO - Epoch: 47, Training Loss: 0.6764
2025-11-12 13:29:36,624 - INFO - Epoch: 48, Training Loss: 0.6762
2025-11-12 13:29:44,000 - INFO - Epoch: 49, Training Loss: 0.6756
2025-11-12 13:29:51,703 - INFO - Epoch: 50, Training Loss: 0.6764
2025-11-12 13:29:59,848 - INFO - Epoch: 51, Training Loss: 0.6755
2025-11-12 13:30:07,447 - INFO - Epoch: 52, Training Loss: 0.6759
2025-11-12 13:30:14,922 - INFO - Epoch: 53, Training Loss: 0.6760
2025-11-12 13:30:23,453 - INFO - Epoch: 54, Training Loss: 0.6754
2025-11-12 13:30:30,794 - INFO - Epoch: 55, Training Loss: 0.6756
2025-11-12 13:30:38,422 - INFO - Epoch: 56, Training Loss: 0.6765
2025-11-12 13:30:46,225 - INFO - Epoch: 57, Training Loss: 0.6761
2025-11-12 13:30:54,138 - INFO - Epoch: 58, Training Loss: 0.6762
2025-11-12 13:31:02,171 - INFO - Epoch: 59, Training Loss: 0.6748
2025-11-12 13:31:10,425 - INFO - Epoch: 60, Training Loss: 0.6757
2025-11-12 13:31:19,063 - INFO - Epoch: 61, Training Loss: 0.6766
2025-11-12 13:31:26,327 - INFO - Epoch: 62, Training Loss: 0.6753
2025-11-12 13:31:33,790 - INFO - Epoch: 63, Training Loss: 0.6762
2025-11-12 13:31:42,319 - INFO - Epoch: 64, Training Loss: 0.6764
2025-11-12 13:31:51,208 - INFO - Epoch: 65, Training Loss: 0.6759
2025-11-12 13:31:58,381 - INFO - Epoch: 66, Training Loss: 0.6755
2025-11-12 13:32:06,201 - INFO - Epoch: 67, Training Loss: 0.6760
2025-11-12 13:32:14,629 - INFO - Epoch: 68, Training Loss: 0.6752
2025-11-12 13:32:22,302 - INFO - Epoch: 69, Training Loss: 0.6762
2025-11-12 13:32:30,318 - INFO - Epoch: 70, Training Loss: 0.6753
2025-11-12 13:32:37,868 - INFO - Epoch: 71, Training Loss: 0.6764
2025-11-12 13:32:46,065 - INFO - Epoch: 72, Training Loss: 0.6755
2025-11-12 13:32:53,466 - INFO - Epoch: 73, Training Loss: 0.6760
2025-11-12 13:33:02,084 - INFO - Epoch: 74, Training Loss: 0.6752
2025-11-12 13:33:11,250 - INFO - Epoch: 75, Training Loss: 0.6748
2025-11-12 13:33:18,802 - INFO - Epoch: 76, Training Loss: 0.6751
2025-11-12 13:33:26,797 - INFO - Epoch: 77, Training Loss: 0.6751
2025-11-12 13:33:35,585 - INFO - Epoch: 78, Training Loss: 0.6751
2025-11-12 13:33:44,146 - INFO - Epoch: 79, Training Loss: 0.6753
2025-11-12 13:33:52,084 - INFO - Epoch: 80, Training Loss: 0.6743
2025-11-12 13:33:59,891 - INFO - Epoch: 81, Training Loss: 0.6756
2025-11-12 13:34:07,279 - INFO - Epoch: 82, Training Loss: 0.6742
2025-11-12 13:34:15,019 - INFO - Epoch: 83, Training Loss: 0.6747
2025-11-12 13:34:23,683 - INFO - Epoch: 84, Training Loss: 0.6739
2025-11-12 13:34:31,081 - INFO - Epoch: 85, Training Loss: 0.6747
2025-11-12 13:34:38,391 - INFO - Epoch: 86, Training Loss: 0.6755
2025-11-12 13:34:45,537 - INFO - Epoch: 87, Training Loss: 0.6736
2025-11-12 13:34:53,809 - INFO - Epoch: 88, Training Loss: 0.6722
2025-11-12 13:35:02,682 - INFO - Epoch: 89, Training Loss: 0.6715
2025-11-12 13:35:10,329 - INFO - Epoch: 90, Training Loss: 0.6714
2025-11-12 13:35:17,736 - INFO - Epoch: 91, Training Loss: 0.6701
2025-11-12 13:35:26,129 - INFO - Epoch: 92, Training Loss: 0.6681
2025-11-12 13:35:34,229 - INFO - Epoch: 93, Training Loss: 0.6673
2025-11-12 13:35:43,065 - INFO - Epoch: 94, Training Loss: 0.6646
2025-11-12 13:35:51,101 - INFO - Epoch: 95, Training Loss: 0.6628
2025-11-12 13:35:59,614 - INFO - Epoch: 96, Training Loss: 0.6625
2025-11-12 13:36:07,658 - INFO - Epoch: 97, Training Loss: 0.6615
2025-11-12 13:36:15,663 - INFO - Epoch: 98, Training Loss: 0.6612
2025-11-12 13:36:23,647 - INFO - Epoch: 99, Training Loss: 0.6611
2025-11-12 13:36:32,180 - INFO - Epoch: 100, Training Loss: 0.6619
2025-11-12 13:36:32,180 - INFO - Training completed for Trial 11 CV 4

