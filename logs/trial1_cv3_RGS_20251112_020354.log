2025-11-12 02:03:54,422 - INFO - Log file: ./logs/trial1_cv3_RGS_20251112_020354.log
2025-11-12 02:03:54,422 - INFO - START TRAINING TRIAL 1 CV 3 - Task: RGS
2025-11-12 02:03:54,422 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 02:03:54,422 - INFO - Loading dataset...
2025-11-12 02:03:54,511 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 02:03:54,511 - INFO - Initializing VIGNet model...
2025-11-12 02:03:54,514 - INFO - Number of batch iterations per epoch: 113
2025-11-12 02:04:02,967 - INFO - Epoch: 1, Training Loss: 1.0145
2025-11-12 02:04:10,693 - INFO - Epoch: 2, Training Loss: 0.6776
2025-11-12 02:04:19,047 - INFO - Epoch: 3, Training Loss: 0.6687
2025-11-12 02:04:26,204 - INFO - Epoch: 4, Training Loss: 0.6600
2025-11-12 02:04:33,837 - INFO - Epoch: 5, Training Loss: 0.6558
2025-11-12 02:04:41,092 - INFO - Epoch: 6, Training Loss: 0.6525
2025-11-12 02:04:48,708 - INFO - Epoch: 7, Training Loss: 0.6540
2025-11-12 02:04:56,478 - INFO - Epoch: 8, Training Loss: 0.6553
2025-11-12 02:05:04,138 - INFO - Epoch: 9, Training Loss: 0.6535
2025-11-12 02:05:11,970 - INFO - Epoch: 10, Training Loss: 0.6532
2025-11-12 02:05:19,808 - INFO - Epoch: 11, Training Loss: 0.6514
2025-11-12 02:05:27,685 - INFO - Epoch: 12, Training Loss: 0.6495
2025-11-12 02:05:36,535 - INFO - Epoch: 13, Training Loss: 0.6499
2025-11-12 02:05:45,122 - INFO - Epoch: 14, Training Loss: 0.6476
2025-11-12 02:05:53,716 - INFO - Epoch: 15, Training Loss: 0.6503
2025-11-12 02:06:02,440 - INFO - Epoch: 16, Training Loss: 0.6492
2025-11-12 02:06:10,404 - INFO - Epoch: 17, Training Loss: 0.6519
2025-11-12 02:06:18,128 - INFO - Epoch: 18, Training Loss: 0.6477
2025-11-12 02:06:26,707 - INFO - Epoch: 19, Training Loss: 0.6490
2025-11-12 02:06:35,421 - INFO - Epoch: 20, Training Loss: 0.6440
2025-11-12 02:06:42,957 - INFO - Epoch: 21, Training Loss: 0.6434
2025-11-12 02:06:50,331 - INFO - Epoch: 22, Training Loss: 0.6452
2025-11-12 02:06:58,946 - INFO - Epoch: 23, Training Loss: 0.6460
2025-11-12 02:07:07,371 - INFO - Epoch: 24, Training Loss: 0.6354
2025-11-12 02:07:14,847 - INFO - Epoch: 25, Training Loss: 0.6392
2025-11-12 02:07:23,105 - INFO - Epoch: 26, Training Loss: 0.6446
2025-11-12 02:07:31,157 - INFO - Epoch: 27, Training Loss: 0.6307
2025-11-12 02:07:39,095 - INFO - Epoch: 28, Training Loss: 0.6246
2025-11-12 02:07:47,672 - INFO - Epoch: 29, Training Loss: 0.6212
2025-11-12 02:07:55,413 - INFO - Epoch: 30, Training Loss: 0.6177
2025-11-12 02:08:02,852 - INFO - Epoch: 31, Training Loss: 0.6117
2025-11-12 02:08:10,547 - INFO - Epoch: 32, Training Loss: 0.5830
2025-11-12 02:08:17,703 - INFO - Epoch: 33, Training Loss: 0.6772
2025-11-12 02:08:25,505 - INFO - Epoch: 34, Training Loss: 0.5943
2025-11-12 02:08:33,086 - INFO - Epoch: 35, Training Loss: 0.5624
2025-11-12 02:08:40,840 - INFO - Epoch: 36, Training Loss: 0.5398
2025-11-12 02:08:49,228 - INFO - Epoch: 37, Training Loss: 0.7292
2025-11-12 02:08:57,461 - INFO - Epoch: 38, Training Loss: 0.6198
2025-11-12 02:09:05,858 - INFO - Epoch: 39, Training Loss: 0.5974
2025-11-12 02:09:13,537 - INFO - Epoch: 40, Training Loss: 0.5720
2025-11-12 02:09:21,990 - INFO - Epoch: 41, Training Loss: 0.5347
2025-11-12 02:09:29,949 - INFO - Epoch: 42, Training Loss: 0.5045
2025-11-12 02:09:38,639 - INFO - Epoch: 43, Training Loss: 0.5088
2025-11-12 02:09:46,893 - INFO - Epoch: 44, Training Loss: 0.4850
2025-11-12 02:09:54,812 - INFO - Epoch: 45, Training Loss: 0.4939
2025-11-12 02:10:02,415 - INFO - Epoch: 46, Training Loss: 0.5023
2025-11-12 02:10:10,207 - INFO - Epoch: 47, Training Loss: 0.5281
2025-11-12 02:10:17,732 - INFO - Epoch: 48, Training Loss: 0.4897
2025-11-12 02:10:26,560 - INFO - Epoch: 49, Training Loss: 0.4920
2025-11-12 02:10:34,790 - INFO - Epoch: 50, Training Loss: 0.4942
2025-11-12 02:10:42,549 - INFO - Epoch: 51, Training Loss: 0.4998
2025-11-12 02:10:50,495 - INFO - Epoch: 52, Training Loss: 0.5004
2025-11-12 02:10:58,748 - INFO - Epoch: 53, Training Loss: 0.5011
2025-11-12 02:11:07,051 - INFO - Epoch: 54, Training Loss: 0.5257
2025-11-12 02:11:14,863 - INFO - Epoch: 55, Training Loss: 0.4887
2025-11-12 02:11:23,332 - INFO - Epoch: 56, Training Loss: 0.4813
2025-11-12 02:11:31,584 - INFO - Epoch: 57, Training Loss: 0.4771
2025-11-12 02:11:39,949 - INFO - Epoch: 58, Training Loss: 0.5276
2025-11-12 02:11:47,809 - INFO - Epoch: 59, Training Loss: 0.4913
2025-11-12 02:11:55,183 - INFO - Epoch: 60, Training Loss: 0.4868
2025-11-12 02:12:03,557 - INFO - Epoch: 61, Training Loss: 0.4722
2025-11-12 02:12:11,887 - INFO - Epoch: 62, Training Loss: 0.4687
2025-11-12 02:12:20,109 - INFO - Epoch: 63, Training Loss: 0.4788
2025-11-12 02:12:27,957 - INFO - Epoch: 64, Training Loss: 0.4844
2025-11-12 02:12:36,131 - INFO - Epoch: 65, Training Loss: 0.4748
2025-11-12 02:12:43,363 - INFO - Epoch: 66, Training Loss: 0.4794
2025-11-12 02:12:51,099 - INFO - Epoch: 67, Training Loss: 0.4655
2025-11-12 02:12:59,916 - INFO - Epoch: 68, Training Loss: 0.4727
2025-11-12 02:13:08,798 - INFO - Epoch: 69, Training Loss: 0.4749
2025-11-12 02:13:17,026 - INFO - Epoch: 70, Training Loss: 0.4716
2025-11-12 02:13:25,453 - INFO - Epoch: 71, Training Loss: 0.4591
2025-11-12 02:13:33,550 - INFO - Epoch: 72, Training Loss: 0.4689
2025-11-12 02:13:41,099 - INFO - Epoch: 73, Training Loss: 0.4768
2025-11-12 02:13:48,720 - INFO - Epoch: 74, Training Loss: 0.4795
2025-11-12 02:13:56,307 - INFO - Epoch: 75, Training Loss: 0.4714
2025-11-12 02:14:04,257 - INFO - Epoch: 76, Training Loss: 0.4771
2025-11-12 02:14:11,876 - INFO - Epoch: 77, Training Loss: 0.4877
2025-11-12 02:14:19,421 - INFO - Epoch: 78, Training Loss: 0.4709
2025-11-12 02:14:27,377 - INFO - Epoch: 79, Training Loss: 0.4767
2025-11-12 02:14:35,759 - INFO - Epoch: 80, Training Loss: 0.4774
2025-11-12 02:14:43,151 - INFO - Epoch: 81, Training Loss: 0.5187
2025-11-12 02:14:50,692 - INFO - Epoch: 82, Training Loss: 0.4757
2025-11-12 02:14:58,775 - INFO - Epoch: 83, Training Loss: 0.5411
2025-11-12 02:15:06,465 - INFO - Epoch: 84, Training Loss: 0.4834
2025-11-12 02:15:14,273 - INFO - Epoch: 85, Training Loss: 0.4751
2025-11-12 02:15:22,287 - INFO - Epoch: 86, Training Loss: 0.4629
2025-11-12 02:15:29,823 - INFO - Epoch: 87, Training Loss: 0.4734
2025-11-12 02:15:37,230 - INFO - Epoch: 88, Training Loss: 0.4706
2025-11-12 02:15:45,252 - INFO - Epoch: 89, Training Loss: 0.4736
2025-11-12 02:15:53,486 - INFO - Epoch: 90, Training Loss: 0.4639
2025-11-12 02:16:01,192 - INFO - Epoch: 91, Training Loss: 0.4650
2025-11-12 02:16:09,036 - INFO - Epoch: 92, Training Loss: 0.4631
2025-11-12 02:16:17,586 - INFO - Epoch: 93, Training Loss: 0.4824
2025-11-12 02:16:25,315 - INFO - Epoch: 94, Training Loss: 0.4847
2025-11-12 02:16:33,601 - INFO - Epoch: 95, Training Loss: 0.4659
2025-11-12 02:16:41,500 - INFO - Epoch: 96, Training Loss: 0.5881
2025-11-12 02:16:49,333 - INFO - Epoch: 97, Training Loss: 0.4795
2025-11-12 02:16:57,343 - INFO - Epoch: 98, Training Loss: 0.4755
2025-11-12 02:17:05,131 - INFO - Epoch: 99, Training Loss: 0.4702
2025-11-12 02:17:13,030 - INFO - Epoch: 100, Training Loss: 0.4699
2025-11-12 02:17:13,030 - INFO - Training completed for Trial 1 CV 3

