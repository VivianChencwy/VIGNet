2025-11-12 12:16:59,316 - INFO - Log file: ./logs/trial10_cv4_RGS_20251112_121659.log
2025-11-12 12:16:59,316 - INFO - START TRAINING TRIAL 10 CV 4 - Task: RGS
2025-11-12 12:16:59,316 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 12:16:59,316 - INFO - Loading dataset...
2025-11-12 12:16:59,407 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 12:16:59,407 - INFO - Initializing VIGNet model...
2025-11-12 12:16:59,410 - INFO - Number of batch iterations per epoch: 113
2025-11-12 12:17:07,112 - INFO - Epoch: 1, Training Loss: 1.1271
2025-11-12 12:17:15,292 - INFO - Epoch: 2, Training Loss: 0.7816
2025-11-12 12:17:23,042 - INFO - Epoch: 3, Training Loss: 0.6945
2025-11-12 12:17:31,273 - INFO - Epoch: 4, Training Loss: 0.6875
2025-11-12 12:17:39,433 - INFO - Epoch: 5, Training Loss: 0.6889
2025-11-12 12:17:46,769 - INFO - Epoch: 6, Training Loss: 0.6872
2025-11-12 12:17:54,399 - INFO - Epoch: 7, Training Loss: 0.6852
2025-11-12 12:18:02,744 - INFO - Epoch: 8, Training Loss: 0.6848
2025-11-12 12:18:11,258 - INFO - Epoch: 9, Training Loss: 0.6856
2025-11-12 12:18:19,669 - INFO - Epoch: 10, Training Loss: 0.6853
2025-11-12 12:18:27,893 - INFO - Epoch: 11, Training Loss: 0.6853
2025-11-12 12:18:36,970 - INFO - Epoch: 12, Training Loss: 0.6850
2025-11-12 12:18:45,406 - INFO - Epoch: 13, Training Loss: 0.6839
2025-11-12 12:18:53,675 - INFO - Epoch: 14, Training Loss: 0.6857
2025-11-12 12:19:01,484 - INFO - Epoch: 15, Training Loss: 0.6846
2025-11-12 12:19:09,781 - INFO - Epoch: 16, Training Loss: 0.6835
2025-11-12 12:19:17,983 - INFO - Epoch: 17, Training Loss: 0.6846
2025-11-12 12:19:25,529 - INFO - Epoch: 18, Training Loss: 0.6841
2025-11-12 12:19:33,783 - INFO - Epoch: 19, Training Loss: 0.6848
2025-11-12 12:19:41,521 - INFO - Epoch: 20, Training Loss: 0.6850
2025-11-12 12:19:49,391 - INFO - Epoch: 21, Training Loss: 0.6846
2025-11-12 12:19:56,794 - INFO - Epoch: 22, Training Loss: 0.6851
2025-11-12 12:20:05,241 - INFO - Epoch: 23, Training Loss: 0.6857
2025-11-12 12:20:13,378 - INFO - Epoch: 24, Training Loss: 0.6839
2025-11-12 12:20:20,861 - INFO - Epoch: 25, Training Loss: 0.6851
2025-11-12 12:20:28,300 - INFO - Epoch: 26, Training Loss: 0.6842
2025-11-12 12:20:35,780 - INFO - Epoch: 27, Training Loss: 0.6844
2025-11-12 12:20:43,529 - INFO - Epoch: 28, Training Loss: 0.6837
2025-11-12 12:20:51,445 - INFO - Epoch: 29, Training Loss: 0.6843
2025-11-12 12:20:58,804 - INFO - Epoch: 30, Training Loss: 0.6847
2025-11-12 12:21:06,229 - INFO - Epoch: 31, Training Loss: 0.6847
2025-11-12 12:21:14,120 - INFO - Epoch: 32, Training Loss: 0.6844
2025-11-12 12:21:22,142 - INFO - Epoch: 33, Training Loss: 0.6841
2025-11-12 12:21:30,757 - INFO - Epoch: 34, Training Loss: 0.6846
2025-11-12 12:21:37,922 - INFO - Epoch: 35, Training Loss: 0.6843
2025-11-12 12:21:46,377 - INFO - Epoch: 36, Training Loss: 0.6840
2025-11-12 12:21:55,167 - INFO - Epoch: 37, Training Loss: 0.6839
2025-11-12 12:22:03,013 - INFO - Epoch: 38, Training Loss: 0.6850
2025-11-12 12:22:11,100 - INFO - Epoch: 39, Training Loss: 0.6850
2025-11-12 12:22:18,778 - INFO - Epoch: 40, Training Loss: 0.6838
2025-11-12 12:22:25,879 - INFO - Epoch: 41, Training Loss: 0.6840
2025-11-12 12:22:33,938 - INFO - Epoch: 42, Training Loss: 0.6841
2025-11-12 12:22:41,617 - INFO - Epoch: 43, Training Loss: 0.6844
2025-11-12 12:22:50,393 - INFO - Epoch: 44, Training Loss: 0.6855
2025-11-12 12:22:59,069 - INFO - Epoch: 45, Training Loss: 0.6841
2025-11-12 12:23:06,976 - INFO - Epoch: 46, Training Loss: 0.6844
2025-11-12 12:23:14,611 - INFO - Epoch: 47, Training Loss: 0.6837
2025-11-12 12:23:21,695 - INFO - Epoch: 48, Training Loss: 0.6843
2025-11-12 12:23:29,128 - INFO - Epoch: 49, Training Loss: 0.6851
2025-11-12 12:23:36,920 - INFO - Epoch: 50, Training Loss: 0.6847
2025-11-12 12:23:44,985 - INFO - Epoch: 51, Training Loss: 0.6846
2025-11-12 12:23:53,157 - INFO - Epoch: 52, Training Loss: 0.6846
2025-11-12 12:24:01,075 - INFO - Epoch: 53, Training Loss: 0.6854
2025-11-12 12:24:08,736 - INFO - Epoch: 54, Training Loss: 0.6843
2025-11-12 12:24:16,208 - INFO - Epoch: 55, Training Loss: 0.6852
2025-11-12 12:24:24,919 - INFO - Epoch: 56, Training Loss: 0.6846
2025-11-12 12:24:33,031 - INFO - Epoch: 57, Training Loss: 0.6839
2025-11-12 12:24:40,963 - INFO - Epoch: 58, Training Loss: 0.6842
2025-11-12 12:24:48,610 - INFO - Epoch: 59, Training Loss: 0.6843
2025-11-12 12:24:56,465 - INFO - Epoch: 60, Training Loss: 0.6847
2025-11-12 12:25:04,183 - INFO - Epoch: 61, Training Loss: 0.6839
2025-11-12 12:25:12,663 - INFO - Epoch: 62, Training Loss: 0.6845
2025-11-12 12:25:20,107 - INFO - Epoch: 63, Training Loss: 0.6856
2025-11-12 12:25:27,131 - INFO - Epoch: 64, Training Loss: 0.6846
2025-11-12 12:25:35,340 - INFO - Epoch: 65, Training Loss: 0.6847
2025-11-12 12:25:42,826 - INFO - Epoch: 66, Training Loss: 0.6846
2025-11-12 12:25:51,190 - INFO - Epoch: 67, Training Loss: 0.6841
2025-11-12 12:25:59,555 - INFO - Epoch: 68, Training Loss: 0.6851
2025-11-12 12:26:07,061 - INFO - Epoch: 69, Training Loss: 0.6849
2025-11-12 12:26:14,878 - INFO - Epoch: 70, Training Loss: 0.6847
2025-11-12 12:26:23,102 - INFO - Epoch: 71, Training Loss: 0.6848
2025-11-12 12:26:31,177 - INFO - Epoch: 72, Training Loss: 0.6837
2025-11-12 12:26:39,211 - INFO - Epoch: 73, Training Loss: 0.6850
2025-11-12 12:26:47,104 - INFO - Epoch: 74, Training Loss: 0.6845
2025-11-12 12:26:55,097 - INFO - Epoch: 75, Training Loss: 0.6845
2025-11-12 12:27:02,731 - INFO - Epoch: 76, Training Loss: 0.6846
2025-11-12 12:27:11,432 - INFO - Epoch: 77, Training Loss: 0.6849
2025-11-12 12:27:20,115 - INFO - Epoch: 78, Training Loss: 0.6840
2025-11-12 12:27:28,137 - INFO - Epoch: 79, Training Loss: 0.6859
2025-11-12 12:27:36,694 - INFO - Epoch: 80, Training Loss: 0.6862
2025-11-12 12:27:44,537 - INFO - Epoch: 81, Training Loss: 0.6837
2025-11-12 12:27:52,974 - INFO - Epoch: 82, Training Loss: 0.6842
2025-11-12 12:28:01,085 - INFO - Epoch: 83, Training Loss: 0.6839
2025-11-12 12:28:09,941 - INFO - Epoch: 84, Training Loss: 0.6845
2025-11-12 12:28:17,683 - INFO - Epoch: 85, Training Loss: 0.6855
2025-11-12 12:28:25,679 - INFO - Epoch: 86, Training Loss: 0.6841
2025-11-12 12:28:33,148 - INFO - Epoch: 87, Training Loss: 0.6843
2025-11-12 12:28:41,033 - INFO - Epoch: 88, Training Loss: 0.6834
2025-11-12 12:28:48,829 - INFO - Epoch: 89, Training Loss: 0.6848
2025-11-12 12:28:56,517 - INFO - Epoch: 90, Training Loss: 0.6843
2025-11-12 12:29:04,210 - INFO - Epoch: 91, Training Loss: 0.6842
2025-11-12 12:29:12,747 - INFO - Epoch: 92, Training Loss: 0.6850
2025-11-12 12:29:21,188 - INFO - Epoch: 93, Training Loss: 0.6845
2025-11-12 12:29:29,235 - INFO - Epoch: 94, Training Loss: 0.6839
2025-11-12 12:29:37,052 - INFO - Epoch: 95, Training Loss: 0.6855
2025-11-12 12:29:44,557 - INFO - Epoch: 96, Training Loss: 0.6841
2025-11-12 12:29:52,621 - INFO - Epoch: 97, Training Loss: 0.6841
2025-11-12 12:30:00,285 - INFO - Epoch: 98, Training Loss: 0.6844
2025-11-12 12:30:08,120 - INFO - Epoch: 99, Training Loss: 0.6836
2025-11-12 12:30:16,510 - INFO - Epoch: 100, Training Loss: 0.6849
2025-11-12 12:30:16,510 - INFO - Training completed for Trial 10 CV 4

