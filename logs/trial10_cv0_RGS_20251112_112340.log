2025-11-12 11:23:40,543 - INFO - Log file: ./logs/trial10_cv0_RGS_20251112_112340.log
2025-11-12 11:23:40,543 - INFO - START TRAINING TRIAL 10 CV 0 - Task: RGS
2025-11-12 11:23:40,543 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 11:23:40,543 - INFO - Loading dataset...
2025-11-12 11:23:40,740 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 11:23:40,740 - INFO - Initializing VIGNet model...
2025-11-12 11:23:40,743 - INFO - Number of batch iterations per epoch: 113
2025-11-12 11:23:49,358 - INFO - Epoch: 1, Training Loss: 0.9362
2025-11-12 11:23:57,941 - INFO - Epoch: 2, Training Loss: 0.6976
2025-11-12 11:24:05,848 - INFO - Epoch: 3, Training Loss: 0.6916
2025-11-12 11:24:14,267 - INFO - Epoch: 4, Training Loss: 0.6892
2025-11-12 11:24:22,000 - INFO - Epoch: 5, Training Loss: 0.6881
2025-11-12 11:24:30,037 - INFO - Epoch: 6, Training Loss: 0.6861
2025-11-12 11:24:38,305 - INFO - Epoch: 7, Training Loss: 0.6857
2025-11-12 11:24:46,634 - INFO - Epoch: 8, Training Loss: 0.6862
2025-11-12 11:24:55,234 - INFO - Epoch: 9, Training Loss: 0.6852
2025-11-12 11:25:03,577 - INFO - Epoch: 10, Training Loss: 0.6846
2025-11-12 11:25:11,730 - INFO - Epoch: 11, Training Loss: 0.6850
2025-11-12 11:25:19,883 - INFO - Epoch: 12, Training Loss: 0.6860
2025-11-12 11:25:28,005 - INFO - Epoch: 13, Training Loss: 0.6841
2025-11-12 11:25:35,444 - INFO - Epoch: 14, Training Loss: 0.6848
2025-11-12 11:25:43,691 - INFO - Epoch: 15, Training Loss: 0.6860
2025-11-12 11:25:51,736 - INFO - Epoch: 16, Training Loss: 0.6854
2025-11-12 11:25:59,273 - INFO - Epoch: 17, Training Loss: 0.6850
2025-11-12 11:26:06,631 - INFO - Epoch: 18, Training Loss: 0.6862
2025-11-12 11:26:14,769 - INFO - Epoch: 19, Training Loss: 0.6854
2025-11-12 11:26:22,284 - INFO - Epoch: 20, Training Loss: 0.6852
2025-11-12 11:26:30,350 - INFO - Epoch: 21, Training Loss: 0.6862
2025-11-12 11:26:39,005 - INFO - Epoch: 22, Training Loss: 0.6859
2025-11-12 11:26:47,821 - INFO - Epoch: 23, Training Loss: 0.6853
2025-11-12 11:26:56,010 - INFO - Epoch: 24, Training Loss: 0.6848
2025-11-12 11:27:04,190 - INFO - Epoch: 25, Training Loss: 0.6857
2025-11-12 11:27:12,310 - INFO - Epoch: 26, Training Loss: 0.6854
2025-11-12 11:27:19,890 - INFO - Epoch: 27, Training Loss: 0.6857
2025-11-12 11:27:28,429 - INFO - Epoch: 28, Training Loss: 0.6853
2025-11-12 11:27:36,793 - INFO - Epoch: 29, Training Loss: 0.6849
2025-11-12 11:27:44,666 - INFO - Epoch: 30, Training Loss: 0.6854
2025-11-12 11:27:52,094 - INFO - Epoch: 31, Training Loss: 0.6846
2025-11-12 11:27:59,576 - INFO - Epoch: 32, Training Loss: 0.6846
2025-11-12 11:28:07,307 - INFO - Epoch: 33, Training Loss: 0.6856
2025-11-12 11:28:15,295 - INFO - Epoch: 34, Training Loss: 0.6856
2025-11-12 11:28:22,906 - INFO - Epoch: 35, Training Loss: 0.6859
2025-11-12 11:28:31,636 - INFO - Epoch: 36, Training Loss: 0.6845
2025-11-12 11:28:39,516 - INFO - Epoch: 37, Training Loss: 0.6852
2025-11-12 11:28:47,556 - INFO - Epoch: 38, Training Loss: 0.6853
2025-11-12 11:28:55,102 - INFO - Epoch: 39, Training Loss: 0.6847
2025-11-12 11:29:03,238 - INFO - Epoch: 40, Training Loss: 0.6846
2025-11-12 11:29:12,213 - INFO - Epoch: 41, Training Loss: 0.6851
2025-11-12 11:29:20,223 - INFO - Epoch: 42, Training Loss: 0.6857
2025-11-12 11:29:28,523 - INFO - Epoch: 43, Training Loss: 0.6850
2025-11-12 11:29:36,291 - INFO - Epoch: 44, Training Loss: 0.6850
2025-11-12 11:29:45,139 - INFO - Epoch: 45, Training Loss: 0.6859
2025-11-12 11:29:52,466 - INFO - Epoch: 46, Training Loss: 0.6851
2025-11-12 11:30:01,019 - INFO - Epoch: 47, Training Loss: 0.6869
2025-11-12 11:30:09,588 - INFO - Epoch: 48, Training Loss: 0.6849
2025-11-12 11:30:17,726 - INFO - Epoch: 49, Training Loss: 0.6865
2025-11-12 11:30:25,187 - INFO - Epoch: 50, Training Loss: 0.6847
2025-11-12 11:30:33,292 - INFO - Epoch: 51, Training Loss: 0.6848
2025-11-12 11:30:40,627 - INFO - Epoch: 52, Training Loss: 0.6849
2025-11-12 11:30:47,984 - INFO - Epoch: 53, Training Loss: 0.6848
2025-11-12 11:30:56,003 - INFO - Epoch: 54, Training Loss: 0.6860
2025-11-12 11:31:04,266 - INFO - Epoch: 55, Training Loss: 0.6850
2025-11-12 11:31:12,872 - INFO - Epoch: 56, Training Loss: 0.6844
2025-11-12 11:31:21,406 - INFO - Epoch: 57, Training Loss: 0.6859
2025-11-12 11:31:29,873 - INFO - Epoch: 58, Training Loss: 0.6846
2025-11-12 11:31:38,028 - INFO - Epoch: 59, Training Loss: 0.6855
2025-11-12 11:31:45,555 - INFO - Epoch: 60, Training Loss: 0.6855
2025-11-12 11:31:53,396 - INFO - Epoch: 61, Training Loss: 0.6849
2025-11-12 11:32:01,348 - INFO - Epoch: 62, Training Loss: 0.6855
2025-11-12 11:32:09,617 - INFO - Epoch: 63, Training Loss: 0.6849
2025-11-12 11:32:17,143 - INFO - Epoch: 64, Training Loss: 0.6855
2025-11-12 11:32:24,871 - INFO - Epoch: 65, Training Loss: 0.6848
2025-11-12 11:32:33,374 - INFO - Epoch: 66, Training Loss: 0.6847
2025-11-12 11:32:41,946 - INFO - Epoch: 67, Training Loss: 0.6857
2025-11-12 11:32:50,652 - INFO - Epoch: 68, Training Loss: 0.6850
2025-11-12 11:32:58,605 - INFO - Epoch: 69, Training Loss: 0.6863
2025-11-12 11:33:07,069 - INFO - Epoch: 70, Training Loss: 0.6852
2025-11-12 11:33:14,651 - INFO - Epoch: 71, Training Loss: 0.6861
2025-11-12 11:33:23,645 - INFO - Epoch: 72, Training Loss: 0.6853
2025-11-12 11:33:31,476 - INFO - Epoch: 73, Training Loss: 0.6849
2025-11-12 11:33:39,601 - INFO - Epoch: 74, Training Loss: 0.6850
2025-11-12 11:33:47,965 - INFO - Epoch: 75, Training Loss: 0.6852
2025-11-12 11:33:56,279 - INFO - Epoch: 76, Training Loss: 0.6862
2025-11-12 11:34:04,168 - INFO - Epoch: 77, Training Loss: 0.6842
2025-11-12 11:34:11,381 - INFO - Epoch: 78, Training Loss: 0.6853
2025-11-12 11:34:19,263 - INFO - Epoch: 79, Training Loss: 0.6857
2025-11-12 11:34:26,996 - INFO - Epoch: 80, Training Loss: 0.6847
2025-11-12 11:34:34,906 - INFO - Epoch: 81, Training Loss: 0.6860
2025-11-12 11:34:42,661 - INFO - Epoch: 82, Training Loss: 0.6852
2025-11-12 11:34:51,023 - INFO - Epoch: 83, Training Loss: 0.6841
2025-11-12 11:34:58,566 - INFO - Epoch: 84, Training Loss: 0.6842
2025-11-12 11:35:06,382 - INFO - Epoch: 85, Training Loss: 0.6843
2025-11-12 11:35:14,742 - INFO - Epoch: 86, Training Loss: 0.6841
2025-11-12 11:35:23,338 - INFO - Epoch: 87, Training Loss: 0.6840
2025-11-12 11:35:32,060 - INFO - Epoch: 88, Training Loss: 0.6848
2025-11-12 11:35:39,275 - INFO - Epoch: 89, Training Loss: 0.6836
2025-11-12 11:35:46,529 - INFO - Epoch: 90, Training Loss: 0.6838
2025-11-12 11:35:53,990 - INFO - Epoch: 91, Training Loss: 0.6832
2025-11-12 11:36:01,682 - INFO - Epoch: 92, Training Loss: 0.6838
2025-11-12 11:36:08,904 - INFO - Epoch: 93, Training Loss: 0.6826
2025-11-12 11:36:16,354 - INFO - Epoch: 94, Training Loss: 0.6806
2025-11-12 11:36:24,282 - INFO - Epoch: 95, Training Loss: 0.6817
2025-11-12 11:36:32,499 - INFO - Epoch: 96, Training Loss: 0.6808
2025-11-12 11:36:40,924 - INFO - Epoch: 97, Training Loss: 0.6800
2025-11-12 11:36:48,864 - INFO - Epoch: 98, Training Loss: 0.6812
2025-11-12 11:36:56,260 - INFO - Epoch: 99, Training Loss: 0.6788
2025-11-12 11:37:03,451 - INFO - Epoch: 100, Training Loss: 0.6767
2025-11-12 11:37:03,451 - INFO - Training completed for Trial 10 CV 0

