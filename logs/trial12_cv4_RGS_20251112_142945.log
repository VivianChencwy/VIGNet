2025-11-12 14:29:45,795 - INFO - Log file: ./logs/trial12_cv4_RGS_20251112_142945.log
2025-11-12 14:29:45,795 - INFO - START TRAINING TRIAL 12 CV 4 - Task: RGS
2025-11-12 14:29:45,795 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 14:29:45,796 - INFO - Loading dataset...
2025-11-12 14:29:45,983 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 14:29:45,983 - INFO - Initializing VIGNet model...
2025-11-12 14:29:45,986 - INFO - Number of batch iterations per epoch: 113
2025-11-12 14:29:54,610 - INFO - Epoch: 1, Training Loss: 0.9132
2025-11-12 14:30:01,812 - INFO - Epoch: 2, Training Loss: 0.7372
2025-11-12 14:30:10,528 - INFO - Epoch: 3, Training Loss: 0.6727
2025-11-12 14:30:18,712 - INFO - Epoch: 4, Training Loss: 0.6803
2025-11-12 14:30:26,376 - INFO - Epoch: 5, Training Loss: 0.6683
2025-11-12 14:30:34,273 - INFO - Epoch: 6, Training Loss: 0.6712
2025-11-12 14:30:42,438 - INFO - Epoch: 7, Training Loss: 0.6731
2025-11-12 14:30:50,150 - INFO - Epoch: 8, Training Loss: 0.6752
2025-11-12 14:30:58,014 - INFO - Epoch: 9, Training Loss: 0.6734
2025-11-12 14:31:06,845 - INFO - Epoch: 10, Training Loss: 0.6698
2025-11-12 14:31:14,799 - INFO - Epoch: 11, Training Loss: 0.6742
2025-11-12 14:31:23,166 - INFO - Epoch: 12, Training Loss: 0.6689
2025-11-12 14:31:31,472 - INFO - Epoch: 13, Training Loss: 0.6659
2025-11-12 14:31:39,406 - INFO - Epoch: 14, Training Loss: 0.6631
2025-11-12 14:31:48,333 - INFO - Epoch: 15, Training Loss: 0.6695
2025-11-12 14:31:56,182 - INFO - Epoch: 16, Training Loss: 0.6525
2025-11-12 14:32:04,052 - INFO - Epoch: 17, Training Loss: 0.6561
2025-11-12 14:32:12,621 - INFO - Epoch: 18, Training Loss: 0.6573
2025-11-12 14:32:20,825 - INFO - Epoch: 19, Training Loss: 0.6492
2025-11-12 14:32:28,826 - INFO - Epoch: 20, Training Loss: 0.6356
2025-11-12 14:32:37,006 - INFO - Epoch: 21, Training Loss: 0.6120
2025-11-12 14:32:45,009 - INFO - Epoch: 22, Training Loss: 0.6239
2025-11-12 14:32:52,610 - INFO - Epoch: 23, Training Loss: 0.6467
2025-11-12 14:33:01,189 - INFO - Epoch: 24, Training Loss: 0.5555
2025-11-12 14:33:10,005 - INFO - Epoch: 25, Training Loss: 0.6199
2025-11-12 14:33:17,819 - INFO - Epoch: 26, Training Loss: 0.5644
2025-11-12 14:33:25,662 - INFO - Epoch: 27, Training Loss: 0.5563
2025-11-12 14:33:33,657 - INFO - Epoch: 28, Training Loss: 0.5410
2025-11-12 14:33:41,356 - INFO - Epoch: 29, Training Loss: 0.6019
2025-11-12 14:33:48,684 - INFO - Epoch: 30, Training Loss: 0.5424
2025-11-12 14:33:56,505 - INFO - Epoch: 31, Training Loss: 0.5532
2025-11-12 14:34:03,853 - INFO - Epoch: 32, Training Loss: 0.5603
2025-11-12 14:34:12,228 - INFO - Epoch: 33, Training Loss: 0.5265
2025-11-12 14:34:20,221 - INFO - Epoch: 34, Training Loss: 0.4898
2025-11-12 14:34:27,658 - INFO - Epoch: 35, Training Loss: 0.5174
2025-11-12 14:34:35,235 - INFO - Epoch: 36, Training Loss: 0.6808
2025-11-12 14:34:42,988 - INFO - Epoch: 37, Training Loss: 0.5565
2025-11-12 14:34:51,000 - INFO - Epoch: 38, Training Loss: 0.5001
2025-11-12 14:34:59,551 - INFO - Epoch: 39, Training Loss: 0.5067
2025-11-12 14:35:07,522 - INFO - Epoch: 40, Training Loss: 0.4950
2025-11-12 14:35:15,431 - INFO - Epoch: 41, Training Loss: 0.5985
2025-11-12 14:35:22,793 - INFO - Epoch: 42, Training Loss: 0.6510
2025-11-12 14:35:30,429 - INFO - Epoch: 43, Training Loss: 0.6499
2025-11-12 14:35:38,102 - INFO - Epoch: 44, Training Loss: 0.6471
2025-11-12 14:35:46,249 - INFO - Epoch: 45, Training Loss: 0.6379
2025-11-12 14:35:54,117 - INFO - Epoch: 46, Training Loss: 0.6281
2025-11-12 14:36:02,598 - INFO - Epoch: 47, Training Loss: 0.5778
2025-11-12 14:36:09,855 - INFO - Epoch: 48, Training Loss: 0.5495
2025-11-12 14:36:18,184 - INFO - Epoch: 49, Training Loss: 0.4866
2025-11-12 14:36:26,275 - INFO - Epoch: 50, Training Loss: 0.5262
2025-11-12 14:36:34,269 - INFO - Epoch: 51, Training Loss: 0.5311
2025-11-12 14:36:42,319 - INFO - Epoch: 52, Training Loss: 0.5164
2025-11-12 14:36:50,446 - INFO - Epoch: 53, Training Loss: 0.5348
2025-11-12 14:36:58,809 - INFO - Epoch: 54, Training Loss: 0.4948
2025-11-12 14:37:07,294 - INFO - Epoch: 55, Training Loss: 0.4767
2025-11-12 14:37:14,935 - INFO - Epoch: 56, Training Loss: 0.4786
2025-11-12 14:37:22,599 - INFO - Epoch: 57, Training Loss: 4.3859
2025-11-12 14:37:30,929 - INFO - Epoch: 58, Training Loss: 7.3807
2025-11-12 14:37:38,484 - INFO - Epoch: 59, Training Loss: 0.5946
2025-11-12 14:37:45,756 - INFO - Epoch: 60, Training Loss: 0.5996
2025-11-12 14:37:54,059 - INFO - Epoch: 61, Training Loss: 0.5654
2025-11-12 14:38:02,521 - INFO - Epoch: 62, Training Loss: 0.5734
2025-11-12 14:38:10,365 - INFO - Epoch: 63, Training Loss: 0.5629
2025-11-12 14:38:18,412 - INFO - Epoch: 64, Training Loss: 0.5442
2025-11-12 14:38:26,146 - INFO - Epoch: 65, Training Loss: 0.5589
2025-11-12 14:38:34,023 - INFO - Epoch: 66, Training Loss: 0.5623
2025-11-12 14:38:42,285 - INFO - Epoch: 67, Training Loss: 0.5246
2025-11-12 14:38:51,183 - INFO - Epoch: 68, Training Loss: 0.5450
2025-11-12 14:38:59,900 - INFO - Epoch: 69, Training Loss: 0.5236
2025-11-12 14:39:08,337 - INFO - Epoch: 70, Training Loss: 0.5221
2025-11-12 14:39:16,939 - INFO - Epoch: 71, Training Loss: 0.5055
2025-11-12 14:39:24,892 - INFO - Epoch: 72, Training Loss: 0.5042
2025-11-12 14:39:33,062 - INFO - Epoch: 73, Training Loss: 0.5276
2025-11-12 14:39:41,206 - INFO - Epoch: 74, Training Loss: 0.6161
2025-11-12 14:39:51,272 - INFO - Epoch: 75, Training Loss: 0.5006
2025-11-12 14:40:47,021 - INFO - Epoch: 76, Training Loss: 0.5208
2025-11-12 15:01:22,193 - INFO - Epoch: 77, Training Loss: 0.4838
2025-11-12 17:27:08,375 - INFO - Epoch: 78, Training Loss: 0.4957
2025-11-12 17:27:19,196 - INFO - Epoch: 79, Training Loss: 0.4983
2025-11-12 17:29:42,785 - INFO - Epoch: 80, Training Loss: 0.4638
2025-11-12 22:50:17,360 - INFO - Epoch: 81, Training Loss: 0.4741
2025-11-13 00:02:58,356 - INFO - Epoch: 82, Training Loss: 0.4850
2025-11-13 00:03:07,882 - INFO - Epoch: 83, Training Loss: 0.4930
2025-11-13 00:09:27,734 - INFO - Epoch: 84, Training Loss: 0.5065
2025-11-13 01:30:14,878 - INFO - Epoch: 85, Training Loss: 0.5221
2025-11-13 08:56:57,528 - INFO - Epoch: 86, Training Loss: 0.4799
2025-11-13 08:57:06,240 - INFO - Epoch: 87, Training Loss: 0.4724
2025-11-13 08:57:17,874 - INFO - Epoch: 88, Training Loss: 0.4809
2025-11-13 08:57:27,121 - INFO - Epoch: 89, Training Loss: 0.5218
2025-11-13 08:57:39,348 - INFO - Epoch: 90, Training Loss: 0.4758
2025-11-13 08:57:53,055 - INFO - Epoch: 91, Training Loss: 0.4651
2025-11-13 08:58:03,460 - INFO - Epoch: 92, Training Loss: 0.4527
2025-11-13 08:58:14,183 - INFO - Epoch: 93, Training Loss: 0.4954
2025-11-13 08:58:28,307 - INFO - Epoch: 94, Training Loss: 0.4742
2025-11-13 08:58:41,583 - INFO - Epoch: 95, Training Loss: 0.4748
2025-11-13 08:58:54,076 - INFO - Epoch: 96, Training Loss: 0.4902
2025-11-13 08:59:07,797 - INFO - Epoch: 97, Training Loss: 0.4764
2025-11-13 08:59:17,393 - INFO - Epoch: 98, Training Loss: 0.5386
2025-11-13 08:59:31,516 - INFO - Epoch: 99, Training Loss: 0.4878
2025-11-13 08:59:42,037 - INFO - Epoch: 100, Training Loss: 0.4681
2025-11-13 08:59:42,037 - INFO - Training completed for Trial 12 CV 4

