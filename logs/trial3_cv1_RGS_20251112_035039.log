2025-11-12 03:50:39,166 - INFO - Log file: ./logs/trial3_cv1_RGS_20251112_035039.log
2025-11-12 03:50:39,166 - INFO - START TRAINING TRIAL 3 CV 1 - Task: RGS
2025-11-12 03:50:39,166 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 03:50:39,166 - INFO - Loading dataset...
2025-11-12 03:50:39,258 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 03:50:39,258 - INFO - Initializing VIGNet model...
2025-11-12 03:50:39,261 - INFO - Number of batch iterations per epoch: 113
2025-11-12 03:50:46,697 - INFO - Epoch: 1, Training Loss: 0.8938
2025-11-12 03:50:54,566 - INFO - Epoch: 2, Training Loss: 0.7326
2025-11-12 03:51:02,334 - INFO - Epoch: 3, Training Loss: 0.7081
2025-11-12 03:51:10,551 - INFO - Epoch: 4, Training Loss: 0.6998
2025-11-12 03:51:18,103 - INFO - Epoch: 5, Training Loss: 0.7017
2025-11-12 03:51:26,400 - INFO - Epoch: 6, Training Loss: 0.7008
2025-11-12 03:51:34,165 - INFO - Epoch: 7, Training Loss: 0.6973
2025-11-12 03:51:41,412 - INFO - Epoch: 8, Training Loss: 0.6950
2025-11-12 03:51:48,953 - INFO - Epoch: 9, Training Loss: 0.6959
2025-11-12 03:51:57,834 - INFO - Epoch: 10, Training Loss: 0.6968
2025-11-12 03:52:05,496 - INFO - Epoch: 11, Training Loss: 0.6945
2025-11-12 03:52:14,434 - INFO - Epoch: 12, Training Loss: 0.6950
2025-11-12 03:52:22,091 - INFO - Epoch: 13, Training Loss: 0.6939
2025-11-12 03:52:30,121 - INFO - Epoch: 14, Training Loss: 0.6972
2025-11-12 03:52:37,826 - INFO - Epoch: 15, Training Loss: 0.6956
2025-11-12 03:52:45,600 - INFO - Epoch: 16, Training Loss: 0.6948
2025-11-12 03:52:54,224 - INFO - Epoch: 17, Training Loss: 0.6942
2025-11-12 03:53:02,257 - INFO - Epoch: 18, Training Loss: 0.6945
2025-11-12 03:53:10,771 - INFO - Epoch: 19, Training Loss: 0.6941
2025-11-12 03:53:19,083 - INFO - Epoch: 20, Training Loss: 0.6946
2025-11-12 03:53:26,987 - INFO - Epoch: 21, Training Loss: 0.6956
2025-11-12 03:53:35,346 - INFO - Epoch: 22, Training Loss: 0.6949
2025-11-12 03:53:43,525 - INFO - Epoch: 23, Training Loss: 0.6935
2025-11-12 03:53:50,806 - INFO - Epoch: 24, Training Loss: 0.6959
2025-11-12 03:53:58,200 - INFO - Epoch: 25, Training Loss: 0.6939
2025-11-12 03:54:05,810 - INFO - Epoch: 26, Training Loss: 0.6924
2025-11-12 03:54:13,672 - INFO - Epoch: 27, Training Loss: 0.6928
2025-11-12 03:54:21,876 - INFO - Epoch: 28, Training Loss: 0.6933
2025-11-12 03:54:29,384 - INFO - Epoch: 29, Training Loss: 0.6926
2025-11-12 03:54:37,207 - INFO - Epoch: 30, Training Loss: 0.6923
2025-11-12 03:54:45,319 - INFO - Epoch: 31, Training Loss: 0.6926
2025-11-12 03:54:52,822 - INFO - Epoch: 32, Training Loss: 0.6921
2025-11-12 03:55:00,985 - INFO - Epoch: 33, Training Loss: 0.6925
2025-11-12 03:55:10,358 - INFO - Epoch: 34, Training Loss: 0.6901
2025-11-12 03:55:17,422 - INFO - Epoch: 35, Training Loss: 0.6898
2025-11-12 03:55:24,930 - INFO - Epoch: 36, Training Loss: 0.6878
2025-11-12 03:55:34,133 - INFO - Epoch: 37, Training Loss: 0.6874
2025-11-12 03:55:42,373 - INFO - Epoch: 38, Training Loss: 0.6890
2025-11-12 03:55:51,044 - INFO - Epoch: 39, Training Loss: 0.6845
2025-11-12 03:55:58,743 - INFO - Epoch: 40, Training Loss: 0.6837
2025-11-12 03:56:06,671 - INFO - Epoch: 41, Training Loss: 0.6832
2025-11-12 03:56:15,374 - INFO - Epoch: 42, Training Loss: 0.6784
2025-11-12 03:56:23,851 - INFO - Epoch: 43, Training Loss: 0.6834
2025-11-12 03:56:31,953 - INFO - Epoch: 44, Training Loss: 0.6758
2025-11-12 03:56:39,660 - INFO - Epoch: 45, Training Loss: 0.6778
2025-11-12 03:56:47,990 - INFO - Epoch: 46, Training Loss: 0.6716
2025-11-12 03:56:55,272 - INFO - Epoch: 47, Training Loss: 0.6728
2025-11-12 03:57:03,059 - INFO - Epoch: 48, Training Loss: 0.6685
2025-11-12 03:57:11,199 - INFO - Epoch: 49, Training Loss: 0.6704
2025-11-12 03:57:19,410 - INFO - Epoch: 50, Training Loss: 0.6679
2025-11-12 03:57:27,325 - INFO - Epoch: 51, Training Loss: 0.6686
2025-11-12 03:57:35,754 - INFO - Epoch: 52, Training Loss: 0.6665
2025-11-12 03:57:43,607 - INFO - Epoch: 53, Training Loss: 0.6697
2025-11-12 03:57:51,702 - INFO - Epoch: 54, Training Loss: 0.6652
2025-11-12 03:57:59,840 - INFO - Epoch: 55, Training Loss: 0.6647
2025-11-12 03:58:08,879 - INFO - Epoch: 56, Training Loss: 0.6648
2025-11-12 03:58:16,572 - INFO - Epoch: 57, Training Loss: 0.6679
2025-11-12 03:58:24,782 - INFO - Epoch: 58, Training Loss: 0.6629
2025-11-12 03:58:32,724 - INFO - Epoch: 59, Training Loss: 0.6627
2025-11-12 03:58:40,707 - INFO - Epoch: 60, Training Loss: 0.6867
2025-11-12 03:58:48,408 - INFO - Epoch: 61, Training Loss: 0.6642
2025-11-12 03:58:56,467 - INFO - Epoch: 62, Training Loss: 0.6617
2025-11-12 03:59:04,018 - INFO - Epoch: 63, Training Loss: 0.6615
2025-11-12 03:59:12,163 - INFO - Epoch: 64, Training Loss: 0.6616
2025-11-12 03:59:20,541 - INFO - Epoch: 65, Training Loss: 0.6624
2025-11-12 03:59:29,121 - INFO - Epoch: 66, Training Loss: 0.6632
2025-11-12 03:59:36,787 - INFO - Epoch: 67, Training Loss: 0.6620
2025-11-12 03:59:44,682 - INFO - Epoch: 68, Training Loss: 0.6622
2025-11-12 03:59:53,043 - INFO - Epoch: 69, Training Loss: 0.6600
2025-11-12 04:00:00,713 - INFO - Epoch: 70, Training Loss: 0.6638
2025-11-12 04:00:08,608 - INFO - Epoch: 71, Training Loss: 0.6616
2025-11-12 04:00:16,570 - INFO - Epoch: 72, Training Loss: 0.6624
2025-11-12 04:00:25,618 - INFO - Epoch: 73, Training Loss: 0.6648
2025-11-12 04:00:34,161 - INFO - Epoch: 74, Training Loss: 0.6600
2025-11-12 04:00:41,745 - INFO - Epoch: 75, Training Loss: 0.6640
2025-11-12 04:00:49,516 - INFO - Epoch: 76, Training Loss: 0.6615
2025-11-12 04:00:57,958 - INFO - Epoch: 77, Training Loss: 0.6701
2025-11-12 04:01:05,665 - INFO - Epoch: 78, Training Loss: 0.6634
2025-11-12 04:01:13,657 - INFO - Epoch: 79, Training Loss: 0.6631
2025-11-12 04:01:22,291 - INFO - Epoch: 80, Training Loss: 0.6600
2025-11-12 04:01:30,989 - INFO - Epoch: 81, Training Loss: 0.6605
2025-11-12 04:01:39,116 - INFO - Epoch: 82, Training Loss: 0.6610
2025-11-12 04:01:46,693 - INFO - Epoch: 83, Training Loss: 0.6977
2025-11-12 04:01:54,541 - INFO - Epoch: 84, Training Loss: 0.6768
2025-11-12 04:02:01,715 - INFO - Epoch: 85, Training Loss: 0.6705
2025-11-12 04:02:09,806 - INFO - Epoch: 86, Training Loss: 0.6654
2025-11-12 04:02:17,408 - INFO - Epoch: 87, Training Loss: 0.6620
2025-11-12 04:02:25,465 - INFO - Epoch: 88, Training Loss: 0.6616
2025-11-12 04:02:33,687 - INFO - Epoch: 89, Training Loss: 0.6620
2025-11-12 04:02:42,024 - INFO - Epoch: 90, Training Loss: 0.6655
2025-11-12 04:02:50,016 - INFO - Epoch: 91, Training Loss: 0.6613
2025-11-12 04:02:57,334 - INFO - Epoch: 92, Training Loss: 0.6583
2025-11-12 04:03:05,026 - INFO - Epoch: 93, Training Loss: 0.6628
2025-11-12 04:03:12,982 - INFO - Epoch: 94, Training Loss: 0.6591
2025-11-12 04:03:21,672 - INFO - Epoch: 95, Training Loss: 0.6624
2025-11-12 04:03:29,891 - INFO - Epoch: 96, Training Loss: 0.6737
2025-11-12 04:03:37,098 - INFO - Epoch: 97, Training Loss: 0.6633
2025-11-12 04:03:44,306 - INFO - Epoch: 98, Training Loss: 0.6732
2025-11-12 04:03:52,365 - INFO - Epoch: 99, Training Loss: 0.6727
2025-11-12 04:04:00,710 - INFO - Epoch: 100, Training Loss: 0.6656
2025-11-12 04:04:00,710 - INFO - Training completed for Trial 3 CV 1

