2025-11-12 03:10:38,594 - INFO - Log file: ./logs/trial2_cv3_RGS_20251112_031038.log
2025-11-12 03:10:38,594 - INFO - START TRAINING TRIAL 2 CV 3 - Task: RGS
2025-11-12 03:10:38,594 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 03:10:38,595 - INFO - Loading dataset...
2025-11-12 03:10:38,684 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 03:10:38,684 - INFO - Initializing VIGNet model...
2025-11-12 03:10:38,687 - INFO - Number of batch iterations per epoch: 113
2025-11-12 03:10:46,417 - INFO - Epoch: 1, Training Loss: 0.9242
2025-11-12 03:10:53,747 - INFO - Epoch: 2, Training Loss: 0.6035
2025-11-12 03:11:01,937 - INFO - Epoch: 3, Training Loss: 0.6013
2025-11-12 03:11:09,237 - INFO - Epoch: 4, Training Loss: 0.6019
2025-11-12 03:11:17,153 - INFO - Epoch: 5, Training Loss: 0.6012
2025-11-12 03:11:25,290 - INFO - Epoch: 6, Training Loss: 0.6011
2025-11-12 03:11:33,734 - INFO - Epoch: 7, Training Loss: 0.5997
2025-11-12 03:11:41,980 - INFO - Epoch: 8, Training Loss: 0.6006
2025-11-12 03:11:50,005 - INFO - Epoch: 9, Training Loss: 0.6005
2025-11-12 03:11:58,361 - INFO - Epoch: 10, Training Loss: 0.6023
2025-11-12 03:12:06,548 - INFO - Epoch: 11, Training Loss: 0.5995
2025-11-12 03:12:14,506 - INFO - Epoch: 12, Training Loss: 0.6009
2025-11-12 03:12:21,556 - INFO - Epoch: 13, Training Loss: 0.5995
2025-11-12 03:12:29,436 - INFO - Epoch: 14, Training Loss: 0.6008
2025-11-12 03:12:36,657 - INFO - Epoch: 15, Training Loss: 0.6017
2025-11-12 03:12:45,208 - INFO - Epoch: 16, Training Loss: 0.6020
2025-11-12 03:12:52,839 - INFO - Epoch: 17, Training Loss: 0.6001
2025-11-12 03:13:00,616 - INFO - Epoch: 18, Training Loss: 0.6003
2025-11-12 03:13:08,797 - INFO - Epoch: 19, Training Loss: 0.6008
2025-11-12 03:13:17,272 - INFO - Epoch: 20, Training Loss: 0.6010
2025-11-12 03:13:24,884 - INFO - Epoch: 21, Training Loss: 0.6009
2025-11-12 03:13:32,507 - INFO - Epoch: 22, Training Loss: 0.5991
2025-11-12 03:13:39,963 - INFO - Epoch: 23, Training Loss: 0.6005
2025-11-12 03:13:48,012 - INFO - Epoch: 24, Training Loss: 0.6005
2025-11-12 03:13:56,093 - INFO - Epoch: 25, Training Loss: 0.6008
2025-11-12 03:14:03,524 - INFO - Epoch: 26, Training Loss: 0.6000
2025-11-12 03:14:11,037 - INFO - Epoch: 27, Training Loss: 0.6005
2025-11-12 03:14:19,037 - INFO - Epoch: 28, Training Loss: 0.6006
2025-11-12 03:14:26,446 - INFO - Epoch: 29, Training Loss: 0.6004
2025-11-12 03:14:34,748 - INFO - Epoch: 30, Training Loss: 0.6009
2025-11-12 03:14:42,423 - INFO - Epoch: 31, Training Loss: 0.5999
2025-11-12 03:14:50,223 - INFO - Epoch: 32, Training Loss: 0.6001
2025-11-12 03:14:57,915 - INFO - Epoch: 33, Training Loss: 0.6011
2025-11-12 03:15:06,175 - INFO - Epoch: 34, Training Loss: 0.6001
2025-11-12 03:15:13,430 - INFO - Epoch: 35, Training Loss: 0.6009
2025-11-12 03:15:20,732 - INFO - Epoch: 36, Training Loss: 0.6015
2025-11-12 03:15:29,184 - INFO - Epoch: 37, Training Loss: 0.6005
2025-11-12 03:15:36,743 - INFO - Epoch: 38, Training Loss: 0.5996
2025-11-12 03:15:44,972 - INFO - Epoch: 39, Training Loss: 0.6000
2025-11-12 03:15:52,951 - INFO - Epoch: 40, Training Loss: 0.6004
2025-11-12 03:16:00,746 - INFO - Epoch: 41, Training Loss: 0.6006
2025-11-12 03:16:09,041 - INFO - Epoch: 42, Training Loss: 0.6004
2025-11-12 03:16:17,193 - INFO - Epoch: 43, Training Loss: 0.5998
2025-11-12 03:16:24,975 - INFO - Epoch: 44, Training Loss: 0.6002
2025-11-12 03:16:33,707 - INFO - Epoch: 45, Training Loss: 0.6000
2025-11-12 03:16:41,386 - INFO - Epoch: 46, Training Loss: 0.5986
2025-11-12 03:16:48,865 - INFO - Epoch: 47, Training Loss: 0.6004
2025-11-12 03:16:56,908 - INFO - Epoch: 48, Training Loss: 0.6010
2025-11-12 03:17:04,783 - INFO - Epoch: 49, Training Loss: 0.5997
2025-11-12 03:17:12,199 - INFO - Epoch: 50, Training Loss: 0.6005
2025-11-12 03:17:19,941 - INFO - Epoch: 51, Training Loss: 0.6007
2025-11-12 03:17:28,495 - INFO - Epoch: 52, Training Loss: 0.5996
2025-11-12 03:17:35,762 - INFO - Epoch: 53, Training Loss: 0.6006
2025-11-12 03:17:43,185 - INFO - Epoch: 54, Training Loss: 0.6019
2025-11-12 03:17:51,563 - INFO - Epoch: 55, Training Loss: 0.6007
2025-11-12 03:17:59,491 - INFO - Epoch: 56, Training Loss: 0.5997
2025-11-12 03:18:07,226 - INFO - Epoch: 57, Training Loss: 0.5995
2025-11-12 03:18:15,674 - INFO - Epoch: 58, Training Loss: 0.6009
2025-11-12 03:18:23,791 - INFO - Epoch: 59, Training Loss: 0.6011
2025-11-12 03:18:31,377 - INFO - Epoch: 60, Training Loss: 0.6003
2025-11-12 03:18:39,637 - INFO - Epoch: 61, Training Loss: 0.6007
2025-11-12 03:18:48,321 - INFO - Epoch: 62, Training Loss: 0.5992
2025-11-12 03:18:56,925 - INFO - Epoch: 63, Training Loss: 0.6021
2025-11-12 03:19:05,497 - INFO - Epoch: 64, Training Loss: 0.5999
2025-11-12 03:19:13,517 - INFO - Epoch: 65, Training Loss: 0.5995
2025-11-12 03:19:21,743 - INFO - Epoch: 66, Training Loss: 0.6003
2025-11-12 03:19:30,588 - INFO - Epoch: 67, Training Loss: 0.6000
2025-11-12 03:19:38,149 - INFO - Epoch: 68, Training Loss: 0.5998
2025-11-12 03:19:45,941 - INFO - Epoch: 69, Training Loss: 0.6003
2025-11-12 03:19:53,906 - INFO - Epoch: 70, Training Loss: 0.6008
2025-11-12 03:20:01,541 - INFO - Epoch: 71, Training Loss: 0.5993
2025-11-12 03:20:09,963 - INFO - Epoch: 72, Training Loss: 0.5982
2025-11-12 03:20:18,640 - INFO - Epoch: 73, Training Loss: 0.6006
2025-11-12 03:20:26,264 - INFO - Epoch: 74, Training Loss: 0.6011
2025-11-12 03:20:33,802 - INFO - Epoch: 75, Training Loss: 0.6004
2025-11-12 03:20:43,046 - INFO - Epoch: 76, Training Loss: 0.6011
2025-11-12 03:20:51,734 - INFO - Epoch: 77, Training Loss: 0.6006
2025-11-12 03:20:59,994 - INFO - Epoch: 78, Training Loss: 0.6008
2025-11-12 03:21:08,607 - INFO - Epoch: 79, Training Loss: 0.5999
2025-11-12 03:21:17,719 - INFO - Epoch: 80, Training Loss: 0.5992
2025-11-12 03:21:26,417 - INFO - Epoch: 81, Training Loss: 0.5987
2025-11-12 03:21:34,272 - INFO - Epoch: 82, Training Loss: 0.5995
2025-11-12 03:21:42,580 - INFO - Epoch: 83, Training Loss: 0.5996
2025-11-12 03:21:50,760 - INFO - Epoch: 84, Training Loss: 0.5989
2025-11-12 03:21:59,562 - INFO - Epoch: 85, Training Loss: 0.5973
2025-11-12 03:22:07,463 - INFO - Epoch: 86, Training Loss: 0.5941
2025-11-12 03:22:15,685 - INFO - Epoch: 87, Training Loss: 0.5912
2025-11-12 03:22:24,982 - INFO - Epoch: 88, Training Loss: 0.5833
2025-11-12 03:22:32,772 - INFO - Epoch: 89, Training Loss: 0.5808
2025-11-12 03:22:40,397 - INFO - Epoch: 90, Training Loss: 0.5775
2025-11-12 03:22:47,788 - INFO - Epoch: 91, Training Loss: 0.5760
2025-11-12 03:22:55,362 - INFO - Epoch: 92, Training Loss: 0.5709
2025-11-12 03:23:03,784 - INFO - Epoch: 93, Training Loss: 0.5717
2025-11-12 03:23:11,471 - INFO - Epoch: 94, Training Loss: 0.5698
2025-11-12 03:23:18,819 - INFO - Epoch: 95, Training Loss: 0.5656
2025-11-12 03:23:26,783 - INFO - Epoch: 96, Training Loss: 0.5681
2025-11-12 03:23:35,256 - INFO - Epoch: 97, Training Loss: 0.5674
2025-11-12 03:23:42,982 - INFO - Epoch: 98, Training Loss: 0.5650
2025-11-12 03:23:50,697 - INFO - Epoch: 99, Training Loss: 0.6252
2025-11-12 03:23:58,493 - INFO - Epoch: 100, Training Loss: 0.5832
2025-11-12 03:23:58,493 - INFO - Training completed for Trial 2 CV 3

