2025-11-12 03:37:21,343 - INFO - Log file: ./logs/trial3_cv0_RGS_20251112_033721.log
2025-11-12 03:37:21,343 - INFO - START TRAINING TRIAL 3 CV 0 - Task: RGS
2025-11-12 03:37:21,343 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 03:37:21,343 - INFO - Loading dataset...
2025-11-12 03:37:21,432 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 03:37:21,432 - INFO - Initializing VIGNet model...
2025-11-12 03:37:21,435 - INFO - Number of batch iterations per epoch: 113
2025-11-12 03:37:29,333 - INFO - Epoch: 1, Training Loss: 1.6249
2025-11-12 03:37:37,702 - INFO - Epoch: 2, Training Loss: 0.7404
2025-11-12 03:37:46,064 - INFO - Epoch: 3, Training Loss: 0.7163
2025-11-12 03:37:53,608 - INFO - Epoch: 4, Training Loss: 0.7053
2025-11-12 03:38:01,610 - INFO - Epoch: 5, Training Loss: 0.7025
2025-11-12 03:38:09,885 - INFO - Epoch: 6, Training Loss: 0.7009
2025-11-12 03:38:18,898 - INFO - Epoch: 7, Training Loss: 0.7070
2025-11-12 03:38:27,296 - INFO - Epoch: 8, Training Loss: 0.6996
2025-11-12 03:38:35,147 - INFO - Epoch: 9, Training Loss: 0.6995
2025-11-12 03:38:43,950 - INFO - Epoch: 10, Training Loss: 0.6978
2025-11-12 03:38:51,540 - INFO - Epoch: 11, Training Loss: 0.6984
2025-11-12 03:38:58,960 - INFO - Epoch: 12, Training Loss: 0.6957
2025-11-12 03:39:06,439 - INFO - Epoch: 13, Training Loss: 0.6973
2025-11-12 03:39:14,824 - INFO - Epoch: 14, Training Loss: 0.6960
2025-11-12 03:39:22,835 - INFO - Epoch: 15, Training Loss: 0.6955
2025-11-12 03:39:31,053 - INFO - Epoch: 16, Training Loss: 0.6962
2025-11-12 03:39:39,014 - INFO - Epoch: 17, Training Loss: 0.6961
2025-11-12 03:39:47,420 - INFO - Epoch: 18, Training Loss: 0.6965
2025-11-12 03:39:54,727 - INFO - Epoch: 19, Training Loss: 0.6954
2025-11-12 03:40:02,019 - INFO - Epoch: 20, Training Loss: 0.6948
2025-11-12 03:40:09,465 - INFO - Epoch: 21, Training Loss: 0.6954
2025-11-12 03:40:17,486 - INFO - Epoch: 22, Training Loss: 0.6955
2025-11-12 03:40:25,051 - INFO - Epoch: 23, Training Loss: 0.6955
2025-11-12 03:40:32,462 - INFO - Epoch: 24, Training Loss: 0.6934
2025-11-12 03:40:41,003 - INFO - Epoch: 25, Training Loss: 0.6950
2025-11-12 03:40:49,064 - INFO - Epoch: 26, Training Loss: 0.6947
2025-11-12 03:40:57,273 - INFO - Epoch: 27, Training Loss: 0.6941
2025-11-12 03:41:05,726 - INFO - Epoch: 28, Training Loss: 0.6933
2025-11-12 03:41:14,110 - INFO - Epoch: 29, Training Loss: 0.6951
2025-11-12 03:41:22,107 - INFO - Epoch: 30, Training Loss: 0.6943
2025-11-12 03:41:29,655 - INFO - Epoch: 31, Training Loss: 0.6945
2025-11-12 03:41:36,815 - INFO - Epoch: 32, Training Loss: 0.6940
2025-11-12 03:41:45,043 - INFO - Epoch: 33, Training Loss: 0.6947
2025-11-12 03:41:53,421 - INFO - Epoch: 34, Training Loss: 0.6939
2025-11-12 03:42:02,170 - INFO - Epoch: 35, Training Loss: 0.6939
2025-11-12 03:42:10,175 - INFO - Epoch: 36, Training Loss: 0.6937
2025-11-12 03:42:18,772 - INFO - Epoch: 37, Training Loss: 0.6950
2025-11-12 03:42:27,041 - INFO - Epoch: 38, Training Loss: 0.6936
2025-11-12 03:42:34,760 - INFO - Epoch: 39, Training Loss: 0.6934
2025-11-12 03:42:42,703 - INFO - Epoch: 40, Training Loss: 0.6929
2025-11-12 03:42:50,345 - INFO - Epoch: 41, Training Loss: 0.6926
2025-11-12 03:42:57,568 - INFO - Epoch: 42, Training Loss: 0.6944
2025-11-12 03:43:06,059 - INFO - Epoch: 43, Training Loss: 0.6936
2025-11-12 03:43:13,829 - INFO - Epoch: 44, Training Loss: 0.6925
2025-11-12 03:43:21,439 - INFO - Epoch: 45, Training Loss: 0.6944
2025-11-12 03:43:29,411 - INFO - Epoch: 46, Training Loss: 0.6939
2025-11-12 03:43:36,823 - INFO - Epoch: 47, Training Loss: 0.6920
2025-11-12 03:43:45,007 - INFO - Epoch: 48, Training Loss: 0.6937
2025-11-12 03:43:52,815 - INFO - Epoch: 49, Training Loss: 0.6930
2025-11-12 03:44:00,246 - INFO - Epoch: 50, Training Loss: 0.6925
2025-11-12 03:44:09,062 - INFO - Epoch: 51, Training Loss: 0.6920
2025-11-12 03:44:17,207 - INFO - Epoch: 52, Training Loss: 0.6914
2025-11-12 03:44:24,660 - INFO - Epoch: 53, Training Loss: 0.6902
2025-11-12 03:44:33,414 - INFO - Epoch: 54, Training Loss: 0.6926
2025-11-12 03:44:41,159 - INFO - Epoch: 55, Training Loss: 0.6909
2025-11-12 03:44:49,851 - INFO - Epoch: 56, Training Loss: 0.6918
2025-11-12 03:44:57,656 - INFO - Epoch: 57, Training Loss: 0.6879
2025-11-12 03:45:05,876 - INFO - Epoch: 58, Training Loss: 0.6888
2025-11-12 03:45:13,316 - INFO - Epoch: 59, Training Loss: 0.6912
2025-11-12 03:45:21,230 - INFO - Epoch: 60, Training Loss: 0.6891
2025-11-12 03:45:28,752 - INFO - Epoch: 61, Training Loss: 0.6872
2025-11-12 03:45:36,521 - INFO - Epoch: 62, Training Loss: 0.6909
2025-11-12 03:45:44,535 - INFO - Epoch: 63, Training Loss: 0.6851
2025-11-12 03:45:52,529 - INFO - Epoch: 64, Training Loss: 0.6838
2025-11-12 03:46:01,463 - INFO - Epoch: 65, Training Loss: 0.6879
2025-11-12 03:46:09,665 - INFO - Epoch: 66, Training Loss: 0.6831
2025-11-12 03:46:17,516 - INFO - Epoch: 67, Training Loss: 0.6902
2025-11-12 03:46:25,750 - INFO - Epoch: 68, Training Loss: 0.6824
2025-11-12 03:46:33,590 - INFO - Epoch: 69, Training Loss: 0.6859
2025-11-12 03:46:41,512 - INFO - Epoch: 70, Training Loss: 0.6797
2025-11-12 03:46:49,741 - INFO - Epoch: 71, Training Loss: 0.6748
2025-11-12 03:46:57,608 - INFO - Epoch: 72, Training Loss: 0.6732
2025-11-12 03:47:04,971 - INFO - Epoch: 73, Training Loss: 0.6703
2025-11-12 03:47:12,397 - INFO - Epoch: 74, Training Loss: 0.6755
2025-11-12 03:47:20,955 - INFO - Epoch: 75, Training Loss: 0.6671
2025-11-12 03:47:29,350 - INFO - Epoch: 76, Training Loss: 0.6645
2025-11-12 03:47:37,475 - INFO - Epoch: 77, Training Loss: 0.6668
2025-11-12 03:47:45,035 - INFO - Epoch: 78, Training Loss: 0.6619
2025-11-12 03:47:52,805 - INFO - Epoch: 79, Training Loss: 0.6652
2025-11-12 03:48:00,504 - INFO - Epoch: 80, Training Loss: 0.6650
2025-11-12 03:48:08,890 - INFO - Epoch: 81, Training Loss: 0.6628
2025-11-12 03:48:16,403 - INFO - Epoch: 82, Training Loss: 0.6632
2025-11-12 03:48:24,699 - INFO - Epoch: 83, Training Loss: 0.6573
2025-11-12 03:48:32,911 - INFO - Epoch: 84, Training Loss: 0.6608
2025-11-12 03:48:40,246 - INFO - Epoch: 85, Training Loss: 0.6587
2025-11-12 03:48:48,525 - INFO - Epoch: 86, Training Loss: 0.6583
2025-11-12 03:48:56,524 - INFO - Epoch: 87, Training Loss: 0.6641
2025-11-12 03:49:04,458 - INFO - Epoch: 88, Training Loss: 0.6575
2025-11-12 03:49:12,522 - INFO - Epoch: 89, Training Loss: 0.6554
2025-11-12 03:49:20,067 - INFO - Epoch: 90, Training Loss: 0.6603
2025-11-12 03:49:27,944 - INFO - Epoch: 91, Training Loss: 0.6646
2025-11-12 03:49:36,374 - INFO - Epoch: 92, Training Loss: 0.6605
2025-11-12 03:49:44,371 - INFO - Epoch: 93, Training Loss: 0.6597
2025-11-12 03:49:52,305 - INFO - Epoch: 94, Training Loss: 0.6604
2025-11-12 03:49:59,816 - INFO - Epoch: 95, Training Loss: 0.6543
2025-11-12 03:50:07,412 - INFO - Epoch: 96, Training Loss: 0.6601
2025-11-12 03:50:15,098 - INFO - Epoch: 97, Training Loss: 0.6670
2025-11-12 03:50:23,130 - INFO - Epoch: 98, Training Loss: 0.6665
2025-11-12 03:50:31,770 - INFO - Epoch: 99, Training Loss: 0.6553
2025-11-12 03:50:39,165 - INFO - Epoch: 100, Training Loss: 0.6535
2025-11-12 03:50:39,166 - INFO - Training completed for Trial 3 CV 0

