2025-11-13 14:29:50,001 - INFO - Log file: ./logs/trial16_cv1_RGS_20251113_142950.log
2025-11-13 14:29:50,001 - INFO - START TRAINING TRIAL 16 CV 1 - Task: RGS
2025-11-13 14:29:50,001 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 14:29:50,002 - INFO - Loading dataset...
2025-11-13 14:29:50,123 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 14:29:50,123 - INFO - Initializing VIGNet model...
2025-11-13 14:29:50,126 - INFO - Number of batch iterations per epoch: 113
2025-11-13 14:30:03,290 - INFO - Epoch: 1, Training Loss: 1.4951
2025-11-13 14:30:15,546 - INFO - Epoch: 2, Training Loss: 0.7593
2025-11-13 14:30:26,535 - INFO - Epoch: 3, Training Loss: 0.7127
2025-11-13 14:30:39,138 - INFO - Epoch: 4, Training Loss: 0.6888
2025-11-13 14:30:47,102 - INFO - Epoch: 5, Training Loss: 0.7037
2025-11-13 14:30:58,707 - INFO - Epoch: 6, Training Loss: 0.6667
2025-11-13 14:31:09,644 - INFO - Epoch: 7, Training Loss: 0.7032
2025-11-13 14:31:21,114 - INFO - Epoch: 8, Training Loss: 0.6486
2025-11-13 14:31:31,456 - INFO - Epoch: 9, Training Loss: 0.6519
2025-11-13 14:31:44,490 - INFO - Epoch: 10, Training Loss: 0.6511
2025-11-13 14:31:59,415 - INFO - Epoch: 11, Training Loss: 0.6489
2025-11-13 14:32:14,100 - INFO - Epoch: 12, Training Loss: 0.6368
2025-11-13 14:32:27,714 - INFO - Epoch: 13, Training Loss: 0.6521
2025-11-13 14:32:39,122 - INFO - Epoch: 14, Training Loss: 0.6407
2025-11-13 14:32:54,186 - INFO - Epoch: 15, Training Loss: 0.6394
2025-11-13 14:33:06,671 - INFO - Epoch: 16, Training Loss: 0.6397
2025-11-13 14:33:18,876 - INFO - Epoch: 17, Training Loss: 0.6448
2025-11-13 14:33:33,264 - INFO - Epoch: 18, Training Loss: 0.6391
2025-11-13 14:33:46,409 - INFO - Epoch: 19, Training Loss: 0.6382
2025-11-13 14:33:59,251 - INFO - Epoch: 20, Training Loss: 0.6450
2025-11-13 14:34:12,934 - INFO - Epoch: 21, Training Loss: 0.6412
2025-11-13 14:34:26,292 - INFO - Epoch: 22, Training Loss: 0.6390
2025-11-13 14:34:38,325 - INFO - Epoch: 23, Training Loss: 0.6423
2025-11-13 14:34:49,956 - INFO - Epoch: 24, Training Loss: 0.6400
2025-11-13 14:35:05,065 - INFO - Epoch: 25, Training Loss: 0.6358
2025-11-13 14:35:15,671 - INFO - Epoch: 26, Training Loss: 0.6400
2025-11-13 14:35:28,892 - INFO - Epoch: 27, Training Loss: 0.6382
2025-11-13 14:35:40,844 - INFO - Epoch: 28, Training Loss: 0.6376
2025-11-13 14:35:56,597 - INFO - Epoch: 29, Training Loss: 0.6409
2025-11-13 14:36:08,956 - INFO - Epoch: 30, Training Loss: 0.6343
2025-11-13 14:36:21,954 - INFO - Epoch: 31, Training Loss: 0.6374
2025-11-13 14:36:34,391 - INFO - Epoch: 32, Training Loss: 0.6355
2025-11-13 14:36:53,076 - INFO - Epoch: 33, Training Loss: 0.6364
2025-11-13 14:37:06,832 - INFO - Epoch: 34, Training Loss: 0.6353
2025-11-13 14:37:18,980 - INFO - Epoch: 35, Training Loss: 0.6378
2025-11-13 14:37:30,452 - INFO - Epoch: 36, Training Loss: 0.6323
2025-11-13 14:37:40,377 - INFO - Epoch: 37, Training Loss: 0.6326
2025-11-13 14:37:55,418 - INFO - Epoch: 38, Training Loss: 0.6287
2025-11-13 14:38:08,326 - INFO - Epoch: 39, Training Loss: 0.6191
2025-11-13 14:38:20,716 - INFO - Epoch: 40, Training Loss: 0.6011
2025-11-13 14:38:33,298 - INFO - Epoch: 41, Training Loss: 0.5982
2025-11-13 14:38:48,050 - INFO - Epoch: 42, Training Loss: 0.5802
2025-11-13 14:39:01,030 - INFO - Epoch: 43, Training Loss: 0.6172
2025-11-13 14:39:12,332 - INFO - Epoch: 44, Training Loss: 0.5488
2025-11-13 14:39:26,609 - INFO - Epoch: 45, Training Loss: 0.5408
2025-11-13 14:39:40,004 - INFO - Epoch: 46, Training Loss: 0.5328
2025-11-13 14:39:53,914 - INFO - Epoch: 47, Training Loss: 0.5054
2025-11-13 14:40:08,117 - INFO - Epoch: 48, Training Loss: 0.5450
2025-11-13 14:40:20,459 - INFO - Epoch: 49, Training Loss: 0.5159
2025-11-13 14:40:31,446 - INFO - Epoch: 50, Training Loss: 0.5052
2025-11-13 14:40:43,198 - INFO - Epoch: 51, Training Loss: 0.5015
2025-11-13 14:40:57,914 - INFO - Epoch: 52, Training Loss: 0.6112
2025-11-13 14:41:09,190 - INFO - Epoch: 53, Training Loss: 0.5238
2025-11-13 14:41:21,377 - INFO - Epoch: 54, Training Loss: 0.5161
2025-11-13 14:41:33,164 - INFO - Epoch: 55, Training Loss: 0.5085
2025-11-13 14:41:46,222 - INFO - Epoch: 56, Training Loss: 0.4989
2025-11-13 14:41:59,174 - INFO - Epoch: 57, Training Loss: 0.5123
2025-11-13 14:42:11,842 - INFO - Epoch: 58, Training Loss: 0.8568
2025-11-13 14:42:23,550 - INFO - Epoch: 59, Training Loss: 0.5888
2025-11-13 14:42:37,518 - INFO - Epoch: 60, Training Loss: 0.5256
2025-11-13 14:42:48,191 - INFO - Epoch: 61, Training Loss: 0.5355
2025-11-13 14:43:00,474 - INFO - Epoch: 62, Training Loss: 0.5251
2025-11-13 14:43:12,722 - INFO - Epoch: 63, Training Loss: 0.4882
2025-11-13 14:43:23,696 - INFO - Epoch: 64, Training Loss: 0.4930
2025-11-13 14:43:38,608 - INFO - Epoch: 65, Training Loss: 0.5059
2025-11-13 14:43:50,329 - INFO - Epoch: 66, Training Loss: 0.4854
2025-11-13 14:43:59,479 - INFO - Epoch: 67, Training Loss: 0.4755
2025-11-13 14:44:11,024 - INFO - Epoch: 68, Training Loss: 0.4820
2025-11-13 14:44:21,780 - INFO - Epoch: 69, Training Loss: 0.4801
2025-11-13 14:44:35,002 - INFO - Epoch: 70, Training Loss: 0.4847
2025-11-13 14:44:48,607 - INFO - Epoch: 71, Training Loss: 0.5193
2025-11-13 14:44:59,569 - INFO - Epoch: 72, Training Loss: 0.5296
2025-11-13 14:45:09,186 - INFO - Epoch: 73, Training Loss: 0.4816
2025-11-13 14:45:20,381 - INFO - Epoch: 74, Training Loss: 0.4914
2025-11-13 14:45:33,217 - INFO - Epoch: 75, Training Loss: 0.4901
2025-11-13 14:45:46,390 - INFO - Epoch: 76, Training Loss: 0.4801
2025-11-13 14:46:00,091 - INFO - Epoch: 77, Training Loss: 0.4897
2025-11-13 14:46:14,867 - INFO - Epoch: 78, Training Loss: 0.4756
2025-11-13 14:46:28,775 - INFO - Epoch: 79, Training Loss: 0.4897
2025-11-13 14:46:39,229 - INFO - Epoch: 80, Training Loss: 0.4814
2025-11-13 14:46:49,712 - INFO - Epoch: 81, Training Loss: 0.4818
2025-11-13 14:46:59,154 - INFO - Epoch: 82, Training Loss: 0.4874
2025-11-13 14:47:12,228 - INFO - Epoch: 83, Training Loss: 0.6090
2025-11-13 14:47:24,984 - INFO - Epoch: 84, Training Loss: 0.5899
2025-11-13 14:47:33,726 - INFO - Epoch: 85, Training Loss: 0.4971
2025-11-13 14:47:48,118 - INFO - Epoch: 86, Training Loss: 3.7104
2025-11-13 14:47:57,707 - INFO - Epoch: 87, Training Loss: 10.3155
2025-11-13 14:48:05,756 - INFO - Epoch: 88, Training Loss: 10.3351
2025-11-13 14:48:16,549 - INFO - Epoch: 89, Training Loss: 10.3357
2025-11-13 14:48:25,424 - INFO - Epoch: 90, Training Loss: 10.3381
2025-11-13 14:48:37,182 - INFO - Epoch: 91, Training Loss: 10.3185
2025-11-13 14:48:51,392 - INFO - Epoch: 92, Training Loss: 10.3332
2025-11-13 14:49:03,751 - INFO - Epoch: 93, Training Loss: 10.3260
2025-11-13 14:49:18,616 - INFO - Epoch: 94, Training Loss: 10.3411
2025-11-13 14:49:29,443 - INFO - Epoch: 95, Training Loss: 10.3139
2025-11-13 14:49:42,415 - INFO - Epoch: 96, Training Loss: 10.3612
2025-11-13 14:49:56,330 - INFO - Epoch: 97, Training Loss: 10.3278
2025-11-13 14:50:09,437 - INFO - Epoch: 98, Training Loss: 10.3159
2025-11-13 14:50:18,319 - INFO - Epoch: 99, Training Loss: 10.3306
2025-11-13 14:50:31,930 - INFO - Epoch: 100, Training Loss: 10.3165
2025-11-13 14:50:31,931 - INFO - Training completed for Trial 16 CV 1

