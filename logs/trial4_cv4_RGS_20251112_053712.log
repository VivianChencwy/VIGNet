2025-11-12 05:37:12,430 - INFO - Log file: ./logs/trial4_cv4_RGS_20251112_053712.log
2025-11-12 05:37:12,430 - INFO - START TRAINING TRIAL 4 CV 4 - Task: RGS
2025-11-12 05:37:12,430 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 05:37:12,430 - INFO - Loading dataset...
2025-11-12 05:37:12,519 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 05:37:12,519 - INFO - Initializing VIGNet model...
2025-11-12 05:37:12,522 - INFO - Number of batch iterations per epoch: 113
2025-11-12 05:37:21,171 - INFO - Epoch: 1, Training Loss: 1.0942
2025-11-12 05:37:28,826 - INFO - Epoch: 2, Training Loss: 0.6585
2025-11-12 05:37:36,599 - INFO - Epoch: 3, Training Loss: 0.6453
2025-11-12 05:37:44,437 - INFO - Epoch: 4, Training Loss: 0.6448
2025-11-12 05:37:51,893 - INFO - Epoch: 5, Training Loss: 0.6476
2025-11-12 05:38:00,095 - INFO - Epoch: 6, Training Loss: 0.6443
2025-11-12 05:38:07,623 - INFO - Epoch: 7, Training Loss: 0.6454
2025-11-12 05:38:15,158 - INFO - Epoch: 8, Training Loss: 0.6424
2025-11-12 05:38:23,009 - INFO - Epoch: 9, Training Loss: 0.6433
2025-11-12 05:38:30,697 - INFO - Epoch: 10, Training Loss: 0.6435
2025-11-12 05:38:38,274 - INFO - Epoch: 11, Training Loss: 0.6437
2025-11-12 05:38:46,724 - INFO - Epoch: 12, Training Loss: 0.6426
2025-11-12 05:38:54,484 - INFO - Epoch: 13, Training Loss: 0.6430
2025-11-12 05:39:02,214 - INFO - Epoch: 14, Training Loss: 0.6414
2025-11-12 05:39:10,041 - INFO - Epoch: 15, Training Loss: 0.6426
2025-11-12 05:39:18,328 - INFO - Epoch: 16, Training Loss: 0.6426
2025-11-12 05:39:26,626 - INFO - Epoch: 17, Training Loss: 0.6420
2025-11-12 05:39:33,881 - INFO - Epoch: 18, Training Loss: 0.6415
2025-11-12 05:39:42,335 - INFO - Epoch: 19, Training Loss: 0.6440
2025-11-12 05:39:50,729 - INFO - Epoch: 20, Training Loss: 0.6429
2025-11-12 05:39:59,484 - INFO - Epoch: 21, Training Loss: 0.6427
2025-11-12 05:40:07,244 - INFO - Epoch: 22, Training Loss: 0.6444
2025-11-12 05:40:15,894 - INFO - Epoch: 23, Training Loss: 0.6437
2025-11-12 05:40:24,220 - INFO - Epoch: 24, Training Loss: 0.6425
2025-11-12 05:40:31,759 - INFO - Epoch: 25, Training Loss: 0.6423
2025-11-12 05:40:38,934 - INFO - Epoch: 26, Training Loss: 0.6426
2025-11-12 05:40:46,135 - INFO - Epoch: 27, Training Loss: 0.6424
2025-11-12 05:40:53,709 - INFO - Epoch: 28, Training Loss: 0.6425
2025-11-12 05:41:01,707 - INFO - Epoch: 29, Training Loss: 0.6429
2025-11-12 05:41:10,101 - INFO - Epoch: 30, Training Loss: 0.6427
2025-11-12 05:41:18,722 - INFO - Epoch: 31, Training Loss: 0.6417
2025-11-12 05:41:26,514 - INFO - Epoch: 32, Training Loss: 0.6435
2025-11-12 05:41:34,516 - INFO - Epoch: 33, Training Loss: 0.6420
2025-11-12 05:41:42,627 - INFO - Epoch: 34, Training Loss: 0.6424
2025-11-12 05:41:51,152 - INFO - Epoch: 35, Training Loss: 0.6436
2025-11-12 05:41:59,269 - INFO - Epoch: 36, Training Loss: 0.6411
2025-11-12 05:42:07,904 - INFO - Epoch: 37, Training Loss: 0.6428
2025-11-12 05:42:15,281 - INFO - Epoch: 38, Training Loss: 0.6430
2025-11-12 05:42:23,751 - INFO - Epoch: 39, Training Loss: 0.6427
2025-11-12 05:42:31,152 - INFO - Epoch: 40, Training Loss: 0.6420
2025-11-12 05:42:39,215 - INFO - Epoch: 41, Training Loss: 0.6416
2025-11-12 05:42:46,513 - INFO - Epoch: 42, Training Loss: 0.6431
2025-11-12 05:42:54,699 - INFO - Epoch: 43, Training Loss: 0.6427
2025-11-12 05:43:02,539 - INFO - Epoch: 44, Training Loss: 0.6413
2025-11-12 05:43:11,779 - INFO - Epoch: 45, Training Loss: 0.6426
2025-11-12 05:43:20,230 - INFO - Epoch: 46, Training Loss: 0.6416
2025-11-12 05:43:28,667 - INFO - Epoch: 47, Training Loss: 0.6418
2025-11-12 05:43:36,443 - INFO - Epoch: 48, Training Loss: 0.6428
2025-11-12 05:43:43,895 - INFO - Epoch: 49, Training Loss: 0.6427
2025-11-12 05:43:52,372 - INFO - Epoch: 50, Training Loss: 0.6425
2025-11-12 05:44:00,863 - INFO - Epoch: 51, Training Loss: 0.6415
2025-11-12 05:44:08,699 - INFO - Epoch: 52, Training Loss: 0.6426
2025-11-12 05:44:16,677 - INFO - Epoch: 53, Training Loss: 0.6418
2025-11-12 05:44:24,874 - INFO - Epoch: 54, Training Loss: 0.6418
2025-11-12 05:44:32,760 - INFO - Epoch: 55, Training Loss: 0.6430
2025-11-12 05:44:41,119 - INFO - Epoch: 56, Training Loss: 0.6415
2025-11-12 05:44:49,403 - INFO - Epoch: 57, Training Loss: 0.6407
2025-11-12 05:44:56,760 - INFO - Epoch: 58, Training Loss: 0.6401
2025-11-12 05:45:04,813 - INFO - Epoch: 59, Training Loss: 0.6404
2025-11-12 05:45:13,321 - INFO - Epoch: 60, Training Loss: 0.6372
2025-11-12 05:45:21,707 - INFO - Epoch: 61, Training Loss: 0.6326
2025-11-12 05:45:29,442 - INFO - Epoch: 62, Training Loss: 0.6147
2025-11-12 05:45:37,044 - INFO - Epoch: 63, Training Loss: 0.6044
2025-11-12 05:45:44,935 - INFO - Epoch: 64, Training Loss: 0.6011
2025-11-12 05:45:52,568 - INFO - Epoch: 65, Training Loss: 0.6040
2025-11-12 05:46:00,616 - INFO - Epoch: 66, Training Loss: 0.6031
2025-11-12 05:46:08,252 - INFO - Epoch: 67, Training Loss: 0.5994
2025-11-12 05:46:15,740 - INFO - Epoch: 68, Training Loss: 0.6011
2025-11-12 05:46:24,160 - INFO - Epoch: 69, Training Loss: 0.5956
2025-11-12 05:46:31,727 - INFO - Epoch: 70, Training Loss: 0.5973
2025-11-12 05:46:39,861 - INFO - Epoch: 71, Training Loss: 0.5973
2025-11-12 05:46:47,504 - INFO - Epoch: 72, Training Loss: 0.5952
2025-11-12 05:46:54,978 - INFO - Epoch: 73, Training Loss: 0.5964
2025-11-12 05:47:02,591 - INFO - Epoch: 74, Training Loss: 0.5950
2025-11-12 05:47:10,169 - INFO - Epoch: 75, Training Loss: 0.5960
2025-11-12 05:47:18,161 - INFO - Epoch: 76, Training Loss: 0.6003
2025-11-12 05:47:26,540 - INFO - Epoch: 77, Training Loss: 0.5978
2025-11-12 05:47:34,324 - INFO - Epoch: 78, Training Loss: 0.5955
2025-11-12 05:47:42,060 - INFO - Epoch: 79, Training Loss: 0.5955
2025-11-12 05:47:49,780 - INFO - Epoch: 80, Training Loss: 0.5944
2025-11-12 05:47:57,730 - INFO - Epoch: 81, Training Loss: 0.5983
2025-11-12 05:48:05,359 - INFO - Epoch: 82, Training Loss: 0.5945
2025-11-12 05:48:13,301 - INFO - Epoch: 83, Training Loss: 0.5979
2025-11-12 05:48:21,763 - INFO - Epoch: 84, Training Loss: 0.5948
2025-11-12 05:48:30,541 - INFO - Epoch: 85, Training Loss: 0.5923
2025-11-12 05:48:38,596 - INFO - Epoch: 86, Training Loss: 0.5922
2025-11-12 05:48:47,069 - INFO - Epoch: 87, Training Loss: 0.5949
2025-11-12 05:48:55,222 - INFO - Epoch: 88, Training Loss: 0.5947
2025-11-12 05:49:03,228 - INFO - Epoch: 89, Training Loss: 0.5943
2025-11-12 05:49:10,538 - INFO - Epoch: 90, Training Loss: 0.5916
2025-11-12 05:49:18,169 - INFO - Epoch: 91, Training Loss: 0.6257
2025-11-12 05:49:26,003 - INFO - Epoch: 92, Training Loss: 0.6338
2025-11-12 05:49:34,651 - INFO - Epoch: 93, Training Loss: 0.6306
2025-11-12 05:49:42,130 - INFO - Epoch: 94, Training Loss: 0.6285
2025-11-12 05:49:49,766 - INFO - Epoch: 95, Training Loss: 0.6291
2025-11-12 05:49:58,287 - INFO - Epoch: 96, Training Loss: 0.6221
2025-11-12 05:50:06,272 - INFO - Epoch: 97, Training Loss: 0.6155
2025-11-12 05:50:14,423 - INFO - Epoch: 98, Training Loss: 0.6053
2025-11-12 05:50:22,168 - INFO - Epoch: 99, Training Loss: 0.6025
2025-11-12 05:50:29,251 - INFO - Epoch: 100, Training Loss: 0.5996
2025-11-12 05:50:29,251 - INFO - Training completed for Trial 4 CV 4

