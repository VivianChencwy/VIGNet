2025-11-12 08:56:33,233 - INFO - Log file: ./logs/trial7_cv4_RGS_20251112_085633.log
2025-11-12 08:56:33,233 - INFO - START TRAINING TRIAL 7 CV 4 - Task: RGS
2025-11-12 08:56:33,233 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 08:56:33,233 - INFO - Loading dataset...
2025-11-12 08:56:33,573 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 08:56:33,573 - INFO - Initializing VIGNet model...
2025-11-12 08:56:33,576 - INFO - Number of batch iterations per epoch: 113
2025-11-12 08:56:40,867 - INFO - Epoch: 1, Training Loss: 0.9491
2025-11-12 08:56:49,640 - INFO - Epoch: 2, Training Loss: 0.6920
2025-11-12 08:56:58,451 - INFO - Epoch: 3, Training Loss: 0.6904
2025-11-12 08:57:06,039 - INFO - Epoch: 4, Training Loss: 0.6891
2025-11-12 08:57:13,636 - INFO - Epoch: 5, Training Loss: 0.6887
2025-11-12 08:57:21,889 - INFO - Epoch: 6, Training Loss: 0.6883
2025-11-12 08:57:30,421 - INFO - Epoch: 7, Training Loss: 0.6884
2025-11-12 08:57:38,185 - INFO - Epoch: 8, Training Loss: 0.6886
2025-11-12 08:57:45,614 - INFO - Epoch: 9, Training Loss: 0.6882
2025-11-12 08:57:54,145 - INFO - Epoch: 10, Training Loss: 0.6884
2025-11-12 08:58:02,717 - INFO - Epoch: 11, Training Loss: 0.6882
2025-11-12 08:58:10,206 - INFO - Epoch: 12, Training Loss: 0.6880
2025-11-12 08:58:17,872 - INFO - Epoch: 13, Training Loss: 0.6883
2025-11-12 08:58:26,010 - INFO - Epoch: 14, Training Loss: 0.6884
2025-11-12 08:58:33,749 - INFO - Epoch: 15, Training Loss: 0.6884
2025-11-12 08:58:41,797 - INFO - Epoch: 16, Training Loss: 0.6882
2025-11-12 08:58:50,107 - INFO - Epoch: 17, Training Loss: 0.6879
2025-11-12 08:58:58,068 - INFO - Epoch: 18, Training Loss: 0.6885
2025-11-12 08:59:05,683 - INFO - Epoch: 19, Training Loss: 0.6881
2025-11-12 08:59:13,883 - INFO - Epoch: 20, Training Loss: 0.6881
2025-11-12 08:59:21,953 - INFO - Epoch: 21, Training Loss: 0.6883
2025-11-12 08:59:29,545 - INFO - Epoch: 22, Training Loss: 0.6881
2025-11-12 08:59:37,429 - INFO - Epoch: 23, Training Loss: 0.6881
2025-11-12 08:59:44,905 - INFO - Epoch: 24, Training Loss: 0.6880
2025-11-12 08:59:53,197 - INFO - Epoch: 25, Training Loss: 0.6880
2025-11-12 09:00:01,291 - INFO - Epoch: 26, Training Loss: 0.6880
2025-11-12 09:00:08,924 - INFO - Epoch: 27, Training Loss: 0.6893
2025-11-12 09:00:16,867 - INFO - Epoch: 28, Training Loss: 0.6888
2025-11-12 09:00:24,996 - INFO - Epoch: 29, Training Loss: 0.6885
2025-11-12 09:00:32,948 - INFO - Epoch: 30, Training Loss: 0.6885
2025-11-12 09:00:41,123 - INFO - Epoch: 31, Training Loss: 0.6888
2025-11-12 09:00:49,080 - INFO - Epoch: 32, Training Loss: 0.6880
2025-11-12 09:00:57,232 - INFO - Epoch: 33, Training Loss: 0.6885
2025-11-12 09:01:05,307 - INFO - Epoch: 34, Training Loss: 0.6879
2025-11-12 09:01:13,775 - INFO - Epoch: 35, Training Loss: 0.6884
2025-11-12 09:01:22,047 - INFO - Epoch: 36, Training Loss: 0.6883
2025-11-12 09:01:29,645 - INFO - Epoch: 37, Training Loss: 0.6889
2025-11-12 09:01:37,589 - INFO - Epoch: 38, Training Loss: 0.6886
2025-11-12 09:01:45,344 - INFO - Epoch: 39, Training Loss: 0.6881
2025-11-12 09:01:53,530 - INFO - Epoch: 40, Training Loss: 0.6882
2025-11-12 09:02:01,290 - INFO - Epoch: 41, Training Loss: 0.6879
2025-11-12 09:02:09,467 - INFO - Epoch: 42, Training Loss: 0.6883
2025-11-12 09:02:17,479 - INFO - Epoch: 43, Training Loss: 0.6885
2025-11-12 09:02:24,633 - INFO - Epoch: 44, Training Loss: 0.6883
2025-11-12 09:02:32,496 - INFO - Epoch: 45, Training Loss: 0.6887
2025-11-12 09:02:39,867 - INFO - Epoch: 46, Training Loss: 0.6882
2025-11-12 09:02:47,888 - INFO - Epoch: 47, Training Loss: 0.6882
2025-11-12 09:02:55,733 - INFO - Epoch: 48, Training Loss: 0.6881
2025-11-12 09:03:02,907 - INFO - Epoch: 49, Training Loss: 0.6878
2025-11-12 09:03:10,995 - INFO - Epoch: 50, Training Loss: 0.6894
2025-11-12 09:03:19,242 - INFO - Epoch: 51, Training Loss: 0.6886
2025-11-12 09:03:26,743 - INFO - Epoch: 52, Training Loss: 0.6880
2025-11-12 09:03:35,261 - INFO - Epoch: 53, Training Loss: 0.6884
2025-11-12 09:03:43,759 - INFO - Epoch: 54, Training Loss: 0.6880
2025-11-12 09:03:51,701 - INFO - Epoch: 55, Training Loss: 0.6888
2025-11-12 09:03:59,219 - INFO - Epoch: 56, Training Loss: 0.6887
2025-11-12 09:04:06,830 - INFO - Epoch: 57, Training Loss: 0.6886
2025-11-12 09:04:14,596 - INFO - Epoch: 58, Training Loss: 0.6886
2025-11-12 09:04:23,106 - INFO - Epoch: 59, Training Loss: 0.6885
2025-11-12 09:04:31,073 - INFO - Epoch: 60, Training Loss: 0.6883
2025-11-12 09:04:38,636 - INFO - Epoch: 61, Training Loss: 0.6883
2025-11-12 09:04:46,035 - INFO - Epoch: 62, Training Loss: 0.6893
2025-11-12 09:04:54,025 - INFO - Epoch: 63, Training Loss: 0.6887
2025-11-12 09:05:02,154 - INFO - Epoch: 64, Training Loss: 0.6885
2025-11-12 09:05:10,370 - INFO - Epoch: 65, Training Loss: 0.6881
2025-11-12 09:05:18,049 - INFO - Epoch: 66, Training Loss: 0.6885
2025-11-12 09:05:26,206 - INFO - Epoch: 67, Training Loss: 0.6881
2025-11-12 09:05:34,001 - INFO - Epoch: 68, Training Loss: 0.6890
2025-11-12 09:05:41,827 - INFO - Epoch: 69, Training Loss: 0.6881
2025-11-12 09:05:49,914 - INFO - Epoch: 70, Training Loss: 0.6886
2025-11-12 09:05:58,359 - INFO - Epoch: 71, Training Loss: 0.6883
2025-11-12 09:06:06,467 - INFO - Epoch: 72, Training Loss: 0.6882
2025-11-12 09:06:13,721 - INFO - Epoch: 73, Training Loss: 0.6884
2025-11-12 09:06:21,508 - INFO - Epoch: 74, Training Loss: 0.6879
2025-11-12 09:06:29,033 - INFO - Epoch: 75, Training Loss: 0.6884
2025-11-12 09:06:37,073 - INFO - Epoch: 76, Training Loss: 0.6888
2025-11-12 09:06:44,901 - INFO - Epoch: 77, Training Loss: 0.6875
2025-11-12 09:06:52,079 - INFO - Epoch: 78, Training Loss: 0.6883
2025-11-12 09:07:00,584 - INFO - Epoch: 79, Training Loss: 0.6869
2025-11-12 09:07:09,302 - INFO - Epoch: 80, Training Loss: 0.6841
2025-11-12 09:07:18,134 - INFO - Epoch: 81, Training Loss: 0.6776
2025-11-12 09:07:26,387 - INFO - Epoch: 82, Training Loss: 0.6741
2025-11-12 09:07:34,249 - INFO - Epoch: 83, Training Loss: 0.6737
2025-11-12 09:07:41,993 - INFO - Epoch: 84, Training Loss: 0.6723
2025-11-12 09:07:49,809 - INFO - Epoch: 85, Training Loss: 0.6710
2025-11-12 09:07:59,129 - INFO - Epoch: 86, Training Loss: 0.6700
2025-11-12 09:08:07,219 - INFO - Epoch: 87, Training Loss: 0.6690
2025-11-12 09:08:14,959 - INFO - Epoch: 88, Training Loss: 0.6679
2025-11-12 09:08:22,299 - INFO - Epoch: 89, Training Loss: 0.6674
2025-11-12 09:08:30,404 - INFO - Epoch: 90, Training Loss: 0.6690
2025-11-12 09:08:38,211 - INFO - Epoch: 91, Training Loss: 0.6666
2025-11-12 09:08:45,961 - INFO - Epoch: 92, Training Loss: 0.6668
2025-11-12 09:08:53,395 - INFO - Epoch: 93, Training Loss: 0.6664
2025-11-12 09:09:01,437 - INFO - Epoch: 94, Training Loss: 0.6667
2025-11-12 09:09:09,256 - INFO - Epoch: 95, Training Loss: 0.6660
2025-11-12 09:09:17,126 - INFO - Epoch: 96, Training Loss: 0.6664
2025-11-12 09:09:24,567 - INFO - Epoch: 97, Training Loss: 0.6664
2025-11-12 09:09:32,330 - INFO - Epoch: 98, Training Loss: 0.6671
2025-11-12 09:09:40,373 - INFO - Epoch: 99, Training Loss: 0.6682
2025-11-12 09:09:49,250 - INFO - Epoch: 100, Training Loss: 0.6654
2025-11-12 09:09:49,250 - INFO - Training completed for Trial 7 CV 4

