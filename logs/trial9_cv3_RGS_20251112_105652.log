2025-11-12 10:56:52,477 - INFO - Log file: ./logs/trial9_cv3_RGS_20251112_105652.log
2025-11-12 10:56:52,477 - INFO - START TRAINING TRIAL 9 CV 3 - Task: RGS
2025-11-12 10:56:52,477 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 10:56:52,477 - INFO - Loading dataset...
2025-11-12 10:56:52,570 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 10:56:52,570 - INFO - Initializing VIGNet model...
2025-11-12 10:56:52,573 - INFO - Number of batch iterations per epoch: 113
2025-11-12 10:57:00,699 - INFO - Epoch: 1, Training Loss: 1.1371
2025-11-12 10:57:09,636 - INFO - Epoch: 2, Training Loss: 0.7041
2025-11-12 10:57:17,667 - INFO - Epoch: 3, Training Loss: 0.6954
2025-11-12 10:57:24,859 - INFO - Epoch: 4, Training Loss: 0.6930
2025-11-12 10:57:32,841 - INFO - Epoch: 5, Training Loss: 0.6888
2025-11-12 10:57:40,338 - INFO - Epoch: 6, Training Loss: 0.6929
2025-11-12 10:57:48,469 - INFO - Epoch: 7, Training Loss: 0.6905
2025-11-12 10:57:56,722 - INFO - Epoch: 8, Training Loss: 0.6895
2025-11-12 10:58:05,374 - INFO - Epoch: 9, Training Loss: 0.6887
2025-11-12 10:58:13,202 - INFO - Epoch: 10, Training Loss: 0.6870
2025-11-12 10:58:21,337 - INFO - Epoch: 11, Training Loss: 0.6879
2025-11-12 10:58:30,119 - INFO - Epoch: 12, Training Loss: 0.6877
2025-11-12 10:58:37,798 - INFO - Epoch: 13, Training Loss: 0.6883
2025-11-12 10:58:46,687 - INFO - Epoch: 14, Training Loss: 0.6885
2025-11-12 10:58:54,380 - INFO - Epoch: 15, Training Loss: 0.6873
2025-11-12 10:59:01,710 - INFO - Epoch: 16, Training Loss: 0.6884
2025-11-12 10:59:09,685 - INFO - Epoch: 17, Training Loss: 0.6883
2025-11-12 10:59:17,448 - INFO - Epoch: 18, Training Loss: 0.6876
2025-11-12 10:59:25,198 - INFO - Epoch: 19, Training Loss: 0.6877
2025-11-12 10:59:33,331 - INFO - Epoch: 20, Training Loss: 0.6873
2025-11-12 10:59:41,342 - INFO - Epoch: 21, Training Loss: 0.6877
2025-11-12 10:59:48,818 - INFO - Epoch: 22, Training Loss: 0.6868
2025-11-12 10:59:56,672 - INFO - Epoch: 23, Training Loss: 0.6872
2025-11-12 11:00:04,774 - INFO - Epoch: 24, Training Loss: 0.6873
2025-11-12 11:00:12,344 - INFO - Epoch: 25, Training Loss: 0.6877
2025-11-12 11:00:20,204 - INFO - Epoch: 26, Training Loss: 0.6870
2025-11-12 11:00:27,912 - INFO - Epoch: 27, Training Loss: 0.6872
2025-11-12 11:00:35,920 - INFO - Epoch: 28, Training Loss: 0.6874
2025-11-12 11:00:43,286 - INFO - Epoch: 29, Training Loss: 0.6877
2025-11-12 11:00:51,120 - INFO - Epoch: 30, Training Loss: 0.6869
2025-11-12 11:00:59,028 - INFO - Epoch: 31, Training Loss: 0.6889
2025-11-12 11:01:06,841 - INFO - Epoch: 32, Training Loss: 0.6871
2025-11-12 11:01:14,718 - INFO - Epoch: 33, Training Loss: 0.6870
2025-11-12 11:01:22,304 - INFO - Epoch: 34, Training Loss: 0.6875
2025-11-12 11:01:30,474 - INFO - Epoch: 35, Training Loss: 0.6876
2025-11-12 11:01:38,116 - INFO - Epoch: 36, Training Loss: 0.6874
2025-11-12 11:01:45,971 - INFO - Epoch: 37, Training Loss: 0.6873
2025-11-12 11:01:53,443 - INFO - Epoch: 38, Training Loss: 0.6873
2025-11-12 11:02:01,600 - INFO - Epoch: 39, Training Loss: 0.6876
2025-11-12 11:02:10,187 - INFO - Epoch: 40, Training Loss: 0.6874
2025-11-12 11:02:18,326 - INFO - Epoch: 41, Training Loss: 0.6866
2025-11-12 11:02:26,253 - INFO - Epoch: 42, Training Loss: 0.6878
2025-11-12 11:02:33,491 - INFO - Epoch: 43, Training Loss: 0.6871
2025-11-12 11:02:40,909 - INFO - Epoch: 44, Training Loss: 0.6863
2025-11-12 11:02:49,122 - INFO - Epoch: 45, Training Loss: 0.6869
2025-11-12 11:02:57,866 - INFO - Epoch: 46, Training Loss: 0.6869
2025-11-12 11:03:05,763 - INFO - Epoch: 47, Training Loss: 0.6868
2025-11-12 11:03:13,197 - INFO - Epoch: 48, Training Loss: 0.6861
2025-11-12 11:03:21,142 - INFO - Epoch: 49, Training Loss: 0.6864
2025-11-12 11:03:29,829 - INFO - Epoch: 50, Training Loss: 0.6846
2025-11-12 11:03:37,547 - INFO - Epoch: 51, Training Loss: 0.6827
2025-11-12 11:03:45,808 - INFO - Epoch: 52, Training Loss: 0.6795
2025-11-12 11:03:53,586 - INFO - Epoch: 53, Training Loss: 0.6737
2025-11-12 11:04:00,566 - INFO - Epoch: 54, Training Loss: 0.6729
2025-11-12 11:04:08,848 - INFO - Epoch: 55, Training Loss: 0.6726
2025-11-12 11:04:16,890 - INFO - Epoch: 56, Training Loss: 0.6734
2025-11-12 11:04:24,303 - INFO - Epoch: 57, Training Loss: 0.6717
2025-11-12 11:04:32,308 - INFO - Epoch: 58, Training Loss: 0.6728
2025-11-12 11:04:39,792 - INFO - Epoch: 59, Training Loss: 0.6721
2025-11-12 11:04:47,376 - INFO - Epoch: 60, Training Loss: 0.6715
2025-11-12 11:04:55,416 - INFO - Epoch: 61, Training Loss: 0.6731
2025-11-12 11:05:03,452 - INFO - Epoch: 62, Training Loss: 0.6725
2025-11-12 11:05:10,904 - INFO - Epoch: 63, Training Loss: 0.6710
2025-11-12 11:05:18,683 - INFO - Epoch: 64, Training Loss: 0.6765
2025-11-12 11:05:26,797 - INFO - Epoch: 65, Training Loss: 0.6792
2025-11-12 11:05:35,170 - INFO - Epoch: 66, Training Loss: 0.6721
2025-11-12 11:05:43,408 - INFO - Epoch: 67, Training Loss: 0.6710
2025-11-12 11:05:51,261 - INFO - Epoch: 68, Training Loss: 0.6704
2025-11-12 11:05:58,850 - INFO - Epoch: 69, Training Loss: 0.6704
2025-11-12 11:06:06,794 - INFO - Epoch: 70, Training Loss: 0.6709
2025-11-12 11:06:14,572 - INFO - Epoch: 71, Training Loss: 0.6699
2025-11-12 11:06:23,020 - INFO - Epoch: 72, Training Loss: 0.6699
2025-11-12 11:06:31,441 - INFO - Epoch: 73, Training Loss: 0.6701
2025-11-12 11:06:38,836 - INFO - Epoch: 74, Training Loss: 0.6700
2025-11-12 11:06:46,414 - INFO - Epoch: 75, Training Loss: 0.6698
2025-11-12 11:06:55,095 - INFO - Epoch: 76, Training Loss: 0.6703
2025-11-12 11:07:03,215 - INFO - Epoch: 77, Training Loss: 0.6710
2025-11-12 11:07:11,134 - INFO - Epoch: 78, Training Loss: 0.6700
2025-11-12 11:07:18,775 - INFO - Epoch: 79, Training Loss: 0.6695
2025-11-12 11:07:27,286 - INFO - Epoch: 80, Training Loss: 0.6695
2025-11-12 11:07:35,750 - INFO - Epoch: 81, Training Loss: 0.6698
2025-11-12 11:07:44,166 - INFO - Epoch: 82, Training Loss: 0.6699
2025-11-12 11:07:52,631 - INFO - Epoch: 83, Training Loss: 0.6694
2025-11-12 11:08:00,056 - INFO - Epoch: 84, Training Loss: 0.6694
2025-11-12 11:08:08,006 - INFO - Epoch: 85, Training Loss: 0.6695
2025-11-12 11:08:16,005 - INFO - Epoch: 86, Training Loss: 0.6690
2025-11-12 11:08:23,953 - INFO - Epoch: 87, Training Loss: 0.6699
2025-11-12 11:08:32,121 - INFO - Epoch: 88, Training Loss: 0.6690
2025-11-12 11:08:39,937 - INFO - Epoch: 89, Training Loss: 0.6691
2025-11-12 11:08:47,874 - INFO - Epoch: 90, Training Loss: 0.6694
2025-11-12 11:08:55,567 - INFO - Epoch: 91, Training Loss: 0.6682
2025-11-12 11:09:03,267 - INFO - Epoch: 92, Training Loss: 0.6687
2025-11-12 11:09:11,290 - INFO - Epoch: 93, Training Loss: 0.6682
2025-11-12 11:09:19,066 - INFO - Epoch: 94, Training Loss: 0.6697
2025-11-12 11:09:27,007 - INFO - Epoch: 95, Training Loss: 0.6690
2025-11-12 11:09:34,963 - INFO - Epoch: 96, Training Loss: 0.6686
2025-11-12 11:09:42,593 - INFO - Epoch: 97, Training Loss: 0.6677
2025-11-12 11:09:50,645 - INFO - Epoch: 98, Training Loss: 0.6689
2025-11-12 11:09:58,637 - INFO - Epoch: 99, Training Loss: 0.6676
2025-11-12 11:10:06,189 - INFO - Epoch: 100, Training Loss: 0.6679
2025-11-12 11:10:06,189 - INFO - Training completed for Trial 9 CV 3

