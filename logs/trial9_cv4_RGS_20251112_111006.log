2025-11-12 11:10:06,190 - INFO - Log file: ./logs/trial9_cv4_RGS_20251112_111006.log
2025-11-12 11:10:06,190 - INFO - START TRAINING TRIAL 9 CV 4 - Task: RGS
2025-11-12 11:10:06,190 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 11:10:06,190 - INFO - Loading dataset...
2025-11-12 11:10:06,349 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 11:10:06,349 - INFO - Initializing VIGNet model...
2025-11-12 11:10:06,352 - INFO - Number of batch iterations per epoch: 113
2025-11-12 11:10:14,017 - INFO - Epoch: 1, Training Loss: 0.8500
2025-11-12 11:10:22,256 - INFO - Epoch: 2, Training Loss: 0.6881
2025-11-12 11:10:29,878 - INFO - Epoch: 3, Training Loss: 0.6879
2025-11-12 11:10:38,550 - INFO - Epoch: 4, Training Loss: 0.6868
2025-11-12 11:10:47,273 - INFO - Epoch: 5, Training Loss: 0.6870
2025-11-12 11:10:55,801 - INFO - Epoch: 6, Training Loss: 0.6874
2025-11-12 11:11:04,167 - INFO - Epoch: 7, Training Loss: 0.6880
2025-11-12 11:11:12,852 - INFO - Epoch: 8, Training Loss: 0.6869
2025-11-12 11:11:21,476 - INFO - Epoch: 9, Training Loss: 0.6868
2025-11-12 11:11:28,554 - INFO - Epoch: 10, Training Loss: 0.6873
2025-11-12 11:11:37,643 - INFO - Epoch: 11, Training Loss: 0.6875
2025-11-12 11:11:45,221 - INFO - Epoch: 12, Training Loss: 0.6870
2025-11-12 11:11:52,938 - INFO - Epoch: 13, Training Loss: 0.6884
2025-11-12 11:12:01,435 - INFO - Epoch: 14, Training Loss: 0.6878
2025-11-12 11:12:10,235 - INFO - Epoch: 15, Training Loss: 0.6867
2025-11-12 11:12:18,845 - INFO - Epoch: 16, Training Loss: 0.6866
2025-11-12 11:12:26,886 - INFO - Epoch: 17, Training Loss: 0.6877
2025-11-12 11:12:34,864 - INFO - Epoch: 18, Training Loss: 0.6869
2025-11-12 11:12:43,593 - INFO - Epoch: 19, Training Loss: 0.6870
2025-11-12 11:12:52,360 - INFO - Epoch: 20, Training Loss: 0.6877
2025-11-12 11:13:01,767 - INFO - Epoch: 21, Training Loss: 0.6881
2025-11-12 11:13:10,388 - INFO - Epoch: 22, Training Loss: 0.6870
2025-11-12 11:13:18,587 - INFO - Epoch: 23, Training Loss: 0.6866
2025-11-12 11:13:26,550 - INFO - Epoch: 24, Training Loss: 0.6867
2025-11-12 11:13:34,244 - INFO - Epoch: 25, Training Loss: 0.6864
2025-11-12 11:13:42,042 - INFO - Epoch: 26, Training Loss: 0.6873
2025-11-12 11:13:50,167 - INFO - Epoch: 27, Training Loss: 0.6870
2025-11-12 11:13:58,425 - INFO - Epoch: 28, Training Loss: 0.6867
2025-11-12 11:14:07,138 - INFO - Epoch: 29, Training Loss: 0.6866
2025-11-12 11:14:14,366 - INFO - Epoch: 30, Training Loss: 0.6865
2025-11-12 11:14:21,977 - INFO - Epoch: 31, Training Loss: 0.6869
2025-11-12 11:14:30,412 - INFO - Epoch: 32, Training Loss: 0.6867
2025-11-12 11:14:39,129 - INFO - Epoch: 33, Training Loss: 0.6867
2025-11-12 11:14:47,711 - INFO - Epoch: 34, Training Loss: 0.6865
2025-11-12 11:14:55,442 - INFO - Epoch: 35, Training Loss: 0.6857
2025-11-12 11:15:03,590 - INFO - Epoch: 36, Training Loss: 0.6865
2025-11-12 11:15:12,465 - INFO - Epoch: 37, Training Loss: 0.6870
2025-11-12 11:15:20,877 - INFO - Epoch: 38, Training Loss: 0.6854
2025-11-12 11:15:28,259 - INFO - Epoch: 39, Training Loss: 0.6853
2025-11-12 11:15:36,350 - INFO - Epoch: 40, Training Loss: 0.6821
2025-11-12 11:15:44,064 - INFO - Epoch: 41, Training Loss: 0.6794
2025-11-12 11:15:51,774 - INFO - Epoch: 42, Training Loss: 0.6756
2025-11-12 11:15:59,743 - INFO - Epoch: 43, Training Loss: 0.6743
2025-11-12 11:16:07,272 - INFO - Epoch: 44, Training Loss: 0.6727
2025-11-12 11:16:15,177 - INFO - Epoch: 45, Training Loss: 0.6730
2025-11-12 11:16:24,278 - INFO - Epoch: 46, Training Loss: 0.6728
2025-11-12 11:16:32,744 - INFO - Epoch: 47, Training Loss: 0.6732
2025-11-12 11:16:40,599 - INFO - Epoch: 48, Training Loss: 0.6728
2025-11-12 11:16:48,380 - INFO - Epoch: 49, Training Loss: 0.6724
2025-11-12 11:16:56,571 - INFO - Epoch: 50, Training Loss: 0.6725
2025-11-12 11:17:05,476 - INFO - Epoch: 51, Training Loss: 0.6731
2025-11-12 11:17:13,603 - INFO - Epoch: 52, Training Loss: 0.6727
2025-11-12 11:17:21,528 - INFO - Epoch: 53, Training Loss: 0.6729
2025-11-12 11:17:29,306 - INFO - Epoch: 54, Training Loss: 0.6727
2025-11-12 11:17:37,938 - INFO - Epoch: 55, Training Loss: 0.6723
2025-11-12 11:17:45,911 - INFO - Epoch: 56, Training Loss: 0.6723
2025-11-12 11:17:54,233 - INFO - Epoch: 57, Training Loss: 0.6722
2025-11-12 11:18:02,490 - INFO - Epoch: 58, Training Loss: 0.6718
2025-11-12 11:18:10,540 - INFO - Epoch: 59, Training Loss: 0.6726
2025-11-12 11:18:18,455 - INFO - Epoch: 60, Training Loss: 0.6723
2025-11-12 11:18:27,112 - INFO - Epoch: 61, Training Loss: 0.6727
2025-11-12 11:18:35,590 - INFO - Epoch: 62, Training Loss: 0.6716
2025-11-12 11:18:44,038 - INFO - Epoch: 63, Training Loss: 0.6714
2025-11-12 11:18:52,128 - INFO - Epoch: 64, Training Loss: 0.6719
2025-11-12 11:19:00,135 - INFO - Epoch: 65, Training Loss: 0.6727
2025-11-12 11:19:07,913 - INFO - Epoch: 66, Training Loss: 0.6726
2025-11-12 11:19:15,797 - INFO - Epoch: 67, Training Loss: 0.6718
2025-11-12 11:19:23,989 - INFO - Epoch: 68, Training Loss: 0.6716
2025-11-12 11:19:31,566 - INFO - Epoch: 69, Training Loss: 0.6723
2025-11-12 11:19:39,597 - INFO - Epoch: 70, Training Loss: 0.6718
2025-11-12 11:19:46,971 - INFO - Epoch: 71, Training Loss: 0.6714
2025-11-12 11:19:54,914 - INFO - Epoch: 72, Training Loss: 0.6718
2025-11-12 11:20:02,865 - INFO - Epoch: 73, Training Loss: 0.6718
2025-11-12 11:20:10,251 - INFO - Epoch: 74, Training Loss: 0.6720
2025-11-12 11:20:18,901 - INFO - Epoch: 75, Training Loss: 0.6707
2025-11-12 11:20:27,057 - INFO - Epoch: 76, Training Loss: 0.6732
2025-11-12 11:20:34,664 - INFO - Epoch: 77, Training Loss: 0.6715
2025-11-12 11:20:43,085 - INFO - Epoch: 78, Training Loss: 0.6709
2025-11-12 11:20:51,942 - INFO - Epoch: 79, Training Loss: 0.6720
2025-11-12 11:20:59,608 - INFO - Epoch: 80, Training Loss: 0.6714
2025-11-12 11:21:07,766 - INFO - Epoch: 81, Training Loss: 0.6703
2025-11-12 11:21:15,810 - INFO - Epoch: 82, Training Loss: 0.6715
2025-11-12 11:21:23,868 - INFO - Epoch: 83, Training Loss: 0.6704
2025-11-12 11:21:31,762 - INFO - Epoch: 84, Training Loss: 0.6708
2025-11-12 11:21:39,624 - INFO - Epoch: 85, Training Loss: 0.6704
2025-11-12 11:21:48,020 - INFO - Epoch: 86, Training Loss: 0.6701
2025-11-12 11:21:55,972 - INFO - Epoch: 87, Training Loss: 0.6701
2025-11-12 11:22:04,809 - INFO - Epoch: 88, Training Loss: 0.6700
2025-11-12 11:22:13,043 - INFO - Epoch: 89, Training Loss: 0.6693
2025-11-12 11:22:21,962 - INFO - Epoch: 90, Training Loss: 0.6698
2025-11-12 11:22:29,415 - INFO - Epoch: 91, Training Loss: 0.6695
2025-11-12 11:22:37,146 - INFO - Epoch: 92, Training Loss: 0.6690
2025-11-12 11:22:44,497 - INFO - Epoch: 93, Training Loss: 0.6693
2025-11-12 11:22:52,746 - INFO - Epoch: 94, Training Loss: 0.6689
2025-11-12 11:23:00,883 - INFO - Epoch: 95, Training Loss: 0.6686
2025-11-12 11:23:09,552 - INFO - Epoch: 96, Training Loss: 0.6688
2025-11-12 11:23:17,338 - INFO - Epoch: 97, Training Loss: 0.6683
2025-11-12 11:23:25,151 - INFO - Epoch: 98, Training Loss: 0.6690
2025-11-12 11:23:32,871 - INFO - Epoch: 99, Training Loss: 0.6690
2025-11-12 11:23:40,542 - INFO - Epoch: 100, Training Loss: 0.6689
2025-11-12 11:23:40,542 - INFO - Training completed for Trial 9 CV 4

