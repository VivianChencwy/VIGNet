2025-11-13 12:27:36,285 - INFO - Log file: ./logs/trial15_cv0_RGS_20251113_122736.log
2025-11-13 12:27:36,285 - INFO - START TRAINING TRIAL 15 CV 0 - Task: RGS
2025-11-13 12:27:36,285 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-13 12:27:36,285 - INFO - Loading dataset...
2025-11-13 12:27:36,375 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-13 12:27:36,375 - INFO - Initializing VIGNet model...
2025-11-13 12:27:36,378 - INFO - Number of batch iterations per epoch: 113
2025-11-13 12:27:50,486 - INFO - Epoch: 1, Training Loss: 1.4108
2025-11-13 12:28:03,979 - INFO - Epoch: 2, Training Loss: 0.8720
2025-11-13 12:28:14,581 - INFO - Epoch: 3, Training Loss: 0.6971
2025-11-13 12:28:26,632 - INFO - Epoch: 4, Training Loss: 0.6940
2025-11-13 12:28:39,967 - INFO - Epoch: 5, Training Loss: 0.6870
2025-11-13 12:28:52,208 - INFO - Epoch: 6, Training Loss: 0.6874
2025-11-13 12:29:04,593 - INFO - Epoch: 7, Training Loss: 0.6861
2025-11-13 12:29:17,136 - INFO - Epoch: 8, Training Loss: 0.6855
2025-11-13 12:29:31,252 - INFO - Epoch: 9, Training Loss: 0.6877
2025-11-13 12:29:43,025 - INFO - Epoch: 10, Training Loss: 0.6859
2025-11-13 12:29:57,269 - INFO - Epoch: 11, Training Loss: 0.6829
2025-11-13 12:30:08,887 - INFO - Epoch: 12, Training Loss: 0.6839
2025-11-13 12:30:20,609 - INFO - Epoch: 13, Training Loss: 0.6824
2025-11-13 12:30:33,403 - INFO - Epoch: 14, Training Loss: 0.6851
2025-11-13 12:30:43,347 - INFO - Epoch: 15, Training Loss: 0.6851
2025-11-13 12:30:52,871 - INFO - Epoch: 16, Training Loss: 0.6855
2025-11-13 12:31:06,632 - INFO - Epoch: 17, Training Loss: 0.6827
2025-11-13 12:31:23,100 - INFO - Epoch: 18, Training Loss: 0.6834
2025-11-13 12:31:34,206 - INFO - Epoch: 19, Training Loss: 0.6844
2025-11-13 12:31:46,635 - INFO - Epoch: 20, Training Loss: 0.6832
2025-11-13 12:32:01,100 - INFO - Epoch: 21, Training Loss: 0.6855
2025-11-13 12:32:10,827 - INFO - Epoch: 22, Training Loss: 0.6855
2025-11-13 12:32:23,769 - INFO - Epoch: 23, Training Loss: 0.6843
2025-11-13 12:32:37,844 - INFO - Epoch: 24, Training Loss: 0.6834
2025-11-13 12:32:49,405 - INFO - Epoch: 25, Training Loss: 0.6824
2025-11-13 12:33:01,931 - INFO - Epoch: 26, Training Loss: 0.6847
2025-11-13 12:33:15,679 - INFO - Epoch: 27, Training Loss: 0.6840
2025-11-13 12:33:29,096 - INFO - Epoch: 28, Training Loss: 0.6823
2025-11-13 12:33:44,633 - INFO - Epoch: 29, Training Loss: 0.6846
2025-11-13 12:33:57,326 - INFO - Epoch: 30, Training Loss: 0.6831
2025-11-13 12:34:10,007 - INFO - Epoch: 31, Training Loss: 0.6818
2025-11-13 12:34:24,251 - INFO - Epoch: 32, Training Loss: 0.6833
2025-11-13 12:34:37,293 - INFO - Epoch: 33, Training Loss: 0.6822
2025-11-13 12:34:52,116 - INFO - Epoch: 34, Training Loss: 0.6828
2025-11-13 12:35:07,754 - INFO - Epoch: 35, Training Loss: 0.6839
2025-11-13 12:35:22,559 - INFO - Epoch: 36, Training Loss: 0.6830
2025-11-13 12:35:31,997 - INFO - Epoch: 37, Training Loss: 0.6830
2025-11-13 12:35:41,782 - INFO - Epoch: 38, Training Loss: 0.6843
2025-11-13 12:35:56,373 - INFO - Epoch: 39, Training Loss: 0.6832
2025-11-13 12:36:05,803 - INFO - Epoch: 40, Training Loss: 0.6831
2025-11-13 12:36:19,263 - INFO - Epoch: 41, Training Loss: 0.6826
2025-11-13 12:36:30,073 - INFO - Epoch: 42, Training Loss: 0.6837
2025-11-13 12:36:40,733 - INFO - Epoch: 43, Training Loss: 0.6837
2025-11-13 12:36:55,415 - INFO - Epoch: 44, Training Loss: 0.6831
2025-11-13 12:37:07,131 - INFO - Epoch: 45, Training Loss: 0.6834
2025-11-13 12:37:22,113 - INFO - Epoch: 46, Training Loss: 0.6838
2025-11-13 12:37:32,568 - INFO - Epoch: 47, Training Loss: 0.6835
2025-11-13 12:37:43,102 - INFO - Epoch: 48, Training Loss: 0.6839
2025-11-13 12:37:56,616 - INFO - Epoch: 49, Training Loss: 0.6842
2025-11-13 12:38:11,442 - INFO - Epoch: 50, Training Loss: 0.6833
2025-11-13 12:38:25,983 - INFO - Epoch: 51, Training Loss: 0.6828
2025-11-13 12:38:37,580 - INFO - Epoch: 52, Training Loss: 0.6832
2025-11-13 12:38:50,287 - INFO - Epoch: 53, Training Loss: 0.6839
2025-11-13 12:39:02,215 - INFO - Epoch: 54, Training Loss: 0.6828
2025-11-13 12:39:18,157 - INFO - Epoch: 55, Training Loss: 0.6846
2025-11-13 12:39:30,084 - INFO - Epoch: 56, Training Loss: 0.6837
2025-11-13 12:39:44,260 - INFO - Epoch: 57, Training Loss: 0.6826
2025-11-13 12:39:58,784 - INFO - Epoch: 58, Training Loss: 0.6839
2025-11-13 12:40:11,904 - INFO - Epoch: 59, Training Loss: 0.6834
2025-11-13 12:40:21,969 - INFO - Epoch: 60, Training Loss: 0.6830
2025-11-13 12:40:38,637 - INFO - Epoch: 61, Training Loss: 0.6839
2025-11-13 12:40:53,722 - INFO - Epoch: 62, Training Loss: 0.6841
2025-11-13 12:41:04,181 - INFO - Epoch: 63, Training Loss: 0.6830
2025-11-13 12:41:17,008 - INFO - Epoch: 64, Training Loss: 0.6827
2025-11-13 12:41:31,796 - INFO - Epoch: 65, Training Loss: 0.6829
2025-11-13 12:41:43,624 - INFO - Epoch: 66, Training Loss: 0.6833
2025-11-13 12:41:55,597 - INFO - Epoch: 67, Training Loss: 0.6829
2025-11-13 12:42:05,510 - INFO - Epoch: 68, Training Loss: 0.6830
2025-11-13 12:42:18,103 - INFO - Epoch: 69, Training Loss: 0.6833
2025-11-13 12:42:30,688 - INFO - Epoch: 70, Training Loss: 0.6833
2025-11-13 12:42:42,756 - INFO - Epoch: 71, Training Loss: 0.6845
2025-11-13 12:42:55,519 - INFO - Epoch: 72, Training Loss: 0.6821
2025-11-13 12:43:08,679 - INFO - Epoch: 73, Training Loss: 0.6836
2025-11-13 12:43:19,354 - INFO - Epoch: 74, Training Loss: 0.6843
2025-11-13 12:43:30,956 - INFO - Epoch: 75, Training Loss: 0.6830
2025-11-13 12:43:45,229 - INFO - Epoch: 76, Training Loss: 0.6835
2025-11-13 12:43:56,756 - INFO - Epoch: 77, Training Loss: 0.6832
2025-11-13 12:44:08,461 - INFO - Epoch: 78, Training Loss: 0.6824
2025-11-13 12:44:20,466 - INFO - Epoch: 79, Training Loss: 0.6828
2025-11-13 12:44:32,338 - INFO - Epoch: 80, Training Loss: 0.6831
2025-11-13 12:44:46,906 - INFO - Epoch: 81, Training Loss: 0.6829
2025-11-13 12:45:01,616 - INFO - Epoch: 82, Training Loss: 0.6817
2025-11-13 12:45:14,304 - INFO - Epoch: 83, Training Loss: 0.6829
2025-11-13 12:45:25,381 - INFO - Epoch: 84, Training Loss: 0.6825
2025-11-13 12:45:36,474 - INFO - Epoch: 85, Training Loss: 0.6829
2025-11-13 12:45:49,938 - INFO - Epoch: 86, Training Loss: 0.6829
2025-11-13 12:46:04,062 - INFO - Epoch: 87, Training Loss: 0.6818
2025-11-13 12:46:12,883 - INFO - Epoch: 88, Training Loss: 0.6812
2025-11-13 12:46:24,040 - INFO - Epoch: 89, Training Loss: 0.6787
2025-11-13 12:46:36,877 - INFO - Epoch: 90, Training Loss: 0.6758
2025-11-13 12:46:48,972 - INFO - Epoch: 91, Training Loss: 0.6722
2025-11-13 12:47:02,457 - INFO - Epoch: 92, Training Loss: 0.6695
2025-11-13 12:47:16,120 - INFO - Epoch: 93, Training Loss: 0.6675
2025-11-13 12:47:29,588 - INFO - Epoch: 94, Training Loss: 0.6639
2025-11-13 12:47:42,207 - INFO - Epoch: 95, Training Loss: 0.6621
2025-11-13 12:47:53,117 - INFO - Epoch: 96, Training Loss: 0.6594
2025-11-13 12:48:03,734 - INFO - Epoch: 97, Training Loss: 0.6593
2025-11-13 12:48:15,285 - INFO - Epoch: 98, Training Loss: 0.6561
2025-11-13 12:48:26,481 - INFO - Epoch: 99, Training Loss: 0.6565
2025-11-13 12:48:39,008 - INFO - Epoch: 100, Training Loss: 0.6530
2025-11-13 12:48:39,008 - INFO - Training completed for Trial 15 CV 0

