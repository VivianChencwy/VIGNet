2025-11-12 04:44:08,545 - INFO - Log file: ./logs/trial4_cv0_RGS_20251112_044408.log
2025-11-12 04:44:08,545 - INFO - START TRAINING TRIAL 4 CV 0 - Task: RGS
2025-11-12 04:44:08,545 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 04:44:08,545 - INFO - Loading dataset...
2025-11-12 04:44:08,644 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 04:44:08,644 - INFO - Initializing VIGNet model...
2025-11-12 04:44:08,647 - INFO - Number of batch iterations per epoch: 113
2025-11-12 04:44:17,166 - INFO - Epoch: 1, Training Loss: 0.7342
2025-11-12 04:44:25,263 - INFO - Epoch: 2, Training Loss: 0.6459
2025-11-12 04:44:32,742 - INFO - Epoch: 3, Training Loss: 0.6465
2025-11-12 04:44:41,191 - INFO - Epoch: 4, Training Loss: 0.6461
2025-11-12 04:44:49,281 - INFO - Epoch: 5, Training Loss: 0.6447
2025-11-12 04:44:57,148 - INFO - Epoch: 6, Training Loss: 0.6459
2025-11-12 04:45:04,526 - INFO - Epoch: 7, Training Loss: 0.6448
2025-11-12 04:45:13,708 - INFO - Epoch: 8, Training Loss: 0.6446
2025-11-12 04:45:22,755 - INFO - Epoch: 9, Training Loss: 0.6446
2025-11-12 04:45:31,029 - INFO - Epoch: 10, Training Loss: 0.6444
2025-11-12 04:45:38,924 - INFO - Epoch: 11, Training Loss: 0.6453
2025-11-12 04:45:47,527 - INFO - Epoch: 12, Training Loss: 0.6440
2025-11-12 04:45:55,431 - INFO - Epoch: 13, Training Loss: 0.6435
2025-11-12 04:46:02,977 - INFO - Epoch: 14, Training Loss: 0.6444
2025-11-12 04:46:10,870 - INFO - Epoch: 15, Training Loss: 0.6448
2025-11-12 04:46:18,992 - INFO - Epoch: 16, Training Loss: 0.6454
2025-11-12 04:46:26,618 - INFO - Epoch: 17, Training Loss: 0.6445
2025-11-12 04:46:34,639 - INFO - Epoch: 18, Training Loss: 0.6433
2025-11-12 04:46:41,847 - INFO - Epoch: 19, Training Loss: 0.6439
2025-11-12 04:46:50,094 - INFO - Epoch: 20, Training Loss: 0.6428
2025-11-12 04:46:57,691 - INFO - Epoch: 21, Training Loss: 0.6442
2025-11-12 04:47:05,362 - INFO - Epoch: 22, Training Loss: 0.6441
2025-11-12 04:47:12,798 - INFO - Epoch: 23, Training Loss: 0.6445
2025-11-12 04:47:20,499 - INFO - Epoch: 24, Training Loss: 0.6429
2025-11-12 04:47:27,792 - INFO - Epoch: 25, Training Loss: 0.6443
2025-11-12 04:47:35,180 - INFO - Epoch: 26, Training Loss: 0.6433
2025-11-12 04:47:43,752 - INFO - Epoch: 27, Training Loss: 0.6450
2025-11-12 04:47:51,554 - INFO - Epoch: 28, Training Loss: 0.6447
2025-11-12 04:47:59,776 - INFO - Epoch: 29, Training Loss: 0.6448
2025-11-12 04:48:07,770 - INFO - Epoch: 30, Training Loss: 0.6428
2025-11-12 04:48:15,731 - INFO - Epoch: 31, Training Loss: 0.6442
2025-11-12 04:48:23,731 - INFO - Epoch: 32, Training Loss: 0.6435
2025-11-12 04:48:31,694 - INFO - Epoch: 33, Training Loss: 0.6437
2025-11-12 04:48:39,802 - INFO - Epoch: 34, Training Loss: 0.6444
2025-11-12 04:48:48,528 - INFO - Epoch: 35, Training Loss: 0.6430
2025-11-12 04:48:56,418 - INFO - Epoch: 36, Training Loss: 0.6434
2025-11-12 04:49:03,946 - INFO - Epoch: 37, Training Loss: 0.6450
2025-11-12 04:49:12,845 - INFO - Epoch: 38, Training Loss: 0.6430
2025-11-12 04:49:20,480 - INFO - Epoch: 39, Training Loss: 0.6447
2025-11-12 04:49:28,210 - INFO - Epoch: 40, Training Loss: 0.6397
2025-11-12 04:49:35,338 - INFO - Epoch: 41, Training Loss: 0.6341
2025-11-12 04:49:43,870 - INFO - Epoch: 42, Training Loss: 0.6227
2025-11-12 04:49:51,092 - INFO - Epoch: 43, Training Loss: 0.6210
2025-11-12 04:49:58,588 - INFO - Epoch: 44, Training Loss: 0.6151
2025-11-12 04:50:06,744 - INFO - Epoch: 45, Training Loss: 0.6109
2025-11-12 04:50:14,857 - INFO - Epoch: 46, Training Loss: 0.6088
2025-11-12 04:50:22,992 - INFO - Epoch: 47, Training Loss: 0.6090
2025-11-12 04:50:31,826 - INFO - Epoch: 48, Training Loss: 0.6040
2025-11-12 04:50:40,414 - INFO - Epoch: 49, Training Loss: 0.6032
2025-11-12 04:50:48,404 - INFO - Epoch: 50, Training Loss: 0.6050
2025-11-12 04:50:56,650 - INFO - Epoch: 51, Training Loss: 0.6017
2025-11-12 04:51:05,968 - INFO - Epoch: 52, Training Loss: 0.6037
2025-11-12 04:51:13,822 - INFO - Epoch: 53, Training Loss: 0.6043
2025-11-12 04:51:21,855 - INFO - Epoch: 54, Training Loss: 0.6005
2025-11-12 04:51:29,723 - INFO - Epoch: 55, Training Loss: 0.6003
2025-11-12 04:51:38,969 - INFO - Epoch: 56, Training Loss: 0.6008
2025-11-12 04:51:47,277 - INFO - Epoch: 57, Training Loss: 0.5992
2025-11-12 04:51:55,649 - INFO - Epoch: 58, Training Loss: 0.6006
2025-11-12 04:52:02,820 - INFO - Epoch: 59, Training Loss: 0.6006
2025-11-12 04:52:10,930 - INFO - Epoch: 60, Training Loss: 0.5994
2025-11-12 04:52:18,971 - INFO - Epoch: 61, Training Loss: 0.5999
2025-11-12 04:52:27,463 - INFO - Epoch: 62, Training Loss: 0.5979
2025-11-12 04:52:36,071 - INFO - Epoch: 63, Training Loss: 0.5967
2025-11-12 04:52:43,518 - INFO - Epoch: 64, Training Loss: 0.5956
2025-11-12 04:52:51,275 - INFO - Epoch: 65, Training Loss: 0.5949
2025-11-12 04:52:59,009 - INFO - Epoch: 66, Training Loss: 0.5942
2025-11-12 04:53:06,730 - INFO - Epoch: 67, Training Loss: 0.6006
2025-11-12 04:53:14,402 - INFO - Epoch: 68, Training Loss: 0.5975
2025-11-12 04:53:21,812 - INFO - Epoch: 69, Training Loss: 0.5954
2025-11-12 04:53:30,216 - INFO - Epoch: 70, Training Loss: 0.5951
2025-11-12 04:53:37,867 - INFO - Epoch: 71, Training Loss: 0.6164
2025-11-12 04:53:46,129 - INFO - Epoch: 72, Training Loss: 0.6131
2025-11-12 04:53:53,772 - INFO - Epoch: 73, Training Loss: 0.5983
2025-11-12 04:54:00,922 - INFO - Epoch: 74, Training Loss: 0.5967
2025-11-12 04:54:08,592 - INFO - Epoch: 75, Training Loss: 0.5950
2025-11-12 04:54:16,237 - INFO - Epoch: 76, Training Loss: 0.5935
2025-11-12 04:54:24,182 - INFO - Epoch: 77, Training Loss: 0.5933
2025-11-12 04:54:32,376 - INFO - Epoch: 78, Training Loss: 0.5932
2025-11-12 04:54:40,311 - INFO - Epoch: 79, Training Loss: 0.5925
2025-11-12 04:54:48,309 - INFO - Epoch: 80, Training Loss: 0.5911
2025-11-12 04:54:56,498 - INFO - Epoch: 81, Training Loss: 0.6269
2025-11-12 04:55:04,415 - INFO - Epoch: 82, Training Loss: 0.6300
2025-11-12 04:55:12,375 - INFO - Epoch: 83, Training Loss: 0.6270
2025-11-12 04:55:19,864 - INFO - Epoch: 84, Training Loss: 0.6219
2025-11-12 04:55:28,661 - INFO - Epoch: 85, Training Loss: 0.6149
2025-11-12 04:55:36,906 - INFO - Epoch: 86, Training Loss: 0.6115
2025-11-12 04:55:44,817 - INFO - Epoch: 87, Training Loss: 0.6093
2025-11-12 04:55:52,282 - INFO - Epoch: 88, Training Loss: 0.6086
2025-11-12 04:56:00,590 - INFO - Epoch: 89, Training Loss: 0.6053
2025-11-12 04:56:08,667 - INFO - Epoch: 90, Training Loss: 0.6021
2025-11-12 04:56:17,168 - INFO - Epoch: 91, Training Loss: 0.6013
2025-11-12 04:56:24,710 - INFO - Epoch: 92, Training Loss: 0.6011
2025-11-12 04:56:32,098 - INFO - Epoch: 93, Training Loss: 0.6003
2025-11-12 04:56:39,966 - INFO - Epoch: 94, Training Loss: 0.5985
2025-11-12 04:56:48,318 - INFO - Epoch: 95, Training Loss: 0.5977
2025-11-12 04:56:55,921 - INFO - Epoch: 96, Training Loss: 0.5981
2025-11-12 04:57:03,716 - INFO - Epoch: 97, Training Loss: 0.5964
2025-11-12 04:57:11,884 - INFO - Epoch: 98, Training Loss: 0.5985
2025-11-12 04:57:19,862 - INFO - Epoch: 99, Training Loss: 0.5978
2025-11-12 04:57:27,358 - INFO - Epoch: 100, Training Loss: 0.5958
2025-11-12 04:57:27,358 - INFO - Training completed for Trial 4 CV 0

