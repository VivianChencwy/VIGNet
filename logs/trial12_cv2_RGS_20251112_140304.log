2025-11-12 14:03:04,689 - INFO - Log file: ./logs/trial12_cv2_RGS_20251112_140304.log
2025-11-12 14:03:04,689 - INFO - START TRAINING TRIAL 12 CV 2 - Task: RGS
2025-11-12 14:03:04,689 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 14:03:04,689 - INFO - Loading dataset...
2025-11-12 14:03:04,967 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 14:03:04,967 - INFO - Initializing VIGNet model...
2025-11-12 14:03:04,972 - INFO - Number of batch iterations per epoch: 113
2025-11-12 14:03:13,863 - INFO - Epoch: 1, Training Loss: 1.4653
2025-11-12 14:03:22,320 - INFO - Epoch: 2, Training Loss: 0.7083
2025-11-12 14:03:30,260 - INFO - Epoch: 3, Training Loss: 0.6797
2025-11-12 14:03:38,024 - INFO - Epoch: 4, Training Loss: 0.6961
2025-11-12 14:03:46,122 - INFO - Epoch: 5, Training Loss: 0.6697
2025-11-12 14:03:54,094 - INFO - Epoch: 6, Training Loss: 0.6683
2025-11-12 14:04:01,773 - INFO - Epoch: 7, Training Loss: 0.6781
2025-11-12 14:04:09,752 - INFO - Epoch: 8, Training Loss: 0.6711
2025-11-12 14:04:17,441 - INFO - Epoch: 9, Training Loss: 0.6672
2025-11-12 14:04:26,198 - INFO - Epoch: 10, Training Loss: 0.6705
2025-11-12 14:04:33,970 - INFO - Epoch: 11, Training Loss: 0.6692
2025-11-12 14:04:41,708 - INFO - Epoch: 12, Training Loss: 0.6633
2025-11-12 14:04:49,145 - INFO - Epoch: 13, Training Loss: 0.6691
2025-11-12 14:04:57,546 - INFO - Epoch: 14, Training Loss: 0.6641
2025-11-12 14:05:06,360 - INFO - Epoch: 15, Training Loss: 0.6675
2025-11-12 14:05:14,237 - INFO - Epoch: 16, Training Loss: 0.6685
2025-11-12 14:05:21,895 - INFO - Epoch: 17, Training Loss: 0.6701
2025-11-12 14:05:29,589 - INFO - Epoch: 18, Training Loss: 0.6671
2025-11-12 14:05:37,629 - INFO - Epoch: 19, Training Loss: 0.6646
2025-11-12 14:05:46,360 - INFO - Epoch: 20, Training Loss: 0.6636
2025-11-12 14:05:54,651 - INFO - Epoch: 21, Training Loss: 0.6631
2025-11-12 14:06:02,777 - INFO - Epoch: 22, Training Loss: 0.6665
2025-11-12 14:06:10,829 - INFO - Epoch: 23, Training Loss: 0.6650
2025-11-12 14:06:18,316 - INFO - Epoch: 24, Training Loss: 0.6594
2025-11-12 14:06:26,390 - INFO - Epoch: 25, Training Loss: 0.6620
2025-11-12 14:06:34,932 - INFO - Epoch: 26, Training Loss: 0.6654
2025-11-12 14:06:43,619 - INFO - Epoch: 27, Training Loss: 0.6570
2025-11-12 14:06:52,675 - INFO - Epoch: 28, Training Loss: 0.6512
2025-11-12 14:07:00,713 - INFO - Epoch: 29, Training Loss: 0.6465
2025-11-12 14:07:08,843 - INFO - Epoch: 30, Training Loss: 0.6163
2025-11-12 14:07:16,997 - INFO - Epoch: 31, Training Loss: 0.5998
2025-11-12 14:07:25,009 - INFO - Epoch: 32, Training Loss: 0.6212
2025-11-12 14:07:32,495 - INFO - Epoch: 33, Training Loss: 0.5765
2025-11-12 14:07:41,144 - INFO - Epoch: 34, Training Loss: 0.5869
2025-11-12 14:07:49,283 - INFO - Epoch: 35, Training Loss: 0.5702
2025-11-12 14:07:56,919 - INFO - Epoch: 36, Training Loss: 0.6018
2025-11-12 14:08:04,322 - INFO - Epoch: 37, Training Loss: 0.6552
2025-11-12 14:08:12,412 - INFO - Epoch: 38, Training Loss: 0.5642
2025-11-12 14:08:21,231 - INFO - Epoch: 39, Training Loss: 0.5448
2025-11-12 14:08:28,719 - INFO - Epoch: 40, Training Loss: 0.5851
2025-11-12 14:08:36,278 - INFO - Epoch: 41, Training Loss: 0.5790
2025-11-12 14:08:43,929 - INFO - Epoch: 42, Training Loss: 0.5410
2025-11-12 14:08:51,435 - INFO - Epoch: 43, Training Loss: 0.5718
2025-11-12 14:08:59,695 - INFO - Epoch: 44, Training Loss: 0.5729
2025-11-12 14:09:07,241 - INFO - Epoch: 45, Training Loss: 0.5610
2025-11-12 14:09:15,699 - INFO - Epoch: 46, Training Loss: 0.5594
2025-11-12 14:09:23,519 - INFO - Epoch: 47, Training Loss: 0.5223
2025-11-12 14:09:31,224 - INFO - Epoch: 48, Training Loss: 0.5545
2025-11-12 14:09:39,250 - INFO - Epoch: 49, Training Loss: 0.5532
2025-11-12 14:09:46,688 - INFO - Epoch: 50, Training Loss: 0.5629
2025-11-12 14:09:54,874 - INFO - Epoch: 51, Training Loss: 0.5086
2025-11-12 14:10:02,700 - INFO - Epoch: 52, Training Loss: 0.4984
2025-11-12 14:10:10,978 - INFO - Epoch: 53, Training Loss: 0.4920
2025-11-12 14:10:18,858 - INFO - Epoch: 54, Training Loss: 0.5594
2025-11-12 14:10:27,366 - INFO - Epoch: 55, Training Loss: 0.5090
2025-11-12 14:10:35,330 - INFO - Epoch: 56, Training Loss: 0.4707
2025-11-12 14:10:43,924 - INFO - Epoch: 57, Training Loss: 0.4995
2025-11-12 14:10:52,125 - INFO - Epoch: 58, Training Loss: 0.4779
2025-11-12 14:10:59,581 - INFO - Epoch: 59, Training Loss: 0.4652
2025-11-12 14:11:07,847 - INFO - Epoch: 60, Training Loss: 0.4626
2025-11-12 14:11:16,023 - INFO - Epoch: 61, Training Loss: 0.4546
2025-11-12 14:11:24,123 - INFO - Epoch: 62, Training Loss: 0.4579
2025-11-12 14:11:32,879 - INFO - Epoch: 63, Training Loss: 0.4478
2025-11-12 14:11:40,578 - INFO - Epoch: 64, Training Loss: 0.4568
2025-11-12 14:11:47,876 - INFO - Epoch: 65, Training Loss: 0.4498
2025-11-12 14:11:55,542 - INFO - Epoch: 66, Training Loss: 0.4411
2025-11-12 14:12:03,655 - INFO - Epoch: 67, Training Loss: 0.4575
2025-11-12 14:12:11,680 - INFO - Epoch: 68, Training Loss: 0.4693
2025-11-12 14:12:20,306 - INFO - Epoch: 69, Training Loss: 0.5116
2025-11-12 14:12:28,400 - INFO - Epoch: 70, Training Loss: 0.4620
2025-11-12 14:12:35,964 - INFO - Epoch: 71, Training Loss: 0.4455
2025-11-12 14:12:43,651 - INFO - Epoch: 72, Training Loss: 0.4369
2025-11-12 14:12:51,628 - INFO - Epoch: 73, Training Loss: 0.4444
2025-11-12 14:13:00,028 - INFO - Epoch: 74, Training Loss: 0.4695
2025-11-12 14:13:08,545 - INFO - Epoch: 75, Training Loss: 0.4382
2025-11-12 14:13:16,262 - INFO - Epoch: 76, Training Loss: 0.4605
2025-11-12 14:13:24,189 - INFO - Epoch: 77, Training Loss: 0.4488
2025-11-12 14:13:32,825 - INFO - Epoch: 78, Training Loss: 0.4694
2025-11-12 14:13:40,728 - INFO - Epoch: 79, Training Loss: 0.4355
2025-11-12 14:13:48,581 - INFO - Epoch: 80, Training Loss: 0.4269
2025-11-12 14:13:56,258 - INFO - Epoch: 81, Training Loss: 0.4394
2025-11-12 14:14:04,340 - INFO - Epoch: 82, Training Loss: 0.4730
2025-11-12 14:14:13,301 - INFO - Epoch: 83, Training Loss: 0.4509
2025-11-12 14:14:20,986 - INFO - Epoch: 84, Training Loss: 0.4258
2025-11-12 14:14:29,434 - INFO - Epoch: 85, Training Loss: 0.4481
2025-11-12 14:14:36,967 - INFO - Epoch: 86, Training Loss: 0.4571
2025-11-12 14:14:45,223 - INFO - Epoch: 87, Training Loss: 0.4483
2025-11-12 14:14:52,602 - INFO - Epoch: 88, Training Loss: 0.4283
2025-11-12 14:15:00,356 - INFO - Epoch: 89, Training Loss: 0.4404
2025-11-12 14:15:08,247 - INFO - Epoch: 90, Training Loss: 0.4312
2025-11-12 14:15:16,287 - INFO - Epoch: 91, Training Loss: 0.4531
2025-11-12 14:15:23,899 - INFO - Epoch: 92, Training Loss: 0.4272
2025-11-12 14:15:32,348 - INFO - Epoch: 93, Training Loss: 0.4286
2025-11-12 14:15:40,395 - INFO - Epoch: 94, Training Loss: 0.4292
2025-11-12 14:15:49,230 - INFO - Epoch: 95, Training Loss: 0.4194
2025-11-12 14:15:57,329 - INFO - Epoch: 96, Training Loss: 0.4048
2025-11-12 14:16:04,467 - INFO - Epoch: 97, Training Loss: 0.4268
2025-11-12 14:16:12,750 - INFO - Epoch: 98, Training Loss: 0.4283
2025-11-12 14:16:20,471 - INFO - Epoch: 99, Training Loss: 0.3996
2025-11-12 14:16:28,167 - INFO - Epoch: 100, Training Loss: 0.4436
2025-11-12 14:16:28,167 - INFO - Training completed for Trial 12 CV 2

