2025-11-12 01:24:04,816 - INFO - Log file: ./logs/trial1_cv0_RGS_20251112_012404.log
2025-11-12 01:24:04,816 - INFO - START TRAINING TRIAL 1 CV 0 - Task: RGS
2025-11-12 01:24:04,817 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 01:24:04,817 - INFO - Loading dataset...
2025-11-12 01:24:04,906 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 01:24:04,906 - INFO - Initializing VIGNet model...
2025-11-12 01:24:04,912 - INFO - Number of batch iterations per epoch: 113
2025-11-12 01:24:13,786 - INFO - Epoch: 1, Training Loss: 1.5209
2025-11-12 01:24:20,717 - INFO - Epoch: 2, Training Loss: 0.6727
2025-11-12 01:24:29,065 - INFO - Epoch: 3, Training Loss: 0.6545
2025-11-12 01:24:36,330 - INFO - Epoch: 4, Training Loss: 0.6463
2025-11-12 01:24:44,990 - INFO - Epoch: 5, Training Loss: 0.6459
2025-11-12 01:24:53,084 - INFO - Epoch: 6, Training Loss: 0.6456
2025-11-12 01:25:01,488 - INFO - Epoch: 7, Training Loss: 0.6414
2025-11-12 01:25:09,038 - INFO - Epoch: 8, Training Loss: 0.6368
2025-11-12 01:25:16,401 - INFO - Epoch: 9, Training Loss: 0.6416
2025-11-12 01:25:24,639 - INFO - Epoch: 10, Training Loss: 0.6345
2025-11-12 01:25:32,890 - INFO - Epoch: 11, Training Loss: 0.6355
2025-11-12 01:25:40,087 - INFO - Epoch: 12, Training Loss: 0.6425
2025-11-12 01:25:47,974 - INFO - Epoch: 13, Training Loss: 0.6315
2025-11-12 01:25:56,031 - INFO - Epoch: 14, Training Loss: 0.6379
2025-11-12 01:26:03,728 - INFO - Epoch: 15, Training Loss: 0.6319
2025-11-12 01:26:11,697 - INFO - Epoch: 16, Training Loss: 0.6289
2025-11-12 01:26:19,423 - INFO - Epoch: 17, Training Loss: 0.6247
2025-11-12 01:26:26,738 - INFO - Epoch: 18, Training Loss: 0.6224
2025-11-12 01:26:34,388 - INFO - Epoch: 19, Training Loss: 0.6184
2025-11-12 01:26:42,035 - INFO - Epoch: 20, Training Loss: 0.6096
2025-11-12 01:26:49,646 - INFO - Epoch: 21, Training Loss: 0.5804
2025-11-12 01:26:57,457 - INFO - Epoch: 22, Training Loss: 0.5479
2025-11-12 01:27:05,474 - INFO - Epoch: 23, Training Loss: 0.4961
2025-11-12 01:27:13,375 - INFO - Epoch: 24, Training Loss: 0.4940
2025-11-12 01:27:21,620 - INFO - Epoch: 25, Training Loss: 0.4933
2025-11-12 01:27:30,150 - INFO - Epoch: 26, Training Loss: 0.5006
2025-11-12 01:27:38,580 - INFO - Epoch: 27, Training Loss: 0.4799
2025-11-12 01:27:46,916 - INFO - Epoch: 28, Training Loss: 0.4898
2025-11-12 01:27:55,088 - INFO - Epoch: 29, Training Loss: 0.4928
2025-11-12 01:28:02,765 - INFO - Epoch: 30, Training Loss: 0.4776
2025-11-12 01:28:10,805 - INFO - Epoch: 31, Training Loss: 0.5193
2025-11-12 01:28:18,416 - INFO - Epoch: 32, Training Loss: 0.4822
2025-11-12 01:28:26,198 - INFO - Epoch: 33, Training Loss: 0.4779
2025-11-12 01:28:33,985 - INFO - Epoch: 34, Training Loss: 0.4831
2025-11-12 01:28:41,674 - INFO - Epoch: 35, Training Loss: 0.4893
2025-11-12 01:28:49,511 - INFO - Epoch: 36, Training Loss: 0.4909
2025-11-12 01:28:57,319 - INFO - Epoch: 37, Training Loss: 0.4790
2025-11-12 01:29:04,697 - INFO - Epoch: 38, Training Loss: 0.4983
2025-11-12 01:29:12,340 - INFO - Epoch: 39, Training Loss: 0.4907
2025-11-12 01:29:19,654 - INFO - Epoch: 40, Training Loss: 0.4957
2025-11-12 01:29:27,437 - INFO - Epoch: 41, Training Loss: 0.4746
2025-11-12 01:29:34,660 - INFO - Epoch: 42, Training Loss: 0.5057
2025-11-12 01:29:42,436 - INFO - Epoch: 43, Training Loss: 0.4820
2025-11-12 01:29:50,995 - INFO - Epoch: 44, Training Loss: 0.4852
2025-11-12 01:29:58,653 - INFO - Epoch: 45, Training Loss: 0.4756
2025-11-12 01:30:07,275 - INFO - Epoch: 46, Training Loss: 0.4761
2025-11-12 01:30:15,254 - INFO - Epoch: 47, Training Loss: 0.4859
2025-11-12 01:30:23,025 - INFO - Epoch: 48, Training Loss: 0.4885
2025-11-12 01:30:30,379 - INFO - Epoch: 49, Training Loss: 0.4848
2025-11-12 01:30:37,839 - INFO - Epoch: 50, Training Loss: 0.4827
2025-11-12 01:30:47,121 - INFO - Epoch: 51, Training Loss: 0.4769
2025-11-12 01:30:54,928 - INFO - Epoch: 52, Training Loss: 0.4651
2025-11-12 01:31:01,986 - INFO - Epoch: 53, Training Loss: 0.4822
2025-11-12 01:31:10,473 - INFO - Epoch: 54, Training Loss: 0.4893
2025-11-12 01:31:18,467 - INFO - Epoch: 55, Training Loss: 0.4688
2025-11-12 01:31:26,276 - INFO - Epoch: 56, Training Loss: 0.4790
2025-11-12 01:31:35,036 - INFO - Epoch: 57, Training Loss: 0.4813
2025-11-12 01:31:42,258 - INFO - Epoch: 58, Training Loss: 0.4817
2025-11-12 01:31:50,747 - INFO - Epoch: 59, Training Loss: 0.4703
2025-11-12 01:31:59,052 - INFO - Epoch: 60, Training Loss: 0.4795
2025-11-12 01:32:06,523 - INFO - Epoch: 61, Training Loss: 0.4792
2025-11-12 01:32:15,077 - INFO - Epoch: 62, Training Loss: 0.4759
2025-11-12 01:32:23,598 - INFO - Epoch: 63, Training Loss: 0.4674
2025-11-12 01:32:31,293 - INFO - Epoch: 64, Training Loss: 0.4674
2025-11-12 01:32:40,085 - INFO - Epoch: 65, Training Loss: 0.4749
2025-11-12 01:32:48,483 - INFO - Epoch: 66, Training Loss: 0.4663
2025-11-12 01:32:56,252 - INFO - Epoch: 67, Training Loss: 0.4668
2025-11-12 01:33:04,755 - INFO - Epoch: 68, Training Loss: 0.4738
2025-11-12 01:33:12,688 - INFO - Epoch: 69, Training Loss: 0.4716
2025-11-12 01:33:20,724 - INFO - Epoch: 70, Training Loss: 0.4790
2025-11-12 01:33:28,638 - INFO - Epoch: 71, Training Loss: 0.4726
2025-11-12 01:33:35,951 - INFO - Epoch: 72, Training Loss: 0.4767
2025-11-12 01:33:44,245 - INFO - Epoch: 73, Training Loss: 0.4671
2025-11-12 01:33:51,662 - INFO - Epoch: 74, Training Loss: 0.4650
2025-11-12 01:33:59,040 - INFO - Epoch: 75, Training Loss: 0.4705
2025-11-12 01:34:06,540 - INFO - Epoch: 76, Training Loss: 0.4791
2025-11-12 01:34:14,793 - INFO - Epoch: 77, Training Loss: 0.4654
2025-11-12 01:34:22,323 - INFO - Epoch: 78, Training Loss: 0.4691
2025-11-12 01:34:31,296 - INFO - Epoch: 79, Training Loss: 0.4665
2025-11-12 01:34:38,814 - INFO - Epoch: 80, Training Loss: 0.4718
2025-11-12 01:34:46,725 - INFO - Epoch: 81, Training Loss: 0.7239
2025-11-12 01:34:54,220 - INFO - Epoch: 82, Training Loss: 0.4718
2025-11-12 01:35:02,190 - INFO - Epoch: 83, Training Loss: 0.4709
2025-11-12 01:35:10,340 - INFO - Epoch: 84, Training Loss: 0.4628
2025-11-12 01:35:17,898 - INFO - Epoch: 85, Training Loss: 0.4782
2025-11-12 01:35:26,194 - INFO - Epoch: 86, Training Loss: 0.4786
2025-11-12 01:35:34,080 - INFO - Epoch: 87, Training Loss: 0.4746
2025-11-12 01:35:43,500 - INFO - Epoch: 88, Training Loss: 0.4681
2025-11-12 01:35:51,736 - INFO - Epoch: 89, Training Loss: 0.4704
2025-11-12 01:35:59,682 - INFO - Epoch: 90, Training Loss: 0.4799
2025-11-12 01:36:07,343 - INFO - Epoch: 91, Training Loss: 0.4611
2025-11-12 01:36:15,305 - INFO - Epoch: 92, Training Loss: 0.4671
2025-11-12 01:36:23,061 - INFO - Epoch: 93, Training Loss: 0.4858
2025-11-12 01:36:30,903 - INFO - Epoch: 94, Training Loss: 0.4631
2025-11-12 01:36:38,566 - INFO - Epoch: 95, Training Loss: 0.4656
2025-11-12 01:36:46,494 - INFO - Epoch: 96, Training Loss: 0.4666
2025-11-12 01:36:54,223 - INFO - Epoch: 97, Training Loss: 0.4731
2025-11-12 01:37:01,753 - INFO - Epoch: 98, Training Loss: 0.4662
2025-11-12 01:37:09,311 - INFO - Epoch: 99, Training Loss: 0.4641
2025-11-12 01:37:16,957 - INFO - Epoch: 100, Training Loss: 0.4636
2025-11-12 01:37:16,957 - INFO - Training completed for Trial 1 CV 0

