2025-11-12 02:57:23,850 - INFO - Log file: ./logs/trial2_cv2_RGS_20251112_025723.log
2025-11-12 02:57:23,850 - INFO - START TRAINING TRIAL 2 CV 2 - Task: RGS
2025-11-12 02:57:23,850 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 02:57:23,850 - INFO - Loading dataset...
2025-11-12 02:57:23,940 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 02:57:23,941 - INFO - Initializing VIGNet model...
2025-11-12 02:57:23,944 - INFO - Number of batch iterations per epoch: 113
2025-11-12 02:57:32,008 - INFO - Epoch: 1, Training Loss: 0.7589
2025-11-12 02:57:39,637 - INFO - Epoch: 2, Training Loss: 0.6105
2025-11-12 02:57:47,503 - INFO - Epoch: 3, Training Loss: 0.6070
2025-11-12 02:57:55,621 - INFO - Epoch: 4, Training Loss: 0.6078
2025-11-12 02:58:03,952 - INFO - Epoch: 5, Training Loss: 0.6051
2025-11-12 02:58:11,546 - INFO - Epoch: 6, Training Loss: 0.6062
2025-11-12 02:58:18,616 - INFO - Epoch: 7, Training Loss: 0.6063
2025-11-12 02:58:26,299 - INFO - Epoch: 8, Training Loss: 0.6058
2025-11-12 02:58:34,163 - INFO - Epoch: 9, Training Loss: 0.6060
2025-11-12 02:58:41,323 - INFO - Epoch: 10, Training Loss: 0.6078
2025-11-12 02:58:49,455 - INFO - Epoch: 11, Training Loss: 0.6067
2025-11-12 02:58:57,868 - INFO - Epoch: 12, Training Loss: 0.6064
2025-11-12 02:59:06,719 - INFO - Epoch: 13, Training Loss: 0.6067
2025-11-12 02:59:14,329 - INFO - Epoch: 14, Training Loss: 0.6060
2025-11-12 02:59:22,298 - INFO - Epoch: 15, Training Loss: 0.6061
2025-11-12 02:59:30,728 - INFO - Epoch: 16, Training Loss: 0.6071
2025-11-12 02:59:38,543 - INFO - Epoch: 17, Training Loss: 0.6047
2025-11-12 02:59:46,503 - INFO - Epoch: 18, Training Loss: 0.6066
2025-11-12 02:59:54,509 - INFO - Epoch: 19, Training Loss: 0.6072
2025-11-12 03:00:01,844 - INFO - Epoch: 20, Training Loss: 0.6059
2025-11-12 03:00:09,785 - INFO - Epoch: 21, Training Loss: 0.6067
2025-11-12 03:00:17,128 - INFO - Epoch: 22, Training Loss: 0.6061
2025-11-12 03:00:24,769 - INFO - Epoch: 23, Training Loss: 0.6057
2025-11-12 03:00:32,241 - INFO - Epoch: 24, Training Loss: 0.6055
2025-11-12 03:00:40,953 - INFO - Epoch: 25, Training Loss: 0.6061
2025-11-12 03:00:48,297 - INFO - Epoch: 26, Training Loss: 0.6061
2025-11-12 03:00:56,344 - INFO - Epoch: 27, Training Loss: 0.6053
2025-11-12 03:01:03,944 - INFO - Epoch: 28, Training Loss: 0.6063
2025-11-12 03:01:11,655 - INFO - Epoch: 29, Training Loss: 0.6073
2025-11-12 03:01:19,407 - INFO - Epoch: 30, Training Loss: 0.6079
2025-11-12 03:01:27,051 - INFO - Epoch: 31, Training Loss: 0.6063
2025-11-12 03:01:34,790 - INFO - Epoch: 32, Training Loss: 0.6077
2025-11-12 03:01:42,987 - INFO - Epoch: 33, Training Loss: 0.6049
2025-11-12 03:01:50,722 - INFO - Epoch: 34, Training Loss: 0.6058
2025-11-12 03:01:58,552 - INFO - Epoch: 35, Training Loss: 0.6051
2025-11-12 03:02:06,374 - INFO - Epoch: 36, Training Loss: 0.6069
2025-11-12 03:02:14,656 - INFO - Epoch: 37, Training Loss: 0.6065
2025-11-12 03:02:22,172 - INFO - Epoch: 38, Training Loss: 0.6055
2025-11-12 03:02:29,884 - INFO - Epoch: 39, Training Loss: 0.6057
2025-11-12 03:02:37,584 - INFO - Epoch: 40, Training Loss: 0.6060
2025-11-12 03:02:44,859 - INFO - Epoch: 41, Training Loss: 0.6057
2025-11-12 03:02:52,357 - INFO - Epoch: 42, Training Loss: 0.6059
2025-11-12 03:03:00,838 - INFO - Epoch: 43, Training Loss: 0.6059
2025-11-12 03:03:09,389 - INFO - Epoch: 44, Training Loss: 0.6062
2025-11-12 03:03:18,905 - INFO - Epoch: 45, Training Loss: 0.6072
2025-11-12 03:03:26,747 - INFO - Epoch: 46, Training Loss: 0.6058
2025-11-12 03:03:34,549 - INFO - Epoch: 47, Training Loss: 0.6058
2025-11-12 03:03:42,148 - INFO - Epoch: 48, Training Loss: 0.6049
2025-11-12 03:03:50,414 - INFO - Epoch: 49, Training Loss: 0.6067
2025-11-12 03:03:58,203 - INFO - Epoch: 50, Training Loss: 0.6051
2025-11-12 03:04:05,727 - INFO - Epoch: 51, Training Loss: 0.6068
2025-11-12 03:04:13,881 - INFO - Epoch: 52, Training Loss: 0.6069
2025-11-12 03:04:21,260 - INFO - Epoch: 53, Training Loss: 0.6071
2025-11-12 03:04:29,702 - INFO - Epoch: 54, Training Loss: 0.6061
2025-11-12 03:04:37,244 - INFO - Epoch: 55, Training Loss: 0.6059
2025-11-12 03:04:45,665 - INFO - Epoch: 56, Training Loss: 0.6060
2025-11-12 03:04:53,234 - INFO - Epoch: 57, Training Loss: 0.6056
2025-11-12 03:05:02,510 - INFO - Epoch: 58, Training Loss: 0.6065
2025-11-12 03:05:10,608 - INFO - Epoch: 59, Training Loss: 0.6061
2025-11-12 03:05:19,575 - INFO - Epoch: 60, Training Loss: 0.6065
2025-11-12 03:05:28,328 - INFO - Epoch: 61, Training Loss: 0.6064
2025-11-12 03:05:36,719 - INFO - Epoch: 62, Training Loss: 0.6054
2025-11-12 03:05:44,310 - INFO - Epoch: 63, Training Loss: 0.6061
2025-11-12 03:05:52,437 - INFO - Epoch: 64, Training Loss: 0.6070
2025-11-12 03:06:00,947 - INFO - Epoch: 65, Training Loss: 0.6051
2025-11-12 03:06:09,566 - INFO - Epoch: 66, Training Loss: 0.6056
2025-11-12 03:06:17,708 - INFO - Epoch: 67, Training Loss: 0.6067
2025-11-12 03:06:25,195 - INFO - Epoch: 68, Training Loss: 0.6067
2025-11-12 03:06:32,750 - INFO - Epoch: 69, Training Loss: 0.6063
2025-11-12 03:06:41,195 - INFO - Epoch: 70, Training Loss: 0.6067
2025-11-12 03:06:49,016 - INFO - Epoch: 71, Training Loss: 0.6058
2025-11-12 03:06:56,675 - INFO - Epoch: 72, Training Loss: 0.6059
2025-11-12 03:07:04,103 - INFO - Epoch: 73, Training Loss: 0.6064
2025-11-12 03:07:12,029 - INFO - Epoch: 74, Training Loss: 0.6053
2025-11-12 03:07:19,788 - INFO - Epoch: 75, Training Loss: 0.6067
2025-11-12 03:07:27,734 - INFO - Epoch: 76, Training Loss: 0.6068
2025-11-12 03:07:35,615 - INFO - Epoch: 77, Training Loss: 0.6067
2025-11-12 03:07:43,768 - INFO - Epoch: 78, Training Loss: 0.6060
2025-11-12 03:07:51,899 - INFO - Epoch: 79, Training Loss: 0.6068
2025-11-12 03:07:59,887 - INFO - Epoch: 80, Training Loss: 0.6063
2025-11-12 03:08:08,058 - INFO - Epoch: 81, Training Loss: 0.6057
2025-11-12 03:08:15,915 - INFO - Epoch: 82, Training Loss: 0.6067
2025-11-12 03:08:23,628 - INFO - Epoch: 83, Training Loss: 0.6051
2025-11-12 03:08:31,241 - INFO - Epoch: 84, Training Loss: 0.6056
2025-11-12 03:08:38,732 - INFO - Epoch: 85, Training Loss: 0.6053
2025-11-12 03:08:46,101 - INFO - Epoch: 86, Training Loss: 0.6003
2025-11-12 03:08:54,027 - INFO - Epoch: 87, Training Loss: 0.5893
2025-11-12 03:09:02,005 - INFO - Epoch: 88, Training Loss: 0.5860
2025-11-12 03:09:10,367 - INFO - Epoch: 89, Training Loss: 0.5771
2025-11-12 03:09:18,681 - INFO - Epoch: 90, Training Loss: 0.5711
2025-11-12 03:09:26,997 - INFO - Epoch: 91, Training Loss: 0.5692
2025-11-12 03:09:35,087 - INFO - Epoch: 92, Training Loss: 0.5702
2025-11-12 03:09:43,162 - INFO - Epoch: 93, Training Loss: 0.5722
2025-11-12 03:09:50,839 - INFO - Epoch: 94, Training Loss: 0.5633
2025-11-12 03:09:58,957 - INFO - Epoch: 95, Training Loss: 0.5635
2025-11-12 03:10:06,549 - INFO - Epoch: 96, Training Loss: 0.5660
2025-11-12 03:10:14,192 - INFO - Epoch: 97, Training Loss: 0.5702
2025-11-12 03:10:21,821 - INFO - Epoch: 98, Training Loss: 0.5618
2025-11-12 03:10:30,190 - INFO - Epoch: 99, Training Loss: 0.5615
2025-11-12 03:10:38,594 - INFO - Epoch: 100, Training Loss: 0.5597
2025-11-12 03:10:38,594 - INFO - Training completed for Trial 2 CV 2

