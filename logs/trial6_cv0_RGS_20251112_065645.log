2025-11-12 06:56:45,444 - INFO - Log file: ./logs/trial6_cv0_RGS_20251112_065645.log
2025-11-12 06:56:45,444 - INFO - START TRAINING TRIAL 6 CV 0 - Task: RGS
2025-11-12 06:56:45,444 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 06:56:45,444 - INFO - Loading dataset...
2025-11-12 06:56:45,533 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 06:56:45,533 - INFO - Initializing VIGNet model...
2025-11-12 06:56:45,536 - INFO - Number of batch iterations per epoch: 113
2025-11-12 06:56:53,803 - INFO - Epoch: 1, Training Loss: 0.8546
2025-11-12 06:57:02,848 - INFO - Epoch: 2, Training Loss: 0.6795
2025-11-12 06:57:11,615 - INFO - Epoch: 3, Training Loss: 0.6801
2025-11-12 06:57:19,873 - INFO - Epoch: 4, Training Loss: 0.6731
2025-11-12 06:57:27,737 - INFO - Epoch: 5, Training Loss: 0.6758
2025-11-12 06:57:34,960 - INFO - Epoch: 6, Training Loss: 0.6668
2025-11-12 06:57:42,261 - INFO - Epoch: 7, Training Loss: 0.6684
2025-11-12 06:57:49,942 - INFO - Epoch: 8, Training Loss: 0.6673
2025-11-12 06:57:58,505 - INFO - Epoch: 9, Training Loss: 0.6681
2025-11-12 06:58:06,122 - INFO - Epoch: 10, Training Loss: 0.6652
2025-11-12 06:58:13,367 - INFO - Epoch: 11, Training Loss: 0.6658
2025-11-12 06:58:22,215 - INFO - Epoch: 12, Training Loss: 0.6648
2025-11-12 06:58:31,107 - INFO - Epoch: 13, Training Loss: 0.6652
2025-11-12 06:58:39,306 - INFO - Epoch: 14, Training Loss: 0.6651
2025-11-12 06:58:47,444 - INFO - Epoch: 15, Training Loss: 0.6662
2025-11-12 06:58:55,471 - INFO - Epoch: 16, Training Loss: 0.6657
2025-11-12 06:59:02,569 - INFO - Epoch: 17, Training Loss: 0.6651
2025-11-12 06:59:10,626 - INFO - Epoch: 18, Training Loss: 0.6649
2025-11-12 06:59:18,469 - INFO - Epoch: 19, Training Loss: 0.6651
2025-11-12 06:59:27,021 - INFO - Epoch: 20, Training Loss: 0.6650
2025-11-12 06:59:35,712 - INFO - Epoch: 21, Training Loss: 0.6641
2025-11-12 06:59:43,458 - INFO - Epoch: 22, Training Loss: 0.6644
2025-11-12 06:59:51,420 - INFO - Epoch: 23, Training Loss: 0.6652
2025-11-12 06:59:59,702 - INFO - Epoch: 24, Training Loss: 0.6645
2025-11-12 07:00:07,286 - INFO - Epoch: 25, Training Loss: 0.6647
2025-11-12 07:00:14,702 - INFO - Epoch: 26, Training Loss: 0.6644
2025-11-12 07:00:22,884 - INFO - Epoch: 27, Training Loss: 0.6642
2025-11-12 07:00:32,272 - INFO - Epoch: 28, Training Loss: 0.6642
2025-11-12 07:00:40,403 - INFO - Epoch: 29, Training Loss: 0.6647
2025-11-12 07:00:48,002 - INFO - Epoch: 30, Training Loss: 0.6654
2025-11-12 07:00:56,315 - INFO - Epoch: 31, Training Loss: 0.6642
2025-11-12 07:01:05,419 - INFO - Epoch: 32, Training Loss: 0.6637
2025-11-12 07:01:13,146 - INFO - Epoch: 33, Training Loss: 0.6642
2025-11-12 07:01:21,679 - INFO - Epoch: 34, Training Loss: 0.6645
2025-11-12 07:01:29,592 - INFO - Epoch: 35, Training Loss: 0.6644
2025-11-12 07:01:37,832 - INFO - Epoch: 36, Training Loss: 0.6646
2025-11-12 07:01:45,811 - INFO - Epoch: 37, Training Loss: 0.6647
2025-11-12 07:01:53,451 - INFO - Epoch: 38, Training Loss: 0.6640
2025-11-12 07:02:01,666 - INFO - Epoch: 39, Training Loss: 0.6652
2025-11-12 07:02:09,607 - INFO - Epoch: 40, Training Loss: 0.6644
2025-11-12 07:02:17,550 - INFO - Epoch: 41, Training Loss: 0.6649
2025-11-12 07:02:25,861 - INFO - Epoch: 42, Training Loss: 0.6642
2025-11-12 07:02:34,465 - INFO - Epoch: 43, Training Loss: 0.6640
2025-11-12 07:02:42,166 - INFO - Epoch: 44, Training Loss: 0.6646
2025-11-12 07:02:49,695 - INFO - Epoch: 45, Training Loss: 0.6640
2025-11-12 07:02:57,628 - INFO - Epoch: 46, Training Loss: 0.6642
2025-11-12 07:03:05,473 - INFO - Epoch: 47, Training Loss: 0.6643
2025-11-12 07:03:12,874 - INFO - Epoch: 48, Training Loss: 0.6648
2025-11-12 07:03:20,747 - INFO - Epoch: 49, Training Loss: 0.6638
2025-11-12 07:03:28,749 - INFO - Epoch: 50, Training Loss: 0.6649
2025-11-12 07:03:36,654 - INFO - Epoch: 51, Training Loss: 0.6642
2025-11-12 07:03:44,640 - INFO - Epoch: 52, Training Loss: 0.6652
2025-11-12 07:03:52,148 - INFO - Epoch: 53, Training Loss: 0.6644
2025-11-12 07:04:00,269 - INFO - Epoch: 54, Training Loss: 0.6642
2025-11-12 07:04:08,339 - INFO - Epoch: 55, Training Loss: 0.6642
2025-11-12 07:04:15,936 - INFO - Epoch: 56, Training Loss: 0.6646
2025-11-12 07:04:23,711 - INFO - Epoch: 57, Training Loss: 0.6655
2025-11-12 07:04:31,787 - INFO - Epoch: 58, Training Loss: 0.6648
2025-11-12 07:04:40,062 - INFO - Epoch: 59, Training Loss: 0.6646
2025-11-12 07:04:47,639 - INFO - Epoch: 60, Training Loss: 0.6642
2025-11-12 07:04:55,253 - INFO - Epoch: 61, Training Loss: 0.6649
2025-11-12 07:05:03,217 - INFO - Epoch: 62, Training Loss: 0.6644
2025-11-12 07:05:11,665 - INFO - Epoch: 63, Training Loss: 0.6646
2025-11-12 07:05:19,796 - INFO - Epoch: 64, Training Loss: 0.6646
2025-11-12 07:05:28,040 - INFO - Epoch: 65, Training Loss: 0.6659
2025-11-12 07:05:35,280 - INFO - Epoch: 66, Training Loss: 0.6643
2025-11-12 07:05:42,866 - INFO - Epoch: 67, Training Loss: 0.6643
2025-11-12 07:05:50,811 - INFO - Epoch: 68, Training Loss: 0.6642
2025-11-12 07:05:58,881 - INFO - Epoch: 69, Training Loss: 0.6644
2025-11-12 07:06:07,269 - INFO - Epoch: 70, Training Loss: 0.6648
2025-11-12 07:06:16,224 - INFO - Epoch: 71, Training Loss: 0.6641
2025-11-12 07:06:24,696 - INFO - Epoch: 72, Training Loss: 0.6647
2025-11-12 07:06:32,383 - INFO - Epoch: 73, Training Loss: 0.6647
2025-11-12 07:06:41,255 - INFO - Epoch: 74, Training Loss: 0.6642
2025-11-12 07:06:48,926 - INFO - Epoch: 75, Training Loss: 0.6645
2025-11-12 07:06:56,373 - INFO - Epoch: 76, Training Loss: 0.6650
2025-11-12 07:07:04,756 - INFO - Epoch: 77, Training Loss: 0.6645
2025-11-12 07:07:12,279 - INFO - Epoch: 78, Training Loss: 0.6647
2025-11-12 07:07:20,047 - INFO - Epoch: 79, Training Loss: 0.6647
2025-11-12 07:07:28,197 - INFO - Epoch: 80, Training Loss: 0.6644
2025-11-12 07:07:35,839 - INFO - Epoch: 81, Training Loss: 0.6643
2025-11-12 07:07:44,675 - INFO - Epoch: 82, Training Loss: 0.6650
2025-11-12 07:07:52,195 - INFO - Epoch: 83, Training Loss: 0.6651
2025-11-12 07:07:59,902 - INFO - Epoch: 84, Training Loss: 0.6650
2025-11-12 07:08:07,218 - INFO - Epoch: 85, Training Loss: 0.6648
2025-11-12 07:08:15,118 - INFO - Epoch: 86, Training Loss: 0.6643
2025-11-12 07:08:22,734 - INFO - Epoch: 87, Training Loss: 0.6646
2025-11-12 07:08:30,753 - INFO - Epoch: 88, Training Loss: 0.6642
2025-11-12 07:08:38,716 - INFO - Epoch: 89, Training Loss: 0.6648
2025-11-12 07:08:46,426 - INFO - Epoch: 90, Training Loss: 0.6646
2025-11-12 07:08:53,620 - INFO - Epoch: 91, Training Loss: 0.6649
2025-11-12 07:09:01,570 - INFO - Epoch: 92, Training Loss: 0.6648
2025-11-12 07:09:09,442 - INFO - Epoch: 93, Training Loss: 0.6636
2025-11-12 07:09:17,745 - INFO - Epoch: 94, Training Loss: 0.6646
2025-11-12 07:09:26,478 - INFO - Epoch: 95, Training Loss: 0.6642
2025-11-12 07:09:34,690 - INFO - Epoch: 96, Training Loss: 0.6643
2025-11-12 07:09:42,666 - INFO - Epoch: 97, Training Loss: 0.6646
2025-11-12 07:09:50,230 - INFO - Epoch: 98, Training Loss: 0.6644
2025-11-12 07:09:58,030 - INFO - Epoch: 99, Training Loss: 0.6653
2025-11-12 07:10:05,673 - INFO - Epoch: 100, Training Loss: 0.6648
2025-11-12 07:10:05,673 - INFO - Training completed for Trial 6 CV 0

