2025-11-12 10:03:09,191 - INFO - Log file: ./logs/trial8_cv4_RGS_20251112_100309.log
2025-11-12 10:03:09,191 - INFO - START TRAINING TRIAL 8 CV 4 - Task: RGS
2025-11-12 10:03:09,191 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 10:03:09,191 - INFO - Loading dataset...
2025-11-12 10:03:09,286 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 10:03:09,286 - INFO - Initializing VIGNet model...
2025-11-12 10:03:09,289 - INFO - Number of batch iterations per epoch: 113
2025-11-12 10:03:16,729 - INFO - Epoch: 1, Training Loss: 0.6681
2025-11-12 10:03:25,439 - INFO - Epoch: 2, Training Loss: 0.5934
2025-11-12 10:03:34,299 - INFO - Epoch: 3, Training Loss: 0.5934
2025-11-12 10:03:42,427 - INFO - Epoch: 4, Training Loss: 0.5881
2025-11-12 10:03:51,278 - INFO - Epoch: 5, Training Loss: 0.5904
2025-11-12 10:03:59,564 - INFO - Epoch: 6, Training Loss: 0.5877
2025-11-12 10:04:07,784 - INFO - Epoch: 7, Training Loss: 0.5892
2025-11-12 10:04:15,422 - INFO - Epoch: 8, Training Loss: 0.5876
2025-11-12 10:04:23,522 - INFO - Epoch: 9, Training Loss: 0.5869
2025-11-12 10:04:30,842 - INFO - Epoch: 10, Training Loss: 0.5879
2025-11-12 10:04:38,775 - INFO - Epoch: 11, Training Loss: 0.5877
2025-11-12 10:04:47,484 - INFO - Epoch: 12, Training Loss: 0.5879
2025-11-12 10:04:55,660 - INFO - Epoch: 13, Training Loss: 0.5887
2025-11-12 10:05:03,593 - INFO - Epoch: 14, Training Loss: 0.5881
2025-11-12 10:05:11,469 - INFO - Epoch: 15, Training Loss: 0.5875
2025-11-12 10:05:19,604 - INFO - Epoch: 16, Training Loss: 0.5873
2025-11-12 10:05:27,752 - INFO - Epoch: 17, Training Loss: 0.5837
2025-11-12 10:05:35,605 - INFO - Epoch: 18, Training Loss: 0.5799
2025-11-12 10:05:44,143 - INFO - Epoch: 19, Training Loss: 0.5718
2025-11-12 10:05:51,809 - INFO - Epoch: 20, Training Loss: 0.5433
2025-11-12 10:06:00,031 - INFO - Epoch: 21, Training Loss: 0.5359
2025-11-12 10:06:08,029 - INFO - Epoch: 22, Training Loss: 0.5032
2025-11-12 10:06:15,779 - INFO - Epoch: 23, Training Loss: 0.4843
2025-11-12 10:06:23,804 - INFO - Epoch: 24, Training Loss: 0.4857
2025-11-12 10:06:32,014 - INFO - Epoch: 25, Training Loss: 0.4768
2025-11-12 10:06:40,240 - INFO - Epoch: 26, Training Loss: 0.4978
2025-11-12 10:06:47,767 - INFO - Epoch: 27, Training Loss: 0.4869
2025-11-12 10:06:55,848 - INFO - Epoch: 28, Training Loss: 0.4769
2025-11-12 10:07:03,943 - INFO - Epoch: 29, Training Loss: 0.4810
2025-11-12 10:07:12,002 - INFO - Epoch: 30, Training Loss: 0.4705
2025-11-12 10:07:20,459 - INFO - Epoch: 31, Training Loss: 0.4872
2025-11-12 10:07:28,673 - INFO - Epoch: 32, Training Loss: 0.4693
2025-11-12 10:07:36,105 - INFO - Epoch: 33, Training Loss: 0.4731
2025-11-12 10:07:44,220 - INFO - Epoch: 34, Training Loss: 0.4694
2025-11-12 10:07:51,905 - INFO - Epoch: 35, Training Loss: 0.4676
2025-11-12 10:07:59,037 - INFO - Epoch: 36, Training Loss: 0.4678
2025-11-12 10:08:07,166 - INFO - Epoch: 37, Training Loss: 0.4695
2025-11-12 10:08:15,691 - INFO - Epoch: 38, Training Loss: 0.4651
2025-11-12 10:08:23,451 - INFO - Epoch: 39, Training Loss: 0.4668
2025-11-12 10:08:31,529 - INFO - Epoch: 40, Training Loss: 0.4652
2025-11-12 10:08:39,558 - INFO - Epoch: 41, Training Loss: 0.4669
2025-11-12 10:08:47,763 - INFO - Epoch: 42, Training Loss: 0.4665
2025-11-12 10:08:55,845 - INFO - Epoch: 43, Training Loss: 0.4651
2025-11-12 10:09:03,399 - INFO - Epoch: 44, Training Loss: 0.4645
2025-11-12 10:09:11,131 - INFO - Epoch: 45, Training Loss: 0.4644
2025-11-12 10:09:19,764 - INFO - Epoch: 46, Training Loss: 0.4648
2025-11-12 10:09:27,249 - INFO - Epoch: 47, Training Loss: 0.4655
2025-11-12 10:09:35,824 - INFO - Epoch: 48, Training Loss: 0.5010
2025-11-12 10:09:43,857 - INFO - Epoch: 49, Training Loss: 0.5575
2025-11-12 10:09:51,699 - INFO - Epoch: 50, Training Loss: 0.5747
2025-11-12 10:09:59,028 - INFO - Epoch: 51, Training Loss: 0.5386
2025-11-12 10:10:06,409 - INFO - Epoch: 52, Training Loss: 0.4806
2025-11-12 10:10:14,886 - INFO - Epoch: 53, Training Loss: 0.4705
2025-11-12 10:10:23,302 - INFO - Epoch: 54, Training Loss: 0.4689
2025-11-12 10:10:31,370 - INFO - Epoch: 55, Training Loss: 0.4679
2025-11-12 10:10:39,300 - INFO - Epoch: 56, Training Loss: 0.4681
2025-11-12 10:10:47,007 - INFO - Epoch: 57, Training Loss: 0.4690
2025-11-12 10:10:54,405 - INFO - Epoch: 58, Training Loss: 0.4697
2025-11-12 10:11:01,975 - INFO - Epoch: 59, Training Loss: 0.4665
2025-11-12 10:11:10,191 - INFO - Epoch: 60, Training Loss: 0.4671
2025-11-12 10:11:17,660 - INFO - Epoch: 61, Training Loss: 0.4667
2025-11-12 10:11:25,360 - INFO - Epoch: 62, Training Loss: 0.4731
2025-11-12 10:11:34,221 - INFO - Epoch: 63, Training Loss: 0.4663
2025-11-12 10:11:42,617 - INFO - Epoch: 64, Training Loss: 0.4658
2025-11-12 10:11:51,101 - INFO - Epoch: 65, Training Loss: 0.4639
2025-11-12 10:11:59,262 - INFO - Epoch: 66, Training Loss: 0.4627
2025-11-12 10:12:07,476 - INFO - Epoch: 67, Training Loss: 0.4655
2025-11-12 10:12:15,425 - INFO - Epoch: 68, Training Loss: 0.4647
2025-11-12 10:12:23,494 - INFO - Epoch: 69, Training Loss: 0.4635
2025-11-12 10:12:31,648 - INFO - Epoch: 70, Training Loss: 0.4632
2025-11-12 10:12:39,918 - INFO - Epoch: 71, Training Loss: 0.5029
2025-11-12 10:12:48,701 - INFO - Epoch: 72, Training Loss: 0.5108
2025-11-12 10:12:56,920 - INFO - Epoch: 73, Training Loss: 0.4722
2025-11-12 10:13:05,276 - INFO - Epoch: 74, Training Loss: 0.4652
2025-11-12 10:13:13,639 - INFO - Epoch: 75, Training Loss: 0.4680
2025-11-12 10:13:20,898 - INFO - Epoch: 76, Training Loss: 0.4659
2025-11-12 10:13:28,775 - INFO - Epoch: 77, Training Loss: 0.4658
2025-11-12 10:13:37,040 - INFO - Epoch: 78, Training Loss: 0.4666
2025-11-12 10:13:44,803 - INFO - Epoch: 79, Training Loss: 0.4644
2025-11-12 10:13:53,250 - INFO - Epoch: 80, Training Loss: 0.4739
2025-11-12 10:14:02,828 - INFO - Epoch: 81, Training Loss: 0.4658
2025-11-12 10:14:12,697 - INFO - Epoch: 82, Training Loss: 0.4698
2025-11-12 10:14:20,948 - INFO - Epoch: 83, Training Loss: 0.4658
2025-11-12 10:14:28,364 - INFO - Epoch: 84, Training Loss: 0.4653
2025-11-12 10:14:36,114 - INFO - Epoch: 85, Training Loss: 0.4951
2025-11-12 10:14:43,726 - INFO - Epoch: 86, Training Loss: 0.4694
2025-11-12 10:14:51,764 - INFO - Epoch: 87, Training Loss: 0.4673
2025-11-12 10:14:59,542 - INFO - Epoch: 88, Training Loss: 0.4697
2025-11-12 10:15:07,552 - INFO - Epoch: 89, Training Loss: 0.4683
2025-11-12 10:15:15,480 - INFO - Epoch: 90, Training Loss: 0.4692
2025-11-12 10:15:24,832 - INFO - Epoch: 91, Training Loss: 0.4641
2025-11-12 10:15:32,519 - INFO - Epoch: 92, Training Loss: 0.4659
2025-11-12 10:15:40,581 - INFO - Epoch: 93, Training Loss: 0.4679
2025-11-12 10:15:49,093 - INFO - Epoch: 94, Training Loss: 0.4631
2025-11-12 10:15:57,393 - INFO - Epoch: 95, Training Loss: 0.4647
2025-11-12 10:16:06,186 - INFO - Epoch: 96, Training Loss: 0.4626
2025-11-12 10:16:14,505 - INFO - Epoch: 97, Training Loss: 0.4656
2025-11-12 10:16:22,325 - INFO - Epoch: 98, Training Loss: 0.4632
2025-11-12 10:16:30,056 - INFO - Epoch: 99, Training Loss: 0.4631
2025-11-12 10:16:38,262 - INFO - Epoch: 100, Training Loss: 0.4636
2025-11-12 10:16:38,263 - INFO - Training completed for Trial 8 CV 4

