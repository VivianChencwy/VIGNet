2025-11-12 05:10:35,496 - INFO - Log file: ./logs/trial4_cv2_RGS_20251112_051035.log
2025-11-12 05:10:35,496 - INFO - START TRAINING TRIAL 4 CV 2 - Task: RGS
2025-11-12 05:10:35,496 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 05:10:35,496 - INFO - Loading dataset...
2025-11-12 05:10:35,585 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 05:10:35,586 - INFO - Initializing VIGNet model...
2025-11-12 05:10:35,589 - INFO - Number of batch iterations per epoch: 113
2025-11-12 05:10:43,497 - INFO - Epoch: 1, Training Loss: 0.7444
2025-11-12 05:10:51,067 - INFO - Epoch: 2, Training Loss: 0.6510
2025-11-12 05:10:58,124 - INFO - Epoch: 3, Training Loss: 0.6459
2025-11-12 05:11:05,964 - INFO - Epoch: 4, Training Loss: 0.6469
2025-11-12 05:11:14,058 - INFO - Epoch: 5, Training Loss: 0.6457
2025-11-12 05:11:21,372 - INFO - Epoch: 6, Training Loss: 0.6463
2025-11-12 05:11:28,910 - INFO - Epoch: 7, Training Loss: 0.6485
2025-11-12 05:11:37,821 - INFO - Epoch: 8, Training Loss: 0.6437
2025-11-12 05:11:45,070 - INFO - Epoch: 9, Training Loss: 0.6445
2025-11-12 05:11:53,205 - INFO - Epoch: 10, Training Loss: 0.6440
2025-11-12 05:12:01,082 - INFO - Epoch: 11, Training Loss: 0.6443
2025-11-12 05:12:08,561 - INFO - Epoch: 12, Training Loss: 0.6445
2025-11-12 05:12:16,144 - INFO - Epoch: 13, Training Loss: 0.6435
2025-11-12 05:12:24,546 - INFO - Epoch: 14, Training Loss: 0.6444
2025-11-12 05:12:32,919 - INFO - Epoch: 15, Training Loss: 0.6433
2025-11-12 05:12:41,266 - INFO - Epoch: 16, Training Loss: 0.6441
2025-11-12 05:12:49,318 - INFO - Epoch: 17, Training Loss: 0.6434
2025-11-12 05:12:56,916 - INFO - Epoch: 18, Training Loss: 0.6439
2025-11-12 05:13:04,576 - INFO - Epoch: 19, Training Loss: 0.6460
2025-11-12 05:13:12,304 - INFO - Epoch: 20, Training Loss: 0.6440
2025-11-12 05:13:20,423 - INFO - Epoch: 21, Training Loss: 0.6432
2025-11-12 05:13:28,898 - INFO - Epoch: 22, Training Loss: 0.6436
2025-11-12 05:13:37,164 - INFO - Epoch: 23, Training Loss: 0.6438
2025-11-12 05:13:45,820 - INFO - Epoch: 24, Training Loss: 0.6436
2025-11-12 05:13:53,897 - INFO - Epoch: 25, Training Loss: 0.6432
2025-11-12 05:14:01,923 - INFO - Epoch: 26, Training Loss: 0.6427
2025-11-12 05:14:10,122 - INFO - Epoch: 27, Training Loss: 0.6414
2025-11-12 05:14:17,615 - INFO - Epoch: 28, Training Loss: 0.6408
2025-11-12 05:14:25,395 - INFO - Epoch: 29, Training Loss: 0.6413
2025-11-12 05:14:33,103 - INFO - Epoch: 30, Training Loss: 0.6413
2025-11-12 05:14:41,483 - INFO - Epoch: 31, Training Loss: 0.6343
2025-11-12 05:14:50,113 - INFO - Epoch: 32, Training Loss: 0.6292
2025-11-12 05:14:59,433 - INFO - Epoch: 33, Training Loss: 0.6228
2025-11-12 05:15:07,274 - INFO - Epoch: 34, Training Loss: 0.6123
2025-11-12 05:15:15,060 - INFO - Epoch: 35, Training Loss: 0.6049
2025-11-12 05:15:23,344 - INFO - Epoch: 36, Training Loss: 0.6003
2025-11-12 05:15:31,376 - INFO - Epoch: 37, Training Loss: 0.5982
2025-11-12 05:15:39,299 - INFO - Epoch: 38, Training Loss: 0.6008
2025-11-12 05:15:47,475 - INFO - Epoch: 39, Training Loss: 0.6015
2025-11-12 05:15:55,186 - INFO - Epoch: 40, Training Loss: 0.6012
2025-11-12 05:16:03,196 - INFO - Epoch: 41, Training Loss: 0.6045
2025-11-12 05:16:11,698 - INFO - Epoch: 42, Training Loss: 0.6007
2025-11-12 05:16:19,614 - INFO - Epoch: 43, Training Loss: 0.6000
2025-11-12 05:16:26,689 - INFO - Epoch: 44, Training Loss: 0.5973
2025-11-12 05:16:34,861 - INFO - Epoch: 45, Training Loss: 0.5961
2025-11-12 05:16:42,647 - INFO - Epoch: 46, Training Loss: 0.5972
2025-11-12 05:16:50,143 - INFO - Epoch: 47, Training Loss: 0.5951
2025-11-12 05:16:57,549 - INFO - Epoch: 48, Training Loss: 0.5964
2025-11-12 05:17:05,325 - INFO - Epoch: 49, Training Loss: 0.5959
2025-11-12 05:17:13,437 - INFO - Epoch: 50, Training Loss: 0.6020
2025-11-12 05:17:21,952 - INFO - Epoch: 51, Training Loss: 0.5952
2025-11-12 05:17:30,632 - INFO - Epoch: 52, Training Loss: 0.5927
2025-11-12 05:17:38,184 - INFO - Epoch: 53, Training Loss: 0.5945
2025-11-12 05:17:45,958 - INFO - Epoch: 54, Training Loss: 0.5902
2025-11-12 05:17:53,834 - INFO - Epoch: 55, Training Loss: 0.5916
2025-11-12 05:18:01,561 - INFO - Epoch: 56, Training Loss: 0.5911
2025-11-12 05:18:09,148 - INFO - Epoch: 57, Training Loss: 0.5911
2025-11-12 05:18:16,885 - INFO - Epoch: 58, Training Loss: 0.5924
2025-11-12 05:18:25,650 - INFO - Epoch: 59, Training Loss: 0.5901
2025-11-12 05:18:34,806 - INFO - Epoch: 60, Training Loss: 0.5907
2025-11-12 05:18:43,012 - INFO - Epoch: 61, Training Loss: 0.5908
2025-11-12 05:18:50,745 - INFO - Epoch: 62, Training Loss: 0.5914
2025-11-12 05:18:59,374 - INFO - Epoch: 63, Training Loss: 0.5898
2025-11-12 05:19:08,001 - INFO - Epoch: 64, Training Loss: 0.5915
2025-11-12 05:19:16,518 - INFO - Epoch: 65, Training Loss: 0.5904
2025-11-12 05:19:24,454 - INFO - Epoch: 66, Training Loss: 0.5904
2025-11-12 05:19:32,716 - INFO - Epoch: 67, Training Loss: 0.5903
2025-11-12 05:19:40,058 - INFO - Epoch: 68, Training Loss: 0.5885
2025-11-12 05:19:48,421 - INFO - Epoch: 69, Training Loss: 0.5890
2025-11-12 05:19:56,467 - INFO - Epoch: 70, Training Loss: 0.5886
2025-11-12 05:20:04,969 - INFO - Epoch: 71, Training Loss: 0.5880
2025-11-12 05:20:12,554 - INFO - Epoch: 72, Training Loss: 0.5889
2025-11-12 05:20:20,642 - INFO - Epoch: 73, Training Loss: 0.5876
2025-11-12 05:20:28,579 - INFO - Epoch: 74, Training Loss: 0.5869
2025-11-12 05:20:37,180 - INFO - Epoch: 75, Training Loss: 0.5878
2025-11-12 05:20:45,820 - INFO - Epoch: 76, Training Loss: 0.5886
2025-11-12 05:20:53,798 - INFO - Epoch: 77, Training Loss: 0.5866
2025-11-12 05:21:01,445 - INFO - Epoch: 78, Training Loss: 0.5862
2025-11-12 05:21:09,564 - INFO - Epoch: 79, Training Loss: 0.5877
2025-11-12 05:21:17,952 - INFO - Epoch: 80, Training Loss: 0.5869
2025-11-12 05:21:26,339 - INFO - Epoch: 81, Training Loss: 0.5873
2025-11-12 05:21:34,446 - INFO - Epoch: 82, Training Loss: 0.5877
2025-11-12 05:21:41,961 - INFO - Epoch: 83, Training Loss: 0.5842
2025-11-12 05:21:49,725 - INFO - Epoch: 84, Training Loss: 0.5847
2025-11-12 05:21:57,505 - INFO - Epoch: 85, Training Loss: 0.5853
2025-11-12 05:22:06,552 - INFO - Epoch: 86, Training Loss: 0.5854
2025-11-12 05:22:14,333 - INFO - Epoch: 87, Training Loss: 0.5834
2025-11-12 05:22:22,421 - INFO - Epoch: 88, Training Loss: 0.5861
2025-11-12 05:22:29,877 - INFO - Epoch: 89, Training Loss: 0.5839
2025-11-12 05:22:37,234 - INFO - Epoch: 90, Training Loss: 0.5848
2025-11-12 05:22:45,177 - INFO - Epoch: 91, Training Loss: 0.5853
2025-11-12 05:22:53,498 - INFO - Epoch: 92, Training Loss: 0.5844
2025-11-12 05:23:01,565 - INFO - Epoch: 93, Training Loss: 0.5928
2025-11-12 05:23:09,397 - INFO - Epoch: 94, Training Loss: 0.5955
2025-11-12 05:23:17,217 - INFO - Epoch: 95, Training Loss: 0.5862
2025-11-12 05:23:25,324 - INFO - Epoch: 96, Training Loss: 0.5835
2025-11-12 05:23:32,736 - INFO - Epoch: 97, Training Loss: 0.5826
2025-11-12 05:23:41,710 - INFO - Epoch: 98, Training Loss: 0.5827
2025-11-12 05:23:49,568 - INFO - Epoch: 99, Training Loss: 0.5859
2025-11-12 05:23:57,749 - INFO - Epoch: 100, Training Loss: 0.5819
2025-11-12 05:23:57,750 - INFO - Training completed for Trial 4 CV 2

