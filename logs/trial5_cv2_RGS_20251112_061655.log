2025-11-12 06:16:55,204 - INFO - Log file: ./logs/trial5_cv2_RGS_20251112_061655.log
2025-11-12 06:16:55,204 - INFO - START TRAINING TRIAL 5 CV 2 - Task: RGS
2025-11-12 06:16:55,204 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 06:16:55,204 - INFO - Loading dataset...
2025-11-12 06:16:55,299 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 06:16:55,299 - INFO - Initializing VIGNet model...
2025-11-12 06:16:55,302 - INFO - Number of batch iterations per epoch: 113
2025-11-12 06:17:02,870 - INFO - Epoch: 1, Training Loss: 0.8648
2025-11-12 06:17:11,358 - INFO - Epoch: 2, Training Loss: 0.7075
2025-11-12 06:17:19,819 - INFO - Epoch: 3, Training Loss: 0.7051
2025-11-12 06:17:27,988 - INFO - Epoch: 4, Training Loss: 0.6942
2025-11-12 06:17:35,511 - INFO - Epoch: 5, Training Loss: 0.6959
2025-11-12 06:17:43,568 - INFO - Epoch: 6, Training Loss: 0.6948
2025-11-12 06:17:51,491 - INFO - Epoch: 7, Training Loss: 0.6945
2025-11-12 06:18:00,272 - INFO - Epoch: 8, Training Loss: 0.6954
2025-11-12 06:18:08,384 - INFO - Epoch: 9, Training Loss: 0.6943
2025-11-12 06:18:16,065 - INFO - Epoch: 10, Training Loss: 0.6925
2025-11-12 06:18:24,229 - INFO - Epoch: 11, Training Loss: 0.6912
2025-11-12 06:18:31,520 - INFO - Epoch: 12, Training Loss: 0.6929
2025-11-12 06:18:39,599 - INFO - Epoch: 13, Training Loss: 0.6926
2025-11-12 06:18:47,035 - INFO - Epoch: 14, Training Loss: 0.6942
2025-11-12 06:18:55,724 - INFO - Epoch: 15, Training Loss: 0.6909
2025-11-12 06:19:04,380 - INFO - Epoch: 16, Training Loss: 0.6937
2025-11-12 06:19:11,600 - INFO - Epoch: 17, Training Loss: 0.6947
2025-11-12 06:19:20,161 - INFO - Epoch: 18, Training Loss: 0.6913
2025-11-12 06:19:27,952 - INFO - Epoch: 19, Training Loss: 0.6916
2025-11-12 06:19:35,490 - INFO - Epoch: 20, Training Loss: 0.6916
2025-11-12 06:19:42,809 - INFO - Epoch: 21, Training Loss: 0.6891
2025-11-12 06:19:50,714 - INFO - Epoch: 22, Training Loss: 0.6849
2025-11-12 06:19:58,767 - INFO - Epoch: 23, Training Loss: 0.6893
2025-11-12 06:20:06,732 - INFO - Epoch: 24, Training Loss: 0.6851
2025-11-12 06:20:14,890 - INFO - Epoch: 25, Training Loss: 0.6741
2025-11-12 06:20:22,999 - INFO - Epoch: 26, Training Loss: 0.6625
2025-11-12 06:20:31,224 - INFO - Epoch: 27, Training Loss: 0.6342
2025-11-12 06:20:39,008 - INFO - Epoch: 28, Training Loss: 0.6411
2025-11-12 06:20:47,357 - INFO - Epoch: 29, Training Loss: 0.6265
2025-11-12 06:20:55,035 - INFO - Epoch: 30, Training Loss: 0.6281
2025-11-12 06:21:02,903 - INFO - Epoch: 31, Training Loss: 0.6021
2025-11-12 06:21:10,509 - INFO - Epoch: 32, Training Loss: 0.5986
2025-11-12 06:21:18,475 - INFO - Epoch: 33, Training Loss: 0.6048
2025-11-12 06:21:26,126 - INFO - Epoch: 34, Training Loss: 0.6311
2025-11-12 06:21:33,632 - INFO - Epoch: 35, Training Loss: 0.5973
2025-11-12 06:21:41,341 - INFO - Epoch: 36, Training Loss: 0.5935
2025-11-12 06:21:48,977 - INFO - Epoch: 37, Training Loss: 0.6183
2025-11-12 06:21:56,915 - INFO - Epoch: 38, Training Loss: 0.5768
2025-11-12 06:22:04,542 - INFO - Epoch: 39, Training Loss: 0.5840
2025-11-12 06:22:12,132 - INFO - Epoch: 40, Training Loss: 0.5787
2025-11-12 06:22:19,640 - INFO - Epoch: 41, Training Loss: 0.5500
2025-11-12 06:22:27,441 - INFO - Epoch: 42, Training Loss: 0.5649
2025-11-12 06:22:35,337 - INFO - Epoch: 43, Training Loss: 0.5584
2025-11-12 06:22:43,459 - INFO - Epoch: 44, Training Loss: 0.5752
2025-11-12 06:22:52,409 - INFO - Epoch: 45, Training Loss: 0.5706
2025-11-12 06:23:00,270 - INFO - Epoch: 46, Training Loss: 0.5660
2025-11-12 06:23:08,560 - INFO - Epoch: 47, Training Loss: 0.5745
2025-11-12 06:23:16,844 - INFO - Epoch: 48, Training Loss: 0.5828
2025-11-12 06:23:25,298 - INFO - Epoch: 49, Training Loss: 0.5739
2025-11-12 06:23:33,153 - INFO - Epoch: 50, Training Loss: 0.5455
2025-11-12 06:23:40,804 - INFO - Epoch: 51, Training Loss: 0.7394
2025-11-12 06:23:48,737 - INFO - Epoch: 52, Training Loss: 0.6918
2025-11-12 06:23:55,894 - INFO - Epoch: 53, Training Loss: 0.6598
2025-11-12 06:24:04,632 - INFO - Epoch: 54, Training Loss: 0.6586
2025-11-12 06:24:12,517 - INFO - Epoch: 55, Training Loss: 0.6469
2025-11-12 06:24:20,539 - INFO - Epoch: 56, Training Loss: 0.6395
2025-11-12 06:24:29,416 - INFO - Epoch: 57, Training Loss: 0.6304
2025-11-12 06:24:37,197 - INFO - Epoch: 58, Training Loss: 0.6232
2025-11-12 06:24:44,366 - INFO - Epoch: 59, Training Loss: 0.6230
2025-11-12 06:24:52,157 - INFO - Epoch: 60, Training Loss: 0.6163
2025-11-12 06:25:00,950 - INFO - Epoch: 61, Training Loss: 0.6128
2025-11-12 06:25:08,726 - INFO - Epoch: 62, Training Loss: 0.6073
2025-11-12 06:25:17,183 - INFO - Epoch: 63, Training Loss: 0.5953
2025-11-12 06:25:26,070 - INFO - Epoch: 64, Training Loss: 0.5930
2025-11-12 06:25:33,845 - INFO - Epoch: 65, Training Loss: 0.5752
2025-11-12 06:25:41,562 - INFO - Epoch: 66, Training Loss: 0.5704
2025-11-12 06:25:49,890 - INFO - Epoch: 67, Training Loss: 0.5869
2025-11-12 06:25:57,985 - INFO - Epoch: 68, Training Loss: 0.5650
2025-11-12 06:26:05,557 - INFO - Epoch: 69, Training Loss: 0.5650
2025-11-12 06:26:12,975 - INFO - Epoch: 70, Training Loss: 0.5805
2025-11-12 06:26:21,308 - INFO - Epoch: 71, Training Loss: 0.5636
2025-11-12 06:26:28,833 - INFO - Epoch: 72, Training Loss: 0.6043
2025-11-12 06:26:36,392 - INFO - Epoch: 73, Training Loss: 0.5817
2025-11-12 06:26:44,734 - INFO - Epoch: 74, Training Loss: 0.5620
2025-11-12 06:26:52,002 - INFO - Epoch: 75, Training Loss: 0.5624
2025-11-12 06:26:59,418 - INFO - Epoch: 76, Training Loss: 0.5571
2025-11-12 06:27:07,534 - INFO - Epoch: 77, Training Loss: 0.5680
2025-11-12 06:27:16,118 - INFO - Epoch: 78, Training Loss: 0.5816
2025-11-12 06:27:23,786 - INFO - Epoch: 79, Training Loss: 0.5684
2025-11-12 06:27:31,308 - INFO - Epoch: 80, Training Loss: 0.5617
2025-11-12 06:27:39,383 - INFO - Epoch: 81, Training Loss: 0.5465
2025-11-12 06:27:46,635 - INFO - Epoch: 82, Training Loss: 0.5693
2025-11-12 06:27:54,225 - INFO - Epoch: 83, Training Loss: 0.5537
2025-11-12 06:28:01,393 - INFO - Epoch: 84, Training Loss: 0.5467
2025-11-12 06:28:09,677 - INFO - Epoch: 85, Training Loss: 0.5586
2025-11-12 06:28:17,544 - INFO - Epoch: 86, Training Loss: 0.5359
2025-11-12 06:28:24,933 - INFO - Epoch: 87, Training Loss: 0.5798
2025-11-12 06:28:32,181 - INFO - Epoch: 88, Training Loss: 0.5665
2025-11-12 06:28:39,701 - INFO - Epoch: 89, Training Loss: 0.5609
2025-11-12 06:28:48,200 - INFO - Epoch: 90, Training Loss: 0.5800
2025-11-12 06:28:56,269 - INFO - Epoch: 91, Training Loss: 0.5359
2025-11-12 06:29:04,161 - INFO - Epoch: 92, Training Loss: 0.5728
2025-11-12 06:29:12,359 - INFO - Epoch: 93, Training Loss: 0.5852
2025-11-12 06:29:20,766 - INFO - Epoch: 94, Training Loss: 0.5680
2025-11-12 06:29:28,693 - INFO - Epoch: 95, Training Loss: 0.5585
2025-11-12 06:29:36,439 - INFO - Epoch: 96, Training Loss: 0.5409
2025-11-12 06:29:43,630 - INFO - Epoch: 97, Training Loss: 0.5764
2025-11-12 06:29:51,372 - INFO - Epoch: 98, Training Loss: 0.5417
2025-11-12 06:29:58,717 - INFO - Epoch: 99, Training Loss: 0.5612
2025-11-12 06:30:06,616 - INFO - Epoch: 100, Training Loss: 0.5509
2025-11-12 06:30:06,617 - INFO - Training completed for Trial 5 CV 2

