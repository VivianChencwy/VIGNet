2025-11-12 07:10:05,674 - INFO - Log file: ./logs/trial6_cv1_RGS_20251112_071005.log
2025-11-12 07:10:05,674 - INFO - START TRAINING TRIAL 6 CV 1 - Task: RGS
2025-11-12 07:10:05,674 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 07:10:05,674 - INFO - Loading dataset...
2025-11-12 07:10:05,764 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 07:10:05,764 - INFO - Initializing VIGNet model...
2025-11-12 07:10:05,767 - INFO - Number of batch iterations per epoch: 113
2025-11-12 07:10:13,488 - INFO - Epoch: 1, Training Loss: 0.8137
2025-11-12 07:10:21,874 - INFO - Epoch: 2, Training Loss: 0.6704
2025-11-12 07:10:29,760 - INFO - Epoch: 3, Training Loss: 0.6711
2025-11-12 07:10:37,865 - INFO - Epoch: 4, Training Loss: 0.6651
2025-11-12 07:10:45,829 - INFO - Epoch: 5, Training Loss: 0.6670
2025-11-12 07:10:53,130 - INFO - Epoch: 6, Training Loss: 0.6646
2025-11-12 07:11:00,847 - INFO - Epoch: 7, Training Loss: 0.6639
2025-11-12 07:11:08,728 - INFO - Epoch: 8, Training Loss: 0.6623
2025-11-12 07:11:15,940 - INFO - Epoch: 9, Training Loss: 0.6627
2025-11-12 07:11:24,270 - INFO - Epoch: 10, Training Loss: 0.6627
2025-11-12 07:11:31,879 - INFO - Epoch: 11, Training Loss: 0.6624
2025-11-12 07:11:39,662 - INFO - Epoch: 12, Training Loss: 0.6619
2025-11-12 07:11:46,818 - INFO - Epoch: 13, Training Loss: 0.6621
2025-11-12 07:11:54,512 - INFO - Epoch: 14, Training Loss: 0.6625
2025-11-12 07:12:02,347 - INFO - Epoch: 15, Training Loss: 0.6622
2025-11-12 07:12:10,706 - INFO - Epoch: 16, Training Loss: 0.6626
2025-11-12 07:12:18,610 - INFO - Epoch: 17, Training Loss: 0.6618
2025-11-12 07:12:26,507 - INFO - Epoch: 18, Training Loss: 0.6633
2025-11-12 07:12:34,581 - INFO - Epoch: 19, Training Loss: 0.6622
2025-11-12 07:12:42,139 - INFO - Epoch: 20, Training Loss: 0.6627
2025-11-12 07:12:50,182 - INFO - Epoch: 21, Training Loss: 0.6629
2025-11-12 07:12:57,137 - INFO - Epoch: 22, Training Loss: 0.6628
2025-11-12 07:13:05,207 - INFO - Epoch: 23, Training Loss: 0.6621
2025-11-12 07:13:13,907 - INFO - Epoch: 24, Training Loss: 0.6623
2025-11-12 07:13:21,349 - INFO - Epoch: 25, Training Loss: 0.6625
2025-11-12 07:13:29,783 - INFO - Epoch: 26, Training Loss: 0.6623
2025-11-12 07:13:36,869 - INFO - Epoch: 27, Training Loss: 0.6624
2025-11-12 07:13:44,571 - INFO - Epoch: 28, Training Loss: 0.6618
2025-11-12 07:13:52,307 - INFO - Epoch: 29, Training Loss: 0.6620
2025-11-12 07:14:00,165 - INFO - Epoch: 30, Training Loss: 0.6622
2025-11-12 07:14:08,516 - INFO - Epoch: 31, Training Loss: 0.6618
2025-11-12 07:14:15,938 - INFO - Epoch: 32, Training Loss: 0.6626
2025-11-12 07:14:24,125 - INFO - Epoch: 33, Training Loss: 0.6621
2025-11-12 07:14:32,609 - INFO - Epoch: 34, Training Loss: 0.6622
2025-11-12 07:14:40,532 - INFO - Epoch: 35, Training Loss: 0.6620
2025-11-12 07:14:48,073 - INFO - Epoch: 36, Training Loss: 0.6619
2025-11-12 07:14:56,040 - INFO - Epoch: 37, Training Loss: 0.6621
2025-11-12 07:15:04,579 - INFO - Epoch: 38, Training Loss: 0.6626
2025-11-12 07:15:12,388 - INFO - Epoch: 39, Training Loss: 0.6624
2025-11-12 07:15:19,939 - INFO - Epoch: 40, Training Loss: 0.6619
2025-11-12 07:15:28,211 - INFO - Epoch: 41, Training Loss: 0.6628
2025-11-12 07:15:36,182 - INFO - Epoch: 42, Training Loss: 0.6631
2025-11-12 07:15:43,792 - INFO - Epoch: 43, Training Loss: 0.6625
2025-11-12 07:15:51,829 - INFO - Epoch: 44, Training Loss: 0.6625
2025-11-12 07:15:59,675 - INFO - Epoch: 45, Training Loss: 0.6622
2025-11-12 07:16:07,894 - INFO - Epoch: 46, Training Loss: 0.6626
2025-11-12 07:16:15,746 - INFO - Epoch: 47, Training Loss: 0.6621
2025-11-12 07:16:23,327 - INFO - Epoch: 48, Training Loss: 0.6616
2025-11-12 07:16:31,170 - INFO - Epoch: 49, Training Loss: 0.6612
2025-11-12 07:16:39,309 - INFO - Epoch: 50, Training Loss: 0.6627
2025-11-12 07:16:47,049 - INFO - Epoch: 51, Training Loss: 0.6620
2025-11-12 07:16:54,372 - INFO - Epoch: 52, Training Loss: 0.6622
2025-11-12 07:17:01,620 - INFO - Epoch: 53, Training Loss: 0.6630
2025-11-12 07:17:09,497 - INFO - Epoch: 54, Training Loss: 0.6621
2025-11-12 07:17:17,374 - INFO - Epoch: 55, Training Loss: 0.6630
2025-11-12 07:17:26,802 - INFO - Epoch: 56, Training Loss: 0.6620
2025-11-12 07:17:35,050 - INFO - Epoch: 57, Training Loss: 0.6615
2025-11-12 07:17:43,297 - INFO - Epoch: 58, Training Loss: 0.6617
2025-11-12 07:17:50,890 - INFO - Epoch: 59, Training Loss: 0.6621
2025-11-12 07:17:59,862 - INFO - Epoch: 60, Training Loss: 0.6618
2025-11-12 07:18:07,760 - INFO - Epoch: 61, Training Loss: 0.6620
2025-11-12 07:18:15,692 - INFO - Epoch: 62, Training Loss: 0.6616
2025-11-12 07:18:23,107 - INFO - Epoch: 63, Training Loss: 0.6631
2025-11-12 07:18:31,965 - INFO - Epoch: 64, Training Loss: 0.6618
2025-11-12 07:18:40,848 - INFO - Epoch: 65, Training Loss: 0.6630
2025-11-12 07:18:49,499 - INFO - Epoch: 66, Training Loss: 0.6621
2025-11-12 07:18:57,980 - INFO - Epoch: 67, Training Loss: 0.6623
2025-11-12 07:19:06,477 - INFO - Epoch: 68, Training Loss: 0.6620
2025-11-12 07:19:14,165 - INFO - Epoch: 69, Training Loss: 0.6620
2025-11-12 07:19:21,753 - INFO - Epoch: 70, Training Loss: 0.6625
2025-11-12 07:19:29,152 - INFO - Epoch: 71, Training Loss: 0.6621
2025-11-12 07:19:36,720 - INFO - Epoch: 72, Training Loss: 0.6616
2025-11-12 07:19:44,233 - INFO - Epoch: 73, Training Loss: 0.6623
2025-11-12 07:19:52,274 - INFO - Epoch: 74, Training Loss: 0.6621
2025-11-12 07:20:00,021 - INFO - Epoch: 75, Training Loss: 0.6617
2025-11-12 07:20:07,822 - INFO - Epoch: 76, Training Loss: 0.6627
2025-11-12 07:20:16,464 - INFO - Epoch: 77, Training Loss: 0.6627
2025-11-12 07:20:24,989 - INFO - Epoch: 78, Training Loss: 0.6619
2025-11-12 07:20:33,480 - INFO - Epoch: 79, Training Loss: 0.6620
2025-11-12 07:20:41,882 - INFO - Epoch: 80, Training Loss: 0.6618
2025-11-12 07:20:49,668 - INFO - Epoch: 81, Training Loss: 0.6616
2025-11-12 07:20:58,611 - INFO - Epoch: 82, Training Loss: 0.6625
2025-11-12 07:21:06,717 - INFO - Epoch: 83, Training Loss: 0.6621
2025-11-12 07:21:14,745 - INFO - Epoch: 84, Training Loss: 0.6619
2025-11-12 07:21:23,147 - INFO - Epoch: 85, Training Loss: 0.6621
2025-11-12 07:21:31,148 - INFO - Epoch: 86, Training Loss: 0.6625
2025-11-12 07:21:38,857 - INFO - Epoch: 87, Training Loss: 0.6620
2025-11-12 07:21:46,229 - INFO - Epoch: 88, Training Loss: 0.6627
2025-11-12 07:21:54,239 - INFO - Epoch: 89, Training Loss: 0.6619
2025-11-12 07:22:02,198 - INFO - Epoch: 90, Training Loss: 0.6621
2025-11-12 07:22:10,601 - INFO - Epoch: 91, Training Loss: 0.6622
2025-11-12 07:22:18,628 - INFO - Epoch: 92, Training Loss: 0.6620
2025-11-12 07:22:27,115 - INFO - Epoch: 93, Training Loss: 0.6622
2025-11-12 07:22:34,489 - INFO - Epoch: 94, Training Loss: 0.6619
2025-11-12 07:22:42,491 - INFO - Epoch: 95, Training Loss: 0.6621
2025-11-12 07:22:50,722 - INFO - Epoch: 96, Training Loss: 0.6625
2025-11-12 07:22:58,895 - INFO - Epoch: 97, Training Loss: 0.6618
2025-11-12 07:23:06,870 - INFO - Epoch: 98, Training Loss: 0.6620
2025-11-12 07:23:14,868 - INFO - Epoch: 99, Training Loss: 0.6617
2025-11-12 07:23:22,757 - INFO - Epoch: 100, Training Loss: 0.6626
2025-11-12 07:23:22,757 - INFO - Training completed for Trial 6 CV 1

