2025-11-12 08:16:41,500 - INFO - Log file: ./logs/trial7_cv1_RGS_20251112_081641.log
2025-11-12 08:16:41,500 - INFO - START TRAINING TRIAL 7 CV 1 - Task: RGS
2025-11-12 08:16:41,500 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 08:16:41,500 - INFO - Loading dataset...
2025-11-12 08:16:41,589 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 08:16:41,589 - INFO - Initializing VIGNet model...
2025-11-12 08:16:41,592 - INFO - Number of batch iterations per epoch: 113
2025-11-12 08:16:49,353 - INFO - Epoch: 1, Training Loss: 0.9893
2025-11-12 08:16:56,863 - INFO - Epoch: 2, Training Loss: 0.6948
2025-11-12 08:17:04,604 - INFO - Epoch: 3, Training Loss: 0.6898
2025-11-12 08:17:12,009 - INFO - Epoch: 4, Training Loss: 0.6885
2025-11-12 08:17:19,816 - INFO - Epoch: 5, Training Loss: 0.6895
2025-11-12 08:17:27,597 - INFO - Epoch: 6, Training Loss: 0.6878
2025-11-12 08:17:35,421 - INFO - Epoch: 7, Training Loss: 0.6874
2025-11-12 08:17:43,756 - INFO - Epoch: 8, Training Loss: 0.6882
2025-11-12 08:17:51,463 - INFO - Epoch: 9, Training Loss: 0.6878
2025-11-12 08:17:59,141 - INFO - Epoch: 10, Training Loss: 0.6876
2025-11-12 08:18:07,201 - INFO - Epoch: 11, Training Loss: 0.6873
2025-11-12 08:18:15,478 - INFO - Epoch: 12, Training Loss: 0.6873
2025-11-12 08:18:22,728 - INFO - Epoch: 13, Training Loss: 0.6873
2025-11-12 08:18:30,160 - INFO - Epoch: 14, Training Loss: 0.6879
2025-11-12 08:18:38,053 - INFO - Epoch: 15, Training Loss: 0.6876
2025-11-12 08:18:45,822 - INFO - Epoch: 16, Training Loss: 0.6877
2025-11-12 08:18:53,475 - INFO - Epoch: 17, Training Loss: 0.6877
2025-11-12 08:19:01,699 - INFO - Epoch: 18, Training Loss: 0.6873
2025-11-12 08:19:09,583 - INFO - Epoch: 19, Training Loss: 0.6880
2025-11-12 08:19:18,147 - INFO - Epoch: 20, Training Loss: 0.6877
2025-11-12 08:19:26,803 - INFO - Epoch: 21, Training Loss: 0.6877
2025-11-12 08:19:34,395 - INFO - Epoch: 22, Training Loss: 0.6876
2025-11-12 08:19:42,397 - INFO - Epoch: 23, Training Loss: 0.6880
2025-11-12 08:19:49,638 - INFO - Epoch: 24, Training Loss: 0.6879
2025-11-12 08:19:58,348 - INFO - Epoch: 25, Training Loss: 0.6882
2025-11-12 08:20:06,088 - INFO - Epoch: 26, Training Loss: 0.6871
2025-11-12 08:20:13,922 - INFO - Epoch: 27, Training Loss: 0.6871
2025-11-12 08:20:21,975 - INFO - Epoch: 28, Training Loss: 0.6880
2025-11-12 08:20:30,785 - INFO - Epoch: 29, Training Loss: 0.6871
2025-11-12 08:20:38,899 - INFO - Epoch: 30, Training Loss: 0.6878
2025-11-12 08:20:47,135 - INFO - Epoch: 31, Training Loss: 0.6878
2025-11-12 08:20:55,905 - INFO - Epoch: 32, Training Loss: 0.6881
2025-11-12 08:21:04,146 - INFO - Epoch: 33, Training Loss: 0.6874
2025-11-12 08:21:12,763 - INFO - Epoch: 34, Training Loss: 0.6874
2025-11-12 08:21:20,475 - INFO - Epoch: 35, Training Loss: 0.6876
2025-11-12 08:21:28,039 - INFO - Epoch: 36, Training Loss: 0.6882
2025-11-12 08:21:36,403 - INFO - Epoch: 37, Training Loss: 0.6876
2025-11-12 08:21:44,295 - INFO - Epoch: 38, Training Loss: 0.6874
2025-11-12 08:21:51,721 - INFO - Epoch: 39, Training Loss: 0.6877
2025-11-12 08:21:59,493 - INFO - Epoch: 40, Training Loss: 0.6874
2025-11-12 08:22:07,278 - INFO - Epoch: 41, Training Loss: 0.6880
2025-11-12 08:22:14,635 - INFO - Epoch: 42, Training Loss: 0.6873
2025-11-12 08:22:22,841 - INFO - Epoch: 43, Training Loss: 0.6874
2025-11-12 08:22:30,296 - INFO - Epoch: 44, Training Loss: 0.6876
2025-11-12 08:22:38,134 - INFO - Epoch: 45, Training Loss: 0.6872
2025-11-12 08:22:46,421 - INFO - Epoch: 46, Training Loss: 0.6883
2025-11-12 08:22:55,150 - INFO - Epoch: 47, Training Loss: 0.6873
2025-11-12 08:23:03,273 - INFO - Epoch: 48, Training Loss: 0.6869
2025-11-12 08:23:11,206 - INFO - Epoch: 49, Training Loss: 0.6878
2025-11-12 08:23:18,961 - INFO - Epoch: 50, Training Loss: 0.6876
2025-11-12 08:23:26,950 - INFO - Epoch: 51, Training Loss: 0.6875
2025-11-12 08:23:34,561 - INFO - Epoch: 52, Training Loss: 0.6882
2025-11-12 08:23:42,947 - INFO - Epoch: 53, Training Loss: 0.6874
2025-11-12 08:23:50,441 - INFO - Epoch: 54, Training Loss: 0.6877
2025-11-12 08:23:57,655 - INFO - Epoch: 55, Training Loss: 0.6877
2025-11-12 08:24:05,914 - INFO - Epoch: 56, Training Loss: 0.6881
2025-11-12 08:24:13,964 - INFO - Epoch: 57, Training Loss: 0.6883
2025-11-12 08:24:21,532 - INFO - Epoch: 58, Training Loss: 0.6883
2025-11-12 08:24:29,851 - INFO - Epoch: 59, Training Loss: 0.6880
2025-11-12 08:24:37,804 - INFO - Epoch: 60, Training Loss: 0.6873
2025-11-12 08:24:47,064 - INFO - Epoch: 61, Training Loss: 0.6877
2025-11-12 08:24:54,747 - INFO - Epoch: 62, Training Loss: 0.6873
2025-11-12 08:25:02,307 - INFO - Epoch: 63, Training Loss: 0.6878
2025-11-12 08:25:09,990 - INFO - Epoch: 64, Training Loss: 0.6875
2025-11-12 08:25:17,825 - INFO - Epoch: 65, Training Loss: 0.6879
2025-11-12 08:25:25,201 - INFO - Epoch: 66, Training Loss: 0.6878
2025-11-12 08:25:33,110 - INFO - Epoch: 67, Training Loss: 0.6872
2025-11-12 08:25:40,567 - INFO - Epoch: 68, Training Loss: 0.6882
2025-11-12 08:25:47,865 - INFO - Epoch: 69, Training Loss: 0.6876
2025-11-12 08:25:55,992 - INFO - Epoch: 70, Training Loss: 0.6877
2025-11-12 08:26:03,845 - INFO - Epoch: 71, Training Loss: 0.6875
2025-11-12 08:26:11,310 - INFO - Epoch: 72, Training Loss: 0.6885
2025-11-12 08:26:19,611 - INFO - Epoch: 73, Training Loss: 0.6877
2025-11-12 08:26:28,215 - INFO - Epoch: 74, Training Loss: 0.6871
2025-11-12 08:26:35,865 - INFO - Epoch: 75, Training Loss: 0.6874
2025-11-12 08:26:43,378 - INFO - Epoch: 76, Training Loss: 0.6864
2025-11-12 08:26:51,201 - INFO - Epoch: 77, Training Loss: 0.6858
2025-11-12 08:26:58,798 - INFO - Epoch: 78, Training Loss: 0.6847
2025-11-12 08:27:06,465 - INFO - Epoch: 79, Training Loss: 0.6819
2025-11-12 08:27:14,535 - INFO - Epoch: 80, Training Loss: 0.6797
2025-11-12 08:27:23,459 - INFO - Epoch: 81, Training Loss: 0.6772
2025-11-12 08:27:31,546 - INFO - Epoch: 82, Training Loss: 0.6840
2025-11-12 08:27:39,302 - INFO - Epoch: 83, Training Loss: 0.6784
2025-11-12 08:27:47,336 - INFO - Epoch: 84, Training Loss: 0.6785
2025-11-12 08:27:54,677 - INFO - Epoch: 85, Training Loss: 0.6778
2025-11-12 08:28:01,897 - INFO - Epoch: 86, Training Loss: 0.6777
2025-11-12 08:28:10,243 - INFO - Epoch: 87, Training Loss: 0.6765
2025-11-12 08:28:19,345 - INFO - Epoch: 88, Training Loss: 0.6772
2025-11-12 08:28:27,350 - INFO - Epoch: 89, Training Loss: 0.6753
2025-11-12 08:28:34,927 - INFO - Epoch: 90, Training Loss: 0.6754
2025-11-12 08:28:42,792 - INFO - Epoch: 91, Training Loss: 0.6767
2025-11-12 08:28:51,293 - INFO - Epoch: 92, Training Loss: 0.6739
2025-11-12 08:28:59,304 - INFO - Epoch: 93, Training Loss: 0.6742
2025-11-12 08:29:08,111 - INFO - Epoch: 94, Training Loss: 0.6740
2025-11-12 08:29:16,565 - INFO - Epoch: 95, Training Loss: 0.6734
2025-11-12 08:29:24,650 - INFO - Epoch: 96, Training Loss: 0.6738
2025-11-12 08:29:32,214 - INFO - Epoch: 97, Training Loss: 0.6736
2025-11-12 08:29:39,785 - INFO - Epoch: 98, Training Loss: 0.6728
2025-11-12 08:29:48,632 - INFO - Epoch: 99, Training Loss: 0.6720
2025-11-12 08:29:56,433 - INFO - Epoch: 100, Training Loss: 0.6750
2025-11-12 08:29:56,434 - INFO - Training completed for Trial 7 CV 1

