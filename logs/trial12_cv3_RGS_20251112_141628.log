2025-11-12 14:16:28,168 - INFO - Log file: ./logs/trial12_cv3_RGS_20251112_141628.log
2025-11-12 14:16:28,168 - INFO - START TRAINING TRIAL 12 CV 3 - Task: RGS
2025-11-12 14:16:28,168 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 14:16:28,168 - INFO - Loading dataset...
2025-11-12 14:16:28,348 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 14:16:28,348 - INFO - Initializing VIGNet model...
2025-11-12 14:16:28,351 - INFO - Number of batch iterations per epoch: 113
2025-11-12 14:16:36,559 - INFO - Epoch: 1, Training Loss: 1.3415
2025-11-12 14:16:45,030 - INFO - Epoch: 2, Training Loss: 0.6710
2025-11-12 14:16:53,099 - INFO - Epoch: 3, Training Loss: 0.6571
2025-11-12 14:17:00,514 - INFO - Epoch: 4, Training Loss: 0.6610
2025-11-12 14:17:08,698 - INFO - Epoch: 5, Training Loss: 0.6558
2025-11-12 14:17:17,386 - INFO - Epoch: 6, Training Loss: 0.6690
2025-11-12 14:17:25,034 - INFO - Epoch: 7, Training Loss: 0.6519
2025-11-12 14:17:32,936 - INFO - Epoch: 8, Training Loss: 0.6564
2025-11-12 14:17:40,472 - INFO - Epoch: 9, Training Loss: 0.6539
2025-11-12 14:17:48,494 - INFO - Epoch: 10, Training Loss: 0.6491
2025-11-12 14:17:56,085 - INFO - Epoch: 11, Training Loss: 0.6519
2025-11-12 14:18:03,851 - INFO - Epoch: 12, Training Loss: 0.6548
2025-11-12 14:18:11,574 - INFO - Epoch: 13, Training Loss: 0.6577
2025-11-12 14:18:20,122 - INFO - Epoch: 14, Training Loss: 0.6495
2025-11-12 14:18:28,068 - INFO - Epoch: 15, Training Loss: 0.6481
2025-11-12 14:18:35,761 - INFO - Epoch: 16, Training Loss: 0.6458
2025-11-12 14:18:43,983 - INFO - Epoch: 17, Training Loss: 0.6455
2025-11-12 14:18:51,792 - INFO - Epoch: 18, Training Loss: 0.6453
2025-11-12 14:18:59,821 - INFO - Epoch: 19, Training Loss: 0.6429
2025-11-12 14:19:07,573 - INFO - Epoch: 20, Training Loss: 0.6404
2025-11-12 14:19:15,957 - INFO - Epoch: 21, Training Loss: 0.6380
2025-11-12 14:19:23,734 - INFO - Epoch: 22, Training Loss: 0.6325
2025-11-12 14:19:31,512 - INFO - Epoch: 23, Training Loss: 0.6396
2025-11-12 14:19:39,055 - INFO - Epoch: 24, Training Loss: 0.6196
2025-11-12 14:19:46,603 - INFO - Epoch: 25, Training Loss: 0.6324
2025-11-12 14:19:54,316 - INFO - Epoch: 26, Training Loss: 0.5908
2025-11-12 14:20:02,036 - INFO - Epoch: 27, Training Loss: 0.6213
2025-11-12 14:20:09,198 - INFO - Epoch: 28, Training Loss: 0.5765
2025-11-12 14:20:16,543 - INFO - Epoch: 29, Training Loss: 0.5929
2025-11-12 14:20:24,383 - INFO - Epoch: 30, Training Loss: 0.5624
2025-11-12 14:20:32,949 - INFO - Epoch: 31, Training Loss: 0.5327
2025-11-12 14:20:41,534 - INFO - Epoch: 32, Training Loss: 0.5672
2025-11-12 14:20:49,949 - INFO - Epoch: 33, Training Loss: 0.5129
2025-11-12 14:20:57,894 - INFO - Epoch: 34, Training Loss: 0.7047
2025-11-12 14:21:05,857 - INFO - Epoch: 35, Training Loss: 0.5584
2025-11-12 14:21:12,969 - INFO - Epoch: 36, Training Loss: 0.5376
2025-11-12 14:21:20,436 - INFO - Epoch: 37, Training Loss: 0.5551
2025-11-12 14:21:28,647 - INFO - Epoch: 38, Training Loss: 0.6086
2025-11-12 14:21:36,275 - INFO - Epoch: 39, Training Loss: 0.5545
2025-11-12 14:21:44,632 - INFO - Epoch: 40, Training Loss: 0.5302
2025-11-12 14:21:53,088 - INFO - Epoch: 41, Training Loss: 0.5007
2025-11-12 14:22:01,007 - INFO - Epoch: 42, Training Loss: 0.6489
2025-11-12 14:22:09,559 - INFO - Epoch: 43, Training Loss: 0.5156
2025-11-12 14:22:17,792 - INFO - Epoch: 44, Training Loss: 0.5199
2025-11-12 14:22:25,830 - INFO - Epoch: 45, Training Loss: 0.5125
2025-11-12 14:22:33,576 - INFO - Epoch: 46, Training Loss: 0.5179
2025-11-12 14:22:41,582 - INFO - Epoch: 47, Training Loss: 0.5081
2025-11-12 14:22:48,763 - INFO - Epoch: 48, Training Loss: 0.6166
2025-11-12 14:22:56,994 - INFO - Epoch: 49, Training Loss: 0.5796
2025-11-12 14:23:04,585 - INFO - Epoch: 50, Training Loss: 0.4987
2025-11-12 14:23:12,779 - INFO - Epoch: 51, Training Loss: 0.5340
2025-11-12 14:23:21,356 - INFO - Epoch: 52, Training Loss: 0.4897
2025-11-12 14:23:29,878 - INFO - Epoch: 53, Training Loss: 0.5035
2025-11-12 14:23:37,752 - INFO - Epoch: 54, Training Loss: 0.4763
2025-11-12 14:23:45,420 - INFO - Epoch: 55, Training Loss: 0.4936
2025-11-12 14:23:53,454 - INFO - Epoch: 56, Training Loss: 0.5164
2025-11-12 14:24:01,519 - INFO - Epoch: 57, Training Loss: 0.5462
2025-11-12 14:24:09,047 - INFO - Epoch: 58, Training Loss: 0.4851
2025-11-12 14:24:17,256 - INFO - Epoch: 59, Training Loss: 0.4787
2025-11-12 14:24:24,661 - INFO - Epoch: 60, Training Loss: 0.4879
2025-11-12 14:24:32,824 - INFO - Epoch: 61, Training Loss: 0.5186
2025-11-12 14:24:40,966 - INFO - Epoch: 62, Training Loss: 0.4873
2025-11-12 14:24:48,809 - INFO - Epoch: 63, Training Loss: 0.4769
2025-11-12 14:24:56,805 - INFO - Epoch: 64, Training Loss: 0.5063
2025-11-12 14:25:04,887 - INFO - Epoch: 65, Training Loss: 0.5058
2025-11-12 14:25:12,873 - INFO - Epoch: 66, Training Loss: 0.5021
2025-11-12 14:25:20,355 - INFO - Epoch: 67, Training Loss: 0.4986
2025-11-12 14:25:28,526 - INFO - Epoch: 68, Training Loss: 0.4755
2025-11-12 14:25:35,789 - INFO - Epoch: 69, Training Loss: 0.4862
2025-11-12 14:25:43,855 - INFO - Epoch: 70, Training Loss: 0.4701
2025-11-12 14:25:52,486 - INFO - Epoch: 71, Training Loss: 0.4672
2025-11-12 14:26:00,521 - INFO - Epoch: 72, Training Loss: 0.4699
2025-11-12 14:26:08,735 - INFO - Epoch: 73, Training Loss: 0.4801
2025-11-12 14:26:16,616 - INFO - Epoch: 74, Training Loss: 0.5374
2025-11-12 14:26:24,363 - INFO - Epoch: 75, Training Loss: 0.5129
2025-11-12 14:26:32,128 - INFO - Epoch: 76, Training Loss: 0.4908
2025-11-12 14:26:39,908 - INFO - Epoch: 77, Training Loss: 0.4648
2025-11-12 14:26:47,884 - INFO - Epoch: 78, Training Loss: 0.4705
2025-11-12 14:26:55,819 - INFO - Epoch: 79, Training Loss: 0.4948
2025-11-12 14:27:05,151 - INFO - Epoch: 80, Training Loss: 0.5681
2025-11-12 14:27:12,617 - INFO - Epoch: 81, Training Loss: 0.5010
2025-11-12 14:27:21,252 - INFO - Epoch: 82, Training Loss: 0.4697
2025-11-12 14:27:29,942 - INFO - Epoch: 83, Training Loss: 0.4880
2025-11-12 14:27:37,984 - INFO - Epoch: 84, Training Loss: 0.5354
2025-11-12 14:27:45,651 - INFO - Epoch: 85, Training Loss: 0.4891
2025-11-12 14:27:54,160 - INFO - Epoch: 86, Training Loss: 0.4747
2025-11-12 14:28:02,165 - INFO - Epoch: 87, Training Loss: 0.4666
2025-11-12 14:28:10,486 - INFO - Epoch: 88, Training Loss: 0.4774
2025-11-12 14:28:17,928 - INFO - Epoch: 89, Training Loss: 0.5938
2025-11-12 14:28:26,098 - INFO - Epoch: 90, Training Loss: 0.5512
2025-11-12 14:28:34,559 - INFO - Epoch: 91, Training Loss: 0.4756
2025-11-12 14:28:42,293 - INFO - Epoch: 92, Training Loss: 0.4598
2025-11-12 14:28:50,096 - INFO - Epoch: 93, Training Loss: 0.4944
2025-11-12 14:28:58,062 - INFO - Epoch: 94, Training Loss: 0.5251
2025-11-12 14:29:05,870 - INFO - Epoch: 95, Training Loss: 0.5146
2025-11-12 14:29:14,467 - INFO - Epoch: 96, Training Loss: 0.7919
2025-11-12 14:29:22,431 - INFO - Epoch: 97, Training Loss: 0.5633
2025-11-12 14:29:30,068 - INFO - Epoch: 98, Training Loss: 0.5635
2025-11-12 14:29:37,336 - INFO - Epoch: 99, Training Loss: 0.4865
2025-11-12 14:29:45,793 - INFO - Epoch: 100, Training Loss: 0.4500
2025-11-12 14:29:45,793 - INFO - Training completed for Trial 12 CV 3

