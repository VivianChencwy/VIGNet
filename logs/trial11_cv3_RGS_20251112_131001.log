2025-11-12 13:10:01,690 - INFO - Log file: ./logs/trial11_cv3_RGS_20251112_131001.log
2025-11-12 13:10:01,690 - INFO - START TRAINING TRIAL 11 CV 3 - Task: RGS
2025-11-12 13:10:01,690 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 13:10:01,690 - INFO - Loading dataset...
2025-11-12 13:10:01,962 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 13:10:01,962 - INFO - Initializing VIGNet model...
2025-11-12 13:10:01,966 - INFO - Number of batch iterations per epoch: 113
2025-11-12 13:10:09,939 - INFO - Epoch: 1, Training Loss: 1.1287
2025-11-12 13:10:17,522 - INFO - Epoch: 2, Training Loss: 0.6892
2025-11-12 13:10:25,094 - INFO - Epoch: 3, Training Loss: 0.6780
2025-11-12 13:10:32,721 - INFO - Epoch: 4, Training Loss: 0.6810
2025-11-12 13:10:41,687 - INFO - Epoch: 5, Training Loss: 0.6761
2025-11-12 13:10:49,522 - INFO - Epoch: 6, Training Loss: 0.6770
2025-11-12 13:10:57,545 - INFO - Epoch: 7, Training Loss: 0.6748
2025-11-12 13:11:04,848 - INFO - Epoch: 8, Training Loss: 0.6734
2025-11-12 13:11:12,632 - INFO - Epoch: 9, Training Loss: 0.6740
2025-11-12 13:11:20,065 - INFO - Epoch: 10, Training Loss: 0.6724
2025-11-12 13:11:28,830 - INFO - Epoch: 11, Training Loss: 0.6739
2025-11-12 13:11:36,217 - INFO - Epoch: 12, Training Loss: 0.6731
2025-11-12 13:11:44,414 - INFO - Epoch: 13, Training Loss: 0.6730
2025-11-12 13:11:51,915 - INFO - Epoch: 14, Training Loss: 0.6729
2025-11-12 13:11:59,583 - INFO - Epoch: 15, Training Loss: 0.6730
2025-11-12 13:12:07,843 - INFO - Epoch: 16, Training Loss: 0.6725
2025-11-12 13:12:16,280 - INFO - Epoch: 17, Training Loss: 0.6730
2025-11-12 13:12:24,882 - INFO - Epoch: 18, Training Loss: 0.6725
2025-11-12 13:12:32,927 - INFO - Epoch: 19, Training Loss: 0.6721
2025-11-12 13:12:40,495 - INFO - Epoch: 20, Training Loss: 0.6737
2025-11-12 13:12:48,083 - INFO - Epoch: 21, Training Loss: 0.6728
2025-11-12 13:12:55,394 - INFO - Epoch: 22, Training Loss: 0.6739
2025-11-12 13:13:03,182 - INFO - Epoch: 23, Training Loss: 0.6724
2025-11-12 13:13:11,748 - INFO - Epoch: 24, Training Loss: 0.6717
2025-11-12 13:13:19,634 - INFO - Epoch: 25, Training Loss: 0.6740
2025-11-12 13:13:28,125 - INFO - Epoch: 26, Training Loss: 0.6722
2025-11-12 13:13:37,089 - INFO - Epoch: 27, Training Loss: 0.6721
2025-11-12 13:13:45,218 - INFO - Epoch: 28, Training Loss: 0.6730
2025-11-12 13:13:53,755 - INFO - Epoch: 29, Training Loss: 0.6724
2025-11-12 13:14:01,416 - INFO - Epoch: 30, Training Loss: 0.6723
2025-11-12 13:14:09,495 - INFO - Epoch: 31, Training Loss: 0.6727
2025-11-12 13:14:17,184 - INFO - Epoch: 32, Training Loss: 0.6730
2025-11-12 13:14:25,610 - INFO - Epoch: 33, Training Loss: 0.6732
2025-11-12 13:14:33,541 - INFO - Epoch: 34, Training Loss: 0.6725
2025-11-12 13:14:40,954 - INFO - Epoch: 35, Training Loss: 0.6730
2025-11-12 13:14:48,508 - INFO - Epoch: 36, Training Loss: 0.6730
2025-11-12 13:14:56,860 - INFO - Epoch: 37, Training Loss: 0.6722
2025-11-12 13:15:04,524 - INFO - Epoch: 38, Training Loss: 0.6724
2025-11-12 13:15:13,440 - INFO - Epoch: 39, Training Loss: 0.6725
2025-11-12 13:15:20,736 - INFO - Epoch: 40, Training Loss: 0.6721
2025-11-12 13:15:28,511 - INFO - Epoch: 41, Training Loss: 0.6732
2025-11-12 13:15:35,947 - INFO - Epoch: 42, Training Loss: 0.6732
2025-11-12 13:15:43,935 - INFO - Epoch: 43, Training Loss: 0.6722
2025-11-12 13:15:51,514 - INFO - Epoch: 44, Training Loss: 0.6722
2025-11-12 13:15:59,744 - INFO - Epoch: 45, Training Loss: 0.6719
2025-11-12 13:16:07,176 - INFO - Epoch: 46, Training Loss: 0.6725
2025-11-12 13:16:15,502 - INFO - Epoch: 47, Training Loss: 0.6726
2025-11-12 13:16:23,324 - INFO - Epoch: 48, Training Loss: 0.6724
2025-11-12 13:16:30,655 - INFO - Epoch: 49, Training Loss: 0.6728
2025-11-12 13:16:39,018 - INFO - Epoch: 50, Training Loss: 0.6729
2025-11-12 13:16:46,299 - INFO - Epoch: 51, Training Loss: 0.6723
2025-11-12 13:16:54,467 - INFO - Epoch: 52, Training Loss: 0.6720
2025-11-12 13:17:02,210 - INFO - Epoch: 53, Training Loss: 0.6726
2025-11-12 13:17:10,249 - INFO - Epoch: 54, Training Loss: 0.6726
2025-11-12 13:17:17,878 - INFO - Epoch: 55, Training Loss: 0.6731
2025-11-12 13:17:25,727 - INFO - Epoch: 56, Training Loss: 0.6733
2025-11-12 13:17:33,618 - INFO - Epoch: 57, Training Loss: 0.6725
2025-11-12 13:17:41,200 - INFO - Epoch: 58, Training Loss: 0.6726
2025-11-12 13:17:49,357 - INFO - Epoch: 59, Training Loss: 0.6723
2025-11-12 13:17:57,750 - INFO - Epoch: 60, Training Loss: 0.6726
2025-11-12 13:18:05,834 - INFO - Epoch: 61, Training Loss: 0.6730
2025-11-12 13:18:14,216 - INFO - Epoch: 62, Training Loss: 0.6720
2025-11-12 13:18:22,064 - INFO - Epoch: 63, Training Loss: 0.6722
2025-11-12 13:18:29,808 - INFO - Epoch: 64, Training Loss: 0.6723
2025-11-12 13:18:37,742 - INFO - Epoch: 65, Training Loss: 0.6722
2025-11-12 13:18:46,072 - INFO - Epoch: 66, Training Loss: 0.6722
2025-11-12 13:18:53,480 - INFO - Epoch: 67, Training Loss: 0.6725
2025-11-12 13:19:00,935 - INFO - Epoch: 68, Training Loss: 0.6718
2025-11-12 13:19:08,900 - INFO - Epoch: 69, Training Loss: 0.6738
2025-11-12 13:19:17,331 - INFO - Epoch: 70, Training Loss: 0.6721
2025-11-12 13:19:25,387 - INFO - Epoch: 71, Training Loss: 0.6725
2025-11-12 13:19:33,216 - INFO - Epoch: 72, Training Loss: 0.6728
2025-11-12 13:19:41,197 - INFO - Epoch: 73, Training Loss: 0.6729
2025-11-12 13:19:49,241 - INFO - Epoch: 74, Training Loss: 0.6718
2025-11-12 13:19:56,351 - INFO - Epoch: 75, Training Loss: 0.6730
2025-11-12 13:20:03,966 - INFO - Epoch: 76, Training Loss: 0.6722
2025-11-12 13:20:12,420 - INFO - Epoch: 77, Training Loss: 0.6719
2025-11-12 13:20:20,505 - INFO - Epoch: 78, Training Loss: 0.6724
2025-11-12 13:20:28,110 - INFO - Epoch: 79, Training Loss: 0.6734
2025-11-12 13:20:35,928 - INFO - Epoch: 80, Training Loss: 0.6725
2025-11-12 13:20:44,622 - INFO - Epoch: 81, Training Loss: 0.6721
2025-11-12 13:20:52,502 - INFO - Epoch: 82, Training Loss: 0.6723
2025-11-12 13:21:00,218 - INFO - Epoch: 83, Training Loss: 0.6717
2025-11-12 13:21:07,743 - INFO - Epoch: 84, Training Loss: 0.6722
2025-11-12 13:21:14,896 - INFO - Epoch: 85, Training Loss: 0.6727
2025-11-12 13:21:22,883 - INFO - Epoch: 86, Training Loss: 0.6729
2025-11-12 13:21:31,104 - INFO - Epoch: 87, Training Loss: 0.6717
2025-11-12 13:21:38,846 - INFO - Epoch: 88, Training Loss: 0.6725
2025-11-12 13:21:46,478 - INFO - Epoch: 89, Training Loss: 0.6719
2025-11-12 13:21:54,576 - INFO - Epoch: 90, Training Loss: 0.6726
2025-11-12 13:22:02,030 - INFO - Epoch: 91, Training Loss: 0.6720
2025-11-12 13:22:09,625 - INFO - Epoch: 92, Training Loss: 0.6719
2025-11-12 13:22:17,750 - INFO - Epoch: 93, Training Loss: 0.6724
2025-11-12 13:22:25,796 - INFO - Epoch: 94, Training Loss: 0.6718
2025-11-12 13:22:33,155 - INFO - Epoch: 95, Training Loss: 0.6702
2025-11-12 13:22:40,734 - INFO - Epoch: 96, Training Loss: 0.6684
2025-11-12 13:22:48,629 - INFO - Epoch: 97, Training Loss: 0.6660
2025-11-12 13:22:56,919 - INFO - Epoch: 98, Training Loss: 0.6628
2025-11-12 13:23:04,587 - INFO - Epoch: 99, Training Loss: 0.6611
2025-11-12 13:23:13,272 - INFO - Epoch: 100, Training Loss: 0.6618
2025-11-12 13:23:13,273 - INFO - Training completed for Trial 11 CV 3

