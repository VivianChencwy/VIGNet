2025-11-12 06:43:21,744 - INFO - Log file: ./logs/trial5_cv4_RGS_20251112_064321.log
2025-11-12 06:43:21,744 - INFO - START TRAINING TRIAL 5 CV 4 - Task: RGS
2025-11-12 06:43:21,744 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 06:43:21,744 - INFO - Loading dataset...
2025-11-12 06:43:21,833 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 06:43:21,833 - INFO - Initializing VIGNet model...
2025-11-12 06:43:21,836 - INFO - Number of batch iterations per epoch: 113
2025-11-12 06:43:29,883 - INFO - Epoch: 1, Training Loss: 0.9071
2025-11-12 06:43:38,478 - INFO - Epoch: 2, Training Loss: 0.6979
2025-11-12 06:43:46,139 - INFO - Epoch: 3, Training Loss: 0.6973
2025-11-12 06:43:54,775 - INFO - Epoch: 4, Training Loss: 0.6963
2025-11-12 06:44:03,490 - INFO - Epoch: 5, Training Loss: 0.6896
2025-11-12 06:44:10,489 - INFO - Epoch: 6, Training Loss: 0.6959
2025-11-12 06:44:18,158 - INFO - Epoch: 7, Training Loss: 0.6900
2025-11-12 06:44:25,820 - INFO - Epoch: 8, Training Loss: 0.6927
2025-11-12 06:44:34,131 - INFO - Epoch: 9, Training Loss: 0.6988
2025-11-12 06:44:41,571 - INFO - Epoch: 10, Training Loss: 0.6879
2025-11-12 06:44:49,431 - INFO - Epoch: 11, Training Loss: 0.6934
2025-11-12 06:44:57,399 - INFO - Epoch: 12, Training Loss: 0.6906
2025-11-12 06:45:05,344 - INFO - Epoch: 13, Training Loss: 0.6923
2025-11-12 06:45:13,837 - INFO - Epoch: 14, Training Loss: 0.6926
2025-11-12 06:45:21,853 - INFO - Epoch: 15, Training Loss: 0.6894
2025-11-12 06:45:29,437 - INFO - Epoch: 16, Training Loss: 0.6921
2025-11-12 06:45:36,992 - INFO - Epoch: 17, Training Loss: 0.6894
2025-11-12 06:45:44,515 - INFO - Epoch: 18, Training Loss: 0.6912
2025-11-12 06:45:52,078 - INFO - Epoch: 19, Training Loss: 0.6889
2025-11-12 06:46:00,161 - INFO - Epoch: 20, Training Loss: 0.6888
2025-11-12 06:46:09,144 - INFO - Epoch: 21, Training Loss: 0.6883
2025-11-12 06:46:17,180 - INFO - Epoch: 22, Training Loss: 0.6907
2025-11-12 06:46:24,901 - INFO - Epoch: 23, Training Loss: 0.6942
2025-11-12 06:46:34,031 - INFO - Epoch: 24, Training Loss: 0.6895
2025-11-12 06:46:42,050 - INFO - Epoch: 25, Training Loss: 0.6904
2025-11-12 06:46:50,678 - INFO - Epoch: 26, Training Loss: 0.6922
2025-11-12 06:46:58,252 - INFO - Epoch: 27, Training Loss: 0.6944
2025-11-12 06:47:06,457 - INFO - Epoch: 28, Training Loss: 0.6898
2025-11-12 06:47:15,102 - INFO - Epoch: 29, Training Loss: 0.6886
2025-11-12 06:47:23,231 - INFO - Epoch: 30, Training Loss: 0.6861
2025-11-12 06:47:30,436 - INFO - Epoch: 31, Training Loss: 0.6868
2025-11-12 06:47:37,723 - INFO - Epoch: 32, Training Loss: 0.6843
2025-11-12 06:47:45,283 - INFO - Epoch: 33, Training Loss: 0.6767
2025-11-12 06:47:53,169 - INFO - Epoch: 34, Training Loss: 0.6790
2025-11-12 06:48:01,537 - INFO - Epoch: 35, Training Loss: 0.6536
2025-11-12 06:48:09,581 - INFO - Epoch: 36, Training Loss: 0.6369
2025-11-12 06:48:17,023 - INFO - Epoch: 37, Training Loss: 0.6655
2025-11-12 06:48:25,101 - INFO - Epoch: 38, Training Loss: 0.6468
2025-11-12 06:48:33,252 - INFO - Epoch: 39, Training Loss: 0.6015
2025-11-12 06:48:40,785 - INFO - Epoch: 40, Training Loss: 0.5921
2025-11-12 06:48:49,343 - INFO - Epoch: 41, Training Loss: 0.6078
2025-11-12 06:48:57,224 - INFO - Epoch: 42, Training Loss: 0.5933
2025-11-12 06:49:05,716 - INFO - Epoch: 43, Training Loss: 0.5911
2025-11-12 06:49:13,261 - INFO - Epoch: 44, Training Loss: 0.5901
2025-11-12 06:49:20,816 - INFO - Epoch: 45, Training Loss: 0.6526
2025-11-12 06:49:29,109 - INFO - Epoch: 46, Training Loss: 0.5828
2025-11-12 06:49:36,883 - INFO - Epoch: 47, Training Loss: 0.5696
2025-11-12 06:49:44,450 - INFO - Epoch: 48, Training Loss: 0.5809
2025-11-12 06:49:52,446 - INFO - Epoch: 49, Training Loss: 0.5747
2025-11-12 06:50:02,121 - INFO - Epoch: 50, Training Loss: 0.5689
2025-11-12 06:50:09,583 - INFO - Epoch: 51, Training Loss: 0.5596
2025-11-12 06:50:17,455 - INFO - Epoch: 52, Training Loss: 0.5589
2025-11-12 06:50:25,098 - INFO - Epoch: 53, Training Loss: 0.5458
2025-11-12 06:50:32,964 - INFO - Epoch: 54, Training Loss: 0.5728
2025-11-12 06:50:40,429 - INFO - Epoch: 55, Training Loss: 0.5592
2025-11-12 06:50:48,084 - INFO - Epoch: 56, Training Loss: 0.5493
2025-11-12 06:50:56,459 - INFO - Epoch: 57, Training Loss: 0.5408
2025-11-12 06:51:04,876 - INFO - Epoch: 58, Training Loss: 0.5532
2025-11-12 06:51:13,218 - INFO - Epoch: 59, Training Loss: 0.5595
2025-11-12 06:51:21,278 - INFO - Epoch: 60, Training Loss: 0.5286
2025-11-12 06:51:29,242 - INFO - Epoch: 61, Training Loss: 0.5476
2025-11-12 06:51:37,471 - INFO - Epoch: 62, Training Loss: 0.5471
2025-11-12 06:51:45,436 - INFO - Epoch: 63, Training Loss: 0.5478
2025-11-12 06:51:53,447 - INFO - Epoch: 64, Training Loss: 0.5518
2025-11-12 06:52:01,358 - INFO - Epoch: 65, Training Loss: 0.5716
2025-11-12 06:52:09,541 - INFO - Epoch: 66, Training Loss: 0.5532
2025-11-12 06:52:17,924 - INFO - Epoch: 67, Training Loss: 0.5499
2025-11-12 06:52:26,161 - INFO - Epoch: 68, Training Loss: 0.5601
2025-11-12 06:52:34,325 - INFO - Epoch: 69, Training Loss: 0.5823
2025-11-12 06:52:42,382 - INFO - Epoch: 70, Training Loss: 0.6729
2025-11-12 06:52:50,178 - INFO - Epoch: 71, Training Loss: 0.5790
2025-11-12 06:52:58,509 - INFO - Epoch: 72, Training Loss: 0.5502
2025-11-12 06:53:06,735 - INFO - Epoch: 73, Training Loss: 0.6145
2025-11-12 06:53:14,465 - INFO - Epoch: 74, Training Loss: 0.5452
2025-11-12 06:53:23,050 - INFO - Epoch: 75, Training Loss: 0.5363
2025-11-12 06:53:30,882 - INFO - Epoch: 76, Training Loss: 0.5531
2025-11-12 06:53:39,431 - INFO - Epoch: 77, Training Loss: 0.5329
2025-11-12 06:53:47,568 - INFO - Epoch: 78, Training Loss: 0.5368
2025-11-12 06:53:55,921 - INFO - Epoch: 79, Training Loss: 0.5591
2025-11-12 06:54:03,540 - INFO - Epoch: 80, Training Loss: 0.9634
2025-11-12 06:54:12,080 - INFO - Epoch: 81, Training Loss: 0.7797
2025-11-12 06:54:20,668 - INFO - Epoch: 82, Training Loss: 0.7002
2025-11-12 06:54:28,178 - INFO - Epoch: 83, Training Loss: 0.6429
2025-11-12 06:54:35,587 - INFO - Epoch: 84, Training Loss: 0.6198
2025-11-12 06:54:42,775 - INFO - Epoch: 85, Training Loss: 0.6123
2025-11-12 06:54:50,289 - INFO - Epoch: 86, Training Loss: 0.6052
2025-11-12 06:54:58,745 - INFO - Epoch: 87, Training Loss: 0.5896
2025-11-12 06:55:06,435 - INFO - Epoch: 88, Training Loss: 0.5861
2025-11-12 06:55:14,571 - INFO - Epoch: 89, Training Loss: 0.5840
2025-11-12 06:55:22,944 - INFO - Epoch: 90, Training Loss: 0.5771
2025-11-12 06:55:30,843 - INFO - Epoch: 91, Training Loss: 0.5789
2025-11-12 06:55:38,978 - INFO - Epoch: 92, Training Loss: 0.5755
2025-11-12 06:55:47,238 - INFO - Epoch: 93, Training Loss: 0.5825
2025-11-12 06:55:54,835 - INFO - Epoch: 94, Training Loss: 0.5571
2025-11-12 06:56:04,111 - INFO - Epoch: 95, Training Loss: 0.6377
2025-11-12 06:56:12,353 - INFO - Epoch: 96, Training Loss: 0.7810
2025-11-12 06:56:21,011 - INFO - Epoch: 97, Training Loss: 0.5790
2025-11-12 06:56:29,151 - INFO - Epoch: 98, Training Loss: 0.5597
2025-11-12 06:56:37,427 - INFO - Epoch: 99, Training Loss: 0.5553
2025-11-12 06:56:45,443 - INFO - Epoch: 100, Training Loss: 0.5530
2025-11-12 06:56:45,443 - INFO - Training completed for Trial 5 CV 4

