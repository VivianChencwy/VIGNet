2025-11-12 04:17:25,249 - INFO - Log file: ./logs/trial3_cv3_RGS_20251112_041725.log
2025-11-12 04:17:25,249 - INFO - START TRAINING TRIAL 3 CV 3 - Task: RGS
2025-11-12 04:17:25,249 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 04:17:25,249 - INFO - Loading dataset...
2025-11-12 04:17:25,338 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 04:17:25,338 - INFO - Initializing VIGNet model...
2025-11-12 04:17:25,341 - INFO - Number of batch iterations per epoch: 113
2025-11-12 04:17:33,098 - INFO - Epoch: 1, Training Loss: 1.0828
2025-11-12 04:17:41,118 - INFO - Epoch: 2, Training Loss: 0.7072
2025-11-12 04:17:48,606 - INFO - Epoch: 3, Training Loss: 0.6963
2025-11-12 04:17:56,599 - INFO - Epoch: 4, Training Loss: 0.6963
2025-11-12 04:18:04,336 - INFO - Epoch: 5, Training Loss: 0.6973
2025-11-12 04:18:13,769 - INFO - Epoch: 6, Training Loss: 0.6964
2025-11-12 04:18:21,051 - INFO - Epoch: 7, Training Loss: 0.6952
2025-11-12 04:18:29,809 - INFO - Epoch: 8, Training Loss: 0.6957
2025-11-12 04:18:37,802 - INFO - Epoch: 9, Training Loss: 0.6943
2025-11-12 04:18:45,576 - INFO - Epoch: 10, Training Loss: 0.6955
2025-11-12 04:18:52,987 - INFO - Epoch: 11, Training Loss: 0.6950
2025-11-12 04:19:00,546 - INFO - Epoch: 12, Training Loss: 0.6949
2025-11-12 04:19:08,104 - INFO - Epoch: 13, Training Loss: 0.6941
2025-11-12 04:19:16,376 - INFO - Epoch: 14, Training Loss: 0.6948
2025-11-12 04:19:24,972 - INFO - Epoch: 15, Training Loss: 0.6940
2025-11-12 04:19:32,333 - INFO - Epoch: 16, Training Loss: 0.6932
2025-11-12 04:19:40,979 - INFO - Epoch: 17, Training Loss: 0.6935
2025-11-12 04:19:49,453 - INFO - Epoch: 18, Training Loss: 0.6948
2025-11-12 04:19:57,607 - INFO - Epoch: 19, Training Loss: 0.6949
2025-11-12 04:20:05,454 - INFO - Epoch: 20, Training Loss: 0.6938
2025-11-12 04:20:13,197 - INFO - Epoch: 21, Training Loss: 0.6940
2025-11-12 04:20:21,538 - INFO - Epoch: 22, Training Loss: 0.6952
2025-11-12 04:20:30,349 - INFO - Epoch: 23, Training Loss: 0.6946
2025-11-12 04:20:38,939 - INFO - Epoch: 24, Training Loss: 0.6933
2025-11-12 04:20:46,906 - INFO - Epoch: 25, Training Loss: 0.6939
2025-11-12 04:20:54,845 - INFO - Epoch: 26, Training Loss: 0.6955
2025-11-12 04:21:03,848 - INFO - Epoch: 27, Training Loss: 0.6948
2025-11-12 04:21:12,353 - INFO - Epoch: 28, Training Loss: 0.6947
2025-11-12 04:21:21,123 - INFO - Epoch: 29, Training Loss: 0.6932
2025-11-12 04:21:28,655 - INFO - Epoch: 30, Training Loss: 0.6936
2025-11-12 04:21:36,953 - INFO - Epoch: 31, Training Loss: 0.6938
2025-11-12 04:21:44,803 - INFO - Epoch: 32, Training Loss: 0.6946
2025-11-12 04:21:52,107 - INFO - Epoch: 33, Training Loss: 0.6936
2025-11-12 04:22:00,833 - INFO - Epoch: 34, Training Loss: 0.6949
2025-11-12 04:22:09,866 - INFO - Epoch: 35, Training Loss: 0.6930
2025-11-12 04:22:17,892 - INFO - Epoch: 36, Training Loss: 0.6938
2025-11-12 04:22:26,535 - INFO - Epoch: 37, Training Loss: 0.6932
2025-11-12 04:22:34,499 - INFO - Epoch: 38, Training Loss: 0.6930
2025-11-12 04:22:41,882 - INFO - Epoch: 39, Training Loss: 0.6942
2025-11-12 04:22:49,857 - INFO - Epoch: 40, Training Loss: 0.6934
2025-11-12 04:22:57,868 - INFO - Epoch: 41, Training Loss: 0.6922
2025-11-12 04:23:06,188 - INFO - Epoch: 42, Training Loss: 0.6934
2025-11-12 04:23:13,536 - INFO - Epoch: 43, Training Loss: 0.6915
2025-11-12 04:23:21,802 - INFO - Epoch: 44, Training Loss: 0.6931
2025-11-12 04:23:29,934 - INFO - Epoch: 45, Training Loss: 0.6917
2025-11-12 04:23:37,435 - INFO - Epoch: 46, Training Loss: 0.6898
2025-11-12 04:23:45,643 - INFO - Epoch: 47, Training Loss: 0.6911
2025-11-12 04:23:54,097 - INFO - Epoch: 48, Training Loss: 0.6888
2025-11-12 04:24:02,003 - INFO - Epoch: 49, Training Loss: 0.6888
2025-11-12 04:24:09,364 - INFO - Epoch: 50, Training Loss: 0.6880
2025-11-12 04:24:16,605 - INFO - Epoch: 51, Training Loss: 0.6881
2025-11-12 04:24:23,906 - INFO - Epoch: 52, Training Loss: 0.6835
2025-11-12 04:24:33,159 - INFO - Epoch: 53, Training Loss: 0.6816
2025-11-12 04:24:40,903 - INFO - Epoch: 54, Training Loss: 0.6793
2025-11-12 04:24:48,355 - INFO - Epoch: 55, Training Loss: 0.6809
2025-11-12 04:24:55,840 - INFO - Epoch: 56, Training Loss: 0.6728
2025-11-12 04:25:03,318 - INFO - Epoch: 57, Training Loss: 0.6764
2025-11-12 04:25:11,017 - INFO - Epoch: 58, Training Loss: 0.6722
2025-11-12 04:25:18,642 - INFO - Epoch: 59, Training Loss: 0.6700
2025-11-12 04:25:26,782 - INFO - Epoch: 60, Training Loss: 0.6941
2025-11-12 04:25:34,208 - INFO - Epoch: 61, Training Loss: 0.6640
2025-11-12 04:25:42,198 - INFO - Epoch: 62, Training Loss: 0.6641
2025-11-12 04:25:50,303 - INFO - Epoch: 63, Training Loss: 0.6651
2025-11-12 04:25:58,095 - INFO - Epoch: 64, Training Loss: 0.6943
2025-11-12 04:26:05,747 - INFO - Epoch: 65, Training Loss: 0.6819
2025-11-12 04:26:13,492 - INFO - Epoch: 66, Training Loss: 0.6756
2025-11-12 04:26:21,159 - INFO - Epoch: 67, Training Loss: 0.6719
2025-11-12 04:26:29,010 - INFO - Epoch: 68, Training Loss: 0.6740
2025-11-12 04:26:37,321 - INFO - Epoch: 69, Training Loss: 0.6686
2025-11-12 04:26:44,960 - INFO - Epoch: 70, Training Loss: 0.6699
2025-11-12 04:26:52,684 - INFO - Epoch: 71, Training Loss: 0.6674
2025-11-12 04:27:00,787 - INFO - Epoch: 72, Training Loss: 0.6636
2025-11-12 04:27:08,881 - INFO - Epoch: 73, Training Loss: 0.6644
2025-11-12 04:27:17,407 - INFO - Epoch: 74, Training Loss: 0.6646
2025-11-12 04:27:24,683 - INFO - Epoch: 75, Training Loss: 0.6615
2025-11-12 04:27:32,207 - INFO - Epoch: 76, Training Loss: 0.6615
2025-11-12 04:27:41,017 - INFO - Epoch: 77, Training Loss: 0.6624
2025-11-12 04:27:49,460 - INFO - Epoch: 78, Training Loss: 0.6647
2025-11-12 04:27:56,973 - INFO - Epoch: 79, Training Loss: 0.6666
2025-11-12 04:28:04,751 - INFO - Epoch: 80, Training Loss: 0.6609
2025-11-12 04:28:12,541 - INFO - Epoch: 81, Training Loss: 0.6654
2025-11-12 04:28:20,198 - INFO - Epoch: 82, Training Loss: 0.6618
2025-11-12 04:28:28,566 - INFO - Epoch: 83, Training Loss: 0.6630
2025-11-12 04:28:36,974 - INFO - Epoch: 84, Training Loss: 0.6778
2025-11-12 04:28:44,485 - INFO - Epoch: 85, Training Loss: 0.6765
2025-11-12 04:28:52,813 - INFO - Epoch: 86, Training Loss: 0.6686
2025-11-12 04:29:01,075 - INFO - Epoch: 87, Training Loss: 0.6647
2025-11-12 04:29:08,658 - INFO - Epoch: 88, Training Loss: 0.6761
2025-11-12 04:29:17,125 - INFO - Epoch: 89, Training Loss: 0.6681
2025-11-12 04:29:24,809 - INFO - Epoch: 90, Training Loss: 0.6642
2025-11-12 04:29:32,715 - INFO - Epoch: 91, Training Loss: 0.6628
2025-11-12 04:29:40,465 - INFO - Epoch: 92, Training Loss: 0.6608
2025-11-12 04:29:48,686 - INFO - Epoch: 93, Training Loss: 0.6608
2025-11-12 04:29:56,920 - INFO - Epoch: 94, Training Loss: 0.6595
2025-11-12 04:30:04,764 - INFO - Epoch: 95, Training Loss: 0.6616
2025-11-12 04:30:13,236 - INFO - Epoch: 96, Training Loss: 0.6658
2025-11-12 04:30:21,235 - INFO - Epoch: 97, Training Loss: 0.6612
2025-11-12 04:30:29,091 - INFO - Epoch: 98, Training Loss: 0.6620
2025-11-12 04:30:36,535 - INFO - Epoch: 99, Training Loss: 0.6645
2025-11-12 04:30:44,930 - INFO - Epoch: 100, Training Loss: 0.6617
2025-11-12 04:30:44,930 - INFO - Training completed for Trial 3 CV 3

