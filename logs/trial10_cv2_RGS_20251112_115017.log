2025-11-12 11:50:17,277 - INFO - Log file: ./logs/trial10_cv2_RGS_20251112_115017.log
2025-11-12 11:50:17,277 - INFO - START TRAINING TRIAL 10 CV 2 - Task: RGS
2025-11-12 11:50:17,277 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 11:50:17,277 - INFO - Loading dataset...
2025-11-12 11:50:17,404 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 11:50:17,405 - INFO - Initializing VIGNet model...
2025-11-12 11:50:17,409 - INFO - Number of batch iterations per epoch: 113
2025-11-12 11:50:25,703 - INFO - Epoch: 1, Training Loss: 1.3068
2025-11-12 11:50:34,153 - INFO - Epoch: 2, Training Loss: 0.7623
2025-11-12 11:50:41,572 - INFO - Epoch: 3, Training Loss: 0.7961
2025-11-12 11:50:49,486 - INFO - Epoch: 4, Training Loss: 0.7146
2025-11-12 11:50:57,879 - INFO - Epoch: 5, Training Loss: 0.7095
2025-11-12 11:51:05,894 - INFO - Epoch: 6, Training Loss: 0.6992
2025-11-12 11:51:13,166 - INFO - Epoch: 7, Training Loss: 0.6968
2025-11-12 11:51:21,988 - INFO - Epoch: 8, Training Loss: 0.6935
2025-11-12 11:51:29,981 - INFO - Epoch: 9, Training Loss: 0.6952
2025-11-12 11:51:37,722 - INFO - Epoch: 10, Training Loss: 0.6908
2025-11-12 11:51:45,765 - INFO - Epoch: 11, Training Loss: 0.6894
2025-11-12 11:51:53,916 - INFO - Epoch: 12, Training Loss: 0.6873
2025-11-12 11:52:01,577 - INFO - Epoch: 13, Training Loss: 0.6886
2025-11-12 11:52:09,615 - INFO - Epoch: 14, Training Loss: 0.6855
2025-11-12 11:52:18,142 - INFO - Epoch: 15, Training Loss: 0.6873
2025-11-12 11:52:26,358 - INFO - Epoch: 16, Training Loss: 0.6863
2025-11-12 11:52:34,541 - INFO - Epoch: 17, Training Loss: 0.6863
2025-11-12 11:52:42,895 - INFO - Epoch: 18, Training Loss: 0.6877
2025-11-12 11:52:50,847 - INFO - Epoch: 19, Training Loss: 0.6856
2025-11-12 11:52:58,846 - INFO - Epoch: 20, Training Loss: 0.6865
2025-11-12 11:53:06,143 - INFO - Epoch: 21, Training Loss: 0.6864
2025-11-12 11:53:14,139 - INFO - Epoch: 22, Training Loss: 0.6853
2025-11-12 11:53:21,592 - INFO - Epoch: 23, Training Loss: 0.6855
2025-11-12 11:53:29,804 - INFO - Epoch: 24, Training Loss: 0.6848
2025-11-12 11:53:38,189 - INFO - Epoch: 25, Training Loss: 0.6851
2025-11-12 11:53:45,812 - INFO - Epoch: 26, Training Loss: 0.6869
2025-11-12 11:53:53,583 - INFO - Epoch: 27, Training Loss: 0.6848
2025-11-12 11:54:01,461 - INFO - Epoch: 28, Training Loss: 0.6853
2025-11-12 11:54:08,888 - INFO - Epoch: 29, Training Loss: 0.6860
2025-11-12 11:54:17,131 - INFO - Epoch: 30, Training Loss: 0.6846
2025-11-12 11:54:25,701 - INFO - Epoch: 31, Training Loss: 0.6849
2025-11-12 11:54:33,435 - INFO - Epoch: 32, Training Loss: 0.6852
2025-11-12 11:54:41,709 - INFO - Epoch: 33, Training Loss: 0.6870
2025-11-12 11:54:49,855 - INFO - Epoch: 34, Training Loss: 0.6852
2025-11-12 11:54:57,533 - INFO - Epoch: 35, Training Loss: 0.6855
2025-11-12 11:55:05,853 - INFO - Epoch: 36, Training Loss: 0.6846
2025-11-12 11:55:13,876 - INFO - Epoch: 37, Training Loss: 0.6850
2025-11-12 11:55:21,867 - INFO - Epoch: 38, Training Loss: 0.6853
2025-11-12 11:55:29,767 - INFO - Epoch: 39, Training Loss: 0.6838
2025-11-12 11:55:37,049 - INFO - Epoch: 40, Training Loss: 0.6849
2025-11-12 11:55:45,014 - INFO - Epoch: 41, Training Loss: 0.6840
2025-11-12 11:55:53,344 - INFO - Epoch: 42, Training Loss: 0.6843
2025-11-12 11:56:01,783 - INFO - Epoch: 43, Training Loss: 0.6847
2025-11-12 11:56:09,365 - INFO - Epoch: 44, Training Loss: 0.6860
2025-11-12 11:56:16,811 - INFO - Epoch: 45, Training Loss: 0.6846
2025-11-12 11:56:24,571 - INFO - Epoch: 46, Training Loss: 0.6844
2025-11-12 11:56:32,472 - INFO - Epoch: 47, Training Loss: 0.6844
2025-11-12 11:56:39,979 - INFO - Epoch: 48, Training Loss: 0.6840
2025-11-12 11:56:47,983 - INFO - Epoch: 49, Training Loss: 0.6848
2025-11-12 11:56:55,835 - INFO - Epoch: 50, Training Loss: 0.6846
2025-11-12 11:57:03,453 - INFO - Epoch: 51, Training Loss: 0.6850
2025-11-12 11:57:10,952 - INFO - Epoch: 52, Training Loss: 0.6845
2025-11-12 11:57:18,347 - INFO - Epoch: 53, Training Loss: 0.6850
2025-11-12 11:57:26,665 - INFO - Epoch: 54, Training Loss: 0.6842
2025-11-12 11:57:34,862 - INFO - Epoch: 55, Training Loss: 0.6856
2025-11-12 11:57:42,975 - INFO - Epoch: 56, Training Loss: 0.6854
2025-11-12 11:57:50,836 - INFO - Epoch: 57, Training Loss: 0.6842
2025-11-12 11:57:59,190 - INFO - Epoch: 58, Training Loss: 0.6849
2025-11-12 11:58:07,326 - INFO - Epoch: 59, Training Loss: 0.6852
2025-11-12 11:58:15,123 - INFO - Epoch: 60, Training Loss: 0.6848
2025-11-12 11:58:23,000 - INFO - Epoch: 61, Training Loss: 0.6844
2025-11-12 11:58:31,162 - INFO - Epoch: 62, Training Loss: 0.6842
2025-11-12 11:58:39,501 - INFO - Epoch: 63, Training Loss: 0.6851
2025-11-12 11:58:47,573 - INFO - Epoch: 64, Training Loss: 0.6849
2025-11-12 11:58:55,882 - INFO - Epoch: 65, Training Loss: 0.6849
2025-11-12 11:59:04,265 - INFO - Epoch: 66, Training Loss: 0.6839
2025-11-12 11:59:13,086 - INFO - Epoch: 67, Training Loss: 0.6845
2025-11-12 11:59:21,471 - INFO - Epoch: 68, Training Loss: 0.6839
2025-11-12 11:59:29,745 - INFO - Epoch: 69, Training Loss: 0.6862
2025-11-12 11:59:36,770 - INFO - Epoch: 70, Training Loss: 0.6848
2025-11-12 11:59:44,310 - INFO - Epoch: 71, Training Loss: 0.6838
2025-11-12 11:59:52,387 - INFO - Epoch: 72, Training Loss: 0.6839
2025-11-12 12:00:00,698 - INFO - Epoch: 73, Training Loss: 0.6844
2025-11-12 12:00:09,124 - INFO - Epoch: 74, Training Loss: 0.6842
2025-11-12 12:00:17,055 - INFO - Epoch: 75, Training Loss: 0.6851
2025-11-12 12:00:25,251 - INFO - Epoch: 76, Training Loss: 0.6843
2025-11-12 12:00:32,763 - INFO - Epoch: 77, Training Loss: 0.6850
2025-11-12 12:00:40,548 - INFO - Epoch: 78, Training Loss: 0.6853
2025-11-12 12:00:48,281 - INFO - Epoch: 79, Training Loss: 0.6840
2025-11-12 12:00:56,981 - INFO - Epoch: 80, Training Loss: 0.6844
2025-11-12 12:01:04,977 - INFO - Epoch: 81, Training Loss: 0.6841
2025-11-12 12:01:12,705 - INFO - Epoch: 82, Training Loss: 0.6840
2025-11-12 12:01:20,517 - INFO - Epoch: 83, Training Loss: 0.6844
2025-11-12 12:01:28,561 - INFO - Epoch: 84, Training Loss: 0.6839
2025-11-12 12:01:37,148 - INFO - Epoch: 85, Training Loss: 0.6842
2025-11-12 12:01:44,925 - INFO - Epoch: 86, Training Loss: 0.6844
2025-11-12 12:01:53,719 - INFO - Epoch: 87, Training Loss: 0.6838
2025-11-12 12:02:02,173 - INFO - Epoch: 88, Training Loss: 0.6841
2025-11-12 12:02:10,394 - INFO - Epoch: 89, Training Loss: 0.6852
2025-11-12 12:02:18,312 - INFO - Epoch: 90, Training Loss: 0.6842
2025-11-12 12:02:27,411 - INFO - Epoch: 91, Training Loss: 0.6839
2025-11-12 12:02:35,749 - INFO - Epoch: 92, Training Loss: 0.6841
2025-11-12 12:02:42,938 - INFO - Epoch: 93, Training Loss: 0.6838
2025-11-12 12:02:51,033 - INFO - Epoch: 94, Training Loss: 0.6835
2025-11-12 12:02:59,461 - INFO - Epoch: 95, Training Loss: 0.6826
2025-11-12 12:03:07,258 - INFO - Epoch: 96, Training Loss: 0.6812
2025-11-12 12:03:14,661 - INFO - Epoch: 97, Training Loss: 0.6815
2025-11-12 12:03:22,909 - INFO - Epoch: 98, Training Loss: 0.6784
2025-11-12 12:03:30,582 - INFO - Epoch: 99, Training Loss: 0.6783
2025-11-12 12:03:38,540 - INFO - Epoch: 100, Training Loss: 0.6761
2025-11-12 12:03:38,540 - INFO - Training completed for Trial 10 CV 2

