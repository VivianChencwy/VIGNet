2025-11-12 12:56:43,298 - INFO - Log file: ./logs/trial11_cv2_RGS_20251112_125643.log
2025-11-12 12:56:43,298 - INFO - START TRAINING TRIAL 11 CV 2 - Task: RGS
2025-11-12 12:56:43,298 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 12:56:43,298 - INFO - Loading dataset...
2025-11-12 12:56:43,670 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 12:56:43,670 - INFO - Initializing VIGNet model...
2025-11-12 12:56:43,673 - INFO - Number of batch iterations per epoch: 113
2025-11-12 12:56:51,909 - INFO - Epoch: 1, Training Loss: 0.8130
2025-11-12 12:56:59,620 - INFO - Epoch: 2, Training Loss: 0.6790
2025-11-12 12:57:07,806 - INFO - Epoch: 3, Training Loss: 0.6763
2025-11-12 12:57:16,640 - INFO - Epoch: 4, Training Loss: 0.6766
2025-11-12 12:57:25,909 - INFO - Epoch: 5, Training Loss: 0.6775
2025-11-12 12:57:33,339 - INFO - Epoch: 6, Training Loss: 0.6760
2025-11-12 12:57:41,445 - INFO - Epoch: 7, Training Loss: 0.6761
2025-11-12 12:57:49,165 - INFO - Epoch: 8, Training Loss: 0.6779
2025-11-12 12:57:57,348 - INFO - Epoch: 9, Training Loss: 0.6762
2025-11-12 12:58:04,892 - INFO - Epoch: 10, Training Loss: 0.6757
2025-11-12 12:58:13,107 - INFO - Epoch: 11, Training Loss: 0.6754
2025-11-12 12:58:21,884 - INFO - Epoch: 12, Training Loss: 0.6770
2025-11-12 12:58:29,785 - INFO - Epoch: 13, Training Loss: 0.6757
2025-11-12 12:58:38,543 - INFO - Epoch: 14, Training Loss: 0.6755
2025-11-12 12:58:47,167 - INFO - Epoch: 15, Training Loss: 0.6761
2025-11-12 12:58:56,116 - INFO - Epoch: 16, Training Loss: 0.6759
2025-11-12 12:59:05,302 - INFO - Epoch: 17, Training Loss: 0.6753
2025-11-12 12:59:12,724 - INFO - Epoch: 18, Training Loss: 0.6753
2025-11-12 12:59:20,096 - INFO - Epoch: 19, Training Loss: 0.6763
2025-11-12 12:59:27,675 - INFO - Epoch: 20, Training Loss: 0.6767
2025-11-12 12:59:36,483 - INFO - Epoch: 21, Training Loss: 0.6762
2025-11-12 12:59:44,413 - INFO - Epoch: 22, Training Loss: 0.6761
2025-11-12 12:59:51,933 - INFO - Epoch: 23, Training Loss: 0.6756
2025-11-12 12:59:59,890 - INFO - Epoch: 24, Training Loss: 0.6751
2025-11-12 13:00:07,656 - INFO - Epoch: 25, Training Loss: 0.6766
2025-11-12 13:00:15,262 - INFO - Epoch: 26, Training Loss: 0.6759
2025-11-12 13:00:22,893 - INFO - Epoch: 27, Training Loss: 0.6757
2025-11-12 13:00:30,576 - INFO - Epoch: 28, Training Loss: 0.6754
2025-11-12 13:00:38,524 - INFO - Epoch: 29, Training Loss: 0.6752
2025-11-12 13:00:46,922 - INFO - Epoch: 30, Training Loss: 0.6765
2025-11-12 13:00:54,116 - INFO - Epoch: 31, Training Loss: 0.6771
2025-11-12 13:01:01,907 - INFO - Epoch: 32, Training Loss: 0.6758
2025-11-12 13:01:10,462 - INFO - Epoch: 33, Training Loss: 0.6762
2025-11-12 13:01:18,070 - INFO - Epoch: 34, Training Loss: 0.6758
2025-11-12 13:01:25,959 - INFO - Epoch: 35, Training Loss: 0.6759
2025-11-12 13:01:33,924 - INFO - Epoch: 36, Training Loss: 0.6759
2025-11-12 13:01:41,359 - INFO - Epoch: 37, Training Loss: 0.6761
2025-11-12 13:01:50,020 - INFO - Epoch: 38, Training Loss: 0.6751
2025-11-12 13:01:57,460 - INFO - Epoch: 39, Training Loss: 0.6753
2025-11-12 13:02:05,542 - INFO - Epoch: 40, Training Loss: 0.6768
2025-11-12 13:02:13,301 - INFO - Epoch: 41, Training Loss: 0.6754
2025-11-12 13:02:20,430 - INFO - Epoch: 42, Training Loss: 0.6758
2025-11-12 13:02:28,599 - INFO - Epoch: 43, Training Loss: 0.6761
2025-11-12 13:02:36,527 - INFO - Epoch: 44, Training Loss: 0.6756
2025-11-12 13:02:44,812 - INFO - Epoch: 45, Training Loss: 0.6756
2025-11-12 13:02:52,567 - INFO - Epoch: 46, Training Loss: 0.6752
2025-11-12 13:03:00,277 - INFO - Epoch: 47, Training Loss: 0.6751
2025-11-12 13:03:08,261 - INFO - Epoch: 48, Training Loss: 0.6754
2025-11-12 13:03:16,102 - INFO - Epoch: 49, Training Loss: 0.6768
2025-11-12 13:03:24,563 - INFO - Epoch: 50, Training Loss: 0.6758
2025-11-12 13:03:32,650 - INFO - Epoch: 51, Training Loss: 0.6763
2025-11-12 13:03:40,266 - INFO - Epoch: 52, Training Loss: 0.6755
2025-11-12 13:03:47,612 - INFO - Epoch: 53, Training Loss: 0.6756
2025-11-12 13:03:55,529 - INFO - Epoch: 54, Training Loss: 0.6759
2025-11-12 13:04:03,142 - INFO - Epoch: 55, Training Loss: 0.6759
2025-11-12 13:04:11,530 - INFO - Epoch: 56, Training Loss: 0.6765
2025-11-12 13:04:19,671 - INFO - Epoch: 57, Training Loss: 0.6755
2025-11-12 13:04:27,963 - INFO - Epoch: 58, Training Loss: 0.6757
2025-11-12 13:04:35,794 - INFO - Epoch: 59, Training Loss: 0.6747
2025-11-12 13:04:43,945 - INFO - Epoch: 60, Training Loss: 0.6760
2025-11-12 13:04:51,144 - INFO - Epoch: 61, Training Loss: 0.6759
2025-11-12 13:04:58,676 - INFO - Epoch: 62, Training Loss: 0.6758
2025-11-12 13:05:05,993 - INFO - Epoch: 63, Training Loss: 0.6763
2025-11-12 13:05:13,686 - INFO - Epoch: 64, Training Loss: 0.6750
2025-11-12 13:05:21,631 - INFO - Epoch: 65, Training Loss: 0.6750
2025-11-12 13:05:29,470 - INFO - Epoch: 66, Training Loss: 0.6762
2025-11-12 13:05:37,264 - INFO - Epoch: 67, Training Loss: 0.6753
2025-11-12 13:05:45,213 - INFO - Epoch: 68, Training Loss: 0.6759
2025-11-12 13:05:54,301 - INFO - Epoch: 69, Training Loss: 0.6756
2025-11-12 13:06:02,541 - INFO - Epoch: 70, Training Loss: 0.6754
2025-11-12 13:06:10,414 - INFO - Epoch: 71, Training Loss: 0.6761
2025-11-12 13:06:17,979 - INFO - Epoch: 72, Training Loss: 0.6753
2025-11-12 13:06:25,839 - INFO - Epoch: 73, Training Loss: 0.6760
2025-11-12 13:06:33,259 - INFO - Epoch: 74, Training Loss: 0.6752
2025-11-12 13:06:42,169 - INFO - Epoch: 75, Training Loss: 0.6752
2025-11-12 13:06:50,607 - INFO - Epoch: 76, Training Loss: 0.6751
2025-11-12 13:06:58,611 - INFO - Epoch: 77, Training Loss: 0.6751
2025-11-12 13:07:06,681 - INFO - Epoch: 78, Training Loss: 0.6743
2025-11-12 13:07:14,262 - INFO - Epoch: 79, Training Loss: 0.6740
2025-11-12 13:07:22,059 - INFO - Epoch: 80, Training Loss: 0.6747
2025-11-12 13:07:29,387 - INFO - Epoch: 81, Training Loss: 0.6738
2025-11-12 13:07:36,864 - INFO - Epoch: 82, Training Loss: 0.6723
2025-11-12 13:07:44,707 - INFO - Epoch: 83, Training Loss: 0.6720
2025-11-12 13:07:52,683 - INFO - Epoch: 84, Training Loss: 0.6705
2025-11-12 13:08:01,361 - INFO - Epoch: 85, Training Loss: 0.6673
2025-11-12 13:08:09,159 - INFO - Epoch: 86, Training Loss: 0.6655
2025-11-12 13:08:17,196 - INFO - Epoch: 87, Training Loss: 0.6658
2025-11-12 13:08:25,796 - INFO - Epoch: 88, Training Loss: 0.6650
2025-11-12 13:08:34,064 - INFO - Epoch: 89, Training Loss: 0.6645
2025-11-12 13:08:41,854 - INFO - Epoch: 90, Training Loss: 0.6649
2025-11-12 13:08:50,039 - INFO - Epoch: 91, Training Loss: 0.6633
2025-11-12 13:08:58,324 - INFO - Epoch: 92, Training Loss: 0.6611
2025-11-12 13:09:06,549 - INFO - Epoch: 93, Training Loss: 0.6622
2025-11-12 13:09:14,702 - INFO - Epoch: 94, Training Loss: 0.6622
2025-11-12 13:09:22,700 - INFO - Epoch: 95, Training Loss: 0.6603
2025-11-12 13:09:31,483 - INFO - Epoch: 96, Training Loss: 0.6599
2025-11-12 13:09:39,823 - INFO - Epoch: 97, Training Loss: 0.6582
2025-11-12 13:09:47,612 - INFO - Epoch: 98, Training Loss: 0.6581
2025-11-12 13:09:54,667 - INFO - Epoch: 99, Training Loss: 0.6580
2025-11-12 13:10:01,687 - INFO - Epoch: 100, Training Loss: 0.6583
2025-11-12 13:10:01,688 - INFO - Training completed for Trial 11 CV 2

