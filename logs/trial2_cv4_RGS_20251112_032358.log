2025-11-12 03:23:58,494 - INFO - Log file: ./logs/trial2_cv4_RGS_20251112_032358.log
2025-11-12 03:23:58,494 - INFO - START TRAINING TRIAL 2 CV 4 - Task: RGS
2025-11-12 03:23:58,494 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 03:23:58,494 - INFO - Loading dataset...
2025-11-12 03:23:58,585 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 03:23:58,585 - INFO - Initializing VIGNet model...
2025-11-12 03:23:58,588 - INFO - Number of batch iterations per epoch: 113
2025-11-12 03:24:06,496 - INFO - Epoch: 1, Training Loss: 0.6637
2025-11-12 03:24:14,051 - INFO - Epoch: 2, Training Loss: 0.6026
2025-11-12 03:24:21,807 - INFO - Epoch: 3, Training Loss: 0.5981
2025-11-12 03:24:30,378 - INFO - Epoch: 4, Training Loss: 0.5960
2025-11-12 03:24:37,962 - INFO - Epoch: 5, Training Loss: 0.5991
2025-11-12 03:24:45,458 - INFO - Epoch: 6, Training Loss: 0.5968
2025-11-12 03:24:53,490 - INFO - Epoch: 7, Training Loss: 0.5971
2025-11-12 03:25:01,378 - INFO - Epoch: 8, Training Loss: 0.5976
2025-11-12 03:25:09,168 - INFO - Epoch: 9, Training Loss: 0.5967
2025-11-12 03:25:16,968 - INFO - Epoch: 10, Training Loss: 0.5969
2025-11-12 03:25:25,356 - INFO - Epoch: 11, Training Loss: 0.5960
2025-11-12 03:25:33,822 - INFO - Epoch: 12, Training Loss: 0.5958
2025-11-12 03:25:41,442 - INFO - Epoch: 13, Training Loss: 0.5976
2025-11-12 03:25:50,147 - INFO - Epoch: 14, Training Loss: 0.5966
2025-11-12 03:25:58,297 - INFO - Epoch: 15, Training Loss: 0.5960
2025-11-12 03:26:06,669 - INFO - Epoch: 16, Training Loss: 0.5957
2025-11-12 03:26:14,855 - INFO - Epoch: 17, Training Loss: 0.5963
2025-11-12 03:26:22,787 - INFO - Epoch: 18, Training Loss: 0.5962
2025-11-12 03:26:31,734 - INFO - Epoch: 19, Training Loss: 0.5957
2025-11-12 03:26:39,898 - INFO - Epoch: 20, Training Loss: 0.5966
2025-11-12 03:26:47,883 - INFO - Epoch: 21, Training Loss: 0.5964
2025-11-12 03:26:56,789 - INFO - Epoch: 22, Training Loss: 0.5960
2025-11-12 03:27:04,791 - INFO - Epoch: 23, Training Loss: 0.5958
2025-11-12 03:27:12,854 - INFO - Epoch: 24, Training Loss: 0.5965
2025-11-12 03:27:20,824 - INFO - Epoch: 25, Training Loss: 0.5961
2025-11-12 03:27:28,553 - INFO - Epoch: 26, Training Loss: 0.5966
2025-11-12 03:27:36,587 - INFO - Epoch: 27, Training Loss: 0.5958
2025-11-12 03:27:44,667 - INFO - Epoch: 28, Training Loss: 0.5977
2025-11-12 03:27:52,832 - INFO - Epoch: 29, Training Loss: 0.5964
2025-11-12 03:28:01,701 - INFO - Epoch: 30, Training Loss: 0.5973
2025-11-12 03:28:09,828 - INFO - Epoch: 31, Training Loss: 0.5956
2025-11-12 03:28:18,127 - INFO - Epoch: 32, Training Loss: 0.5966
2025-11-12 03:28:25,754 - INFO - Epoch: 33, Training Loss: 0.5963
2025-11-12 03:28:34,559 - INFO - Epoch: 34, Training Loss: 0.5969
2025-11-12 03:28:42,172 - INFO - Epoch: 35, Training Loss: 0.5953
2025-11-12 03:28:50,774 - INFO - Epoch: 36, Training Loss: 0.5964
2025-11-12 03:28:58,418 - INFO - Epoch: 37, Training Loss: 0.5959
2025-11-12 03:29:05,877 - INFO - Epoch: 38, Training Loss: 0.5972
2025-11-12 03:29:13,970 - INFO - Epoch: 39, Training Loss: 0.5967
2025-11-12 03:29:21,323 - INFO - Epoch: 40, Training Loss: 0.5950
2025-11-12 03:29:30,074 - INFO - Epoch: 41, Training Loss: 0.5977
2025-11-12 03:29:38,577 - INFO - Epoch: 42, Training Loss: 0.5966
2025-11-12 03:29:46,395 - INFO - Epoch: 43, Training Loss: 0.5965
2025-11-12 03:29:54,480 - INFO - Epoch: 44, Training Loss: 0.5962
2025-11-12 03:30:02,095 - INFO - Epoch: 45, Training Loss: 0.5963
2025-11-12 03:30:09,387 - INFO - Epoch: 46, Training Loss: 0.5959
2025-11-12 03:30:17,802 - INFO - Epoch: 47, Training Loss: 0.5956
2025-11-12 03:30:25,810 - INFO - Epoch: 48, Training Loss: 0.5960
2025-11-12 03:30:33,984 - INFO - Epoch: 49, Training Loss: 0.5959
2025-11-12 03:30:42,096 - INFO - Epoch: 50, Training Loss: 0.5958
2025-11-12 03:30:50,312 - INFO - Epoch: 51, Training Loss: 0.5957
2025-11-12 03:30:57,804 - INFO - Epoch: 52, Training Loss: 0.5964
2025-11-12 03:31:05,601 - INFO - Epoch: 53, Training Loss: 0.5964
2025-11-12 03:31:13,175 - INFO - Epoch: 54, Training Loss: 0.5964
2025-11-12 03:31:21,690 - INFO - Epoch: 55, Training Loss: 0.5952
2025-11-12 03:31:29,380 - INFO - Epoch: 56, Training Loss: 0.5962
2025-11-12 03:31:36,960 - INFO - Epoch: 57, Training Loss: 0.5958
2025-11-12 03:31:44,816 - INFO - Epoch: 58, Training Loss: 0.5952
2025-11-12 03:31:52,416 - INFO - Epoch: 59, Training Loss: 0.5974
2025-11-12 03:32:00,827 - INFO - Epoch: 60, Training Loss: 0.5963
2025-11-12 03:32:09,206 - INFO - Epoch: 61, Training Loss: 0.5962
2025-11-12 03:32:17,090 - INFO - Epoch: 62, Training Loss: 0.5961
2025-11-12 03:32:25,297 - INFO - Epoch: 63, Training Loss: 0.5954
2025-11-12 03:32:33,420 - INFO - Epoch: 64, Training Loss: 0.5956
2025-11-12 03:32:41,516 - INFO - Epoch: 65, Training Loss: 0.5965
2025-11-12 03:32:49,948 - INFO - Epoch: 66, Training Loss: 0.5957
2025-11-12 03:32:58,628 - INFO - Epoch: 67, Training Loss: 0.5963
2025-11-12 03:33:07,646 - INFO - Epoch: 68, Training Loss: 0.5950
2025-11-12 03:33:15,240 - INFO - Epoch: 69, Training Loss: 0.5962
2025-11-12 03:33:23,037 - INFO - Epoch: 70, Training Loss: 0.5960
2025-11-12 03:33:30,766 - INFO - Epoch: 71, Training Loss: 0.5959
2025-11-12 03:33:38,155 - INFO - Epoch: 72, Training Loss: 0.5956
2025-11-12 03:33:46,402 - INFO - Epoch: 73, Training Loss: 0.5966
2025-11-12 03:33:54,853 - INFO - Epoch: 74, Training Loss: 0.5964
2025-11-12 03:34:03,857 - INFO - Epoch: 75, Training Loss: 0.5955
2025-11-12 03:34:11,750 - INFO - Epoch: 76, Training Loss: 0.5975
2025-11-12 03:34:19,449 - INFO - Epoch: 77, Training Loss: 0.5960
2025-11-12 03:34:26,591 - INFO - Epoch: 78, Training Loss: 0.5961
2025-11-12 03:34:34,097 - INFO - Epoch: 79, Training Loss: 0.5958
2025-11-12 03:34:42,093 - INFO - Epoch: 80, Training Loss: 0.5958
2025-11-12 03:34:49,771 - INFO - Epoch: 81, Training Loss: 0.5961
2025-11-12 03:34:57,553 - INFO - Epoch: 82, Training Loss: 0.5963
2025-11-12 03:35:05,021 - INFO - Epoch: 83, Training Loss: 0.5965
2025-11-12 03:35:13,162 - INFO - Epoch: 84, Training Loss: 0.5948
2025-11-12 03:35:21,067 - INFO - Epoch: 85, Training Loss: 0.5962
2025-11-12 03:35:29,051 - INFO - Epoch: 86, Training Loss: 0.5930
2025-11-12 03:35:36,585 - INFO - Epoch: 87, Training Loss: 0.5859
2025-11-12 03:35:44,699 - INFO - Epoch: 88, Training Loss: 0.5803
2025-11-12 03:35:53,025 - INFO - Epoch: 89, Training Loss: 0.5717
2025-11-12 03:36:00,261 - INFO - Epoch: 90, Training Loss: 0.5714
2025-11-12 03:36:07,964 - INFO - Epoch: 91, Training Loss: 0.5712
2025-11-12 03:36:15,966 - INFO - Epoch: 92, Training Loss: 0.5676
2025-11-12 03:36:24,400 - INFO - Epoch: 93, Training Loss: 0.5658
2025-11-12 03:36:32,854 - INFO - Epoch: 94, Training Loss: 0.5678
2025-11-12 03:36:40,742 - INFO - Epoch: 95, Training Loss: 0.5661
2025-11-12 03:36:48,350 - INFO - Epoch: 96, Training Loss: 0.5705
2025-11-12 03:36:56,615 - INFO - Epoch: 97, Training Loss: 0.5706
2025-11-12 03:37:05,089 - INFO - Epoch: 98, Training Loss: 0.5675
2025-11-12 03:37:13,558 - INFO - Epoch: 99, Training Loss: 0.5685
2025-11-12 03:37:21,342 - INFO - Epoch: 100, Training Loss: 0.5637
2025-11-12 03:37:21,342 - INFO - Training completed for Trial 2 CV 4

