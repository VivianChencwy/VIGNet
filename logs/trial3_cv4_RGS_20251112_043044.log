2025-11-12 04:30:44,931 - INFO - Log file: ./logs/trial3_cv4_RGS_20251112_043044.log
2025-11-12 04:30:44,931 - INFO - START TRAINING TRIAL 3 CV 4 - Task: RGS
2025-11-12 04:30:44,931 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 04:30:44,931 - INFO - Loading dataset...
2025-11-12 04:30:45,021 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 04:30:45,021 - INFO - Initializing VIGNet model...
2025-11-12 04:30:45,024 - INFO - Number of batch iterations per epoch: 113
2025-11-12 04:30:53,080 - INFO - Epoch: 1, Training Loss: 1.0185
2025-11-12 04:31:00,376 - INFO - Epoch: 2, Training Loss: 0.7238
2025-11-12 04:31:07,463 - INFO - Epoch: 3, Training Loss: 0.7112
2025-11-12 04:31:15,508 - INFO - Epoch: 4, Training Loss: 0.6999
2025-11-12 04:31:22,945 - INFO - Epoch: 5, Training Loss: 0.7026
2025-11-12 04:31:30,599 - INFO - Epoch: 6, Training Loss: 0.6956
2025-11-12 04:31:38,865 - INFO - Epoch: 7, Training Loss: 0.6973
2025-11-12 04:31:46,495 - INFO - Epoch: 8, Training Loss: 0.6958
2025-11-12 04:31:54,367 - INFO - Epoch: 9, Training Loss: 0.6948
2025-11-12 04:32:02,472 - INFO - Epoch: 10, Training Loss: 0.6953
2025-11-12 04:32:10,346 - INFO - Epoch: 11, Training Loss: 0.6953
2025-11-12 04:32:17,426 - INFO - Epoch: 12, Training Loss: 0.6945
2025-11-12 04:32:26,406 - INFO - Epoch: 13, Training Loss: 0.6944
2025-11-12 04:32:34,403 - INFO - Epoch: 14, Training Loss: 0.6952
2025-11-12 04:32:42,976 - INFO - Epoch: 15, Training Loss: 0.6945
2025-11-12 04:32:50,958 - INFO - Epoch: 16, Training Loss: 0.6950
2025-11-12 04:32:58,693 - INFO - Epoch: 17, Training Loss: 0.6946
2025-11-12 04:33:06,825 - INFO - Epoch: 18, Training Loss: 0.6931
2025-11-12 04:33:15,406 - INFO - Epoch: 19, Training Loss: 0.6942
2025-11-12 04:33:23,529 - INFO - Epoch: 20, Training Loss: 0.6942
2025-11-12 04:33:31,959 - INFO - Epoch: 21, Training Loss: 0.6937
2025-11-12 04:33:39,843 - INFO - Epoch: 22, Training Loss: 0.6948
2025-11-12 04:33:48,087 - INFO - Epoch: 23, Training Loss: 0.6947
2025-11-12 04:33:56,909 - INFO - Epoch: 24, Training Loss: 0.6938
2025-11-12 04:34:04,941 - INFO - Epoch: 25, Training Loss: 0.6933
2025-11-12 04:34:12,527 - INFO - Epoch: 26, Training Loss: 0.6938
2025-11-12 04:34:20,793 - INFO - Epoch: 27, Training Loss: 0.6946
2025-11-12 04:34:28,554 - INFO - Epoch: 28, Training Loss: 0.6928
2025-11-12 04:34:36,099 - INFO - Epoch: 29, Training Loss: 0.6937
2025-11-12 04:34:43,827 - INFO - Epoch: 30, Training Loss: 0.6931
2025-11-12 04:34:52,147 - INFO - Epoch: 31, Training Loss: 0.6919
2025-11-12 04:35:00,404 - INFO - Epoch: 32, Training Loss: 0.6925
2025-11-12 04:35:08,601 - INFO - Epoch: 33, Training Loss: 0.6921
2025-11-12 04:35:17,685 - INFO - Epoch: 34, Training Loss: 0.6923
2025-11-12 04:35:24,942 - INFO - Epoch: 35, Training Loss: 0.6918
2025-11-12 04:35:32,703 - INFO - Epoch: 36, Training Loss: 0.6913
2025-11-12 04:35:40,657 - INFO - Epoch: 37, Training Loss: 0.6898
2025-11-12 04:35:49,190 - INFO - Epoch: 38, Training Loss: 0.6903
2025-11-12 04:35:57,460 - INFO - Epoch: 39, Training Loss: 0.6908
2025-11-12 04:36:06,163 - INFO - Epoch: 40, Training Loss: 0.6879
2025-11-12 04:36:15,248 - INFO - Epoch: 41, Training Loss: 0.6873
2025-11-12 04:36:23,813 - INFO - Epoch: 42, Training Loss: 0.6874
2025-11-12 04:36:31,146 - INFO - Epoch: 43, Training Loss: 0.6830
2025-11-12 04:36:39,052 - INFO - Epoch: 44, Training Loss: 0.6873
2025-11-12 04:36:47,155 - INFO - Epoch: 45, Training Loss: 0.6836
2025-11-12 04:36:55,108 - INFO - Epoch: 46, Training Loss: 0.6843
2025-11-12 04:37:03,900 - INFO - Epoch: 47, Training Loss: 0.6792
2025-11-12 04:37:12,331 - INFO - Epoch: 48, Training Loss: 0.6788
2025-11-12 04:37:20,028 - INFO - Epoch: 49, Training Loss: 0.6775
2025-11-12 04:37:28,723 - INFO - Epoch: 50, Training Loss: 0.6763
2025-11-12 04:37:36,383 - INFO - Epoch: 51, Training Loss: 0.6718
2025-11-12 04:37:43,758 - INFO - Epoch: 52, Training Loss: 0.6674
2025-11-12 04:37:52,112 - INFO - Epoch: 53, Training Loss: 0.6733
2025-11-12 04:37:59,652 - INFO - Epoch: 54, Training Loss: 0.6659
2025-11-12 04:38:07,567 - INFO - Epoch: 55, Training Loss: 0.6652
2025-11-12 04:38:16,134 - INFO - Epoch: 56, Training Loss: 0.6639
2025-11-12 04:38:23,867 - INFO - Epoch: 57, Training Loss: 0.6729
2025-11-12 04:38:32,232 - INFO - Epoch: 58, Training Loss: 0.6803
2025-11-12 04:38:40,885 - INFO - Epoch: 59, Training Loss: 0.6758
2025-11-12 04:38:48,478 - INFO - Epoch: 60, Training Loss: 0.6677
2025-11-12 04:38:56,039 - INFO - Epoch: 61, Training Loss: 0.6604
2025-11-12 04:39:04,153 - INFO - Epoch: 62, Training Loss: 0.6604
2025-11-12 04:39:12,241 - INFO - Epoch: 63, Training Loss: 0.6590
2025-11-12 04:39:20,611 - INFO - Epoch: 64, Training Loss: 0.6590
2025-11-12 04:39:28,442 - INFO - Epoch: 65, Training Loss: 0.6604
2025-11-12 04:39:36,203 - INFO - Epoch: 66, Training Loss: 0.6582
2025-11-12 04:39:43,878 - INFO - Epoch: 67, Training Loss: 0.6718
2025-11-12 04:39:52,960 - INFO - Epoch: 68, Training Loss: 0.6746
2025-11-12 04:40:01,463 - INFO - Epoch: 69, Training Loss: 0.6675
2025-11-12 04:40:09,231 - INFO - Epoch: 70, Training Loss: 0.6637
2025-11-12 04:40:17,556 - INFO - Epoch: 71, Training Loss: 0.6591
2025-11-12 04:40:26,398 - INFO - Epoch: 72, Training Loss: 0.6642
2025-11-12 04:40:33,753 - INFO - Epoch: 73, Training Loss: 0.6756
2025-11-12 04:40:42,952 - INFO - Epoch: 74, Training Loss: 0.6735
2025-11-12 04:40:51,428 - INFO - Epoch: 75, Training Loss: 0.6636
2025-11-12 04:40:59,876 - INFO - Epoch: 76, Training Loss: 0.6583
2025-11-12 04:41:07,541 - INFO - Epoch: 77, Training Loss: 0.6594
2025-11-12 04:41:15,796 - INFO - Epoch: 78, Training Loss: 0.6571
2025-11-12 04:41:23,876 - INFO - Epoch: 79, Training Loss: 0.6575
2025-11-12 04:41:31,444 - INFO - Epoch: 80, Training Loss: 0.6566
2025-11-12 04:41:38,815 - INFO - Epoch: 81, Training Loss: 0.6561
2025-11-12 04:41:46,488 - INFO - Epoch: 82, Training Loss: 0.6751
2025-11-12 04:41:54,253 - INFO - Epoch: 83, Training Loss: 0.6695
2025-11-12 04:42:01,953 - INFO - Epoch: 84, Training Loss: 0.6634
2025-11-12 04:42:09,694 - INFO - Epoch: 85, Training Loss: 0.6633
2025-11-12 04:42:18,010 - INFO - Epoch: 86, Training Loss: 0.6582
2025-11-12 04:42:26,602 - INFO - Epoch: 87, Training Loss: 0.6583
2025-11-12 04:42:34,297 - INFO - Epoch: 88, Training Loss: 0.6573
2025-11-12 04:42:41,995 - INFO - Epoch: 89, Training Loss: 0.6649
2025-11-12 04:42:49,808 - INFO - Epoch: 90, Training Loss: 0.6625
2025-11-12 04:42:58,245 - INFO - Epoch: 91, Training Loss: 0.6569
2025-11-12 04:43:06,079 - INFO - Epoch: 92, Training Loss: 0.6549
2025-11-12 04:43:14,533 - INFO - Epoch: 93, Training Loss: 0.6562
2025-11-12 04:43:22,208 - INFO - Epoch: 94, Training Loss: 0.6555
2025-11-12 04:43:29,878 - INFO - Epoch: 95, Training Loss: 0.6553
2025-11-12 04:43:37,981 - INFO - Epoch: 96, Training Loss: 0.6589
2025-11-12 04:43:45,827 - INFO - Epoch: 97, Training Loss: 0.6875
2025-11-12 04:43:53,180 - INFO - Epoch: 98, Training Loss: 0.6891
2025-11-12 04:44:01,107 - INFO - Epoch: 99, Training Loss: 0.6832
2025-11-12 04:44:08,544 - INFO - Epoch: 100, Training Loss: 0.6806
2025-11-12 04:44:08,544 - INFO - Training completed for Trial 3 CV 4

