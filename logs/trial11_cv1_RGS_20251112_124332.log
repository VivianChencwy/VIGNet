2025-11-12 12:43:32,485 - INFO - Log file: ./logs/trial11_cv1_RGS_20251112_124332.log
2025-11-12 12:43:32,485 - INFO - START TRAINING TRIAL 11 CV 1 - Task: RGS
2025-11-12 12:43:32,485 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 12:43:32,485 - INFO - Loading dataset...
2025-11-12 12:43:32,794 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 12:43:32,794 - INFO - Initializing VIGNet model...
2025-11-12 12:43:32,797 - INFO - Number of batch iterations per epoch: 113
2025-11-12 12:43:41,267 - INFO - Epoch: 1, Training Loss: 0.8046
2025-11-12 12:43:49,090 - INFO - Epoch: 2, Training Loss: 0.6778
2025-11-12 12:43:56,785 - INFO - Epoch: 3, Training Loss: 0.6756
2025-11-12 12:44:04,614 - INFO - Epoch: 4, Training Loss: 0.6764
2025-11-12 12:44:12,055 - INFO - Epoch: 5, Training Loss: 0.6762
2025-11-12 12:44:19,274 - INFO - Epoch: 6, Training Loss: 0.6748
2025-11-12 12:44:27,211 - INFO - Epoch: 7, Training Loss: 0.6744
2025-11-12 12:44:34,782 - INFO - Epoch: 8, Training Loss: 0.6752
2025-11-12 12:44:42,426 - INFO - Epoch: 9, Training Loss: 0.6740
2025-11-12 12:44:50,754 - INFO - Epoch: 10, Training Loss: 0.6752
2025-11-12 12:44:58,481 - INFO - Epoch: 11, Training Loss: 0.6749
2025-11-12 12:45:06,168 - INFO - Epoch: 12, Training Loss: 0.6757
2025-11-12 12:45:14,110 - INFO - Epoch: 13, Training Loss: 0.6742
2025-11-12 12:45:22,585 - INFO - Epoch: 14, Training Loss: 0.6741
2025-11-12 12:45:30,065 - INFO - Epoch: 15, Training Loss: 0.6742
2025-11-12 12:45:38,001 - INFO - Epoch: 16, Training Loss: 0.6740
2025-11-12 12:45:45,402 - INFO - Epoch: 17, Training Loss: 0.6743
2025-11-12 12:45:53,208 - INFO - Epoch: 18, Training Loss: 0.6753
2025-11-12 12:46:00,886 - INFO - Epoch: 19, Training Loss: 0.6746
2025-11-12 12:46:08,124 - INFO - Epoch: 20, Training Loss: 0.6753
2025-11-12 12:46:16,550 - INFO - Epoch: 21, Training Loss: 0.6750
2025-11-12 12:46:24,068 - INFO - Epoch: 22, Training Loss: 0.6741
2025-11-12 12:46:31,263 - INFO - Epoch: 23, Training Loss: 0.6752
2025-11-12 12:46:38,974 - INFO - Epoch: 24, Training Loss: 0.6750
2025-11-12 12:46:47,074 - INFO - Epoch: 25, Training Loss: 0.6747
2025-11-12 12:46:55,062 - INFO - Epoch: 26, Training Loss: 0.6748
2025-11-12 12:47:03,619 - INFO - Epoch: 27, Training Loss: 0.6746
2025-11-12 12:47:11,743 - INFO - Epoch: 28, Training Loss: 0.6745
2025-11-12 12:47:20,179 - INFO - Epoch: 29, Training Loss: 0.6746
2025-11-12 12:47:27,729 - INFO - Epoch: 30, Training Loss: 0.6743
2025-11-12 12:47:35,422 - INFO - Epoch: 31, Training Loss: 0.6746
2025-11-12 12:47:43,637 - INFO - Epoch: 32, Training Loss: 0.6747
2025-11-12 12:47:51,664 - INFO - Epoch: 33, Training Loss: 0.6750
2025-11-12 12:47:59,526 - INFO - Epoch: 34, Training Loss: 0.6752
2025-11-12 12:48:07,312 - INFO - Epoch: 35, Training Loss: 0.6741
2025-11-12 12:48:15,874 - INFO - Epoch: 36, Training Loss: 0.6742
2025-11-12 12:48:24,152 - INFO - Epoch: 37, Training Loss: 0.6748
2025-11-12 12:48:32,641 - INFO - Epoch: 38, Training Loss: 0.6745
2025-11-12 12:48:40,338 - INFO - Epoch: 39, Training Loss: 0.6752
2025-11-12 12:48:48,175 - INFO - Epoch: 40, Training Loss: 0.6750
2025-11-12 12:48:56,167 - INFO - Epoch: 41, Training Loss: 0.6748
2025-11-12 12:49:04,015 - INFO - Epoch: 42, Training Loss: 0.6745
2025-11-12 12:49:11,921 - INFO - Epoch: 43, Training Loss: 0.6743
2025-11-12 12:49:19,330 - INFO - Epoch: 44, Training Loss: 0.6743
2025-11-12 12:49:26,736 - INFO - Epoch: 45, Training Loss: 0.6747
2025-11-12 12:49:34,375 - INFO - Epoch: 46, Training Loss: 0.6740
2025-11-12 12:49:42,473 - INFO - Epoch: 47, Training Loss: 0.6756
2025-11-12 12:49:50,886 - INFO - Epoch: 48, Training Loss: 0.6747
2025-11-12 12:49:59,078 - INFO - Epoch: 49, Training Loss: 0.6744
2025-11-12 12:50:07,615 - INFO - Epoch: 50, Training Loss: 0.6757
2025-11-12 12:50:16,244 - INFO - Epoch: 51, Training Loss: 0.6747
2025-11-12 12:50:24,481 - INFO - Epoch: 52, Training Loss: 0.6732
2025-11-12 12:50:32,046 - INFO - Epoch: 53, Training Loss: 0.6743
2025-11-12 12:50:40,753 - INFO - Epoch: 54, Training Loss: 0.6738
2025-11-12 12:50:49,084 - INFO - Epoch: 55, Training Loss: 0.6738
2025-11-12 12:50:57,068 - INFO - Epoch: 56, Training Loss: 0.6734
2025-11-12 12:51:05,381 - INFO - Epoch: 57, Training Loss: 0.6708
2025-11-12 12:51:12,734 - INFO - Epoch: 58, Training Loss: 0.6688
2025-11-12 12:51:21,684 - INFO - Epoch: 59, Training Loss: 0.6644
2025-11-12 12:51:30,034 - INFO - Epoch: 60, Training Loss: 0.6641
2025-11-12 12:51:37,542 - INFO - Epoch: 61, Training Loss: 0.6621
2025-11-12 12:51:44,670 - INFO - Epoch: 62, Training Loss: 0.6607
2025-11-12 12:51:53,539 - INFO - Epoch: 63, Training Loss: 0.6609
2025-11-12 12:52:01,521 - INFO - Epoch: 64, Training Loss: 0.6599
2025-11-12 12:52:09,001 - INFO - Epoch: 65, Training Loss: 0.6600
2025-11-12 12:52:16,906 - INFO - Epoch: 66, Training Loss: 0.6569
2025-11-12 12:52:24,775 - INFO - Epoch: 67, Training Loss: 0.6582
2025-11-12 12:52:32,498 - INFO - Epoch: 68, Training Loss: 0.6570
2025-11-12 12:52:40,447 - INFO - Epoch: 69, Training Loss: 0.6570
2025-11-12 12:52:48,021 - INFO - Epoch: 70, Training Loss: 0.6547
2025-11-12 12:52:56,511 - INFO - Epoch: 71, Training Loss: 0.6554
2025-11-12 12:53:04,316 - INFO - Epoch: 72, Training Loss: 0.6552
2025-11-12 12:53:11,669 - INFO - Epoch: 73, Training Loss: 0.6538
2025-11-12 12:53:19,017 - INFO - Epoch: 74, Training Loss: 0.6535
2025-11-12 12:53:27,020 - INFO - Epoch: 75, Training Loss: 0.6533
2025-11-12 12:53:35,022 - INFO - Epoch: 76, Training Loss: 0.6522
2025-11-12 12:53:42,802 - INFO - Epoch: 77, Training Loss: 0.6518
2025-11-12 12:53:50,879 - INFO - Epoch: 78, Training Loss: 0.6531
2025-11-12 12:53:58,538 - INFO - Epoch: 79, Training Loss: 0.6520
2025-11-12 12:54:06,284 - INFO - Epoch: 80, Training Loss: 0.6518
2025-11-12 12:54:13,714 - INFO - Epoch: 81, Training Loss: 0.6521
2025-11-12 12:54:21,319 - INFO - Epoch: 82, Training Loss: 0.6513
2025-11-12 12:54:29,244 - INFO - Epoch: 83, Training Loss: 0.6518
2025-11-12 12:54:36,660 - INFO - Epoch: 84, Training Loss: 0.6522
2025-11-12 12:54:44,984 - INFO - Epoch: 85, Training Loss: 0.6510
2025-11-12 12:54:53,253 - INFO - Epoch: 86, Training Loss: 0.6520
2025-11-12 12:55:00,716 - INFO - Epoch: 87, Training Loss: 0.6505
2025-11-12 12:55:08,640 - INFO - Epoch: 88, Training Loss: 0.6498
2025-11-12 12:55:15,902 - INFO - Epoch: 89, Training Loss: 0.6485
2025-11-12 12:55:23,905 - INFO - Epoch: 90, Training Loss: 0.6498
2025-11-12 12:55:31,678 - INFO - Epoch: 91, Training Loss: 0.6490
2025-11-12 12:55:40,258 - INFO - Epoch: 92, Training Loss: 0.6500
2025-11-12 12:55:48,186 - INFO - Epoch: 93, Training Loss: 0.6489
2025-11-12 12:55:56,272 - INFO - Epoch: 94, Training Loss: 0.6483
2025-11-12 12:56:04,403 - INFO - Epoch: 95, Training Loss: 0.6484
2025-11-12 12:56:11,811 - INFO - Epoch: 96, Training Loss: 0.6508
2025-11-12 12:56:19,974 - INFO - Epoch: 97, Training Loss: 0.6481
2025-11-12 12:56:27,606 - INFO - Epoch: 98, Training Loss: 0.6478
2025-11-12 12:56:35,392 - INFO - Epoch: 99, Training Loss: 0.6470
2025-11-12 12:56:43,293 - INFO - Epoch: 100, Training Loss: 0.6480
2025-11-12 12:56:43,294 - INFO - Training completed for Trial 11 CV 1

