2025-11-12 12:03:38,542 - INFO - Log file: ./logs/trial10_cv3_RGS_20251112_120338.log
2025-11-12 12:03:38,542 - INFO - START TRAINING TRIAL 10 CV 3 - Task: RGS
2025-11-12 12:03:38,542 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 12:03:38,542 - INFO - Loading dataset...
2025-11-12 12:03:38,632 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 12:03:38,632 - INFO - Initializing VIGNet model...
2025-11-12 12:03:38,635 - INFO - Number of batch iterations per epoch: 113
2025-11-12 12:03:46,725 - INFO - Epoch: 1, Training Loss: 1.1694
2025-11-12 12:03:54,582 - INFO - Epoch: 2, Training Loss: 0.7003
2025-11-12 12:04:03,554 - INFO - Epoch: 3, Training Loss: 0.6864
2025-11-12 12:04:11,810 - INFO - Epoch: 4, Training Loss: 0.6868
2025-11-12 12:04:19,447 - INFO - Epoch: 5, Training Loss: 0.6849
2025-11-12 12:04:27,609 - INFO - Epoch: 6, Training Loss: 0.6855
2025-11-12 12:04:35,391 - INFO - Epoch: 7, Training Loss: 0.6825
2025-11-12 12:04:42,505 - INFO - Epoch: 8, Training Loss: 0.6821
2025-11-12 12:04:50,736 - INFO - Epoch: 9, Training Loss: 0.6842
2025-11-12 12:04:59,527 - INFO - Epoch: 10, Training Loss: 0.6830
2025-11-12 12:05:07,303 - INFO - Epoch: 11, Training Loss: 0.6830
2025-11-12 12:05:15,924 - INFO - Epoch: 12, Training Loss: 0.6835
2025-11-12 12:05:23,667 - INFO - Epoch: 13, Training Loss: 0.6822
2025-11-12 12:05:31,670 - INFO - Epoch: 14, Training Loss: 0.6828
2025-11-12 12:05:40,238 - INFO - Epoch: 15, Training Loss: 0.6828
2025-11-12 12:05:47,312 - INFO - Epoch: 16, Training Loss: 0.6827
2025-11-12 12:05:54,851 - INFO - Epoch: 17, Training Loss: 0.6820
2025-11-12 12:06:03,800 - INFO - Epoch: 18, Training Loss: 0.6832
2025-11-12 12:06:12,107 - INFO - Epoch: 19, Training Loss: 0.6824
2025-11-12 12:06:19,862 - INFO - Epoch: 20, Training Loss: 0.6830
2025-11-12 12:06:28,122 - INFO - Epoch: 21, Training Loss: 0.6829
2025-11-12 12:06:36,470 - INFO - Epoch: 22, Training Loss: 0.6826
2025-11-12 12:06:43,766 - INFO - Epoch: 23, Training Loss: 0.6819
2025-11-12 12:06:51,966 - INFO - Epoch: 24, Training Loss: 0.6822
2025-11-12 12:06:59,936 - INFO - Epoch: 25, Training Loss: 0.6822
2025-11-12 12:07:07,575 - INFO - Epoch: 26, Training Loss: 0.6822
2025-11-12 12:07:15,170 - INFO - Epoch: 27, Training Loss: 0.6828
2025-11-12 12:07:23,494 - INFO - Epoch: 28, Training Loss: 0.6825
2025-11-12 12:07:31,434 - INFO - Epoch: 29, Training Loss: 0.6825
2025-11-12 12:07:39,102 - INFO - Epoch: 30, Training Loss: 0.6821
2025-11-12 12:07:47,332 - INFO - Epoch: 31, Training Loss: 0.6831
2025-11-12 12:07:54,513 - INFO - Epoch: 32, Training Loss: 0.6824
2025-11-12 12:08:02,850 - INFO - Epoch: 33, Training Loss: 0.6827
2025-11-12 12:08:10,809 - INFO - Epoch: 34, Training Loss: 0.6825
2025-11-12 12:08:19,182 - INFO - Epoch: 35, Training Loss: 0.6823
2025-11-12 12:08:27,609 - INFO - Epoch: 36, Training Loss: 0.6828
2025-11-12 12:08:35,236 - INFO - Epoch: 37, Training Loss: 0.6832
2025-11-12 12:08:43,211 - INFO - Epoch: 38, Training Loss: 0.6827
2025-11-12 12:08:50,590 - INFO - Epoch: 39, Training Loss: 0.6826
2025-11-12 12:08:58,304 - INFO - Epoch: 40, Training Loss: 0.6826
2025-11-12 12:09:06,212 - INFO - Epoch: 41, Training Loss: 0.6838
2025-11-12 12:09:14,243 - INFO - Epoch: 42, Training Loss: 0.6827
2025-11-12 12:09:22,829 - INFO - Epoch: 43, Training Loss: 0.6829
2025-11-12 12:09:30,431 - INFO - Epoch: 44, Training Loss: 0.6833
2025-11-12 12:09:38,581 - INFO - Epoch: 45, Training Loss: 0.6825
2025-11-12 12:09:46,790 - INFO - Epoch: 46, Training Loss: 0.6833
2025-11-12 12:09:54,907 - INFO - Epoch: 47, Training Loss: 0.6820
2025-11-12 12:10:03,126 - INFO - Epoch: 48, Training Loss: 0.6835
2025-11-12 12:10:11,755 - INFO - Epoch: 49, Training Loss: 0.6829
2025-11-12 12:10:19,703 - INFO - Epoch: 50, Training Loss: 0.6818
2025-11-12 12:10:28,613 - INFO - Epoch: 51, Training Loss: 0.6826
2025-11-12 12:10:37,213 - INFO - Epoch: 52, Training Loss: 0.6828
2025-11-12 12:10:44,829 - INFO - Epoch: 53, Training Loss: 0.6825
2025-11-12 12:10:52,378 - INFO - Epoch: 54, Training Loss: 0.6822
2025-11-12 12:11:01,380 - INFO - Epoch: 55, Training Loss: 0.6828
2025-11-12 12:11:09,152 - INFO - Epoch: 56, Training Loss: 0.6829
2025-11-12 12:11:16,331 - INFO - Epoch: 57, Training Loss: 0.6829
2025-11-12 12:11:24,663 - INFO - Epoch: 58, Training Loss: 0.6830
2025-11-12 12:11:32,713 - INFO - Epoch: 59, Training Loss: 0.6827
2025-11-12 12:11:40,826 - INFO - Epoch: 60, Training Loss: 0.6828
2025-11-12 12:11:49,042 - INFO - Epoch: 61, Training Loss: 0.6832
2025-11-12 12:11:56,627 - INFO - Epoch: 62, Training Loss: 0.6824
2025-11-12 12:12:04,323 - INFO - Epoch: 63, Training Loss: 0.6821
2025-11-12 12:12:12,051 - INFO - Epoch: 64, Training Loss: 0.6828
2025-11-12 12:12:20,165 - INFO - Epoch: 65, Training Loss: 0.6820
2025-11-12 12:12:28,284 - INFO - Epoch: 66, Training Loss: 0.6823
2025-11-12 12:12:35,933 - INFO - Epoch: 67, Training Loss: 0.6817
2025-11-12 12:12:43,926 - INFO - Epoch: 68, Training Loss: 0.6824
2025-11-12 12:12:51,729 - INFO - Epoch: 69, Training Loss: 0.6825
2025-11-12 12:12:58,795 - INFO - Epoch: 70, Training Loss: 0.6836
2025-11-12 12:13:07,660 - INFO - Epoch: 71, Training Loss: 0.6817
2025-11-12 12:13:15,791 - INFO - Epoch: 72, Training Loss: 0.6818
2025-11-12 12:13:24,347 - INFO - Epoch: 73, Training Loss: 0.6821
2025-11-12 12:13:32,635 - INFO - Epoch: 74, Training Loss: 0.6823
2025-11-12 12:13:41,171 - INFO - Epoch: 75, Training Loss: 0.6815
2025-11-12 12:13:49,318 - INFO - Epoch: 76, Training Loss: 0.6829
2025-11-12 12:13:57,041 - INFO - Epoch: 77, Training Loss: 0.6813
2025-11-12 12:14:05,105 - INFO - Epoch: 78, Training Loss: 0.6770
2025-11-12 12:14:13,148 - INFO - Epoch: 79, Training Loss: 0.6726
2025-11-12 12:14:20,786 - INFO - Epoch: 80, Training Loss: 0.6723
2025-11-12 12:14:29,013 - INFO - Epoch: 81, Training Loss: 0.6691
2025-11-12 12:14:36,814 - INFO - Epoch: 82, Training Loss: 0.6688
2025-11-12 12:14:44,993 - INFO - Epoch: 83, Training Loss: 0.6673
2025-11-12 12:14:53,256 - INFO - Epoch: 84, Training Loss: 0.6668
2025-11-12 12:15:01,033 - INFO - Epoch: 85, Training Loss: 0.6650
2025-11-12 12:15:08,441 - INFO - Epoch: 86, Training Loss: 0.6655
2025-11-12 12:15:15,915 - INFO - Epoch: 87, Training Loss: 0.6652
2025-11-12 12:15:24,289 - INFO - Epoch: 88, Training Loss: 0.6651
2025-11-12 12:15:32,777 - INFO - Epoch: 89, Training Loss: 0.6644
2025-11-12 12:15:40,996 - INFO - Epoch: 90, Training Loss: 0.6640
2025-11-12 12:15:49,339 - INFO - Epoch: 91, Training Loss: 0.6628
2025-11-12 12:15:57,195 - INFO - Epoch: 92, Training Loss: 0.6635
2025-11-12 12:16:04,754 - INFO - Epoch: 93, Training Loss: 0.6636
2025-11-12 12:16:12,359 - INFO - Epoch: 94, Training Loss: 0.6621
2025-11-12 12:16:20,361 - INFO - Epoch: 95, Training Loss: 0.6603
2025-11-12 12:16:28,254 - INFO - Epoch: 96, Training Loss: 0.6606
2025-11-12 12:16:35,768 - INFO - Epoch: 97, Training Loss: 0.6609
2025-11-12 12:16:43,356 - INFO - Epoch: 98, Training Loss: 0.6577
2025-11-12 12:16:51,576 - INFO - Epoch: 99, Training Loss: 0.6584
2025-11-12 12:16:59,315 - INFO - Epoch: 100, Training Loss: 0.6587
2025-11-12 12:16:59,315 - INFO - Training completed for Trial 10 CV 3

