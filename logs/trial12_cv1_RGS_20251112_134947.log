2025-11-12 13:49:47,051 - INFO - Log file: ./logs/trial12_cv1_RGS_20251112_134947.log
2025-11-12 13:49:47,051 - INFO - START TRAINING TRIAL 12 CV 1 - Task: RGS
2025-11-12 13:49:47,051 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 13:49:47,051 - INFO - Loading dataset...
2025-11-12 13:49:47,150 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 13:49:47,150 - INFO - Initializing VIGNet model...
2025-11-12 13:49:47,153 - INFO - Number of batch iterations per epoch: 113
2025-11-12 13:49:55,904 - INFO - Epoch: 1, Training Loss: 0.9241
2025-11-12 13:50:04,097 - INFO - Epoch: 2, Training Loss: 0.6932
2025-11-12 13:50:12,229 - INFO - Epoch: 3, Training Loss: 0.6747
2025-11-12 13:50:20,325 - INFO - Epoch: 4, Training Loss: 0.6729
2025-11-12 13:50:28,246 - INFO - Epoch: 5, Training Loss: 0.6700
2025-11-12 13:50:36,005 - INFO - Epoch: 6, Training Loss: 0.6712
2025-11-12 13:50:44,148 - INFO - Epoch: 7, Training Loss: 0.6736
2025-11-12 13:50:52,273 - INFO - Epoch: 8, Training Loss: 0.6700
2025-11-12 13:51:00,400 - INFO - Epoch: 9, Training Loss: 0.6637
2025-11-12 13:51:09,039 - INFO - Epoch: 10, Training Loss: 0.6642
2025-11-12 13:51:16,381 - INFO - Epoch: 11, Training Loss: 0.6724
2025-11-12 13:51:24,074 - INFO - Epoch: 12, Training Loss: 0.6651
2025-11-12 13:51:31,021 - INFO - Epoch: 13, Training Loss: 0.6619
2025-11-12 13:51:38,810 - INFO - Epoch: 14, Training Loss: 0.6639
2025-11-12 13:51:47,166 - INFO - Epoch: 15, Training Loss: 0.6615
2025-11-12 13:51:55,482 - INFO - Epoch: 16, Training Loss: 0.6569
2025-11-12 13:52:04,249 - INFO - Epoch: 17, Training Loss: 0.6480
2025-11-12 13:52:13,436 - INFO - Epoch: 18, Training Loss: 0.6442
2025-11-12 13:52:21,170 - INFO - Epoch: 19, Training Loss: 0.6480
2025-11-12 13:52:29,043 - INFO - Epoch: 20, Training Loss: 0.6384
2025-11-12 13:52:37,297 - INFO - Epoch: 21, Training Loss: 0.6153
2025-11-12 13:52:45,646 - INFO - Epoch: 22, Training Loss: 0.5915
2025-11-12 13:52:53,711 - INFO - Epoch: 23, Training Loss: 0.5830
2025-11-12 13:53:01,006 - INFO - Epoch: 24, Training Loss: 0.6036
2025-11-12 13:53:08,549 - INFO - Epoch: 25, Training Loss: 0.5744
2025-11-12 13:53:15,906 - INFO - Epoch: 26, Training Loss: 0.6590
2025-11-12 13:53:23,873 - INFO - Epoch: 27, Training Loss: 0.5435
2025-11-12 13:53:31,200 - INFO - Epoch: 28, Training Loss: 0.6259
2025-11-12 13:53:40,194 - INFO - Epoch: 29, Training Loss: 0.5757
2025-11-12 13:53:48,798 - INFO - Epoch: 30, Training Loss: 0.5437
2025-11-12 13:53:56,577 - INFO - Epoch: 31, Training Loss: 0.5913
2025-11-12 13:54:05,173 - INFO - Epoch: 32, Training Loss: 0.5528
2025-11-12 13:54:13,011 - INFO - Epoch: 33, Training Loss: 0.5835
2025-11-12 13:54:21,149 - INFO - Epoch: 34, Training Loss: 0.5003
2025-11-12 13:54:29,447 - INFO - Epoch: 35, Training Loss: 0.7181
2025-11-12 13:54:36,884 - INFO - Epoch: 36, Training Loss: 0.5346
2025-11-12 13:54:44,460 - INFO - Epoch: 37, Training Loss: 0.4909
2025-11-12 13:54:52,621 - INFO - Epoch: 38, Training Loss: 1.2992
2025-11-12 13:55:00,016 - INFO - Epoch: 39, Training Loss: 0.6144
2025-11-12 13:55:07,872 - INFO - Epoch: 40, Training Loss: 0.5920
2025-11-12 13:55:16,357 - INFO - Epoch: 41, Training Loss: 0.5457
2025-11-12 13:55:23,915 - INFO - Epoch: 42, Training Loss: 0.4876
2025-11-12 13:55:31,967 - INFO - Epoch: 43, Training Loss: 0.5186
2025-11-12 13:55:40,125 - INFO - Epoch: 44, Training Loss: 0.5024
2025-11-12 13:55:47,531 - INFO - Epoch: 45, Training Loss: 0.4676
2025-11-12 13:55:55,185 - INFO - Epoch: 46, Training Loss: 0.7613
2025-11-12 13:56:02,605 - INFO - Epoch: 47, Training Loss: 0.5160
2025-11-12 13:56:10,737 - INFO - Epoch: 48, Training Loss: 0.6877
2025-11-12 13:56:18,473 - INFO - Epoch: 49, Training Loss: 0.6527
2025-11-12 13:56:27,263 - INFO - Epoch: 50, Training Loss: 0.6463
2025-11-12 13:56:34,930 - INFO - Epoch: 51, Training Loss: 0.6479
2025-11-12 13:56:43,196 - INFO - Epoch: 52, Training Loss: 0.6421
2025-11-12 13:56:50,839 - INFO - Epoch: 53, Training Loss: 0.6392
2025-11-12 13:56:58,590 - INFO - Epoch: 54, Training Loss: 0.6280
2025-11-12 13:57:06,534 - INFO - Epoch: 55, Training Loss: 0.6216
2025-11-12 13:57:14,657 - INFO - Epoch: 56, Training Loss: 0.6057
2025-11-12 13:57:23,145 - INFO - Epoch: 57, Training Loss: 0.5871
2025-11-12 13:57:31,196 - INFO - Epoch: 58, Training Loss: 0.5707
2025-11-12 13:57:39,508 - INFO - Epoch: 59, Training Loss: 0.5481
2025-11-12 13:57:47,350 - INFO - Epoch: 60, Training Loss: 0.4868
2025-11-12 13:57:54,980 - INFO - Epoch: 61, Training Loss: 0.4843
2025-11-12 13:58:02,873 - INFO - Epoch: 62, Training Loss: 0.4884
2025-11-12 13:58:10,446 - INFO - Epoch: 63, Training Loss: 0.4996
2025-11-12 13:58:18,706 - INFO - Epoch: 64, Training Loss: 0.5414
2025-11-12 13:58:26,812 - INFO - Epoch: 65, Training Loss: 1.4518
2025-11-12 13:58:34,175 - INFO - Epoch: 66, Training Loss: 0.7665
2025-11-12 13:58:42,450 - INFO - Epoch: 67, Training Loss: 0.7122
2025-11-12 13:58:50,377 - INFO - Epoch: 68, Training Loss: 0.6596
2025-11-12 13:58:58,645 - INFO - Epoch: 69, Training Loss: 0.6462
2025-11-12 13:59:06,138 - INFO - Epoch: 70, Training Loss: 0.6053
2025-11-12 13:59:13,475 - INFO - Epoch: 71, Training Loss: 0.6025
2025-11-12 13:59:21,372 - INFO - Epoch: 72, Training Loss: 0.5957
2025-11-12 13:59:28,911 - INFO - Epoch: 73, Training Loss: 0.6015
2025-11-12 13:59:36,295 - INFO - Epoch: 74, Training Loss: 0.5838
2025-11-12 13:59:44,585 - INFO - Epoch: 75, Training Loss: 0.5816
2025-11-12 13:59:52,570 - INFO - Epoch: 76, Training Loss: 0.5732
2025-11-12 14:00:01,095 - INFO - Epoch: 77, Training Loss: 0.5754
2025-11-12 14:00:08,706 - INFO - Epoch: 78, Training Loss: 0.5663
2025-11-12 14:00:16,472 - INFO - Epoch: 79, Training Loss: 0.5630
2025-11-12 14:00:24,980 - INFO - Epoch: 80, Training Loss: 0.5606
2025-11-12 14:00:32,839 - INFO - Epoch: 81, Training Loss: 0.5535
2025-11-12 14:00:40,633 - INFO - Epoch: 82, Training Loss: 0.5480
2025-11-12 14:00:48,694 - INFO - Epoch: 83, Training Loss: 0.5397
2025-11-12 14:00:56,557 - INFO - Epoch: 84, Training Loss: 0.5343
2025-11-12 14:01:04,905 - INFO - Epoch: 85, Training Loss: 0.5316
2025-11-12 14:01:12,157 - INFO - Epoch: 86, Training Loss: 0.5232
2025-11-12 14:01:20,228 - INFO - Epoch: 87, Training Loss: 0.5167
2025-11-12 14:01:28,733 - INFO - Epoch: 88, Training Loss: 0.5102
2025-11-12 14:01:36,653 - INFO - Epoch: 89, Training Loss: 0.5014
2025-11-12 14:01:45,870 - INFO - Epoch: 90, Training Loss: 0.4956
2025-11-12 14:01:54,579 - INFO - Epoch: 91, Training Loss: 0.4976
2025-11-12 14:02:02,255 - INFO - Epoch: 92, Training Loss: 0.4807
2025-11-12 14:02:10,543 - INFO - Epoch: 93, Training Loss: 0.5023
2025-11-12 14:02:18,546 - INFO - Epoch: 94, Training Loss: 0.4698
2025-11-12 14:02:26,249 - INFO - Epoch: 95, Training Loss: 0.5033
2025-11-12 14:02:34,111 - INFO - Epoch: 96, Training Loss: 0.4903
2025-11-12 14:02:41,341 - INFO - Epoch: 97, Training Loss: 0.4878
2025-11-12 14:02:49,112 - INFO - Epoch: 98, Training Loss: 0.5034
2025-11-12 14:02:56,880 - INFO - Epoch: 99, Training Loss: 0.5031
2025-11-12 14:03:04,688 - INFO - Epoch: 100, Training Loss: 0.5091
2025-11-12 14:03:04,688 - INFO - Training completed for Trial 12 CV 1

