2025-11-12 12:30:16,541 - INFO - Log file: ./logs/trial11_cv0_RGS_20251112_123016.log
2025-11-12 12:30:16,541 - INFO - START TRAINING TRIAL 11 CV 0 - Task: RGS
2025-11-12 12:30:16,541 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 12:30:16,541 - INFO - Loading dataset...
2025-11-12 12:30:16,727 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 12:30:16,727 - INFO - Initializing VIGNet model...
2025-11-12 12:30:16,730 - INFO - Number of batch iterations per epoch: 113
2025-11-12 12:30:24,723 - INFO - Epoch: 1, Training Loss: 0.8734
2025-11-12 12:30:32,888 - INFO - Epoch: 2, Training Loss: 0.6787
2025-11-12 12:30:41,411 - INFO - Epoch: 3, Training Loss: 0.6760
2025-11-12 12:30:48,929 - INFO - Epoch: 4, Training Loss: 0.6768
2025-11-12 12:30:57,561 - INFO - Epoch: 5, Training Loss: 0.6758
2025-11-12 12:31:05,080 - INFO - Epoch: 6, Training Loss: 0.6761
2025-11-12 12:31:12,887 - INFO - Epoch: 7, Training Loss: 0.6754
2025-11-12 12:31:20,689 - INFO - Epoch: 8, Training Loss: 0.6756
2025-11-12 12:31:28,408 - INFO - Epoch: 9, Training Loss: 0.6757
2025-11-12 12:31:36,920 - INFO - Epoch: 10, Training Loss: 0.6755
2025-11-12 12:31:44,827 - INFO - Epoch: 11, Training Loss: 0.6752
2025-11-12 12:31:53,194 - INFO - Epoch: 12, Training Loss: 0.6753
2025-11-12 12:32:01,206 - INFO - Epoch: 13, Training Loss: 0.6757
2025-11-12 12:32:08,677 - INFO - Epoch: 14, Training Loss: 0.6759
2025-11-12 12:32:16,067 - INFO - Epoch: 15, Training Loss: 0.6762
2025-11-12 12:32:23,880 - INFO - Epoch: 16, Training Loss: 0.6750
2025-11-12 12:32:31,758 - INFO - Epoch: 17, Training Loss: 0.6752
2025-11-12 12:32:39,839 - INFO - Epoch: 18, Training Loss: 0.6764
2025-11-12 12:32:48,192 - INFO - Epoch: 19, Training Loss: 0.6746
2025-11-12 12:32:56,861 - INFO - Epoch: 20, Training Loss: 0.6751
2025-11-12 12:33:05,002 - INFO - Epoch: 21, Training Loss: 0.6754
2025-11-12 12:33:13,090 - INFO - Epoch: 22, Training Loss: 0.6756
2025-11-12 12:33:20,587 - INFO - Epoch: 23, Training Loss: 0.6754
2025-11-12 12:33:29,452 - INFO - Epoch: 24, Training Loss: 0.6762
2025-11-12 12:33:37,219 - INFO - Epoch: 25, Training Loss: 0.6756
2025-11-12 12:33:46,378 - INFO - Epoch: 26, Training Loss: 0.6752
2025-11-12 12:33:54,493 - INFO - Epoch: 27, Training Loss: 0.6753
2025-11-12 12:34:02,285 - INFO - Epoch: 28, Training Loss: 0.6755
2025-11-12 12:34:10,795 - INFO - Epoch: 29, Training Loss: 0.6754
2025-11-12 12:34:18,599 - INFO - Epoch: 30, Training Loss: 0.6761
2025-11-12 12:34:26,286 - INFO - Epoch: 31, Training Loss: 0.6756
2025-11-12 12:34:33,686 - INFO - Epoch: 32, Training Loss: 0.6756
2025-11-12 12:34:41,074 - INFO - Epoch: 33, Training Loss: 0.6756
2025-11-12 12:34:48,371 - INFO - Epoch: 34, Training Loss: 0.6753
2025-11-12 12:34:56,302 - INFO - Epoch: 35, Training Loss: 0.6753
2025-11-12 12:35:03,545 - INFO - Epoch: 36, Training Loss: 0.6758
2025-11-12 12:35:11,286 - INFO - Epoch: 37, Training Loss: 0.6766
2025-11-12 12:35:18,917 - INFO - Epoch: 38, Training Loss: 0.6753
2025-11-12 12:35:26,545 - INFO - Epoch: 39, Training Loss: 0.6750
2025-11-12 12:35:35,613 - INFO - Epoch: 40, Training Loss: 0.6752
2025-11-12 12:35:44,210 - INFO - Epoch: 41, Training Loss: 0.6754
2025-11-12 12:35:52,019 - INFO - Epoch: 42, Training Loss: 0.6751
2025-11-12 12:35:59,462 - INFO - Epoch: 43, Training Loss: 0.6749
2025-11-12 12:36:08,547 - INFO - Epoch: 44, Training Loss: 0.6753
2025-11-12 12:36:16,629 - INFO - Epoch: 45, Training Loss: 0.6754
2025-11-12 12:36:24,623 - INFO - Epoch: 46, Training Loss: 0.6748
2025-11-12 12:36:33,534 - INFO - Epoch: 47, Training Loss: 0.6748
2025-11-12 12:36:41,731 - INFO - Epoch: 48, Training Loss: 0.6747
2025-11-12 12:36:50,430 - INFO - Epoch: 49, Training Loss: 0.6750
2025-11-12 12:36:58,004 - INFO - Epoch: 50, Training Loss: 0.6732
2025-11-12 12:37:05,705 - INFO - Epoch: 51, Training Loss: 0.6707
2025-11-12 12:37:13,228 - INFO - Epoch: 52, Training Loss: 0.6680
2025-11-12 12:37:20,866 - INFO - Epoch: 53, Training Loss: 0.6662
2025-11-12 12:37:28,600 - INFO - Epoch: 54, Training Loss: 0.6655
2025-11-12 12:37:37,694 - INFO - Epoch: 55, Training Loss: 0.6644
2025-11-12 12:37:45,072 - INFO - Epoch: 56, Training Loss: 0.6638
2025-11-12 12:37:52,309 - INFO - Epoch: 57, Training Loss: 0.6633
2025-11-12 12:37:59,731 - INFO - Epoch: 58, Training Loss: 0.6626
2025-11-12 12:38:07,683 - INFO - Epoch: 59, Training Loss: 0.6629
2025-11-12 12:38:15,037 - INFO - Epoch: 60, Training Loss: 0.6624
2025-11-12 12:38:22,517 - INFO - Epoch: 61, Training Loss: 0.6611
2025-11-12 12:38:30,131 - INFO - Epoch: 62, Training Loss: 0.6620
2025-11-12 12:38:39,075 - INFO - Epoch: 63, Training Loss: 0.6610
2025-11-12 12:38:46,900 - INFO - Epoch: 64, Training Loss: 0.6603
2025-11-12 12:38:55,266 - INFO - Epoch: 65, Training Loss: 0.6597
2025-11-12 12:39:04,082 - INFO - Epoch: 66, Training Loss: 0.6596
2025-11-12 12:39:11,911 - INFO - Epoch: 67, Training Loss: 0.6592
2025-11-12 12:39:20,136 - INFO - Epoch: 68, Training Loss: 0.6605
2025-11-12 12:39:28,020 - INFO - Epoch: 69, Training Loss: 0.6594
2025-11-12 12:39:36,907 - INFO - Epoch: 70, Training Loss: 0.6584
2025-11-12 12:39:44,888 - INFO - Epoch: 71, Training Loss: 0.6576
2025-11-12 12:39:52,312 - INFO - Epoch: 72, Training Loss: 0.6567
2025-11-12 12:40:00,261 - INFO - Epoch: 73, Training Loss: 0.6565
2025-11-12 12:40:08,970 - INFO - Epoch: 74, Training Loss: 0.6561
2025-11-12 12:40:16,849 - INFO - Epoch: 75, Training Loss: 0.6543
2025-11-12 12:40:25,180 - INFO - Epoch: 76, Training Loss: 0.6550
2025-11-12 12:40:32,358 - INFO - Epoch: 77, Training Loss: 0.6547
2025-11-12 12:40:39,578 - INFO - Epoch: 78, Training Loss: 0.6550
2025-11-12 12:40:47,996 - INFO - Epoch: 79, Training Loss: 0.6550
2025-11-12 12:40:56,454 - INFO - Epoch: 80, Training Loss: 0.6552
2025-11-12 12:41:04,272 - INFO - Epoch: 81, Training Loss: 0.6542
2025-11-12 12:41:12,021 - INFO - Epoch: 82, Training Loss: 0.6539
2025-11-12 12:41:19,816 - INFO - Epoch: 83, Training Loss: 0.6559
2025-11-12 12:41:28,841 - INFO - Epoch: 84, Training Loss: 0.6553
2025-11-12 12:41:36,139 - INFO - Epoch: 85, Training Loss: 0.6540
2025-11-12 12:41:43,813 - INFO - Epoch: 86, Training Loss: 0.6534
2025-11-12 12:41:51,379 - INFO - Epoch: 87, Training Loss: 0.6523
2025-11-12 12:41:59,537 - INFO - Epoch: 88, Training Loss: 0.6532
2025-11-12 12:42:07,717 - INFO - Epoch: 89, Training Loss: 0.6523
2025-11-12 12:42:15,333 - INFO - Epoch: 90, Training Loss: 0.6517
2025-11-12 12:42:23,864 - INFO - Epoch: 91, Training Loss: 0.6523
2025-11-12 12:42:31,637 - INFO - Epoch: 92, Training Loss: 0.6526
2025-11-12 12:42:38,982 - INFO - Epoch: 93, Training Loss: 0.6526
2025-11-12 12:42:47,633 - INFO - Epoch: 94, Training Loss: 0.6519
2025-11-12 12:42:54,873 - INFO - Epoch: 95, Training Loss: 0.6522
2025-11-12 12:43:02,225 - INFO - Epoch: 96, Training Loss: 0.6513
2025-11-12 12:43:09,760 - INFO - Epoch: 97, Training Loss: 0.6520
2025-11-12 12:43:17,478 - INFO - Epoch: 98, Training Loss: 0.6521
2025-11-12 12:43:25,212 - INFO - Epoch: 99, Training Loss: 0.6501
2025-11-12 12:43:32,482 - INFO - Epoch: 100, Training Loss: 0.6507
2025-11-12 12:43:32,483 - INFO - Training completed for Trial 11 CV 0

