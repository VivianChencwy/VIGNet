2025-11-12 13:36:32,182 - INFO - Log file: ./logs/trial12_cv0_RGS_20251112_133632.log
2025-11-12 13:36:32,182 - INFO - START TRAINING TRIAL 12 CV 0 - Task: RGS
2025-11-12 13:36:32,182 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 13:36:32,182 - INFO - Loading dataset...
2025-11-12 13:36:32,444 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 13:36:32,444 - INFO - Initializing VIGNet model...
2025-11-12 13:36:32,447 - INFO - Number of batch iterations per epoch: 113
2025-11-12 13:36:40,504 - INFO - Epoch: 1, Training Loss: 1.4827
2025-11-12 13:36:48,507 - INFO - Epoch: 2, Training Loss: 0.7318
2025-11-12 13:36:56,446 - INFO - Epoch: 3, Training Loss: 0.6955
2025-11-12 13:37:04,669 - INFO - Epoch: 4, Training Loss: 0.6901
2025-11-12 13:37:13,025 - INFO - Epoch: 5, Training Loss: 0.6778
2025-11-12 13:37:20,664 - INFO - Epoch: 6, Training Loss: 0.6766
2025-11-12 13:37:28,674 - INFO - Epoch: 7, Training Loss: 0.6721
2025-11-12 13:37:36,240 - INFO - Epoch: 8, Training Loss: 0.6743
2025-11-12 13:37:44,202 - INFO - Epoch: 9, Training Loss: 0.6752
2025-11-12 13:37:53,157 - INFO - Epoch: 10, Training Loss: 0.6734
2025-11-12 13:38:01,788 - INFO - Epoch: 11, Training Loss: 0.6688
2025-11-12 13:38:10,070 - INFO - Epoch: 12, Training Loss: 0.6733
2025-11-12 13:38:18,188 - INFO - Epoch: 13, Training Loss: 0.6708
2025-11-12 13:38:26,156 - INFO - Epoch: 14, Training Loss: 0.6684
2025-11-12 13:38:34,200 - INFO - Epoch: 15, Training Loss: 0.6683
2025-11-12 13:38:42,619 - INFO - Epoch: 16, Training Loss: 0.6702
2025-11-12 13:38:50,591 - INFO - Epoch: 17, Training Loss: 0.6710
2025-11-12 13:38:58,140 - INFO - Epoch: 18, Training Loss: 0.6703
2025-11-12 13:39:06,060 - INFO - Epoch: 19, Training Loss: 0.6695
2025-11-12 13:39:13,376 - INFO - Epoch: 20, Training Loss: 0.6684
2025-11-12 13:39:21,251 - INFO - Epoch: 21, Training Loss: 0.6753
2025-11-12 13:39:28,210 - INFO - Epoch: 22, Training Loss: 0.6747
2025-11-12 13:39:36,302 - INFO - Epoch: 23, Training Loss: 0.6659
2025-11-12 13:39:43,891 - INFO - Epoch: 24, Training Loss: 0.6642
2025-11-12 13:39:51,072 - INFO - Epoch: 25, Training Loss: 0.6713
2025-11-12 13:39:58,856 - INFO - Epoch: 26, Training Loss: 0.6691
2025-11-12 13:40:06,777 - INFO - Epoch: 27, Training Loss: 0.6622
2025-11-12 13:40:15,003 - INFO - Epoch: 28, Training Loss: 0.6695
2025-11-12 13:40:23,646 - INFO - Epoch: 29, Training Loss: 0.6572
2025-11-12 13:40:31,957 - INFO - Epoch: 30, Training Loss: 0.6634
2025-11-12 13:40:40,600 - INFO - Epoch: 31, Training Loss: 0.6582
2025-11-12 13:40:49,066 - INFO - Epoch: 32, Training Loss: 0.6410
2025-11-12 13:40:56,854 - INFO - Epoch: 33, Training Loss: 0.6220
2025-11-12 13:41:04,376 - INFO - Epoch: 34, Training Loss: 0.6158
2025-11-12 13:41:13,262 - INFO - Epoch: 35, Training Loss: 0.6181
2025-11-12 13:41:20,946 - INFO - Epoch: 36, Training Loss: 0.5741
2025-11-12 13:41:28,646 - INFO - Epoch: 37, Training Loss: 0.5927
2025-11-12 13:41:36,924 - INFO - Epoch: 38, Training Loss: 0.5347
2025-11-12 13:41:44,313 - INFO - Epoch: 39, Training Loss: 4.4384
2025-11-12 13:41:52,200 - INFO - Epoch: 40, Training Loss: 5.9972
2025-11-12 13:42:00,529 - INFO - Epoch: 41, Training Loss: 6.0012
2025-11-12 13:42:08,813 - INFO - Epoch: 42, Training Loss: 6.0102
2025-11-12 13:42:16,668 - INFO - Epoch: 43, Training Loss: 6.0204
2025-11-12 13:42:24,303 - INFO - Epoch: 44, Training Loss: 6.0205
2025-11-12 13:42:31,835 - INFO - Epoch: 45, Training Loss: 5.9975
2025-11-12 13:42:39,560 - INFO - Epoch: 46, Training Loss: 5.9970
2025-11-12 13:42:48,077 - INFO - Epoch: 47, Training Loss: 6.0204
2025-11-12 13:42:56,450 - INFO - Epoch: 48, Training Loss: 6.0204
2025-11-12 13:43:04,028 - INFO - Epoch: 49, Training Loss: 5.9921
2025-11-12 13:43:11,714 - INFO - Epoch: 50, Training Loss: 5.9898
2025-11-12 13:43:19,056 - INFO - Epoch: 51, Training Loss: 5.9752
2025-11-12 13:43:26,763 - INFO - Epoch: 52, Training Loss: 5.9978
2025-11-12 13:43:34,294 - INFO - Epoch: 53, Training Loss: 6.0197
2025-11-12 13:43:42,546 - INFO - Epoch: 54, Training Loss: 5.9951
2025-11-12 13:43:49,641 - INFO - Epoch: 55, Training Loss: 5.9923
2025-11-12 13:43:58,268 - INFO - Epoch: 56, Training Loss: 5.9748
2025-11-12 13:44:06,264 - INFO - Epoch: 57, Training Loss: 5.9959
2025-11-12 13:44:13,777 - INFO - Epoch: 58, Training Loss: 6.0205
2025-11-12 13:44:22,018 - INFO - Epoch: 59, Training Loss: 5.9871
2025-11-12 13:44:29,799 - INFO - Epoch: 60, Training Loss: 6.0203
2025-11-12 13:44:37,629 - INFO - Epoch: 61, Training Loss: 5.9972
2025-11-12 13:44:45,237 - INFO - Epoch: 62, Training Loss: 5.9967
2025-11-12 13:44:53,048 - INFO - Epoch: 63, Training Loss: 6.0133
2025-11-12 13:45:01,056 - INFO - Epoch: 64, Training Loss: 6.0123
2025-11-12 13:45:08,796 - INFO - Epoch: 65, Training Loss: 6.0185
2025-11-12 13:45:16,433 - INFO - Epoch: 66, Training Loss: 6.0202
2025-11-12 13:45:24,426 - INFO - Epoch: 67, Training Loss: 5.9980
2025-11-12 13:45:32,281 - INFO - Epoch: 68, Training Loss: 6.0202
2025-11-12 13:45:40,005 - INFO - Epoch: 69, Training Loss: 5.9977
2025-11-12 13:45:48,349 - INFO - Epoch: 70, Training Loss: 5.9998
2025-11-12 13:45:55,604 - INFO - Epoch: 71, Training Loss: 6.0109
2025-11-12 13:46:03,010 - INFO - Epoch: 72, Training Loss: 6.0161
2025-11-12 13:46:10,793 - INFO - Epoch: 73, Training Loss: 6.0122
2025-11-12 13:46:18,532 - INFO - Epoch: 74, Training Loss: 5.9972
2025-11-12 13:46:26,153 - INFO - Epoch: 75, Training Loss: 5.9739
2025-11-12 13:46:33,799 - INFO - Epoch: 76, Training Loss: 6.0121
2025-11-12 13:46:42,099 - INFO - Epoch: 77, Training Loss: 6.0204
2025-11-12 13:46:49,772 - INFO - Epoch: 78, Training Loss: 5.9966
2025-11-12 13:46:57,566 - INFO - Epoch: 79, Training Loss: 6.0126
2025-11-12 13:47:06,474 - INFO - Epoch: 80, Training Loss: 5.9971
2025-11-12 13:47:13,679 - INFO - Epoch: 81, Training Loss: 6.0182
2025-11-12 13:47:20,942 - INFO - Epoch: 82, Training Loss: 5.9812
2025-11-12 13:47:28,785 - INFO - Epoch: 83, Training Loss: 6.0204
2025-11-12 13:47:36,163 - INFO - Epoch: 84, Training Loss: 5.9844
2025-11-12 13:47:44,530 - INFO - Epoch: 85, Training Loss: 5.9975
2025-11-12 13:47:53,762 - INFO - Epoch: 86, Training Loss: 5.9898
2025-11-12 13:48:02,133 - INFO - Epoch: 87, Training Loss: 6.0204
2025-11-12 13:48:10,893 - INFO - Epoch: 88, Training Loss: 6.0027
2025-11-12 13:48:20,302 - INFO - Epoch: 89, Training Loss: 6.0095
2025-11-12 13:48:28,534 - INFO - Epoch: 90, Training Loss: 6.0203
2025-11-12 13:48:36,427 - INFO - Epoch: 91, Training Loss: 5.9741
2025-11-12 13:48:43,785 - INFO - Epoch: 92, Training Loss: 6.0007
2025-11-12 13:48:52,053 - INFO - Epoch: 93, Training Loss: 5.9973
2025-11-12 13:49:00,353 - INFO - Epoch: 94, Training Loss: 6.0205
2025-11-12 13:49:08,198 - INFO - Epoch: 95, Training Loss: 5.9976
2025-11-12 13:49:16,384 - INFO - Epoch: 96, Training Loss: 5.9978
2025-11-12 13:49:23,868 - INFO - Epoch: 97, Training Loss: 5.9738
2025-11-12 13:49:32,298 - INFO - Epoch: 98, Training Loss: 5.9937
2025-11-12 13:49:39,750 - INFO - Epoch: 99, Training Loss: 5.9744
2025-11-12 13:49:47,048 - INFO - Epoch: 100, Training Loss: 5.9984
2025-11-12 13:49:47,048 - INFO - Training completed for Trial 12 CV 0

