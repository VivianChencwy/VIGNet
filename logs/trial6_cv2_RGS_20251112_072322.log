2025-11-12 07:23:22,757 - INFO - Log file: ./logs/trial6_cv2_RGS_20251112_072322.log
2025-11-12 07:23:22,757 - INFO - START TRAINING TRIAL 6 CV 2 - Task: RGS
2025-11-12 07:23:22,757 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 07:23:22,758 - INFO - Loading dataset...
2025-11-12 07:23:22,847 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 07:23:22,847 - INFO - Initializing VIGNet model...
2025-11-12 07:23:22,850 - INFO - Number of batch iterations per epoch: 113
2025-11-12 07:23:30,966 - INFO - Epoch: 1, Training Loss: 0.9097
2025-11-12 07:23:39,552 - INFO - Epoch: 2, Training Loss: 0.6849
2025-11-12 07:23:46,932 - INFO - Epoch: 3, Training Loss: 0.6756
2025-11-12 07:23:55,302 - INFO - Epoch: 4, Training Loss: 0.6746
2025-11-12 07:24:03,772 - INFO - Epoch: 5, Training Loss: 0.6694
2025-11-12 07:24:11,772 - INFO - Epoch: 6, Training Loss: 0.6697
2025-11-12 07:24:19,916 - INFO - Epoch: 7, Training Loss: 0.6680
2025-11-12 07:24:27,792 - INFO - Epoch: 8, Training Loss: 0.6703
2025-11-12 07:24:35,282 - INFO - Epoch: 9, Training Loss: 0.6683
2025-11-12 07:24:42,783 - INFO - Epoch: 10, Training Loss: 0.6674
2025-11-12 07:24:51,562 - INFO - Epoch: 11, Training Loss: 0.6676
2025-11-12 07:25:00,895 - INFO - Epoch: 12, Training Loss: 0.6676
2025-11-12 07:25:09,323 - INFO - Epoch: 13, Training Loss: 0.6676
2025-11-12 07:25:17,051 - INFO - Epoch: 14, Training Loss: 0.6681
2025-11-12 07:25:25,417 - INFO - Epoch: 15, Training Loss: 0.6674
2025-11-12 07:25:33,218 - INFO - Epoch: 16, Training Loss: 0.6670
2025-11-12 07:25:41,468 - INFO - Epoch: 17, Training Loss: 0.6664
2025-11-12 07:25:49,004 - INFO - Epoch: 18, Training Loss: 0.6670
2025-11-12 07:25:56,608 - INFO - Epoch: 19, Training Loss: 0.6676
2025-11-12 07:26:03,828 - INFO - Epoch: 20, Training Loss: 0.6669
2025-11-12 07:26:11,539 - INFO - Epoch: 21, Training Loss: 0.6665
2025-11-12 07:26:19,802 - INFO - Epoch: 22, Training Loss: 0.6673
2025-11-12 07:26:27,990 - INFO - Epoch: 23, Training Loss: 0.6669
2025-11-12 07:26:35,765 - INFO - Epoch: 24, Training Loss: 0.6671
2025-11-12 07:26:44,455 - INFO - Epoch: 25, Training Loss: 0.6673
2025-11-12 07:26:52,084 - INFO - Epoch: 26, Training Loss: 0.6677
2025-11-12 07:27:00,404 - INFO - Epoch: 27, Training Loss: 0.6673
2025-11-12 07:27:08,225 - INFO - Epoch: 28, Training Loss: 0.6671
2025-11-12 07:27:16,070 - INFO - Epoch: 29, Training Loss: 0.6663
2025-11-12 07:27:23,934 - INFO - Epoch: 30, Training Loss: 0.6670
2025-11-12 07:27:32,360 - INFO - Epoch: 31, Training Loss: 0.6667
2025-11-12 07:27:41,504 - INFO - Epoch: 32, Training Loss: 0.6667
2025-11-12 07:27:50,412 - INFO - Epoch: 33, Training Loss: 0.6674
2025-11-12 07:27:58,298 - INFO - Epoch: 34, Training Loss: 0.6669
2025-11-12 07:28:06,182 - INFO - Epoch: 35, Training Loss: 0.6670
2025-11-12 07:28:13,509 - INFO - Epoch: 36, Training Loss: 0.6673
2025-11-12 07:28:22,115 - INFO - Epoch: 37, Training Loss: 0.6670
2025-11-12 07:28:29,584 - INFO - Epoch: 38, Training Loss: 0.6673
2025-11-12 07:28:36,897 - INFO - Epoch: 39, Training Loss: 0.6665
2025-11-12 07:28:45,483 - INFO - Epoch: 40, Training Loss: 0.6682
2025-11-12 07:28:54,144 - INFO - Epoch: 41, Training Loss: 0.6672
2025-11-12 07:29:02,342 - INFO - Epoch: 42, Training Loss: 0.6670
2025-11-12 07:29:10,050 - INFO - Epoch: 43, Training Loss: 0.6672
2025-11-12 07:29:18,126 - INFO - Epoch: 44, Training Loss: 0.6670
2025-11-12 07:29:26,726 - INFO - Epoch: 45, Training Loss: 0.6668
2025-11-12 07:29:35,463 - INFO - Epoch: 46, Training Loss: 0.6676
2025-11-12 07:29:43,194 - INFO - Epoch: 47, Training Loss: 0.6667
2025-11-12 07:29:51,479 - INFO - Epoch: 48, Training Loss: 0.6672
2025-11-12 07:29:59,404 - INFO - Epoch: 49, Training Loss: 0.6672
2025-11-12 07:30:07,384 - INFO - Epoch: 50, Training Loss: 0.6673
2025-11-12 07:30:15,234 - INFO - Epoch: 51, Training Loss: 0.6667
2025-11-12 07:30:22,458 - INFO - Epoch: 52, Training Loss: 0.6664
2025-11-12 07:30:30,397 - INFO - Epoch: 53, Training Loss: 0.6671
2025-11-12 07:30:38,484 - INFO - Epoch: 54, Training Loss: 0.6671
2025-11-12 07:30:46,035 - INFO - Epoch: 55, Training Loss: 0.6678
2025-11-12 07:30:54,585 - INFO - Epoch: 56, Training Loss: 0.6668
2025-11-12 07:31:02,591 - INFO - Epoch: 57, Training Loss: 0.6675
2025-11-12 07:31:11,200 - INFO - Epoch: 58, Training Loss: 0.6673
2025-11-12 07:31:19,341 - INFO - Epoch: 59, Training Loss: 0.6671
2025-11-12 07:31:27,662 - INFO - Epoch: 60, Training Loss: 0.6668
2025-11-12 07:31:35,356 - INFO - Epoch: 61, Training Loss: 0.6671
2025-11-12 07:31:43,059 - INFO - Epoch: 62, Training Loss: 0.6672
2025-11-12 07:31:50,708 - INFO - Epoch: 63, Training Loss: 0.6676
2025-11-12 07:31:58,684 - INFO - Epoch: 64, Training Loss: 0.6672
2025-11-12 07:32:06,645 - INFO - Epoch: 65, Training Loss: 0.6675
2025-11-12 07:32:13,982 - INFO - Epoch: 66, Training Loss: 0.6664
2025-11-12 07:32:21,529 - INFO - Epoch: 67, Training Loss: 0.6672
2025-11-12 07:32:30,785 - INFO - Epoch: 68, Training Loss: 0.6676
2025-11-12 07:32:38,690 - INFO - Epoch: 69, Training Loss: 0.6667
2025-11-12 07:32:46,722 - INFO - Epoch: 70, Training Loss: 0.6670
2025-11-12 07:32:54,240 - INFO - Epoch: 71, Training Loss: 0.6673
2025-11-12 07:33:01,480 - INFO - Epoch: 72, Training Loss: 0.6673
2025-11-12 07:33:09,851 - INFO - Epoch: 73, Training Loss: 0.6674
2025-11-12 07:33:17,087 - INFO - Epoch: 74, Training Loss: 0.6670
2025-11-12 07:33:24,919 - INFO - Epoch: 75, Training Loss: 0.6666
2025-11-12 07:33:32,540 - INFO - Epoch: 76, Training Loss: 0.6666
2025-11-12 07:33:40,801 - INFO - Epoch: 77, Training Loss: 0.6665
2025-11-12 07:33:49,421 - INFO - Epoch: 78, Training Loss: 0.6670
2025-11-12 07:33:58,714 - INFO - Epoch: 79, Training Loss: 0.6673
2025-11-12 07:34:06,413 - INFO - Epoch: 80, Training Loss: 0.6669
2025-11-12 07:34:15,301 - INFO - Epoch: 81, Training Loss: 0.6670
2025-11-12 07:34:23,536 - INFO - Epoch: 82, Training Loss: 0.6672
2025-11-12 07:34:31,829 - INFO - Epoch: 83, Training Loss: 0.6665
2025-11-12 07:34:39,135 - INFO - Epoch: 84, Training Loss: 0.6667
2025-11-12 07:34:47,309 - INFO - Epoch: 85, Training Loss: 0.6669
2025-11-12 07:34:56,262 - INFO - Epoch: 86, Training Loss: 0.6671
2025-11-12 07:35:03,757 - INFO - Epoch: 87, Training Loss: 0.6679
2025-11-12 07:35:11,577 - INFO - Epoch: 88, Training Loss: 0.6670
2025-11-12 07:35:19,644 - INFO - Epoch: 89, Training Loss: 0.6671
2025-11-12 07:35:27,848 - INFO - Epoch: 90, Training Loss: 0.6666
2025-11-12 07:35:35,365 - INFO - Epoch: 91, Training Loss: 0.6670
2025-11-12 07:35:42,534 - INFO - Epoch: 92, Training Loss: 0.6665
2025-11-12 07:35:50,370 - INFO - Epoch: 93, Training Loss: 0.6675
2025-11-12 07:35:58,087 - INFO - Epoch: 94, Training Loss: 0.6679
2025-11-12 07:36:06,339 - INFO - Epoch: 95, Training Loss: 0.6670
2025-11-12 07:36:13,663 - INFO - Epoch: 96, Training Loss: 0.6664
2025-11-12 07:36:22,341 - INFO - Epoch: 97, Training Loss: 0.6667
2025-11-12 07:36:30,291 - INFO - Epoch: 98, Training Loss: 0.6668
2025-11-12 07:36:38,313 - INFO - Epoch: 99, Training Loss: 0.6668
2025-11-12 07:36:45,956 - INFO - Epoch: 100, Training Loss: 0.6669
2025-11-12 07:36:45,956 - INFO - Training completed for Trial 6 CV 2

