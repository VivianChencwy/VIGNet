2025-11-12 04:57:27,359 - INFO - Log file: ./logs/trial4_cv1_RGS_20251112_045727.log
2025-11-12 04:57:27,359 - INFO - START TRAINING TRIAL 4 CV 1 - Task: RGS
2025-11-12 04:57:27,359 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 04:57:27,359 - INFO - Loading dataset...
2025-11-12 04:57:27,448 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 04:57:27,448 - INFO - Initializing VIGNet model...
2025-11-12 04:57:27,451 - INFO - Number of batch iterations per epoch: 113
2025-11-12 04:57:35,913 - INFO - Epoch: 1, Training Loss: 0.9081
2025-11-12 04:57:44,042 - INFO - Epoch: 2, Training Loss: 0.6460
2025-11-12 04:57:51,725 - INFO - Epoch: 3, Training Loss: 0.6439
2025-11-12 04:58:00,265 - INFO - Epoch: 4, Training Loss: 0.6437
2025-11-12 04:58:08,481 - INFO - Epoch: 5, Training Loss: 0.6435
2025-11-12 04:58:15,667 - INFO - Epoch: 6, Training Loss: 0.6425
2025-11-12 04:58:23,174 - INFO - Epoch: 7, Training Loss: 0.6415
2025-11-12 04:58:30,745 - INFO - Epoch: 8, Training Loss: 0.6415
2025-11-12 04:58:38,890 - INFO - Epoch: 9, Training Loss: 0.6423
2025-11-12 04:58:45,932 - INFO - Epoch: 10, Training Loss: 0.6421
2025-11-12 04:58:53,375 - INFO - Epoch: 11, Training Loss: 0.6410
2025-11-12 04:59:01,086 - INFO - Epoch: 12, Training Loss: 0.6421
2025-11-12 04:59:09,039 - INFO - Epoch: 13, Training Loss: 0.6413
2025-11-12 04:59:16,843 - INFO - Epoch: 14, Training Loss: 0.6408
2025-11-12 04:59:24,222 - INFO - Epoch: 15, Training Loss: 0.6406
2025-11-12 04:59:31,868 - INFO - Epoch: 16, Training Loss: 0.6408
2025-11-12 04:59:39,617 - INFO - Epoch: 17, Training Loss: 0.6411
2025-11-12 04:59:47,580 - INFO - Epoch: 18, Training Loss: 0.6428
2025-11-12 04:59:55,341 - INFO - Epoch: 19, Training Loss: 0.6419
2025-11-12 05:00:03,221 - INFO - Epoch: 20, Training Loss: 0.6413
2025-11-12 05:00:11,159 - INFO - Epoch: 21, Training Loss: 0.6417
2025-11-12 05:00:18,739 - INFO - Epoch: 22, Training Loss: 0.6420
2025-11-12 05:00:26,574 - INFO - Epoch: 23, Training Loss: 0.6409
2025-11-12 05:00:34,599 - INFO - Epoch: 24, Training Loss: 0.6415
2025-11-12 05:00:42,637 - INFO - Epoch: 25, Training Loss: 0.6411
2025-11-12 05:00:51,187 - INFO - Epoch: 26, Training Loss: 0.6409
2025-11-12 05:00:59,003 - INFO - Epoch: 27, Training Loss: 0.6403
2025-11-12 05:01:07,149 - INFO - Epoch: 28, Training Loss: 0.6412
2025-11-12 05:01:15,101 - INFO - Epoch: 29, Training Loss: 0.6428
2025-11-12 05:01:23,859 - INFO - Epoch: 30, Training Loss: 0.6414
2025-11-12 05:01:32,181 - INFO - Epoch: 31, Training Loss: 0.6413
2025-11-12 05:01:40,499 - INFO - Epoch: 32, Training Loss: 0.6410
2025-11-12 05:01:48,135 - INFO - Epoch: 33, Training Loss: 0.6422
2025-11-12 05:01:55,883 - INFO - Epoch: 34, Training Loss: 0.6410
2025-11-12 05:02:02,974 - INFO - Epoch: 35, Training Loss: 0.6415
2025-11-12 05:02:11,055 - INFO - Epoch: 36, Training Loss: 0.6400
2025-11-12 05:02:18,143 - INFO - Epoch: 37, Training Loss: 0.6419
2025-11-12 05:02:25,626 - INFO - Epoch: 38, Training Loss: 0.6402
2025-11-12 05:02:33,484 - INFO - Epoch: 39, Training Loss: 0.6428
2025-11-12 05:02:40,733 - INFO - Epoch: 40, Training Loss: 0.6401
2025-11-12 05:02:49,106 - INFO - Epoch: 41, Training Loss: 0.6420
2025-11-12 05:02:58,465 - INFO - Epoch: 42, Training Loss: 0.6410
2025-11-12 05:03:06,678 - INFO - Epoch: 43, Training Loss: 0.6408
2025-11-12 05:03:13,949 - INFO - Epoch: 44, Training Loss: 0.6411
2025-11-12 05:03:21,634 - INFO - Epoch: 45, Training Loss: 0.6408
2025-11-12 05:03:28,922 - INFO - Epoch: 46, Training Loss: 0.6413
2025-11-12 05:03:36,209 - INFO - Epoch: 47, Training Loss: 0.6394
2025-11-12 05:03:44,027 - INFO - Epoch: 48, Training Loss: 0.6403
2025-11-12 05:03:51,927 - INFO - Epoch: 49, Training Loss: 0.6399
2025-11-12 05:04:00,085 - INFO - Epoch: 50, Training Loss: 0.6389
2025-11-12 05:04:08,771 - INFO - Epoch: 51, Training Loss: 0.6361
2025-11-12 05:04:16,298 - INFO - Epoch: 52, Training Loss: 0.6336
2025-11-12 05:04:24,353 - INFO - Epoch: 53, Training Loss: 0.6314
2025-11-12 05:04:32,878 - INFO - Epoch: 54, Training Loss: 0.6222
2025-11-12 05:04:40,489 - INFO - Epoch: 55, Training Loss: 0.6087
2025-11-12 05:04:48,502 - INFO - Epoch: 56, Training Loss: 0.6060
2025-11-12 05:04:56,803 - INFO - Epoch: 57, Training Loss: 0.6048
2025-11-12 05:05:05,492 - INFO - Epoch: 58, Training Loss: 0.6010
2025-11-12 05:05:12,984 - INFO - Epoch: 59, Training Loss: 0.6002
2025-11-12 05:05:20,582 - INFO - Epoch: 60, Training Loss: 0.5947
2025-11-12 05:05:28,407 - INFO - Epoch: 61, Training Loss: 0.6018
2025-11-12 05:05:35,958 - INFO - Epoch: 62, Training Loss: 0.6006
2025-11-12 05:05:44,072 - INFO - Epoch: 63, Training Loss: 0.5979
2025-11-12 05:05:51,564 - INFO - Epoch: 64, Training Loss: 0.5980
2025-11-12 05:05:59,345 - INFO - Epoch: 65, Training Loss: 0.6060
2025-11-12 05:06:07,429 - INFO - Epoch: 66, Training Loss: 0.6065
2025-11-12 05:06:15,069 - INFO - Epoch: 67, Training Loss: 0.5978
2025-11-12 05:06:23,297 - INFO - Epoch: 68, Training Loss: 0.6088
2025-11-12 05:06:31,063 - INFO - Epoch: 69, Training Loss: 0.6059
2025-11-12 05:06:38,415 - INFO - Epoch: 70, Training Loss: 0.5977
2025-11-12 05:06:45,807 - INFO - Epoch: 71, Training Loss: 0.5954
2025-11-12 05:06:54,043 - INFO - Epoch: 72, Training Loss: 0.5951
2025-11-12 05:07:02,394 - INFO - Epoch: 73, Training Loss: 0.5948
2025-11-12 05:07:10,495 - INFO - Epoch: 74, Training Loss: 0.5920
2025-11-12 05:07:18,145 - INFO - Epoch: 75, Training Loss: 0.5920
2025-11-12 05:07:26,472 - INFO - Epoch: 76, Training Loss: 0.6148
2025-11-12 05:07:34,210 - INFO - Epoch: 77, Training Loss: 0.6116
2025-11-12 05:07:42,125 - INFO - Epoch: 78, Training Loss: 0.6080
2025-11-12 05:07:49,562 - INFO - Epoch: 79, Training Loss: 0.6039
2025-11-12 05:07:57,193 - INFO - Epoch: 80, Training Loss: 0.6029
2025-11-12 05:08:04,588 - INFO - Epoch: 81, Training Loss: 0.6014
2025-11-12 05:08:12,668 - INFO - Epoch: 82, Training Loss: 0.5973
2025-11-12 05:08:20,964 - INFO - Epoch: 83, Training Loss: 0.5960
2025-11-12 05:08:29,193 - INFO - Epoch: 84, Training Loss: 0.5989
2025-11-12 05:08:36,390 - INFO - Epoch: 85, Training Loss: 0.5947
2025-11-12 05:08:44,343 - INFO - Epoch: 86, Training Loss: 0.5934
2025-11-12 05:08:52,134 - INFO - Epoch: 87, Training Loss: 0.5953
2025-11-12 05:09:00,279 - INFO - Epoch: 88, Training Loss: 0.5941
2025-11-12 05:09:09,281 - INFO - Epoch: 89, Training Loss: 0.5949
2025-11-12 05:09:17,712 - INFO - Epoch: 90, Training Loss: 0.5920
2025-11-12 05:09:26,100 - INFO - Epoch: 91, Training Loss: 0.5931
2025-11-12 05:09:34,022 - INFO - Epoch: 92, Training Loss: 0.5917
2025-11-12 05:09:41,280 - INFO - Epoch: 93, Training Loss: 0.5932
2025-11-12 05:09:48,774 - INFO - Epoch: 94, Training Loss: 0.5932
2025-11-12 05:09:56,755 - INFO - Epoch: 95, Training Loss: 0.5928
2025-11-12 05:10:04,108 - INFO - Epoch: 96, Training Loss: 0.5921
2025-11-12 05:10:12,139 - INFO - Epoch: 97, Training Loss: 0.5920
2025-11-12 05:10:19,847 - INFO - Epoch: 98, Training Loss: 0.5919
2025-11-12 05:10:27,678 - INFO - Epoch: 99, Training Loss: 0.5905
2025-11-12 05:10:35,495 - INFO - Epoch: 100, Training Loss: 0.5912
2025-11-12 05:10:35,495 - INFO - Training completed for Trial 4 CV 1

