2025-11-12 05:50:29,252 - INFO - Log file: ./logs/trial5_cv0_RGS_20251112_055029.log
2025-11-12 05:50:29,252 - INFO - START TRAINING TRIAL 5 CV 0 - Task: RGS
2025-11-12 05:50:29,252 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 05:50:29,252 - INFO - Loading dataset...
2025-11-12 05:50:29,350 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 05:50:29,350 - INFO - Initializing VIGNet model...
2025-11-12 05:50:29,353 - INFO - Number of batch iterations per epoch: 113
2025-11-12 05:50:37,068 - INFO - Epoch: 1, Training Loss: 0.8642
2025-11-12 05:50:45,363 - INFO - Epoch: 2, Training Loss: 0.6912
2025-11-12 05:50:53,685 - INFO - Epoch: 3, Training Loss: 0.6952
2025-11-12 05:51:01,353 - INFO - Epoch: 4, Training Loss: 0.6915
2025-11-12 05:51:09,374 - INFO - Epoch: 5, Training Loss: 0.6928
2025-11-12 05:51:17,175 - INFO - Epoch: 6, Training Loss: 0.6942
2025-11-12 05:51:25,982 - INFO - Epoch: 7, Training Loss: 0.6925
2025-11-12 05:51:33,589 - INFO - Epoch: 8, Training Loss: 0.6932
2025-11-12 05:51:41,211 - INFO - Epoch: 9, Training Loss: 0.6938
2025-11-12 05:51:48,473 - INFO - Epoch: 10, Training Loss: 0.6899
2025-11-12 05:51:55,748 - INFO - Epoch: 11, Training Loss: 0.6886
2025-11-12 05:52:03,251 - INFO - Epoch: 12, Training Loss: 0.6932
2025-11-12 05:52:10,748 - INFO - Epoch: 13, Training Loss: 0.6910
2025-11-12 05:52:18,374 - INFO - Epoch: 14, Training Loss: 0.6924
2025-11-12 05:52:27,381 - INFO - Epoch: 15, Training Loss: 0.6898
2025-11-12 05:52:35,584 - INFO - Epoch: 16, Training Loss: 0.6877
2025-11-12 05:52:44,114 - INFO - Epoch: 17, Training Loss: 0.6936
2025-11-12 05:52:52,018 - INFO - Epoch: 18, Training Loss: 0.6904
2025-11-12 05:53:00,096 - INFO - Epoch: 19, Training Loss: 0.6927
2025-11-12 05:53:07,850 - INFO - Epoch: 20, Training Loss: 0.6943
2025-11-12 05:53:16,692 - INFO - Epoch: 21, Training Loss: 0.6920
2025-11-12 05:53:24,961 - INFO - Epoch: 22, Training Loss: 0.6892
2025-11-12 05:53:32,506 - INFO - Epoch: 23, Training Loss: 0.6936
2025-11-12 05:53:40,608 - INFO - Epoch: 24, Training Loss: 0.6871
2025-11-12 05:53:48,074 - INFO - Epoch: 25, Training Loss: 0.6908
2025-11-12 05:53:56,213 - INFO - Epoch: 26, Training Loss: 0.6919
2025-11-12 05:54:04,284 - INFO - Epoch: 27, Training Loss: 0.6883
2025-11-12 05:54:12,378 - INFO - Epoch: 28, Training Loss: 0.6908
2025-11-12 05:54:19,974 - INFO - Epoch: 29, Training Loss: 0.6894
2025-11-12 05:54:28,872 - INFO - Epoch: 30, Training Loss: 0.6893
2025-11-12 05:54:36,556 - INFO - Epoch: 31, Training Loss: 0.6913
2025-11-12 05:54:43,911 - INFO - Epoch: 32, Training Loss: 0.6873
2025-11-12 05:54:52,566 - INFO - Epoch: 33, Training Loss: 0.6852
2025-11-12 05:55:00,543 - INFO - Epoch: 34, Training Loss: 0.6858
2025-11-12 05:55:08,367 - INFO - Epoch: 35, Training Loss: 0.6783
2025-11-12 05:55:17,711 - INFO - Epoch: 36, Training Loss: 0.6675
2025-11-12 05:55:25,927 - INFO - Epoch: 37, Training Loss: 0.6567
2025-11-12 05:55:33,983 - INFO - Epoch: 38, Training Loss: 0.6206
2025-11-12 05:55:42,391 - INFO - Epoch: 39, Training Loss: 0.6087
2025-11-12 05:55:50,159 - INFO - Epoch: 40, Training Loss: 0.5750
2025-11-12 05:55:57,415 - INFO - Epoch: 41, Training Loss: 0.5796
2025-11-12 05:56:05,286 - INFO - Epoch: 42, Training Loss: 0.5988
2025-11-12 05:56:13,783 - INFO - Epoch: 43, Training Loss: 0.8250
2025-11-12 05:56:22,700 - INFO - Epoch: 44, Training Loss: 0.8158
2025-11-12 05:56:30,421 - INFO - Epoch: 45, Training Loss: 0.6871
2025-11-12 05:56:38,500 - INFO - Epoch: 46, Training Loss: 0.6751
2025-11-12 05:56:46,015 - INFO - Epoch: 47, Training Loss: 0.6893
2025-11-12 05:56:54,582 - INFO - Epoch: 48, Training Loss: 0.6678
2025-11-12 05:57:02,570 - INFO - Epoch: 49, Training Loss: 0.6578
2025-11-12 05:57:10,051 - INFO - Epoch: 50, Training Loss: 0.6449
2025-11-12 05:57:17,784 - INFO - Epoch: 51, Training Loss: 0.6391
2025-11-12 05:57:25,336 - INFO - Epoch: 52, Training Loss: 0.6336
2025-11-12 05:57:32,903 - INFO - Epoch: 53, Training Loss: 0.6240
2025-11-12 05:57:40,963 - INFO - Epoch: 54, Training Loss: 0.6148
2025-11-12 05:57:48,542 - INFO - Epoch: 55, Training Loss: 0.6060
2025-11-12 05:57:56,392 - INFO - Epoch: 56, Training Loss: 0.5904
2025-11-12 05:58:04,243 - INFO - Epoch: 57, Training Loss: 0.5830
2025-11-12 05:58:12,186 - INFO - Epoch: 58, Training Loss: 0.5777
2025-11-12 05:58:19,833 - INFO - Epoch: 59, Training Loss: 0.5903
2025-11-12 05:58:27,949 - INFO - Epoch: 60, Training Loss: 0.5706
2025-11-12 05:58:35,787 - INFO - Epoch: 61, Training Loss: 0.5938
2025-11-12 05:58:43,105 - INFO - Epoch: 62, Training Loss: 0.5656
2025-11-12 05:58:50,894 - INFO - Epoch: 63, Training Loss: 0.5838
2025-11-12 05:58:58,964 - INFO - Epoch: 64, Training Loss: 0.5832
2025-11-12 05:59:06,439 - INFO - Epoch: 65, Training Loss: 0.5786
2025-11-12 05:59:14,938 - INFO - Epoch: 66, Training Loss: 0.9107
2025-11-12 05:59:22,509 - INFO - Epoch: 67, Training Loss: 0.6687
2025-11-12 05:59:30,615 - INFO - Epoch: 68, Training Loss: 0.6404
2025-11-12 05:59:38,567 - INFO - Epoch: 69, Training Loss: 0.6212
2025-11-12 05:59:46,243 - INFO - Epoch: 70, Training Loss: 0.6044
2025-11-12 05:59:54,724 - INFO - Epoch: 71, Training Loss: 0.5918
2025-11-12 06:00:02,819 - INFO - Epoch: 72, Training Loss: 0.5858
2025-11-12 06:00:11,612 - INFO - Epoch: 73, Training Loss: 0.5757
2025-11-12 06:00:20,515 - INFO - Epoch: 74, Training Loss: 0.5727
2025-11-12 06:00:28,292 - INFO - Epoch: 75, Training Loss: 0.5677
2025-11-12 06:00:36,002 - INFO - Epoch: 76, Training Loss: 0.5673
2025-11-12 06:00:43,694 - INFO - Epoch: 77, Training Loss: 0.5734
2025-11-12 06:00:51,176 - INFO - Epoch: 78, Training Loss: 0.5546
2025-11-12 06:00:58,652 - INFO - Epoch: 79, Training Loss: 0.6204
2025-11-12 06:01:07,171 - INFO - Epoch: 80, Training Loss: 0.6321
2025-11-12 06:01:15,029 - INFO - Epoch: 81, Training Loss: 0.6220
2025-11-12 06:01:22,803 - INFO - Epoch: 82, Training Loss: 0.6128
2025-11-12 06:01:31,554 - INFO - Epoch: 83, Training Loss: 0.6011
2025-11-12 06:01:39,136 - INFO - Epoch: 84, Training Loss: 0.5878
2025-11-12 06:01:47,098 - INFO - Epoch: 85, Training Loss: 0.5832
2025-11-12 06:01:54,427 - INFO - Epoch: 86, Training Loss: 0.5765
2025-11-12 06:02:03,195 - INFO - Epoch: 87, Training Loss: 0.5799
2025-11-12 06:02:11,035 - INFO - Epoch: 88, Training Loss: 0.6226
2025-11-12 06:02:19,519 - INFO - Epoch: 89, Training Loss: 0.8626
2025-11-12 06:02:27,583 - INFO - Epoch: 90, Training Loss: 0.6001
2025-11-12 06:02:34,937 - INFO - Epoch: 91, Training Loss: 0.5800
2025-11-12 06:02:42,318 - INFO - Epoch: 92, Training Loss: 0.5734
2025-11-12 06:02:50,408 - INFO - Epoch: 93, Training Loss: 0.5664
2025-11-12 06:02:57,798 - INFO - Epoch: 94, Training Loss: 0.5648
2025-11-12 06:03:05,702 - INFO - Epoch: 95, Training Loss: 0.5583
2025-11-12 06:03:13,668 - INFO - Epoch: 96, Training Loss: 0.5543
2025-11-12 06:03:21,268 - INFO - Epoch: 97, Training Loss: 0.5491
2025-11-12 06:03:28,795 - INFO - Epoch: 98, Training Loss: 0.5510
2025-11-12 06:03:35,948 - INFO - Epoch: 99, Training Loss: 0.5523
2025-11-12 06:03:44,600 - INFO - Epoch: 100, Training Loss: 0.5619
2025-11-12 06:03:44,600 - INFO - Training completed for Trial 5 CV 0

