2025-11-12 11:37:03,452 - INFO - Log file: ./logs/trial10_cv1_RGS_20251112_113703.log
2025-11-12 11:37:03,452 - INFO - START TRAINING TRIAL 10 CV 1 - Task: RGS
2025-11-12 11:37:03,452 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 11:37:03,452 - INFO - Loading dataset...
2025-11-12 11:37:03,747 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 11:37:03,747 - INFO - Initializing VIGNet model...
2025-11-12 11:37:03,750 - INFO - Number of batch iterations per epoch: 113
2025-11-12 11:37:11,405 - INFO - Epoch: 1, Training Loss: 1.0624
2025-11-12 11:37:18,603 - INFO - Epoch: 2, Training Loss: 0.6905
2025-11-12 11:37:26,106 - INFO - Epoch: 3, Training Loss: 0.6862
2025-11-12 11:37:34,285 - INFO - Epoch: 4, Training Loss: 0.6858
2025-11-12 11:37:41,745 - INFO - Epoch: 5, Training Loss: 0.6837
2025-11-12 11:37:49,553 - INFO - Epoch: 6, Training Loss: 0.6838
2025-11-12 11:37:57,136 - INFO - Epoch: 7, Training Loss: 0.6823
2025-11-12 11:38:05,744 - INFO - Epoch: 8, Training Loss: 0.6824
2025-11-12 11:38:13,660 - INFO - Epoch: 9, Training Loss: 0.6841
2025-11-12 11:38:22,130 - INFO - Epoch: 10, Training Loss: 0.6821
2025-11-12 11:38:30,156 - INFO - Epoch: 11, Training Loss: 0.6831
2025-11-12 11:38:38,151 - INFO - Epoch: 12, Training Loss: 0.6825
2025-11-12 11:38:46,224 - INFO - Epoch: 13, Training Loss: 0.6835
2025-11-12 11:38:53,420 - INFO - Epoch: 14, Training Loss: 0.6832
2025-11-12 11:39:01,244 - INFO - Epoch: 15, Training Loss: 0.6828
2025-11-12 11:39:08,691 - INFO - Epoch: 16, Training Loss: 0.6838
2025-11-12 11:39:16,746 - INFO - Epoch: 17, Training Loss: 0.6826
2025-11-12 11:39:23,988 - INFO - Epoch: 18, Training Loss: 0.6825
2025-11-12 11:39:31,700 - INFO - Epoch: 19, Training Loss: 0.6824
2025-11-12 11:39:40,067 - INFO - Epoch: 20, Training Loss: 0.6828
2025-11-12 11:39:48,393 - INFO - Epoch: 21, Training Loss: 0.6827
2025-11-12 11:39:57,255 - INFO - Epoch: 22, Training Loss: 0.6829
2025-11-12 11:40:04,974 - INFO - Epoch: 23, Training Loss: 0.6827
2025-11-12 11:40:12,872 - INFO - Epoch: 24, Training Loss: 0.6829
2025-11-12 11:40:20,888 - INFO - Epoch: 25, Training Loss: 0.6820
2025-11-12 11:40:28,473 - INFO - Epoch: 26, Training Loss: 0.6832
2025-11-12 11:40:36,824 - INFO - Epoch: 27, Training Loss: 0.6825
2025-11-12 11:40:44,105 - INFO - Epoch: 28, Training Loss: 0.6830
2025-11-12 11:40:51,935 - INFO - Epoch: 29, Training Loss: 0.6830
2025-11-12 11:40:59,882 - INFO - Epoch: 30, Training Loss: 0.6829
2025-11-12 11:41:07,170 - INFO - Epoch: 31, Training Loss: 0.6823
2025-11-12 11:41:15,084 - INFO - Epoch: 32, Training Loss: 0.6826
2025-11-12 11:41:22,869 - INFO - Epoch: 33, Training Loss: 0.6820
2025-11-12 11:41:29,933 - INFO - Epoch: 34, Training Loss: 0.6841
2025-11-12 11:41:37,707 - INFO - Epoch: 35, Training Loss: 0.6825
2025-11-12 11:41:45,409 - INFO - Epoch: 36, Training Loss: 0.6834
2025-11-12 11:41:55,037 - INFO - Epoch: 37, Training Loss: 0.6821
2025-11-12 11:42:03,193 - INFO - Epoch: 38, Training Loss: 0.6827
2025-11-12 11:42:11,442 - INFO - Epoch: 39, Training Loss: 0.6822
2025-11-12 11:42:18,865 - INFO - Epoch: 40, Training Loss: 0.6829
2025-11-12 11:42:26,248 - INFO - Epoch: 41, Training Loss: 0.6813
2025-11-12 11:42:34,630 - INFO - Epoch: 42, Training Loss: 0.6829
2025-11-12 11:42:43,598 - INFO - Epoch: 43, Training Loss: 0.6836
2025-11-12 11:42:51,639 - INFO - Epoch: 44, Training Loss: 0.6832
2025-11-12 11:42:59,190 - INFO - Epoch: 45, Training Loss: 0.6827
2025-11-12 11:43:07,119 - INFO - Epoch: 46, Training Loss: 0.6821
2025-11-12 11:43:15,046 - INFO - Epoch: 47, Training Loss: 0.6834
2025-11-12 11:43:22,956 - INFO - Epoch: 48, Training Loss: 0.6831
2025-11-12 11:43:30,575 - INFO - Epoch: 49, Training Loss: 0.6826
2025-11-12 11:43:38,440 - INFO - Epoch: 50, Training Loss: 0.6823
2025-11-12 11:43:46,086 - INFO - Epoch: 51, Training Loss: 0.6827
2025-11-12 11:43:53,793 - INFO - Epoch: 52, Training Loss: 0.6829
2025-11-12 11:44:01,659 - INFO - Epoch: 53, Training Loss: 0.6825
2025-11-12 11:44:09,967 - INFO - Epoch: 54, Training Loss: 0.6826
2025-11-12 11:44:17,912 - INFO - Epoch: 55, Training Loss: 0.6829
2025-11-12 11:44:25,887 - INFO - Epoch: 56, Training Loss: 0.6827
2025-11-12 11:44:33,652 - INFO - Epoch: 57, Training Loss: 0.6820
2025-11-12 11:44:42,251 - INFO - Epoch: 58, Training Loss: 0.6829
2025-11-12 11:44:50,155 - INFO - Epoch: 59, Training Loss: 0.6834
2025-11-12 11:44:58,438 - INFO - Epoch: 60, Training Loss: 0.6824
2025-11-12 11:45:06,646 - INFO - Epoch: 61, Training Loss: 0.6825
2025-11-12 11:45:14,635 - INFO - Epoch: 62, Training Loss: 0.6829
2025-11-12 11:45:21,958 - INFO - Epoch: 63, Training Loss: 0.6830
2025-11-12 11:45:30,443 - INFO - Epoch: 64, Training Loss: 0.6833
2025-11-12 11:45:39,084 - INFO - Epoch: 65, Training Loss: 0.6823
2025-11-12 11:45:46,717 - INFO - Epoch: 66, Training Loss: 0.6827
2025-11-12 11:45:54,580 - INFO - Epoch: 67, Training Loss: 0.6826
2025-11-12 11:46:02,241 - INFO - Epoch: 68, Training Loss: 0.6834
2025-11-12 11:46:12,009 - INFO - Epoch: 69, Training Loss: 0.6826
2025-11-12 11:46:19,497 - INFO - Epoch: 70, Training Loss: 0.6829
2025-11-12 11:46:27,326 - INFO - Epoch: 71, Training Loss: 0.6832
2025-11-12 11:46:35,345 - INFO - Epoch: 72, Training Loss: 0.6826
2025-11-12 11:46:43,347 - INFO - Epoch: 73, Training Loss: 0.6826
2025-11-12 11:46:50,787 - INFO - Epoch: 74, Training Loss: 0.6825
2025-11-12 11:46:59,218 - INFO - Epoch: 75, Training Loss: 0.6821
2025-11-12 11:47:07,643 - INFO - Epoch: 76, Training Loss: 0.6826
2025-11-12 11:47:16,400 - INFO - Epoch: 77, Training Loss: 0.6824
2025-11-12 11:47:25,351 - INFO - Epoch: 78, Training Loss: 0.6835
2025-11-12 11:47:33,116 - INFO - Epoch: 79, Training Loss: 0.6828
2025-11-12 11:47:42,090 - INFO - Epoch: 80, Training Loss: 0.6821
2025-11-12 11:47:49,322 - INFO - Epoch: 81, Training Loss: 0.6829
2025-11-12 11:47:57,060 - INFO - Epoch: 82, Training Loss: 0.6823
2025-11-12 11:48:05,277 - INFO - Epoch: 83, Training Loss: 0.6821
2025-11-12 11:48:13,601 - INFO - Epoch: 84, Training Loss: 0.6822
2025-11-12 11:48:21,465 - INFO - Epoch: 85, Training Loss: 0.6831
2025-11-12 11:48:28,850 - INFO - Epoch: 86, Training Loss: 0.6832
2025-11-12 11:48:37,067 - INFO - Epoch: 87, Training Loss: 0.6829
2025-11-12 11:48:44,665 - INFO - Epoch: 88, Training Loss: 0.6829
2025-11-12 11:48:52,389 - INFO - Epoch: 89, Training Loss: 0.6818
2025-11-12 11:49:00,267 - INFO - Epoch: 90, Training Loss: 0.6829
2025-11-12 11:49:08,220 - INFO - Epoch: 91, Training Loss: 0.6824
2025-11-12 11:49:16,275 - INFO - Epoch: 92, Training Loss: 0.6825
2025-11-12 11:49:23,619 - INFO - Epoch: 93, Training Loss: 0.6831
2025-11-12 11:49:30,717 - INFO - Epoch: 94, Training Loss: 0.6826
2025-11-12 11:49:37,966 - INFO - Epoch: 95, Training Loss: 0.6833
2025-11-12 11:49:45,748 - INFO - Epoch: 96, Training Loss: 0.6822
2025-11-12 11:49:53,462 - INFO - Epoch: 97, Training Loss: 0.6823
2025-11-12 11:50:01,293 - INFO - Epoch: 98, Training Loss: 0.6822
2025-11-12 11:50:09,039 - INFO - Epoch: 99, Training Loss: 0.6821
2025-11-12 11:50:17,275 - INFO - Epoch: 100, Training Loss: 0.6824
2025-11-12 11:50:17,276 - INFO - Training completed for Trial 10 CV 1

