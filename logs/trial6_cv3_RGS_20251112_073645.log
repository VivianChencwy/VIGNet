2025-11-12 07:36:45,957 - INFO - Log file: ./logs/trial6_cv3_RGS_20251112_073645.log
2025-11-12 07:36:45,957 - INFO - START TRAINING TRIAL 6 CV 3 - Task: RGS
2025-11-12 07:36:45,957 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 07:36:45,957 - INFO - Loading dataset...
2025-11-12 07:36:46,086 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 07:36:46,086 - INFO - Initializing VIGNet model...
2025-11-12 07:36:46,090 - INFO - Number of batch iterations per epoch: 113
2025-11-12 07:36:54,306 - INFO - Epoch: 1, Training Loss: 1.1542
2025-11-12 07:37:02,745 - INFO - Epoch: 2, Training Loss: 0.6682
2025-11-12 07:37:10,446 - INFO - Epoch: 3, Training Loss: 0.6676
2025-11-12 07:37:17,963 - INFO - Epoch: 4, Training Loss: 0.6642
2025-11-12 07:37:26,180 - INFO - Epoch: 5, Training Loss: 0.6647
2025-11-12 07:37:34,004 - INFO - Epoch: 6, Training Loss: 0.6640
2025-11-12 07:37:41,555 - INFO - Epoch: 7, Training Loss: 0.6638
2025-11-12 07:37:49,567 - INFO - Epoch: 8, Training Loss: 0.6643
2025-11-12 07:37:57,747 - INFO - Epoch: 9, Training Loss: 0.6633
2025-11-12 07:38:05,154 - INFO - Epoch: 10, Training Loss: 0.6639
2025-11-12 07:38:13,470 - INFO - Epoch: 11, Training Loss: 0.6638
2025-11-12 07:38:22,274 - INFO - Epoch: 12, Training Loss: 0.6640
2025-11-12 07:38:30,692 - INFO - Epoch: 13, Training Loss: 0.6643
2025-11-12 07:38:38,207 - INFO - Epoch: 14, Training Loss: 0.6639
2025-11-12 07:38:46,285 - INFO - Epoch: 15, Training Loss: 0.6641
2025-11-12 07:38:54,767 - INFO - Epoch: 16, Training Loss: 0.6638
2025-11-12 07:39:02,509 - INFO - Epoch: 17, Training Loss: 0.6635
2025-11-12 07:39:10,156 - INFO - Epoch: 18, Training Loss: 0.6640
2025-11-12 07:39:17,746 - INFO - Epoch: 19, Training Loss: 0.6638
2025-11-12 07:39:26,547 - INFO - Epoch: 20, Training Loss: 0.6640
2025-11-12 07:39:34,091 - INFO - Epoch: 21, Training Loss: 0.6640
2025-11-12 07:39:41,619 - INFO - Epoch: 22, Training Loss: 0.6637
2025-11-12 07:39:48,971 - INFO - Epoch: 23, Training Loss: 0.6641
2025-11-12 07:39:56,467 - INFO - Epoch: 24, Training Loss: 0.6632
2025-11-12 07:40:04,137 - INFO - Epoch: 25, Training Loss: 0.6632
2025-11-12 07:40:11,917 - INFO - Epoch: 26, Training Loss: 0.6636
2025-11-12 07:40:19,505 - INFO - Epoch: 27, Training Loss: 0.6630
2025-11-12 07:40:26,899 - INFO - Epoch: 28, Training Loss: 0.6634
2025-11-12 07:40:35,563 - INFO - Epoch: 29, Training Loss: 0.6644
2025-11-12 07:40:43,825 - INFO - Epoch: 30, Training Loss: 0.6637
2025-11-12 07:40:52,743 - INFO - Epoch: 31, Training Loss: 0.6638
2025-11-12 07:41:00,520 - INFO - Epoch: 32, Training Loss: 0.6633
2025-11-12 07:41:09,030 - INFO - Epoch: 33, Training Loss: 0.6635
2025-11-12 07:41:16,999 - INFO - Epoch: 34, Training Loss: 0.6649
2025-11-12 07:41:25,082 - INFO - Epoch: 35, Training Loss: 0.6639
2025-11-12 07:41:33,242 - INFO - Epoch: 36, Training Loss: 0.6637
2025-11-12 07:41:40,919 - INFO - Epoch: 37, Training Loss: 0.6635
2025-11-12 07:41:48,930 - INFO - Epoch: 38, Training Loss: 0.6633
2025-11-12 07:41:56,597 - INFO - Epoch: 39, Training Loss: 0.6637
2025-11-12 07:42:05,123 - INFO - Epoch: 40, Training Loss: 0.6636
2025-11-12 07:42:12,776 - INFO - Epoch: 41, Training Loss: 0.6642
2025-11-12 07:42:21,382 - INFO - Epoch: 42, Training Loss: 0.6640
2025-11-12 07:42:29,879 - INFO - Epoch: 43, Training Loss: 0.6639
2025-11-12 07:42:37,747 - INFO - Epoch: 44, Training Loss: 0.6636
2025-11-12 07:42:45,746 - INFO - Epoch: 45, Training Loss: 0.6637
2025-11-12 07:42:53,396 - INFO - Epoch: 46, Training Loss: 0.6637
2025-11-12 07:43:01,372 - INFO - Epoch: 47, Training Loss: 0.6635
2025-11-12 07:43:09,603 - INFO - Epoch: 48, Training Loss: 0.6633
2025-11-12 07:43:16,956 - INFO - Epoch: 49, Training Loss: 0.6638
2025-11-12 07:43:25,603 - INFO - Epoch: 50, Training Loss: 0.6636
2025-11-12 07:43:33,608 - INFO - Epoch: 51, Training Loss: 0.6641
2025-11-12 07:43:41,330 - INFO - Epoch: 52, Training Loss: 0.6636
2025-11-12 07:43:50,007 - INFO - Epoch: 53, Training Loss: 0.6638
2025-11-12 07:43:58,232 - INFO - Epoch: 54, Training Loss: 0.6639
2025-11-12 07:44:05,737 - INFO - Epoch: 55, Training Loss: 0.6634
2025-11-12 07:44:14,458 - INFO - Epoch: 56, Training Loss: 0.6645
2025-11-12 07:44:22,456 - INFO - Epoch: 57, Training Loss: 0.6637
2025-11-12 07:44:29,613 - INFO - Epoch: 58, Training Loss: 0.6632
2025-11-12 07:44:37,196 - INFO - Epoch: 59, Training Loss: 0.6636
2025-11-12 07:44:45,339 - INFO - Epoch: 60, Training Loss: 0.6632
2025-11-12 07:44:52,754 - INFO - Epoch: 61, Training Loss: 0.6635
2025-11-12 07:45:00,753 - INFO - Epoch: 62, Training Loss: 0.6637
2025-11-12 07:45:08,691 - INFO - Epoch: 63, Training Loss: 0.6638
2025-11-12 07:45:17,337 - INFO - Epoch: 64, Training Loss: 0.6639
2025-11-12 07:45:25,784 - INFO - Epoch: 65, Training Loss: 0.6637
2025-11-12 07:45:34,621 - INFO - Epoch: 66, Training Loss: 0.6642
2025-11-12 07:45:42,851 - INFO - Epoch: 67, Training Loss: 0.6640
2025-11-12 07:45:51,148 - INFO - Epoch: 68, Training Loss: 0.6642
2025-11-12 07:45:59,233 - INFO - Epoch: 69, Training Loss: 0.6634
2025-11-12 07:46:06,813 - INFO - Epoch: 70, Training Loss: 0.6638
2025-11-12 07:46:13,833 - INFO - Epoch: 71, Training Loss: 0.6638
2025-11-12 07:46:22,052 - INFO - Epoch: 72, Training Loss: 0.6640
2025-11-12 07:46:29,770 - INFO - Epoch: 73, Training Loss: 0.6638
2025-11-12 07:46:36,895 - INFO - Epoch: 74, Training Loss: 0.6632
2025-11-12 07:46:44,160 - INFO - Epoch: 75, Training Loss: 0.6634
2025-11-12 07:46:52,251 - INFO - Epoch: 76, Training Loss: 0.6636
2025-11-12 07:46:59,549 - INFO - Epoch: 77, Training Loss: 0.6636
2025-11-12 07:47:08,907 - INFO - Epoch: 78, Training Loss: 0.6638
2025-11-12 07:47:17,608 - INFO - Epoch: 79, Training Loss: 0.6635
2025-11-12 07:47:25,531 - INFO - Epoch: 80, Training Loss: 0.6634
2025-11-12 07:47:34,018 - INFO - Epoch: 81, Training Loss: 0.6637
2025-11-12 07:47:42,059 - INFO - Epoch: 82, Training Loss: 0.6636
2025-11-12 07:47:49,952 - INFO - Epoch: 83, Training Loss: 0.6638
2025-11-12 07:47:58,445 - INFO - Epoch: 84, Training Loss: 0.6641
2025-11-12 07:48:06,685 - INFO - Epoch: 85, Training Loss: 0.6632
2025-11-12 07:48:13,975 - INFO - Epoch: 86, Training Loss: 0.6634
2025-11-12 07:48:21,510 - INFO - Epoch: 87, Training Loss: 0.6635
2025-11-12 07:48:29,643 - INFO - Epoch: 88, Training Loss: 0.6639
2025-11-12 07:48:37,683 - INFO - Epoch: 89, Training Loss: 0.6639
2025-11-12 07:48:45,731 - INFO - Epoch: 90, Training Loss: 0.6636
2025-11-12 07:48:53,055 - INFO - Epoch: 91, Training Loss: 0.6636
2025-11-12 07:49:00,471 - INFO - Epoch: 92, Training Loss: 0.6636
2025-11-12 07:49:08,668 - INFO - Epoch: 93, Training Loss: 0.6633
2025-11-12 07:49:17,597 - INFO - Epoch: 94, Training Loss: 0.6639
2025-11-12 07:49:25,294 - INFO - Epoch: 95, Training Loss: 0.6634
2025-11-12 07:49:32,722 - INFO - Epoch: 96, Training Loss: 0.6633
2025-11-12 07:49:40,309 - INFO - Epoch: 97, Training Loss: 0.6628
2025-11-12 07:49:48,417 - INFO - Epoch: 98, Training Loss: 0.6636
2025-11-12 07:49:57,250 - INFO - Epoch: 99, Training Loss: 0.6636
2025-11-12 07:50:05,030 - INFO - Epoch: 100, Training Loss: 0.6637
2025-11-12 07:50:05,030 - INFO - Training completed for Trial 6 CV 3

