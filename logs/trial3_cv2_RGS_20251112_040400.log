2025-11-12 04:04:00,710 - INFO - Log file: ./logs/trial3_cv2_RGS_20251112_040400.log
2025-11-12 04:04:00,710 - INFO - START TRAINING TRIAL 3 CV 2 - Task: RGS
2025-11-12 04:04:00,710 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 04:04:00,711 - INFO - Loading dataset...
2025-11-12 04:04:00,800 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 04:04:00,800 - INFO - Initializing VIGNet model...
2025-11-12 04:04:00,803 - INFO - Number of batch iterations per epoch: 113
2025-11-12 04:04:08,491 - INFO - Epoch: 1, Training Loss: 0.9412
2025-11-12 04:04:15,699 - INFO - Epoch: 2, Training Loss: 0.7079
2025-11-12 04:04:23,642 - INFO - Epoch: 3, Training Loss: 0.7041
2025-11-12 04:04:32,658 - INFO - Epoch: 4, Training Loss: 0.6969
2025-11-12 04:04:40,507 - INFO - Epoch: 5, Training Loss: 0.7013
2025-11-12 04:04:48,831 - INFO - Epoch: 6, Training Loss: 0.6965
2025-11-12 04:04:57,167 - INFO - Epoch: 7, Training Loss: 0.6959
2025-11-12 04:05:05,253 - INFO - Epoch: 8, Training Loss: 0.6955
2025-11-12 04:05:13,092 - INFO - Epoch: 9, Training Loss: 0.6948
2025-11-12 04:05:20,625 - INFO - Epoch: 10, Training Loss: 0.6951
2025-11-12 04:05:29,150 - INFO - Epoch: 11, Training Loss: 0.6948
2025-11-12 04:05:37,352 - INFO - Epoch: 12, Training Loss: 0.6944
2025-11-12 04:05:45,681 - INFO - Epoch: 13, Training Loss: 0.6946
2025-11-12 04:05:54,143 - INFO - Epoch: 14, Training Loss: 0.6945
2025-11-12 04:06:02,043 - INFO - Epoch: 15, Training Loss: 0.6946
2025-11-12 04:06:10,378 - INFO - Epoch: 16, Training Loss: 0.6940
2025-11-12 04:06:18,062 - INFO - Epoch: 17, Training Loss: 0.6942
2025-11-12 04:06:26,668 - INFO - Epoch: 18, Training Loss: 0.6933
2025-11-12 04:06:34,803 - INFO - Epoch: 19, Training Loss: 0.6939
2025-11-12 04:06:43,627 - INFO - Epoch: 20, Training Loss: 0.6943
2025-11-12 04:06:51,929 - INFO - Epoch: 21, Training Loss: 0.6963
2025-11-12 04:06:59,432 - INFO - Epoch: 22, Training Loss: 0.6942
2025-11-12 04:07:07,900 - INFO - Epoch: 23, Training Loss: 0.6948
2025-11-12 04:07:15,805 - INFO - Epoch: 24, Training Loss: 0.6939
2025-11-12 04:07:23,664 - INFO - Epoch: 25, Training Loss: 0.6934
2025-11-12 04:07:31,523 - INFO - Epoch: 26, Training Loss: 0.6934
2025-11-12 04:07:40,421 - INFO - Epoch: 27, Training Loss: 0.6941
2025-11-12 04:07:49,100 - INFO - Epoch: 28, Training Loss: 0.6935
2025-11-12 04:07:57,201 - INFO - Epoch: 29, Training Loss: 0.6917
2025-11-12 04:08:04,977 - INFO - Epoch: 30, Training Loss: 0.6912
2025-11-12 04:08:13,148 - INFO - Epoch: 31, Training Loss: 0.6931
2025-11-12 04:08:20,987 - INFO - Epoch: 32, Training Loss: 0.6929
2025-11-12 04:08:29,649 - INFO - Epoch: 33, Training Loss: 0.6915
2025-11-12 04:08:37,129 - INFO - Epoch: 34, Training Loss: 0.6914
2025-11-12 04:08:44,848 - INFO - Epoch: 35, Training Loss: 0.6920
2025-11-12 04:08:52,310 - INFO - Epoch: 36, Training Loss: 0.6914
2025-11-12 04:09:00,136 - INFO - Epoch: 37, Training Loss: 0.6912
2025-11-12 04:09:07,954 - INFO - Epoch: 38, Training Loss: 0.6919
2025-11-12 04:09:15,834 - INFO - Epoch: 39, Training Loss: 0.6894
2025-11-12 04:09:24,061 - INFO - Epoch: 40, Training Loss: 0.6890
2025-11-12 04:09:31,555 - INFO - Epoch: 41, Training Loss: 0.6918
2025-11-12 04:09:40,358 - INFO - Epoch: 42, Training Loss: 0.6879
2025-11-12 04:09:47,891 - INFO - Epoch: 43, Training Loss: 0.6895
2025-11-12 04:09:55,705 - INFO - Epoch: 44, Training Loss: 0.6863
2025-11-12 04:10:03,272 - INFO - Epoch: 45, Training Loss: 0.6828
2025-11-12 04:10:11,456 - INFO - Epoch: 46, Training Loss: 0.6798
2025-11-12 04:10:18,785 - INFO - Epoch: 47, Training Loss: 0.6800
2025-11-12 04:10:26,862 - INFO - Epoch: 48, Training Loss: 0.6738
2025-11-12 04:10:35,170 - INFO - Epoch: 49, Training Loss: 0.6782
2025-11-12 04:10:42,885 - INFO - Epoch: 50, Training Loss: 0.6706
2025-11-12 04:10:50,290 - INFO - Epoch: 51, Training Loss: 0.6690
2025-11-12 04:10:57,730 - INFO - Epoch: 52, Training Loss: 0.6652
2025-11-12 04:11:05,429 - INFO - Epoch: 53, Training Loss: 0.6609
2025-11-12 04:11:14,036 - INFO - Epoch: 54, Training Loss: 0.6671
2025-11-12 04:11:21,698 - INFO - Epoch: 55, Training Loss: 0.6607
2025-11-12 04:11:29,046 - INFO - Epoch: 56, Training Loss: 0.6599
2025-11-12 04:11:37,176 - INFO - Epoch: 57, Training Loss: 0.6610
2025-11-12 04:11:46,530 - INFO - Epoch: 58, Training Loss: 0.6618
2025-11-12 04:11:54,531 - INFO - Epoch: 59, Training Loss: 0.6580
2025-11-12 04:12:02,178 - INFO - Epoch: 60, Training Loss: 0.7135
2025-11-12 04:12:10,016 - INFO - Epoch: 61, Training Loss: 0.6920
2025-11-12 04:12:18,482 - INFO - Epoch: 62, Training Loss: 0.6881
2025-11-12 04:12:26,517 - INFO - Epoch: 63, Training Loss: 0.6861
2025-11-12 04:12:34,688 - INFO - Epoch: 64, Training Loss: 0.6795
2025-11-12 04:12:43,102 - INFO - Epoch: 65, Training Loss: 0.6803
2025-11-12 04:12:50,897 - INFO - Epoch: 66, Training Loss: 0.6769
2025-11-12 04:12:58,967 - INFO - Epoch: 67, Training Loss: 0.6732
2025-11-12 04:13:06,671 - INFO - Epoch: 68, Training Loss: 0.6719
2025-11-12 04:13:14,784 - INFO - Epoch: 69, Training Loss: 0.6719
2025-11-12 04:13:22,594 - INFO - Epoch: 70, Training Loss: 0.6691
2025-11-12 04:13:30,095 - INFO - Epoch: 71, Training Loss: 0.6662
2025-11-12 04:13:37,858 - INFO - Epoch: 72, Training Loss: 0.6652
2025-11-12 04:13:46,551 - INFO - Epoch: 73, Training Loss: 0.6623
2025-11-12 04:13:54,913 - INFO - Epoch: 74, Training Loss: 0.6702
2025-11-12 04:14:02,106 - INFO - Epoch: 75, Training Loss: 0.6660
2025-11-12 04:14:10,018 - INFO - Epoch: 76, Training Loss: 0.6637
2025-11-12 04:14:18,537 - INFO - Epoch: 77, Training Loss: 0.6632
2025-11-12 04:14:27,007 - INFO - Epoch: 78, Training Loss: 0.6622
2025-11-12 04:14:34,659 - INFO - Epoch: 79, Training Loss: 0.6629
2025-11-12 04:14:43,258 - INFO - Epoch: 80, Training Loss: 0.6624
2025-11-12 04:14:51,451 - INFO - Epoch: 81, Training Loss: 0.6628
2025-11-12 04:14:59,970 - INFO - Epoch: 82, Training Loss: 0.6608
2025-11-12 04:15:07,872 - INFO - Epoch: 83, Training Loss: 0.6616
2025-11-12 04:15:16,549 - INFO - Epoch: 84, Training Loss: 0.6627
2025-11-12 04:15:24,939 - INFO - Epoch: 85, Training Loss: 0.6648
2025-11-12 04:15:32,889 - INFO - Epoch: 86, Training Loss: 0.6590
2025-11-12 04:15:41,710 - INFO - Epoch: 87, Training Loss: 0.6623
2025-11-12 04:15:49,583 - INFO - Epoch: 88, Training Loss: 0.6581
2025-11-12 04:15:57,768 - INFO - Epoch: 89, Training Loss: 0.6601
2025-11-12 04:16:05,625 - INFO - Epoch: 90, Training Loss: 0.6606
2025-11-12 04:16:14,074 - INFO - Epoch: 91, Training Loss: 0.6586
2025-11-12 04:16:21,869 - INFO - Epoch: 92, Training Loss: 0.6575
2025-11-12 04:16:30,768 - INFO - Epoch: 93, Training Loss: 0.6584
2025-11-12 04:16:39,064 - INFO - Epoch: 94, Training Loss: 0.6553
2025-11-12 04:16:46,777 - INFO - Epoch: 95, Training Loss: 0.6561
2025-11-12 04:16:54,564 - INFO - Epoch: 96, Training Loss: 0.6668
2025-11-12 04:17:01,868 - INFO - Epoch: 97, Training Loss: 0.6573
2025-11-12 04:17:09,298 - INFO - Epoch: 98, Training Loss: 0.6558
2025-11-12 04:17:17,552 - INFO - Epoch: 99, Training Loss: 0.6980
2025-11-12 04:17:25,248 - INFO - Epoch: 100, Training Loss: 0.6916
2025-11-12 04:17:25,249 - INFO - Training completed for Trial 3 CV 2

