2025-11-12 02:30:37,412 - INFO - Log file: ./logs/trial2_cv0_RGS_20251112_023037.log
2025-11-12 02:30:37,412 - INFO - START TRAINING TRIAL 2 CV 0 - Task: RGS
2025-11-12 02:30:37,412 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 02:30:37,412 - INFO - Loading dataset...
2025-11-12 02:30:37,501 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 02:30:37,501 - INFO - Initializing VIGNet model...
2025-11-12 02:30:37,504 - INFO - Number of batch iterations per epoch: 113
2025-11-12 02:30:45,690 - INFO - Epoch: 1, Training Loss: 1.1335
2025-11-12 02:30:53,157 - INFO - Epoch: 2, Training Loss: 0.9733
2025-11-12 02:31:00,702 - INFO - Epoch: 3, Training Loss: 0.7361
2025-11-12 02:31:08,873 - INFO - Epoch: 4, Training Loss: 0.6261
2025-11-12 02:31:16,882 - INFO - Epoch: 5, Training Loss: 0.6110
2025-11-12 02:31:25,014 - INFO - Epoch: 6, Training Loss: 0.6048
2025-11-12 02:31:32,509 - INFO - Epoch: 7, Training Loss: 0.6077
2025-11-12 02:31:40,666 - INFO - Epoch: 8, Training Loss: 0.6079
2025-11-12 02:31:49,450 - INFO - Epoch: 9, Training Loss: 0.6018
2025-11-12 02:31:57,109 - INFO - Epoch: 10, Training Loss: 0.6021
2025-11-12 02:32:04,959 - INFO - Epoch: 11, Training Loss: 0.6039
2025-11-12 02:32:12,985 - INFO - Epoch: 12, Training Loss: 0.6002
2025-11-12 02:32:20,340 - INFO - Epoch: 13, Training Loss: 0.6010
2025-11-12 02:32:28,119 - INFO - Epoch: 14, Training Loss: 0.6000
2025-11-12 02:32:35,168 - INFO - Epoch: 15, Training Loss: 0.5993
2025-11-12 02:32:43,401 - INFO - Epoch: 16, Training Loss: 0.6032
2025-11-12 02:32:51,484 - INFO - Epoch: 17, Training Loss: 0.6002
2025-11-12 02:32:59,757 - INFO - Epoch: 18, Training Loss: 0.5993
2025-11-12 02:33:06,756 - INFO - Epoch: 19, Training Loss: 0.5974
2025-11-12 02:33:14,673 - INFO - Epoch: 20, Training Loss: 0.5989
2025-11-12 02:33:22,364 - INFO - Epoch: 21, Training Loss: 0.5993
2025-11-12 02:33:31,500 - INFO - Epoch: 22, Training Loss: 0.5978
2025-11-12 02:33:39,979 - INFO - Epoch: 23, Training Loss: 0.6001
2025-11-12 02:33:48,319 - INFO - Epoch: 24, Training Loss: 0.5972
2025-11-12 02:33:56,283 - INFO - Epoch: 25, Training Loss: 0.5984
2025-11-12 02:34:04,499 - INFO - Epoch: 26, Training Loss: 0.5964
2025-11-12 02:34:12,558 - INFO - Epoch: 27, Training Loss: 0.5978
2025-11-12 02:34:22,017 - INFO - Epoch: 28, Training Loss: 0.5971
2025-11-12 02:34:29,366 - INFO - Epoch: 29, Training Loss: 0.5980
2025-11-12 02:34:37,278 - INFO - Epoch: 30, Training Loss: 0.5980
2025-11-12 02:34:44,815 - INFO - Epoch: 31, Training Loss: 0.5994
2025-11-12 02:34:52,648 - INFO - Epoch: 32, Training Loss: 0.5983
2025-11-12 02:35:02,092 - INFO - Epoch: 33, Training Loss: 0.5972
2025-11-12 02:35:10,813 - INFO - Epoch: 34, Training Loss: 0.5991
2025-11-12 02:35:18,221 - INFO - Epoch: 35, Training Loss: 0.5994
2025-11-12 02:35:26,008 - INFO - Epoch: 36, Training Loss: 0.5981
2025-11-12 02:35:33,838 - INFO - Epoch: 37, Training Loss: 0.5984
2025-11-12 02:35:41,658 - INFO - Epoch: 38, Training Loss: 0.5971
2025-11-12 02:35:49,764 - INFO - Epoch: 39, Training Loss: 0.5975
2025-11-12 02:35:58,156 - INFO - Epoch: 40, Training Loss: 0.5972
2025-11-12 02:36:05,488 - INFO - Epoch: 41, Training Loss: 0.5972
2025-11-12 02:36:13,991 - INFO - Epoch: 42, Training Loss: 0.5977
2025-11-12 02:36:21,969 - INFO - Epoch: 43, Training Loss: 0.5963
2025-11-12 02:36:30,120 - INFO - Epoch: 44, Training Loss: 0.5969
2025-11-12 02:36:39,090 - INFO - Epoch: 45, Training Loss: 0.5980
2025-11-12 02:36:47,785 - INFO - Epoch: 46, Training Loss: 0.5978
2025-11-12 02:36:55,927 - INFO - Epoch: 47, Training Loss: 0.5973
2025-11-12 02:37:03,785 - INFO - Epoch: 48, Training Loss: 0.5976
2025-11-12 02:37:12,340 - INFO - Epoch: 49, Training Loss: 0.5983
2025-11-12 02:37:20,119 - INFO - Epoch: 50, Training Loss: 0.5972
2025-11-12 02:37:27,775 - INFO - Epoch: 51, Training Loss: 0.5972
2025-11-12 02:37:35,931 - INFO - Epoch: 52, Training Loss: 0.5983
2025-11-12 02:37:44,491 - INFO - Epoch: 53, Training Loss: 0.5970
2025-11-12 02:37:51,959 - INFO - Epoch: 54, Training Loss: 0.5981
2025-11-12 02:37:59,150 - INFO - Epoch: 55, Training Loss: 0.5970
2025-11-12 02:38:06,989 - INFO - Epoch: 56, Training Loss: 0.5984
2025-11-12 02:38:14,310 - INFO - Epoch: 57, Training Loss: 0.5980
2025-11-12 02:38:22,381 - INFO - Epoch: 58, Training Loss: 0.5973
2025-11-12 02:38:30,607 - INFO - Epoch: 59, Training Loss: 0.5966
2025-11-12 02:38:39,247 - INFO - Epoch: 60, Training Loss: 0.5983
2025-11-12 02:38:48,406 - INFO - Epoch: 61, Training Loss: 0.5987
2025-11-12 02:38:56,053 - INFO - Epoch: 62, Training Loss: 0.5984
2025-11-12 02:39:03,405 - INFO - Epoch: 63, Training Loss: 0.5980
2025-11-12 02:39:11,658 - INFO - Epoch: 64, Training Loss: 0.5968
2025-11-12 02:39:19,454 - INFO - Epoch: 65, Training Loss: 0.5967
2025-11-12 02:39:26,847 - INFO - Epoch: 66, Training Loss: 0.5975
2025-11-12 02:39:34,800 - INFO - Epoch: 67, Training Loss: 0.5978
2025-11-12 02:39:42,707 - INFO - Epoch: 68, Training Loss: 0.5963
2025-11-12 02:39:50,622 - INFO - Epoch: 69, Training Loss: 0.5977
2025-11-12 02:39:58,248 - INFO - Epoch: 70, Training Loss: 0.5991
2025-11-12 02:40:05,867 - INFO - Epoch: 71, Training Loss: 0.5979
2025-11-12 02:40:13,862 - INFO - Epoch: 72, Training Loss: 0.5982
2025-11-12 02:40:21,754 - INFO - Epoch: 73, Training Loss: 0.5981
2025-11-12 02:40:30,345 - INFO - Epoch: 74, Training Loss: 0.5977
2025-11-12 02:40:37,911 - INFO - Epoch: 75, Training Loss: 0.5975
2025-11-12 02:40:46,297 - INFO - Epoch: 76, Training Loss: 0.5969
2025-11-12 02:40:55,046 - INFO - Epoch: 77, Training Loss: 0.5971
2025-11-12 02:41:02,326 - INFO - Epoch: 78, Training Loss: 0.5968
2025-11-12 02:41:10,307 - INFO - Epoch: 79, Training Loss: 0.5991
2025-11-12 02:41:17,866 - INFO - Epoch: 80, Training Loss: 0.5969
2025-11-12 02:41:25,834 - INFO - Epoch: 81, Training Loss: 0.5961
2025-11-12 02:41:33,556 - INFO - Epoch: 82, Training Loss: 0.5981
2025-11-12 02:41:41,383 - INFO - Epoch: 83, Training Loss: 0.5972
2025-11-12 02:41:48,887 - INFO - Epoch: 84, Training Loss: 0.5975
2025-11-12 02:41:56,830 - INFO - Epoch: 85, Training Loss: 0.5975
2025-11-12 02:42:04,880 - INFO - Epoch: 86, Training Loss: 0.5976
2025-11-12 02:42:13,221 - INFO - Epoch: 87, Training Loss: 0.5983
2025-11-12 02:42:21,899 - INFO - Epoch: 88, Training Loss: 0.5968
2025-11-12 02:42:30,307 - INFO - Epoch: 89, Training Loss: 0.5974
2025-11-12 02:42:37,703 - INFO - Epoch: 90, Training Loss: 0.5974
2025-11-12 02:42:46,219 - INFO - Epoch: 91, Training Loss: 0.5972
2025-11-12 02:42:54,409 - INFO - Epoch: 92, Training Loss: 0.5981
2025-11-12 02:43:02,259 - INFO - Epoch: 93, Training Loss: 0.5976
2025-11-12 02:43:10,266 - INFO - Epoch: 94, Training Loss: 0.5980
2025-11-12 02:43:18,419 - INFO - Epoch: 95, Training Loss: 0.5971
2025-11-12 02:43:26,017 - INFO - Epoch: 96, Training Loss: 0.5977
2025-11-12 02:43:33,996 - INFO - Epoch: 97, Training Loss: 0.5973
2025-11-12 02:43:42,436 - INFO - Epoch: 98, Training Loss: 0.5975
2025-11-12 02:43:50,580 - INFO - Epoch: 99, Training Loss: 0.5986
2025-11-12 02:43:58,067 - INFO - Epoch: 100, Training Loss: 0.5982
2025-11-12 02:43:58,067 - INFO - Training completed for Trial 2 CV 0

