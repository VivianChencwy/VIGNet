2025-11-12 05:23:57,750 - INFO - Log file: ./logs/trial4_cv3_RGS_20251112_052357.log
2025-11-12 05:23:57,750 - INFO - START TRAINING TRIAL 4 CV 3 - Task: RGS
2025-11-12 05:23:57,750 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 05:23:57,750 - INFO - Loading dataset...
2025-11-12 05:23:57,840 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 05:23:57,840 - INFO - Initializing VIGNet model...
2025-11-12 05:23:57,843 - INFO - Number of batch iterations per epoch: 113
2025-11-12 05:24:05,968 - INFO - Epoch: 1, Training Loss: 0.8087
2025-11-12 05:24:13,830 - INFO - Epoch: 2, Training Loss: 0.6548
2025-11-12 05:24:21,861 - INFO - Epoch: 3, Training Loss: 0.6459
2025-11-12 05:24:31,050 - INFO - Epoch: 4, Training Loss: 0.6477
2025-11-12 05:24:38,461 - INFO - Epoch: 5, Training Loss: 0.6431
2025-11-12 05:24:46,490 - INFO - Epoch: 6, Training Loss: 0.6429
2025-11-12 05:24:54,846 - INFO - Epoch: 7, Training Loss: 0.6441
2025-11-12 05:25:02,677 - INFO - Epoch: 8, Training Loss: 0.6423
2025-11-12 05:25:10,102 - INFO - Epoch: 9, Training Loss: 0.6418
2025-11-12 05:25:17,609 - INFO - Epoch: 10, Training Loss: 0.6423
2025-11-12 05:25:25,652 - INFO - Epoch: 11, Training Loss: 0.6416
2025-11-12 05:25:33,397 - INFO - Epoch: 12, Training Loss: 0.6422
2025-11-12 05:25:41,459 - INFO - Epoch: 13, Training Loss: 0.6410
2025-11-12 05:25:49,148 - INFO - Epoch: 14, Training Loss: 0.6416
2025-11-12 05:25:56,672 - INFO - Epoch: 15, Training Loss: 0.6408
2025-11-12 05:26:04,454 - INFO - Epoch: 16, Training Loss: 0.6426
2025-11-12 05:26:11,672 - INFO - Epoch: 17, Training Loss: 0.6412
2025-11-12 05:26:19,368 - INFO - Epoch: 18, Training Loss: 0.6411
2025-11-12 05:26:27,309 - INFO - Epoch: 19, Training Loss: 0.6423
2025-11-12 05:26:35,898 - INFO - Epoch: 20, Training Loss: 0.6408
2025-11-12 05:26:44,515 - INFO - Epoch: 21, Training Loss: 0.6421
2025-11-12 05:26:52,136 - INFO - Epoch: 22, Training Loss: 0.6396
2025-11-12 05:26:59,821 - INFO - Epoch: 23, Training Loss: 0.6419
2025-11-12 05:27:08,094 - INFO - Epoch: 24, Training Loss: 0.6404
2025-11-12 05:27:16,292 - INFO - Epoch: 25, Training Loss: 0.6402
2025-11-12 05:27:23,790 - INFO - Epoch: 26, Training Loss: 0.6402
2025-11-12 05:27:31,392 - INFO - Epoch: 27, Training Loss: 0.6383
2025-11-12 05:27:38,800 - INFO - Epoch: 28, Training Loss: 0.6398
2025-11-12 05:27:46,225 - INFO - Epoch: 29, Training Loss: 0.6369
2025-11-12 05:27:53,467 - INFO - Epoch: 30, Training Loss: 0.6385
2025-11-12 05:28:01,241 - INFO - Epoch: 31, Training Loss: 0.6336
2025-11-12 05:28:09,088 - INFO - Epoch: 32, Training Loss: 0.6265
2025-11-12 05:28:17,700 - INFO - Epoch: 33, Training Loss: 0.6183
2025-11-12 05:28:25,348 - INFO - Epoch: 34, Training Loss: 0.6051
2025-11-12 05:28:33,090 - INFO - Epoch: 35, Training Loss: 0.5974
2025-11-12 05:28:40,500 - INFO - Epoch: 36, Training Loss: 0.5992
2025-11-12 05:28:48,323 - INFO - Epoch: 37, Training Loss: 0.6322
2025-11-12 05:28:57,372 - INFO - Epoch: 38, Training Loss: 0.6327
2025-11-12 05:29:06,292 - INFO - Epoch: 39, Training Loss: 0.6215
2025-11-12 05:29:13,933 - INFO - Epoch: 40, Training Loss: 0.6080
2025-11-12 05:29:21,482 - INFO - Epoch: 41, Training Loss: 0.5962
2025-11-12 05:29:29,724 - INFO - Epoch: 42, Training Loss: 0.5912
2025-11-12 05:29:37,485 - INFO - Epoch: 43, Training Loss: 0.5917
2025-11-12 05:29:45,045 - INFO - Epoch: 44, Training Loss: 0.5902
2025-11-12 05:29:54,085 - INFO - Epoch: 45, Training Loss: 0.5889
2025-11-12 05:30:02,649 - INFO - Epoch: 46, Training Loss: 0.5945
2025-11-12 05:30:10,211 - INFO - Epoch: 47, Training Loss: 0.5907
2025-11-12 05:30:17,712 - INFO - Epoch: 48, Training Loss: 0.5886
2025-11-12 05:30:26,320 - INFO - Epoch: 49, Training Loss: 0.5885
2025-11-12 05:30:34,325 - INFO - Epoch: 50, Training Loss: 0.5873
2025-11-12 05:30:42,794 - INFO - Epoch: 51, Training Loss: 0.5889
2025-11-12 05:30:50,424 - INFO - Epoch: 52, Training Loss: 0.5875
2025-11-12 05:30:58,285 - INFO - Epoch: 53, Training Loss: 0.5884
2025-11-12 05:31:06,546 - INFO - Epoch: 54, Training Loss: 0.5895
2025-11-12 05:31:14,793 - INFO - Epoch: 55, Training Loss: 0.5887
2025-11-12 05:31:22,821 - INFO - Epoch: 56, Training Loss: 0.5868
2025-11-12 05:31:30,912 - INFO - Epoch: 57, Training Loss: 0.5883
2025-11-12 05:31:37,947 - INFO - Epoch: 58, Training Loss: 0.5901
2025-11-12 05:31:45,758 - INFO - Epoch: 59, Training Loss: 0.5873
2025-11-12 05:31:53,988 - INFO - Epoch: 60, Training Loss: 0.5866
2025-11-12 05:32:01,082 - INFO - Epoch: 61, Training Loss: 0.5876
2025-11-12 05:32:09,430 - INFO - Epoch: 62, Training Loss: 0.5874
2025-11-12 05:32:17,781 - INFO - Epoch: 63, Training Loss: 0.5864
2025-11-12 05:32:25,417 - INFO - Epoch: 64, Training Loss: 0.5866
2025-11-12 05:32:33,022 - INFO - Epoch: 65, Training Loss: 0.5843
2025-11-12 05:32:41,507 - INFO - Epoch: 66, Training Loss: 0.5861
2025-11-12 05:32:48,959 - INFO - Epoch: 67, Training Loss: 0.5843
2025-11-12 05:32:57,093 - INFO - Epoch: 68, Training Loss: 0.5857
2025-11-12 05:33:04,483 - INFO - Epoch: 69, Training Loss: 0.5877
2025-11-12 05:33:12,863 - INFO - Epoch: 70, Training Loss: 0.5844
2025-11-12 05:33:21,851 - INFO - Epoch: 71, Training Loss: 0.5841
2025-11-12 05:33:30,678 - INFO - Epoch: 72, Training Loss: 0.5850
2025-11-12 05:33:38,805 - INFO - Epoch: 73, Training Loss: 0.5841
2025-11-12 05:33:46,522 - INFO - Epoch: 74, Training Loss: 0.5852
2025-11-12 05:33:54,421 - INFO - Epoch: 75, Training Loss: 0.5848
2025-11-12 05:34:02,040 - INFO - Epoch: 76, Training Loss: 0.5828
2025-11-12 05:34:10,069 - INFO - Epoch: 77, Training Loss: 0.5845
2025-11-12 05:34:17,541 - INFO - Epoch: 78, Training Loss: 0.5920
2025-11-12 05:34:24,882 - INFO - Epoch: 79, Training Loss: 0.5832
2025-11-12 05:34:32,935 - INFO - Epoch: 80, Training Loss: 0.5858
2025-11-12 05:34:41,486 - INFO - Epoch: 81, Training Loss: 0.5887
2025-11-12 05:34:49,727 - INFO - Epoch: 82, Training Loss: 0.5829
2025-11-12 05:34:57,676 - INFO - Epoch: 83, Training Loss: 0.5831
2025-11-12 05:35:05,918 - INFO - Epoch: 84, Training Loss: 0.5837
2025-11-12 05:35:14,496 - INFO - Epoch: 85, Training Loss: 0.5822
2025-11-12 05:35:22,829 - INFO - Epoch: 86, Training Loss: 0.5953
2025-11-12 05:35:30,817 - INFO - Epoch: 87, Training Loss: 0.5857
2025-11-12 05:35:38,605 - INFO - Epoch: 88, Training Loss: 0.5840
2025-11-12 05:35:46,122 - INFO - Epoch: 89, Training Loss: 0.5811
2025-11-12 05:35:53,923 - INFO - Epoch: 90, Training Loss: 0.5819
2025-11-12 05:36:02,295 - INFO - Epoch: 91, Training Loss: 0.5824
2025-11-12 05:36:09,754 - INFO - Epoch: 92, Training Loss: 0.5816
2025-11-12 05:36:17,677 - INFO - Epoch: 93, Training Loss: 0.5817
2025-11-12 05:36:25,938 - INFO - Epoch: 94, Training Loss: 0.5829
2025-11-12 05:36:33,973 - INFO - Epoch: 95, Training Loss: 0.5816
2025-11-12 05:36:41,618 - INFO - Epoch: 96, Training Loss: 0.5790
2025-11-12 05:36:49,167 - INFO - Epoch: 97, Training Loss: 0.5827
2025-11-12 05:36:57,531 - INFO - Epoch: 98, Training Loss: 0.5819
2025-11-12 05:37:04,968 - INFO - Epoch: 99, Training Loss: 0.5802
2025-11-12 05:37:12,429 - INFO - Epoch: 100, Training Loss: 0.5788
2025-11-12 05:37:12,429 - INFO - Training completed for Trial 4 CV 3

