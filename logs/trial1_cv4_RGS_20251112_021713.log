2025-11-12 02:17:13,030 - INFO - Log file: ./logs/trial1_cv4_RGS_20251112_021713.log
2025-11-12 02:17:13,030 - INFO - START TRAINING TRIAL 1 CV 4 - Task: RGS
2025-11-12 02:17:13,031 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 02:17:13,031 - INFO - Loading dataset...
2025-11-12 02:17:13,120 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 02:17:13,120 - INFO - Initializing VIGNet model...
2025-11-12 02:17:13,124 - INFO - Number of batch iterations per epoch: 113
2025-11-12 02:17:20,939 - INFO - Epoch: 1, Training Loss: 1.4398
2025-11-12 02:17:28,980 - INFO - Epoch: 2, Training Loss: 0.7103
2025-11-12 02:17:37,135 - INFO - Epoch: 3, Training Loss: 0.6955
2025-11-12 02:17:45,385 - INFO - Epoch: 4, Training Loss: 0.6528
2025-11-12 02:17:53,949 - INFO - Epoch: 5, Training Loss: 0.6531
2025-11-12 02:18:01,729 - INFO - Epoch: 6, Training Loss: 0.6481
2025-11-12 02:18:09,984 - INFO - Epoch: 7, Training Loss: 0.6463
2025-11-12 02:18:18,256 - INFO - Epoch: 8, Training Loss: 0.6447
2025-11-12 02:18:26,039 - INFO - Epoch: 9, Training Loss: 0.6427
2025-11-12 02:18:34,033 - INFO - Epoch: 10, Training Loss: 0.6428
2025-11-12 02:18:42,030 - INFO - Epoch: 11, Training Loss: 0.6413
2025-11-12 02:18:50,232 - INFO - Epoch: 12, Training Loss: 0.6397
2025-11-12 02:18:57,411 - INFO - Epoch: 13, Training Loss: 0.6417
2025-11-12 02:19:04,734 - INFO - Epoch: 14, Training Loss: 0.6405
2025-11-12 02:19:12,167 - INFO - Epoch: 15, Training Loss: 0.6418
2025-11-12 02:19:20,386 - INFO - Epoch: 16, Training Loss: 0.6381
2025-11-12 02:19:29,064 - INFO - Epoch: 17, Training Loss: 0.6361
2025-11-12 02:19:36,969 - INFO - Epoch: 18, Training Loss: 0.6339
2025-11-12 02:19:44,289 - INFO - Epoch: 19, Training Loss: 0.6402
2025-11-12 02:19:52,855 - INFO - Epoch: 20, Training Loss: 0.6317
2025-11-12 02:20:00,791 - INFO - Epoch: 21, Training Loss: 0.6319
2025-11-12 02:20:08,250 - INFO - Epoch: 22, Training Loss: 0.6281
2025-11-12 02:20:15,827 - INFO - Epoch: 23, Training Loss: 0.6237
2025-11-12 02:20:23,826 - INFO - Epoch: 24, Training Loss: 0.6077
2025-11-12 02:20:31,665 - INFO - Epoch: 25, Training Loss: 0.5941
2025-11-12 02:20:39,967 - INFO - Epoch: 26, Training Loss: 0.5439
2025-11-12 02:20:48,457 - INFO - Epoch: 27, Training Loss: 0.5219
2025-11-12 02:20:56,242 - INFO - Epoch: 28, Training Loss: 1.0146
2025-11-12 02:21:03,776 - INFO - Epoch: 29, Training Loss: 5.1495
2025-11-12 02:21:11,369 - INFO - Epoch: 30, Training Loss: 5.1798
2025-11-12 02:21:18,962 - INFO - Epoch: 31, Training Loss: 5.1587
2025-11-12 02:21:26,990 - INFO - Epoch: 32, Training Loss: 5.1454
2025-11-12 02:21:35,439 - INFO - Epoch: 33, Training Loss: 5.1409
2025-11-12 02:21:43,150 - INFO - Epoch: 34, Training Loss: 5.1653
2025-11-12 02:21:50,579 - INFO - Epoch: 35, Training Loss: 5.1644
2025-11-12 02:21:58,247 - INFO - Epoch: 36, Training Loss: 5.1786
2025-11-12 02:22:06,029 - INFO - Epoch: 37, Training Loss: 5.1782
2025-11-12 02:22:14,469 - INFO - Epoch: 38, Training Loss: 5.1797
2025-11-12 02:22:22,140 - INFO - Epoch: 39, Training Loss: 5.1749
2025-11-12 02:22:29,944 - INFO - Epoch: 40, Training Loss: 5.1495
2025-11-12 02:22:37,853 - INFO - Epoch: 41, Training Loss: 5.1634
2025-11-12 02:22:46,693 - INFO - Epoch: 42, Training Loss: 5.1618
2025-11-12 02:22:54,951 - INFO - Epoch: 43, Training Loss: 5.1523
2025-11-12 02:23:03,868 - INFO - Epoch: 44, Training Loss: 5.1462
2025-11-12 02:23:12,993 - INFO - Epoch: 45, Training Loss: 5.1634
2025-11-12 02:23:21,467 - INFO - Epoch: 46, Training Loss: 5.1453
2025-11-12 02:23:29,182 - INFO - Epoch: 47, Training Loss: 5.1480
2025-11-12 02:23:36,905 - INFO - Epoch: 48, Training Loss: 5.1621
2025-11-12 02:23:44,699 - INFO - Epoch: 49, Training Loss: 5.1798
2025-11-12 02:23:52,892 - INFO - Epoch: 50, Training Loss: 5.1555
2025-11-12 02:24:00,529 - INFO - Epoch: 51, Training Loss: 5.1630
2025-11-12 02:24:08,947 - INFO - Epoch: 52, Training Loss: 5.1798
2025-11-12 02:24:16,681 - INFO - Epoch: 53, Training Loss: 5.1654
2025-11-12 02:24:24,884 - INFO - Epoch: 54, Training Loss: 5.1470
2025-11-12 02:24:33,298 - INFO - Epoch: 55, Training Loss: 5.1636
2025-11-12 02:24:40,506 - INFO - Epoch: 56, Training Loss: 5.1595
2025-11-12 02:24:48,674 - INFO - Epoch: 57, Training Loss: 5.1798
2025-11-12 02:24:55,903 - INFO - Epoch: 58, Training Loss: 5.1474
2025-11-12 02:25:03,953 - INFO - Epoch: 59, Training Loss: 5.1798
2025-11-12 02:25:12,018 - INFO - Epoch: 60, Training Loss: 5.1635
2025-11-12 02:25:20,220 - INFO - Epoch: 61, Training Loss: 5.1633
2025-11-12 02:25:28,192 - INFO - Epoch: 62, Training Loss: 5.1627
2025-11-12 02:25:35,842 - INFO - Epoch: 63, Training Loss: 5.1627
2025-11-12 02:25:44,796 - INFO - Epoch: 64, Training Loss: 5.1628
2025-11-12 02:25:52,192 - INFO - Epoch: 65, Training Loss: 5.1484
2025-11-12 02:26:00,177 - INFO - Epoch: 66, Training Loss: 5.1648
2025-11-12 02:26:08,849 - INFO - Epoch: 67, Training Loss: 5.1620
2025-11-12 02:26:17,453 - INFO - Epoch: 68, Training Loss: 5.1474
2025-11-12 02:26:25,526 - INFO - Epoch: 69, Training Loss: 5.1635
2025-11-12 02:26:33,819 - INFO - Epoch: 70, Training Loss: 5.1557
2025-11-12 02:26:42,213 - INFO - Epoch: 71, Training Loss: 5.1662
2025-11-12 02:26:50,008 - INFO - Epoch: 72, Training Loss: 5.1735
2025-11-12 02:26:58,501 - INFO - Epoch: 73, Training Loss: 5.1788
2025-11-12 02:27:07,374 - INFO - Epoch: 74, Training Loss: 5.1650
2025-11-12 02:27:15,371 - INFO - Epoch: 75, Training Loss: 5.1619
2025-11-12 02:27:23,282 - INFO - Epoch: 76, Training Loss: 5.1782
2025-11-12 02:27:32,121 - INFO - Epoch: 77, Training Loss: 5.1788
2025-11-12 02:27:40,103 - INFO - Epoch: 78, Training Loss: 5.1522
2025-11-12 02:27:49,121 - INFO - Epoch: 79, Training Loss: 5.1653
2025-11-12 02:27:57,317 - INFO - Epoch: 80, Training Loss: 5.1654
2025-11-12 02:28:05,440 - INFO - Epoch: 81, Training Loss: 5.1664
2025-11-12 02:28:12,803 - INFO - Epoch: 82, Training Loss: 5.1620
2025-11-12 02:28:21,021 - INFO - Epoch: 83, Training Loss: 5.1616
2025-11-12 02:28:28,763 - INFO - Epoch: 84, Training Loss: 5.1798
2025-11-12 02:28:37,667 - INFO - Epoch: 85, Training Loss: 5.1797
2025-11-12 02:28:45,020 - INFO - Epoch: 86, Training Loss: 5.1625
2025-11-12 02:28:53,393 - INFO - Epoch: 87, Training Loss: 5.1798
2025-11-12 02:29:01,047 - INFO - Epoch: 88, Training Loss: 5.1474
2025-11-12 02:29:09,441 - INFO - Epoch: 89, Training Loss: 5.1635
2025-11-12 02:29:16,874 - INFO - Epoch: 90, Training Loss: 5.1431
2025-11-12 02:29:24,587 - INFO - Epoch: 91, Training Loss: 5.1798
2025-11-12 02:29:33,333 - INFO - Epoch: 92, Training Loss: 5.1623
2025-11-12 02:29:40,992 - INFO - Epoch: 93, Training Loss: 5.1432
2025-11-12 02:29:49,876 - INFO - Epoch: 94, Training Loss: 5.1612
2025-11-12 02:29:58,052 - INFO - Epoch: 95, Training Loss: 5.1794
2025-11-12 02:30:06,260 - INFO - Epoch: 96, Training Loss: 5.1645
2025-11-12 02:30:14,068 - INFO - Epoch: 97, Training Loss: 5.1774
2025-11-12 02:30:22,227 - INFO - Epoch: 98, Training Loss: 5.1798
2025-11-12 02:30:30,092 - INFO - Epoch: 99, Training Loss: 5.1487
2025-11-12 02:30:37,411 - INFO - Epoch: 100, Training Loss: 5.1521
2025-11-12 02:30:37,411 - INFO - Training completed for Trial 1 CV 4

