2025-11-12 07:50:05,031 - INFO - Log file: ./logs/trial6_cv4_RGS_20251112_075005.log
2025-11-12 07:50:05,031 - INFO - START TRAINING TRIAL 6 CV 4 - Task: RGS
2025-11-12 07:50:05,031 - INFO - Learning rate: 0.001, Epochs: 100, Batches: 5
2025-11-12 07:50:05,031 - INFO - Loading dataset...
2025-11-12 07:50:05,120 - INFO - Dataset shapes - Train: (567, 17, 25, 1), Valid: (141, 17, 25, 1), Test: (177, 17, 25, 1)
2025-11-12 07:50:05,120 - INFO - Initializing VIGNet model...
2025-11-12 07:50:05,123 - INFO - Number of batch iterations per epoch: 113
2025-11-12 07:50:12,679 - INFO - Epoch: 1, Training Loss: 0.8379
2025-11-12 07:50:20,796 - INFO - Epoch: 2, Training Loss: 0.6689
2025-11-12 07:50:28,993 - INFO - Epoch: 3, Training Loss: 0.6654
2025-11-12 07:50:37,024 - INFO - Epoch: 4, Training Loss: 0.6651
2025-11-12 07:50:45,226 - INFO - Epoch: 5, Training Loss: 0.6641
2025-11-12 07:50:53,891 - INFO - Epoch: 6, Training Loss: 0.6648
2025-11-12 07:51:01,851 - INFO - Epoch: 7, Training Loss: 0.6651
2025-11-12 07:51:10,397 - INFO - Epoch: 8, Training Loss: 0.6650
2025-11-12 07:51:19,425 - INFO - Epoch: 9, Training Loss: 0.6645
2025-11-12 07:51:26,904 - INFO - Epoch: 10, Training Loss: 0.6643
2025-11-12 07:51:35,542 - INFO - Epoch: 11, Training Loss: 0.6653
2025-11-12 07:51:43,240 - INFO - Epoch: 12, Training Loss: 0.6646
2025-11-12 07:51:50,913 - INFO - Epoch: 13, Training Loss: 0.6642
2025-11-12 07:51:59,386 - INFO - Epoch: 14, Training Loss: 0.6648
2025-11-12 07:52:07,484 - INFO - Epoch: 15, Training Loss: 0.6644
2025-11-12 07:52:16,247 - INFO - Epoch: 16, Training Loss: 0.6643
2025-11-12 07:52:25,175 - INFO - Epoch: 17, Training Loss: 0.6650
2025-11-12 07:52:32,743 - INFO - Epoch: 18, Training Loss: 0.6650
2025-11-12 07:52:40,391 - INFO - Epoch: 19, Training Loss: 0.6653
2025-11-12 07:52:49,213 - INFO - Epoch: 20, Training Loss: 0.6643
2025-11-12 07:52:56,621 - INFO - Epoch: 21, Training Loss: 0.6648
2025-11-12 07:53:04,568 - INFO - Epoch: 22, Training Loss: 0.6645
2025-11-12 07:53:13,086 - INFO - Epoch: 23, Training Loss: 0.6646
2025-11-12 07:53:21,685 - INFO - Epoch: 24, Training Loss: 0.6647
2025-11-12 07:53:29,519 - INFO - Epoch: 25, Training Loss: 0.6648
2025-11-12 07:53:37,040 - INFO - Epoch: 26, Training Loss: 0.6647
2025-11-12 07:53:44,491 - INFO - Epoch: 27, Training Loss: 0.6645
2025-11-12 07:53:52,993 - INFO - Epoch: 28, Training Loss: 0.6642
2025-11-12 07:54:01,623 - INFO - Epoch: 29, Training Loss: 0.6643
2025-11-12 07:54:09,076 - INFO - Epoch: 30, Training Loss: 0.6644
2025-11-12 07:54:16,810 - INFO - Epoch: 31, Training Loss: 0.6644
2025-11-12 07:54:24,362 - INFO - Epoch: 32, Training Loss: 0.6647
2025-11-12 07:54:32,173 - INFO - Epoch: 33, Training Loss: 0.6645
2025-11-12 07:54:40,023 - INFO - Epoch: 34, Training Loss: 0.6642
2025-11-12 07:54:47,575 - INFO - Epoch: 35, Training Loss: 0.6640
2025-11-12 07:54:55,234 - INFO - Epoch: 36, Training Loss: 0.6649
2025-11-12 07:55:02,731 - INFO - Epoch: 37, Training Loss: 0.6644
2025-11-12 07:55:11,296 - INFO - Epoch: 38, Training Loss: 0.6652
2025-11-12 07:55:19,789 - INFO - Epoch: 39, Training Loss: 0.6645
2025-11-12 07:55:27,714 - INFO - Epoch: 40, Training Loss: 0.6648
2025-11-12 07:55:35,125 - INFO - Epoch: 41, Training Loss: 0.6640
2025-11-12 07:55:42,205 - INFO - Epoch: 42, Training Loss: 0.6641
2025-11-12 07:55:49,665 - INFO - Epoch: 43, Training Loss: 0.6641
2025-11-12 07:55:57,897 - INFO - Epoch: 44, Training Loss: 0.6639
2025-11-12 07:56:05,901 - INFO - Epoch: 45, Training Loss: 0.6646
2025-11-12 07:56:14,387 - INFO - Epoch: 46, Training Loss: 0.6644
2025-11-12 07:56:22,478 - INFO - Epoch: 47, Training Loss: 0.6653
2025-11-12 07:56:30,629 - INFO - Epoch: 48, Training Loss: 0.6640
2025-11-12 07:56:38,538 - INFO - Epoch: 49, Training Loss: 0.6645
2025-11-12 07:56:46,315 - INFO - Epoch: 50, Training Loss: 0.6641
2025-11-12 07:56:54,943 - INFO - Epoch: 51, Training Loss: 0.6643
2025-11-12 07:57:03,331 - INFO - Epoch: 52, Training Loss: 0.6654
2025-11-12 07:57:10,494 - INFO - Epoch: 53, Training Loss: 0.6647
2025-11-12 07:57:18,400 - INFO - Epoch: 54, Training Loss: 0.6640
2025-11-12 07:57:26,549 - INFO - Epoch: 55, Training Loss: 0.6645
2025-11-12 07:57:34,063 - INFO - Epoch: 56, Training Loss: 0.6647
2025-11-12 07:57:42,222 - INFO - Epoch: 57, Training Loss: 0.6647
2025-11-12 07:57:50,065 - INFO - Epoch: 58, Training Loss: 0.6649
2025-11-12 07:57:57,949 - INFO - Epoch: 59, Training Loss: 0.6644
2025-11-12 07:58:06,208 - INFO - Epoch: 60, Training Loss: 0.6647
2025-11-12 07:58:14,132 - INFO - Epoch: 61, Training Loss: 0.6645
2025-11-12 07:58:21,783 - INFO - Epoch: 62, Training Loss: 0.6654
2025-11-12 07:58:29,871 - INFO - Epoch: 63, Training Loss: 0.6645
2025-11-12 07:58:38,055 - INFO - Epoch: 64, Training Loss: 0.6643
2025-11-12 07:58:45,656 - INFO - Epoch: 65, Training Loss: 0.6638
2025-11-12 07:58:53,153 - INFO - Epoch: 66, Training Loss: 0.6656
2025-11-12 07:59:01,868 - INFO - Epoch: 67, Training Loss: 0.6651
2025-11-12 07:59:10,902 - INFO - Epoch: 68, Training Loss: 0.6645
2025-11-12 07:59:19,408 - INFO - Epoch: 69, Training Loss: 0.6643
2025-11-12 07:59:27,162 - INFO - Epoch: 70, Training Loss: 0.6644
2025-11-12 07:59:34,883 - INFO - Epoch: 71, Training Loss: 0.6643
2025-11-12 07:59:43,026 - INFO - Epoch: 72, Training Loss: 0.6650
2025-11-12 07:59:51,197 - INFO - Epoch: 73, Training Loss: 0.6643
2025-11-12 07:59:59,107 - INFO - Epoch: 74, Training Loss: 0.6650
2025-11-12 08:00:06,547 - INFO - Epoch: 75, Training Loss: 0.6644
2025-11-12 08:00:14,551 - INFO - Epoch: 76, Training Loss: 0.6647
2025-11-12 08:00:22,314 - INFO - Epoch: 77, Training Loss: 0.6643
2025-11-12 08:00:29,714 - INFO - Epoch: 78, Training Loss: 0.6643
2025-11-12 08:00:37,578 - INFO - Epoch: 79, Training Loss: 0.6645
2025-11-12 08:00:46,083 - INFO - Epoch: 80, Training Loss: 0.6640
2025-11-12 08:00:54,255 - INFO - Epoch: 81, Training Loss: 0.6647
2025-11-12 08:01:01,871 - INFO - Epoch: 82, Training Loss: 0.6644
2025-11-12 08:01:09,822 - INFO - Epoch: 83, Training Loss: 0.6644
2025-11-12 08:01:17,567 - INFO - Epoch: 84, Training Loss: 0.6655
2025-11-12 08:01:24,956 - INFO - Epoch: 85, Training Loss: 0.6648
2025-11-12 08:01:32,783 - INFO - Epoch: 86, Training Loss: 0.6645
2025-11-12 08:01:40,489 - INFO - Epoch: 87, Training Loss: 0.6644
2025-11-12 08:01:49,042 - INFO - Epoch: 88, Training Loss: 0.6637
2025-11-12 08:01:56,608 - INFO - Epoch: 89, Training Loss: 0.6651
2025-11-12 08:02:04,732 - INFO - Epoch: 90, Training Loss: 0.6642
2025-11-12 08:02:12,244 - INFO - Epoch: 91, Training Loss: 0.6648
2025-11-12 08:02:20,328 - INFO - Epoch: 92, Training Loss: 0.6649
2025-11-12 08:02:28,946 - INFO - Epoch: 93, Training Loss: 0.6643
2025-11-12 08:02:36,509 - INFO - Epoch: 94, Training Loss: 0.6644
2025-11-12 08:02:44,072 - INFO - Epoch: 95, Training Loss: 0.6643
2025-11-12 08:02:51,751 - INFO - Epoch: 96, Training Loss: 0.6652
2025-11-12 08:02:59,180 - INFO - Epoch: 97, Training Loss: 0.6651
2025-11-12 08:03:06,663 - INFO - Epoch: 98, Training Loss: 0.6653
2025-11-12 08:03:14,665 - INFO - Epoch: 99, Training Loss: 0.6644
2025-11-12 08:03:22,065 - INFO - Epoch: 100, Training Loss: 0.6643
2025-11-12 08:03:22,065 - INFO - Training completed for Trial 6 CV 4

