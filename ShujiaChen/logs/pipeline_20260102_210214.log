2026-01-02 21:02:14,468 - ======================================================================
2026-01-02 21:02:14,468 - DATA PROCESSING AND MODELING PIPELINE
2026-01-02 21:02:14,468 - ======================================================================
2026-01-02 21:02:14,468 - Data directory: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen
2026-01-02 21:02:14,468 - Start time: 2026-01-02 21:02:14
2026-01-02 21:02:14,468 - Log file: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/pipeline_20260102_210214.log
2026-01-02 21:02:14,468 - 
2026-01-02 21:02:14,468 - ============================================================
2026-01-02 21:02:14,468 - STEP 1: Loading and Trimming Data
2026-01-02 21:02:14,468 - ============================================================
2026-01-02 21:02:14,468 - Loading data from: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/merged_data.csv
2026-01-02 21:02:16,038 - Loaded 1161176 samples
2026-01-02 21:02:16,038 - Original duration: 2327.41s (38.79 min)
2026-01-02 21:02:16,047 - Original sampling rate: 528.26 Hz
2026-01-02 21:02:16,047 - Trimming: first 300.0s, last 0.0s
2026-01-02 21:02:16,169 - After trimming: 2027.41s (33.79 min)
2026-01-02 21:02:16,169 - Samples after trimming: 1011464
2026-01-02 21:02:16,172 - ============================================================
2026-01-02 21:02:16,172 - STEP 2: Resampling
2026-01-02 21:02:16,172 - ============================================================
2026-01-02 21:02:16,172 - Resampling from 528.26 Hz to 200 Hz
2026-01-02 21:02:16,172 - Samples: 1011464 -> 382940
2026-01-02 21:02:16,404 - ============================================================
2026-01-02 21:02:16,404 - STEP 3: Segmentation
2026-01-02 21:02:16,404 - ============================================================
2026-01-02 21:02:16,405 - Created 477 windows
2026-01-02 21:02:16,405 - Window shape: 1600 samples x 2 channels
2026-01-02 21:02:16,405 - ============================================================
2026-01-02 21:02:16,405 - STEP 4: Extracting DE Features
2026-01-02 21:02:16,405 - ============================================================
2026-01-02 21:02:16,405 - Extracting DE for 477 windows, 2 channels, 25 bands
2026-01-02 21:02:17,107 -   Processing window 100/477
2026-01-02 21:02:17,815 -   Processing window 200/477
2026-01-02 21:02:18,536 -   Processing window 300/477
2026-01-02 21:02:19,245 -   Processing window 400/477
2026-01-02 21:02:19,794 -   Processing window 477/477
2026-01-02 21:02:19,801 - DE features shape: (2, 477, 25)
2026-01-02 21:02:19,801 - ============================================================
2026-01-02 21:02:19,801 - STEP 5: Applying Smoothing
2026-01-02 21:02:19,801 - ============================================================
2026-01-02 21:02:19,801 - Applying moving average (window=5)...
2026-01-02 21:02:19,802 - Applying LDS (Kalman filter) smoothing...
2026-01-02 21:02:21,658 - Smoothing completed
2026-01-02 21:02:21,658 - ============================================================
2026-01-02 21:02:21,658 - STEP 6: Computing PERCLOS Labels
2026-01-02 21:02:21,658 - ============================================================
2026-01-02 21:02:21,872 - Unique eye states in data: ['close' 'open']
2026-01-02 21:02:21,881 - Eye closed samples: 16342.0 / 1011464 (1.62%)
2026-01-02 21:02:21,881 - Computing PERCLOS with 60.0s window...
2026-01-02 21:02:22,191 - PERCLOS range: [0.0000, 0.0553]
2026-01-02 21:02:22,192 - PERCLOS mean: 0.0163, std: 0.0127
2026-01-02 21:02:22,192 - Distribution: Awake=477 (100.0%), Tired=0 (0.0%), Drowsy=0 (0.0%)
2026-01-02 21:02:22,192 - ============================================================
2026-01-02 21:02:22,192 - STEP 7: Saving Preprocessed Data
2026-01-02 21:02:22,192 - ============================================================
2026-01-02 21:02:22,192 - Saved DE features: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/processed/de_features.npy
2026-01-02 21:02:22,192 -   Shape: (477, 2, 25)
2026-01-02 21:02:22,192 - Saved PERCLOS labels: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/processed/perclos_labels.npy
2026-01-02 21:02:22,192 - Saved timestamps: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/processed/timestamps.npy
2026-01-02 21:02:22,192 - Saved metadata: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/processed/metadata.npy
2026-01-02 21:02:22,192 - ============================================================
2026-01-02 21:02:22,192 - STEP 8: Data Splitting (Block-wise Random)
2026-01-02 21:02:22,192 - ============================================================
2026-01-02 21:02:22,192 - Created 47 blocks (block_size=8, gap=2)
2026-01-02 21:02:22,192 - Split results:
2026-01-02 21:02:22,193 -   Train: 256 samples (68.1%)
2026-01-02 21:02:22,193 -   Valid: 56 samples (14.9%)
2026-01-02 21:02:22,193 -   Test:  64 samples (17.0%)
2026-01-02 21:02:22,193 -   Discarded (gaps): 101 samples
2026-01-02 21:02:22,193 - ============================================================
2026-01-02 21:02:22,193 - STEP 9-10: Model Training
2026-01-02 21:02:22,193 - ============================================================
2026-01-02 21:02:22,220 - Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
2026-01-02 21:02:22,220 - Train: (256, 2, 25), Val: (56, 2, 25), Test: (64, 2, 25)
2026-01-02 21:02:22,220 - Applied StandardScaler normalization
2026-01-02 21:02:22,579 - Learning rate: 0.005
2026-01-02 21:02:22,579 - Max epochs: 500
2026-01-02 21:02:22,579 - Batch size: 8
2026-01-02 21:02:22,579 - Early stopping patience: 50
2026-01-02 21:02:25,439 - Epoch   1: Train Loss = 0.002501, Val Loss = 0.000367
2026-01-02 21:02:25,440 -   -> New best validation loss: 0.000367
2026-01-02 21:02:27,799 - Epoch   2: Train Loss = 0.000390, Val Loss = 0.000236
2026-01-02 21:02:27,800 -   -> New best validation loss: 0.000236
2026-01-02 21:02:30,117 - Epoch   3: Train Loss = 0.000251, Val Loss = 0.000350
2026-01-02 21:02:32,481 - Epoch   4: Train Loss = 0.000222, Val Loss = 0.000292
2026-01-02 21:02:34,837 - Epoch   5: Train Loss = 0.000189, Val Loss = 0.000347
2026-01-02 21:02:37,230 - Epoch   6: Train Loss = 0.000185, Val Loss = 0.000222
2026-01-02 21:02:37,231 -   -> New best validation loss: 0.000222
2026-01-02 21:02:39,511 - Epoch   7: Train Loss = 0.000154, Val Loss = 0.000300
2026-01-02 21:02:41,816 - Epoch   8: Train Loss = 0.000143, Val Loss = 0.000268
2026-01-02 21:02:44,095 - Epoch   9: Train Loss = 0.000147, Val Loss = 0.000304
2026-01-02 21:02:46,435 - Epoch  10: Train Loss = 0.000142, Val Loss = 0.000386
2026-01-02 21:02:48,767 - Epoch  11: Train Loss = 0.000151, Val Loss = 0.000232
2026-01-02 21:02:51,104 - Epoch  12: Train Loss = 0.000149, Val Loss = 0.000347
2026-01-02 21:02:53,425 - Epoch  13: Train Loss = 0.000133, Val Loss = 0.000242
2026-01-02 21:02:55,739 - Epoch  14: Train Loss = 0.000141, Val Loss = 0.000217
2026-01-02 21:02:55,740 -   -> New best validation loss: 0.000217
2026-01-02 21:02:58,049 - Epoch  15: Train Loss = 0.000131, Val Loss = 0.000209
2026-01-02 21:02:58,050 -   -> New best validation loss: 0.000209
2026-01-02 21:03:00,431 - Epoch  16: Train Loss = 0.000143, Val Loss = 0.000220
2026-01-02 21:03:02,723 - Epoch  17: Train Loss = 0.000142, Val Loss = 0.000203
2026-01-02 21:03:02,724 -   -> New best validation loss: 0.000203
2026-01-02 21:03:05,037 - Epoch  18: Train Loss = 0.000149, Val Loss = 0.000228
2026-01-02 21:03:07,353 - Epoch  19: Train Loss = 0.000119, Val Loss = 0.000211
2026-01-02 21:03:09,760 - Epoch  20: Train Loss = 0.000120, Val Loss = 0.000430
2026-01-02 21:03:12,105 - Epoch  21: Train Loss = 0.000113, Val Loss = 0.000248
2026-01-02 21:03:14,424 - Epoch  22: Train Loss = 0.000120, Val Loss = 0.000230
2026-01-02 21:03:16,784 - Epoch  23: Train Loss = 0.000116, Val Loss = 0.000200
2026-01-02 21:03:16,785 -   -> New best validation loss: 0.000200
2026-01-02 21:03:19,112 - Epoch  24: Train Loss = 0.000131, Val Loss = 0.000213
2026-01-02 21:03:21,526 - Epoch  25: Train Loss = 0.000167, Val Loss = 0.000220
2026-01-02 21:03:23,902 - Epoch  26: Train Loss = 0.000132, Val Loss = 0.000191
2026-01-02 21:03:23,903 -   -> New best validation loss: 0.000191
2026-01-02 21:03:26,243 - Epoch  27: Train Loss = 0.000108, Val Loss = 0.000246
2026-01-02 21:03:28,550 - Epoch  28: Train Loss = 0.000141, Val Loss = 0.000255
2026-01-02 21:03:30,921 - Epoch  29: Train Loss = 0.000122, Val Loss = 0.000218
2026-01-02 21:03:33,236 - Epoch  30: Train Loss = 0.000106, Val Loss = 0.000244
2026-01-02 21:03:35,544 - Epoch  31: Train Loss = 0.000102, Val Loss = 0.000237
2026-01-02 21:03:37,897 - Epoch  32: Train Loss = 0.000108, Val Loss = 0.000251
2026-01-02 21:03:40,208 - Epoch  33: Train Loss = 0.000098, Val Loss = 0.000212
2026-01-02 21:03:42,563 - Epoch  34: Train Loss = 0.000106, Val Loss = 0.000283
2026-01-02 21:03:44,968 - Epoch  35: Train Loss = 0.000098, Val Loss = 0.000218
2026-01-02 21:03:47,284 - Epoch  36: Train Loss = 0.000092, Val Loss = 0.000251
2026-01-02 21:03:49,646 - Epoch  37: Train Loss = 0.000095, Val Loss = 0.000255
2026-01-02 21:03:52,003 - Epoch  38: Train Loss = 0.000087, Val Loss = 0.000255
2026-01-02 21:03:54,328 - Epoch  39: Train Loss = 0.000102, Val Loss = 0.000230
2026-01-02 21:03:56,674 - Epoch  40: Train Loss = 0.000093, Val Loss = 0.000274
2026-01-02 21:03:59,008 - Epoch  41: Train Loss = 0.000097, Val Loss = 0.000236
2026-01-02 21:04:01,371 - Epoch  42: Train Loss = 0.000101, Val Loss = 0.000286
2026-01-02 21:04:03,726 - Epoch  43: Train Loss = 0.000104, Val Loss = 0.000232
2026-01-02 21:04:06,154 - Epoch  44: Train Loss = 0.000105, Val Loss = 0.000269
2026-01-02 21:04:08,510 - Epoch  45: Train Loss = 0.000128, Val Loss = 0.000491
2026-01-02 21:04:10,894 - Epoch  46: Train Loss = 0.000095, Val Loss = 0.000294
2026-01-02 21:04:13,245 - Epoch  47: Train Loss = 0.000081, Val Loss = 0.000243
2026-01-02 21:04:15,587 - Epoch  48: Train Loss = 0.000100, Val Loss = 0.000310
2026-01-02 21:04:17,908 - Epoch  49: Train Loss = 0.000089, Val Loss = 0.000235
2026-01-02 21:04:20,277 - Epoch  50: Train Loss = 0.000091, Val Loss = 0.000244
2026-01-02 21:04:22,608 - Epoch  51: Train Loss = 0.000087, Val Loss = 0.000270
2026-01-02 21:04:25,001 - Epoch  52: Train Loss = 0.000108, Val Loss = 0.000298
2026-01-02 21:04:27,333 - Epoch  53: Train Loss = 0.000096, Val Loss = 0.000203
2026-01-02 21:04:29,700 - Epoch  54: Train Loss = 0.000084, Val Loss = 0.000239
2026-01-02 21:04:32,242 - Epoch  55: Train Loss = 0.000084, Val Loss = 0.000252
2026-01-02 21:04:34,440 - Epoch  56: Train Loss = 0.000085, Val Loss = 0.000255
2026-01-02 21:04:36,640 - Epoch  57: Train Loss = 0.000084, Val Loss = 0.000246
2026-01-02 21:04:38,911 - Epoch  58: Train Loss = 0.000078, Val Loss = 0.000280
2026-01-02 21:04:41,209 - Epoch  59: Train Loss = 0.000082, Val Loss = 0.000274
2026-01-02 21:04:43,466 - Epoch  60: Train Loss = 0.000090, Val Loss = 0.000265
2026-01-02 21:04:45,667 - Epoch  61: Train Loss = 0.000095, Val Loss = 0.000242
2026-01-02 21:04:47,996 - Epoch  62: Train Loss = 0.000085, Val Loss = 0.000289
2026-01-02 21:04:50,324 - Epoch  63: Train Loss = 0.000102, Val Loss = 0.000218
2026-01-02 21:04:52,727 - Epoch  64: Train Loss = 0.000076, Val Loss = 0.000219
2026-01-02 21:04:55,096 - Epoch  65: Train Loss = 0.000088, Val Loss = 0.000241
2026-01-02 21:04:57,411 - Epoch  66: Train Loss = 0.000079, Val Loss = 0.000301
2026-01-02 21:04:59,699 - Epoch  67: Train Loss = 0.000094, Val Loss = 0.000208
2026-01-02 21:05:02,021 - Epoch  68: Train Loss = 0.000075, Val Loss = 0.000215
2026-01-02 21:05:04,258 - Epoch  69: Train Loss = 0.000100, Val Loss = 0.000261
2026-01-02 21:05:06,709 - Epoch  70: Train Loss = 0.000081, Val Loss = 0.000215
2026-01-02 21:05:09,030 - Epoch  71: Train Loss = 0.000070, Val Loss = 0.000231
2026-01-02 21:05:11,377 - Epoch  72: Train Loss = 0.000076, Val Loss = 0.000278
2026-01-02 21:05:13,764 - Epoch  73: Train Loss = 0.000077, Val Loss = 0.000241
2026-01-02 21:05:16,007 - Epoch  74: Train Loss = 0.000069, Val Loss = 0.000234
2026-01-02 21:05:18,258 - Epoch  75: Train Loss = 0.000071, Val Loss = 0.000263
2026-01-02 21:05:20,503 - Epoch  76: Train Loss = 0.000087, Val Loss = 0.000312
2026-01-02 21:05:20,503 - Early stopping at epoch 76
2026-01-02 21:05:20,507 - Restored best model weights
2026-01-02 21:05:20,507 - 
============================================================
2026-01-02 21:05:20,507 - EVALUATION RESULTS
2026-01-02 21:05:20,507 - ============================================================
2026-01-02 21:05:20,551 - Validation: MSE=0.000195, MAE=0.012675, RMSE=0.013964, Corr=0.394647
2026-01-02 21:05:20,601 - Test:       MSE=0.000155, MAE=0.011086, RMSE=0.012447, Corr=0.496121
2026-01-02 21:05:20,601 - 
Saving model and results...
2026-01-02 21:05:20,808 - Saved weights to: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/models/best_weights.h5
2026-01-02 21:05:20,808 - Saved scaler to: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/models/scaler.pkl
2026-01-02 21:05:20,808 - Saved predictions to: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/models/predictions.npy
2026-01-02 21:05:20,809 - ============================================================
2026-01-02 21:05:20,809 - STEP 11: Plotting Prediction Results
2026-01-02 21:05:20,809 - ============================================================
2026-01-02 21:05:21,784 - Saved prediction plots to: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/perclos_prediction_results.png
2026-01-02 21:05:21,784 - 
2026-01-02 21:05:21,784 - ======================================================================
2026-01-02 21:05:21,784 - PIPELINE COMPLETED SUCCESSFULLY
2026-01-02 21:05:21,784 - ======================================================================
2026-01-02 21:05:21,784 - End time: 2026-01-02 21:05:21
2026-01-02 21:05:21,784 - Duration: 0:03:07.315907
2026-01-02 21:05:21,784 - 
2026-01-02 21:05:21,784 - Output files:
2026-01-02 21:05:21,784 -   - Preprocessed data: processed/
2026-01-02 21:05:21,784 -   - Model and results: logs/models/
2026-01-02 21:05:21,784 -   - Prediction plots: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/perclos_prediction_results.png
2026-01-02 21:05:21,784 -   - Log file: /home/vivian/eeg/SEED_VIG/VIGNet/ShujiaChen/logs/pipeline_20260102_210214.log
