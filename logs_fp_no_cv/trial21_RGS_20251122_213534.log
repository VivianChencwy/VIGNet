2025-11-23 02:58:34,419 - INFO - ================================================================================
2025-11-23 02:58:34,419 - INFO - TRIAL 21 - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 02:58:34,419 - INFO - Log file: ./logs_fp_no_cv/trial21_RGS_20251122_213534.log
2025-11-23 02:58:34,419 - INFO - Start time: 2025-11-23 02:58:34
2025-11-23 02:58:34,419 - INFO - ================================================================================
2025-11-23 02:58:34,426 - INFO - START TRAINING - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 02:58:34,426 - INFO - Learning rate: 0.005, Epochs: 200, Batches: 8
2025-11-23 02:58:34,426 - INFO - Data split: 70% train / 15% validation / 15% test
2025-11-23 02:58:34,427 - INFO - Loading dataset (FP1/FP2 channels only, fixed split)...
2025-11-23 02:58:34,474 - INFO - Dataset shapes - Train: (617, 2, 25, 1), Valid: (130, 2, 25, 1), Test: (138, 2, 25, 1)
2025-11-23 02:58:34,475 - INFO - Applied feature normalization (StandardScaler)
2025-11-23 02:58:34,477 - INFO - Initializing VIGNet-FP model (2 channels)...
2025-11-23 02:58:34,491 - INFO - Number of batch iterations per epoch: 77
2025-11-23 02:58:43,458 - INFO - Epoch: 1, Training Loss: 0.0826, Validation Loss: 0.0430
2025-11-23 02:58:43,459 - INFO -   → New best validation loss: 0.0430
2025-11-23 02:58:50,742 - INFO - Epoch: 2, Training Loss: 0.0432, Validation Loss: 0.0501
2025-11-23 02:59:00,134 - INFO - Epoch: 3, Training Loss: 0.0413, Validation Loss: 0.0345
2025-11-23 02:59:00,138 - INFO -   → New best validation loss: 0.0345
2025-11-23 02:59:09,509 - INFO - Epoch: 4, Training Loss: 0.0376, Validation Loss: 0.0290
2025-11-23 02:59:09,510 - INFO -   → New best validation loss: 0.0290
2025-11-23 02:59:17,802 - INFO - Epoch: 5, Training Loss: 0.0279, Validation Loss: 0.0236
2025-11-23 02:59:17,803 - INFO -   → New best validation loss: 0.0236
2025-11-23 02:59:25,935 - INFO - Epoch: 6, Training Loss: 0.0246, Validation Loss: 0.0270
2025-11-23 02:59:37,426 - INFO - Epoch: 7, Training Loss: 0.0248, Validation Loss: 0.0227
2025-11-23 02:59:37,427 - INFO -   → New best validation loss: 0.0227
2025-11-23 02:59:45,490 - INFO - Epoch: 8, Training Loss: 0.0212, Validation Loss: 0.0207
2025-11-23 02:59:45,493 - INFO -   → New best validation loss: 0.0207
2025-11-23 02:59:56,022 - INFO - Epoch: 9, Training Loss: 0.0194, Validation Loss: 0.0210
2025-11-23 03:00:07,064 - INFO - Epoch: 10, Training Loss: 0.0172, Validation Loss: 0.0168
2025-11-23 03:00:07,065 - INFO -   → New best validation loss: 0.0168
2025-11-23 03:00:15,503 - INFO - Epoch: 11, Training Loss: 0.0168, Validation Loss: 0.0150
2025-11-23 03:00:15,508 - INFO -   → New best validation loss: 0.0150
2025-11-23 03:00:24,687 - INFO - Epoch: 12, Training Loss: 0.0169, Validation Loss: 0.0227
2025-11-23 03:00:32,329 - INFO - Epoch: 13, Training Loss: 0.0158, Validation Loss: 0.0174
2025-11-23 03:00:39,008 - INFO - Epoch: 14, Training Loss: 0.0159, Validation Loss: 0.0141
2025-11-23 03:00:39,009 - INFO -   → New best validation loss: 0.0141
2025-11-23 03:00:49,041 - INFO - Epoch: 15, Training Loss: 0.0143, Validation Loss: 0.0180
2025-11-23 03:00:59,451 - INFO - Epoch: 16, Training Loss: 0.0124, Validation Loss: 0.0126
2025-11-23 03:00:59,454 - INFO -   → New best validation loss: 0.0126
2025-11-23 03:01:11,487 - INFO - Epoch: 17, Training Loss: 0.0130, Validation Loss: 0.0132
2025-11-23 03:01:20,814 - INFO - Epoch: 18, Training Loss: 0.0134, Validation Loss: 0.0117
2025-11-23 03:01:20,818 - INFO -   → New best validation loss: 0.0117
2025-11-23 03:01:31,026 - INFO - Epoch: 19, Training Loss: 0.0120, Validation Loss: 0.0129
2025-11-23 03:01:41,174 - INFO - Epoch: 20, Training Loss: 0.0116, Validation Loss: 0.0100
2025-11-23 03:01:41,178 - INFO -   → New best validation loss: 0.0100
2025-11-23 03:01:52,629 - INFO - Epoch: 21, Training Loss: 0.0105, Validation Loss: 0.0151
2025-11-23 03:02:00,104 - INFO - Epoch: 22, Training Loss: 0.0094, Validation Loss: 0.0137
2025-11-23 03:02:07,921 - INFO - Epoch: 23, Training Loss: 0.0103, Validation Loss: 0.0107
2025-11-23 03:02:16,226 - INFO - Epoch: 24, Training Loss: 0.0089, Validation Loss: 0.0106
2025-11-23 03:02:24,400 - INFO - Epoch: 25, Training Loss: 0.0099, Validation Loss: 0.0079
2025-11-23 03:02:24,405 - INFO -   → New best validation loss: 0.0079
2025-11-23 03:02:33,525 - INFO - Epoch: 26, Training Loss: 0.0078, Validation Loss: 0.0075
2025-11-23 03:02:33,526 - INFO -   → New best validation loss: 0.0075
2025-11-23 03:02:42,314 - INFO - Epoch: 27, Training Loss: 0.0070, Validation Loss: 0.0084
2025-11-23 03:02:49,810 - INFO - Epoch: 28, Training Loss: 0.0062, Validation Loss: 0.0078
2025-11-23 03:02:56,756 - INFO - Epoch: 29, Training Loss: 0.0079, Validation Loss: 0.0072
2025-11-23 03:02:56,760 - INFO -   → New best validation loss: 0.0072
2025-11-23 03:03:07,370 - INFO - Epoch: 30, Training Loss: 0.0062, Validation Loss: 0.0072
2025-11-23 03:03:07,372 - INFO -   → New best validation loss: 0.0072
2025-11-23 03:03:15,878 - INFO - Epoch: 31, Training Loss: 0.0058, Validation Loss: 0.0065
2025-11-23 03:03:15,879 - INFO -   → New best validation loss: 0.0065
2025-11-23 03:03:26,115 - INFO - Epoch: 32, Training Loss: 0.0047, Validation Loss: 0.0070
2025-11-23 03:03:34,470 - INFO - Epoch: 33, Training Loss: 0.0050, Validation Loss: 0.0057
2025-11-23 03:03:34,471 - INFO -   → New best validation loss: 0.0057
2025-11-23 03:03:43,631 - INFO - Epoch: 34, Training Loss: 0.0048, Validation Loss: 0.0090
2025-11-23 03:03:51,713 - INFO - Epoch: 35, Training Loss: 0.0052, Validation Loss: 0.0085
2025-11-23 03:03:59,392 - INFO - Epoch: 36, Training Loss: 0.0049, Validation Loss: 0.0116
2025-11-23 03:04:09,293 - INFO - Epoch: 37, Training Loss: 0.0058, Validation Loss: 0.0066
2025-11-23 03:04:17,925 - INFO - Epoch: 38, Training Loss: 0.0046, Validation Loss: 0.0050
2025-11-23 03:04:17,925 - INFO -   → New best validation loss: 0.0050
2025-11-23 03:04:25,893 - INFO - Epoch: 39, Training Loss: 0.0052, Validation Loss: 0.0090
2025-11-23 03:04:36,658 - INFO - Epoch: 40, Training Loss: 0.0049, Validation Loss: 0.0095
2025-11-23 03:04:46,988 - INFO - Epoch: 41, Training Loss: 0.0039, Validation Loss: 0.0049
2025-11-23 03:04:46,993 - INFO -   → New best validation loss: 0.0049
2025-11-23 03:04:55,844 - INFO - Epoch: 42, Training Loss: 0.0045, Validation Loss: 0.0052
2025-11-23 03:05:06,037 - INFO - Epoch: 43, Training Loss: 0.0043, Validation Loss: 0.0051
2025-11-23 03:05:14,809 - INFO - Epoch: 44, Training Loss: 0.0057, Validation Loss: 0.0075
2025-11-23 03:05:25,121 - INFO - Epoch: 45, Training Loss: 0.0038, Validation Loss: 0.0057
2025-11-23 03:05:34,972 - INFO - Epoch: 46, Training Loss: 0.0056, Validation Loss: 0.0063
2025-11-23 03:05:42,740 - INFO - Epoch: 47, Training Loss: 0.0041, Validation Loss: 0.0058
2025-11-23 03:05:53,064 - INFO - Epoch: 48, Training Loss: 0.0031, Validation Loss: 0.0037
2025-11-23 03:05:53,066 - INFO -   → New best validation loss: 0.0037
2025-11-23 03:06:01,123 - INFO - Epoch: 49, Training Loss: 0.0037, Validation Loss: 0.0035
2025-11-23 03:06:01,124 - INFO -   → New best validation loss: 0.0035
2025-11-23 03:06:08,639 - INFO - Epoch: 50, Training Loss: 0.0030, Validation Loss: 0.0046
2025-11-23 03:06:17,348 - INFO - Epoch: 51, Training Loss: 0.0035, Validation Loss: 0.0047
2025-11-23 03:06:23,334 - INFO - Epoch: 52, Training Loss: 0.0032, Validation Loss: 0.0049
2025-11-23 03:06:31,409 - INFO - Epoch: 53, Training Loss: 0.0034, Validation Loss: 0.0032
2025-11-23 03:06:31,410 - INFO -   → New best validation loss: 0.0032
2025-11-23 03:06:40,119 - INFO - Epoch: 54, Training Loss: 0.0040, Validation Loss: 0.0056
2025-11-23 03:06:49,929 - INFO - Epoch: 55, Training Loss: 0.0033, Validation Loss: 0.0032
2025-11-23 03:06:57,992 - INFO - Epoch: 56, Training Loss: 0.0029, Validation Loss: 0.0035
2025-11-23 03:07:09,715 - INFO - Epoch: 57, Training Loss: 0.0032, Validation Loss: 0.0041
2025-11-23 03:07:20,688 - INFO - Epoch: 58, Training Loss: 0.0035, Validation Loss: 0.0033
2025-11-23 03:07:32,715 - INFO - Epoch: 59, Training Loss: 0.0036, Validation Loss: 0.0043
2025-11-23 03:07:43,031 - INFO - Epoch: 60, Training Loss: 0.0041, Validation Loss: 0.0066
2025-11-23 03:07:51,889 - INFO - Epoch: 61, Training Loss: 0.0035, Validation Loss: 0.0047
2025-11-23 03:07:59,174 - INFO - Epoch: 62, Training Loss: 0.0027, Validation Loss: 0.0056
2025-11-23 03:08:07,432 - INFO - Epoch: 63, Training Loss: 0.0029, Validation Loss: 0.0040
2025-11-23 03:08:15,790 - INFO - Epoch: 64, Training Loss: 0.0031, Validation Loss: 0.0035
2025-11-23 03:08:25,231 - INFO - Epoch: 65, Training Loss: 0.0029, Validation Loss: 0.0043
2025-11-23 03:08:33,926 - INFO - Epoch: 66, Training Loss: 0.0028, Validation Loss: 0.0039
2025-11-23 03:08:41,751 - INFO - Epoch: 67, Training Loss: 0.0034, Validation Loss: 0.0042
2025-11-23 03:08:49,263 - INFO - Epoch: 68, Training Loss: 0.0034, Validation Loss: 0.0030
2025-11-23 03:08:49,267 - INFO -   → New best validation loss: 0.0030
2025-11-23 03:08:59,180 - INFO - Epoch: 69, Training Loss: 0.0029, Validation Loss: 0.0035
2025-11-23 03:09:08,664 - INFO - Epoch: 70, Training Loss: 0.0028, Validation Loss: 0.0028
2025-11-23 03:09:08,669 - INFO -   → New best validation loss: 0.0028
2025-11-23 03:09:19,093 - INFO - Epoch: 71, Training Loss: 0.0028, Validation Loss: 0.0043
2025-11-23 03:09:26,767 - INFO - Epoch: 72, Training Loss: 0.0033, Validation Loss: 0.0044
2025-11-23 03:09:35,660 - INFO - Epoch: 73, Training Loss: 0.0027, Validation Loss: 0.0025
2025-11-23 03:09:35,661 - INFO -   → New best validation loss: 0.0025
2025-11-23 03:09:43,894 - INFO - Epoch: 74, Training Loss: 0.0032, Validation Loss: 0.0073
2025-11-23 03:09:52,723 - INFO - Epoch: 75, Training Loss: 0.0037, Validation Loss: 0.0039
2025-11-23 03:10:02,499 - INFO - Epoch: 76, Training Loss: 0.0034, Validation Loss: 0.0023
2025-11-23 03:10:02,501 - INFO -   → New best validation loss: 0.0023
2025-11-23 03:10:12,441 - INFO - Epoch: 77, Training Loss: 0.0027, Validation Loss: 0.0034
2025-11-23 03:10:23,724 - INFO - Epoch: 78, Training Loss: 0.0027, Validation Loss: 0.0041
2025-11-23 03:10:33,424 - INFO - Epoch: 79, Training Loss: 0.0031, Validation Loss: 0.0033
2025-11-23 03:10:44,017 - INFO - Epoch: 80, Training Loss: 0.0030, Validation Loss: 0.0029
2025-11-23 03:10:51,136 - INFO - Epoch: 81, Training Loss: 0.0040, Validation Loss: 0.0032
2025-11-23 03:11:00,224 - INFO - Epoch: 82, Training Loss: 0.0029, Validation Loss: 0.0034
2025-11-23 03:11:09,430 - INFO - Epoch: 83, Training Loss: 0.0029, Validation Loss: 0.0030
2025-11-23 03:11:19,257 - INFO - Epoch: 84, Training Loss: 0.0030, Validation Loss: 0.0043
2025-11-23 03:11:30,393 - INFO - Epoch: 85, Training Loss: 0.0031, Validation Loss: 0.0083
2025-11-23 03:11:39,908 - INFO - Epoch: 86, Training Loss: 0.0036, Validation Loss: 0.0033
2025-11-23 03:11:48,580 - INFO - Epoch: 87, Training Loss: 0.0026, Validation Loss: 0.0050
2025-11-23 03:11:58,548 - INFO - Epoch: 88, Training Loss: 0.0027, Validation Loss: 0.0020
2025-11-23 03:11:58,549 - INFO -   → New best validation loss: 0.0020
2025-11-23 03:12:08,073 - INFO - Epoch: 89, Training Loss: 0.0029, Validation Loss: 0.0031
2025-11-23 03:12:19,990 - INFO - Epoch: 90, Training Loss: 0.0025, Validation Loss: 0.0037
2025-11-23 03:12:32,257 - INFO - Epoch: 91, Training Loss: 0.0024, Validation Loss: 0.0032
2025-11-23 03:12:39,018 - INFO - Epoch: 92, Training Loss: 0.0029, Validation Loss: 0.0057
2025-11-23 03:12:45,043 - INFO - Epoch: 93, Training Loss: 0.0026, Validation Loss: 0.0023
2025-11-23 03:12:51,913 - INFO - Epoch: 94, Training Loss: 0.0030, Validation Loss: 0.0048
2025-11-23 03:12:59,445 - INFO - Epoch: 95, Training Loss: 0.0027, Validation Loss: 0.0055
2025-11-23 03:13:10,521 - INFO - Epoch: 96, Training Loss: 0.0028, Validation Loss: 0.0035
2025-11-23 03:13:18,277 - INFO - Epoch: 97, Training Loss: 0.0026, Validation Loss: 0.0023
2025-11-23 03:13:27,496 - INFO - Epoch: 98, Training Loss: 0.0030, Validation Loss: 0.0027
2025-11-23 03:13:38,163 - INFO - Epoch: 99, Training Loss: 0.0025, Validation Loss: 0.0029
2025-11-23 03:13:46,140 - INFO - Epoch: 100, Training Loss: 0.0029, Validation Loss: 0.0023
2025-11-23 03:13:55,759 - INFO - Epoch: 101, Training Loss: 0.0028, Validation Loss: 0.0020
2025-11-23 03:13:55,759 - INFO -   → New best validation loss: 0.0020
2025-11-23 03:14:05,339 - INFO - Epoch: 102, Training Loss: 0.0027, Validation Loss: 0.0029
2025-11-23 03:14:14,029 - INFO - Epoch: 103, Training Loss: 0.0023, Validation Loss: 0.0019
2025-11-23 03:14:14,034 - INFO -   → New best validation loss: 0.0019
2025-11-23 03:14:24,093 - INFO - Epoch: 104, Training Loss: 0.0021, Validation Loss: 0.0021
2025-11-23 03:14:33,895 - INFO - Epoch: 105, Training Loss: 0.0029, Validation Loss: 0.0053
2025-11-23 03:14:41,855 - INFO - Epoch: 106, Training Loss: 0.0029, Validation Loss: 0.0057
2025-11-23 03:14:50,276 - INFO - Epoch: 107, Training Loss: 0.0029, Validation Loss: 0.0026
2025-11-23 03:15:01,649 - INFO - Epoch: 108, Training Loss: 0.0032, Validation Loss: 0.0020
2025-11-23 03:15:09,062 - INFO - Epoch: 109, Training Loss: 0.0023, Validation Loss: 0.0020
2025-11-23 03:15:16,191 - INFO - Epoch: 110, Training Loss: 0.0021, Validation Loss: 0.0030
2025-11-23 03:15:25,616 - INFO - Epoch: 111, Training Loss: 0.0026, Validation Loss: 0.0033
2025-11-23 03:15:35,088 - INFO - Epoch: 112, Training Loss: 0.0027, Validation Loss: 0.0026
2025-11-23 03:15:42,705 - INFO - Epoch: 113, Training Loss: 0.0023, Validation Loss: 0.0020
2025-11-23 03:15:51,103 - INFO - Epoch: 114, Training Loss: 0.0019, Validation Loss: 0.0023
2025-11-23 03:16:00,681 - INFO - Epoch: 115, Training Loss: 0.0020, Validation Loss: 0.0023
2025-11-23 03:16:08,662 - INFO - Epoch: 116, Training Loss: 0.0026, Validation Loss: 0.0019
2025-11-23 03:16:18,893 - INFO - Epoch: 117, Training Loss: 0.0025, Validation Loss: 0.0023
2025-11-23 03:16:31,016 - INFO - Epoch: 118, Training Loss: 0.0030, Validation Loss: 0.0026
2025-11-23 03:16:42,809 - INFO - Epoch: 119, Training Loss: 0.0024, Validation Loss: 0.0057
2025-11-23 03:16:53,516 - INFO - Epoch: 120, Training Loss: 0.0023, Validation Loss: 0.0037
2025-11-23 03:17:02,452 - INFO - Epoch: 121, Training Loss: 0.0024, Validation Loss: 0.0042
2025-11-23 03:17:10,879 - INFO - Epoch: 122, Training Loss: 0.0022, Validation Loss: 0.0022
2025-11-23 03:17:18,011 - INFO - Epoch: 123, Training Loss: 0.0021, Validation Loss: 0.0026
2025-11-23 03:17:18,011 - INFO - Early stopping triggered at epoch 123
2025-11-23 03:17:18,011 - INFO - Best validation loss: 0.0019
2025-11-23 03:17:18,015 - INFO - Restored best model weights
2025-11-23 03:17:18,015 - INFO - Starting model save process...
2025-11-23 03:17:18,015 - INFO - Creating models directory: ./logs_fp_no_cv/models
2025-11-23 03:17:18,015 - INFO - Models directory created/verified: ./logs_fp_no_cv/models
2025-11-23 03:17:18,015 - INFO - Attempting to save model to: ./logs_fp_no_cv/models/trial21_best_model
2025-11-23 03:17:18,155 - WARNING - Failed to save model in SavedModel format: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_20' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_20' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False

2025-11-23 03:17:18,155 - WARNING - Traceback (most recent call last):
  File "experiment_fp_no_cv.py", line 261, in _save_model
    model.save(model_save_path, save_format='tf')
  File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileu3w_yla6.py", line 14, in tf___wrapped_model
    outputs = ag__.converted_call(ag__.ld(model), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
    att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
  File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
  File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
    tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)
ValueError: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_20' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_20' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False


2025-11-23 03:17:18,155 - INFO - Attempting to save model weights to: ./logs_fp_no_cv/models/trial21_best_weights.h5
2025-11-23 03:17:18,162 - INFO - ✓ Saved model weights to: ./logs_fp_no_cv/models/trial21_best_weights.h5
2025-11-23 03:17:18,162 - INFO - Attempting to save scaler to: ./logs_fp_no_cv/models/trial21_scaler.pkl
2025-11-23 03:17:18,162 - INFO - ✓ Saved scaler to: ./logs_fp_no_cv/models/trial21_scaler.pkl
2025-11-23 03:17:18,162 - INFO - Attempting to save metadata to: ./logs_fp_no_cv/models/trial21_metadata.pkl
2025-11-23 03:17:18,162 - INFO - ✓ Saved model metadata to: ./logs_fp_no_cv/models/trial21_metadata.pkl
2025-11-23 03:17:18,162 - INFO - Model save process completed
2025-11-23 03:17:18,162 - INFO - 
============================================================
2025-11-23 03:17:18,162 - INFO - EVALUATION RESULTS
2025-11-23 03:17:18,162 - INFO - ============================================================
2025-11-23 03:17:18,209 - INFO - Validation Prediction Stats:
2025-11-23 03:17:18,209 - INFO -   Std: 0.292947, Range: 0.942253, Unique ratio: 0.6923
2025-11-23 03:17:18,210 - INFO - Validation Set - MSE: 0.003471, MAE: 0.048716, RMSE: 0.058915, Pearson Correlation: 0.989894 (p=0.000000)
2025-11-23 03:17:18,253 - INFO - Test Prediction Stats:
2025-11-23 03:17:18,253 - INFO -   Std: 0.305149, Range: 0.890756, Unique ratio: 0.6739
2025-11-23 03:17:18,254 - INFO - Test Set - MSE: 0.002507, MAE: 0.039941, RMSE: 0.050073, Pearson Correlation: 0.990285 (p=0.000000)
2025-11-23 03:17:18,254 - INFO - ============================================================

2025-11-23 03:17:18,254 - INFO - Trial completed successfully
2025-11-23 03:17:18,254 - INFO - ================================================================================
2025-11-23 03:17:18,254 - INFO - Trial 21 completed. End time: 2025-11-23 03:17:18
2025-11-23 03:17:18,254 - INFO - ================================================================================
