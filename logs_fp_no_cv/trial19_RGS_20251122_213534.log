2025-11-23 02:24:42,249 - INFO - ================================================================================
2025-11-23 02:24:42,249 - INFO - TRIAL 19 - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 02:24:42,249 - INFO - Log file: ./logs_fp_no_cv/trial19_RGS_20251122_213534.log
2025-11-23 02:24:42,249 - INFO - Start time: 2025-11-23 02:24:42
2025-11-23 02:24:42,249 - INFO - ================================================================================
2025-11-23 02:24:42,257 - INFO - START TRAINING - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 02:24:42,257 - INFO - Learning rate: 0.005, Epochs: 200, Batches: 8
2025-11-23 02:24:42,257 - INFO - Data split: 70% train / 15% validation / 15% test
2025-11-23 02:24:42,257 - INFO - Loading dataset (FP1/FP2 channels only, fixed split)...
2025-11-23 02:24:42,301 - INFO - Dataset shapes - Train: (617, 2, 25, 1), Valid: (129, 2, 25, 1), Test: (139, 2, 25, 1)
2025-11-23 02:24:42,303 - INFO - Applied feature normalization (StandardScaler)
2025-11-23 02:24:42,305 - INFO - Initializing VIGNet-FP model (2 channels)...
2025-11-23 02:24:42,320 - INFO - Number of batch iterations per epoch: 77
2025-11-23 02:24:50,692 - INFO - Epoch: 1, Training Loss: 0.0277, Validation Loss: 0.0117
2025-11-23 02:24:50,693 - INFO -   → New best validation loss: 0.0117
2025-11-23 02:24:58,072 - INFO - Epoch: 2, Training Loss: 0.0125, Validation Loss: 0.0104
2025-11-23 02:24:58,073 - INFO -   → New best validation loss: 0.0104
2025-11-23 02:25:05,971 - INFO - Epoch: 3, Training Loss: 0.0093, Validation Loss: 0.0064
2025-11-23 02:25:05,972 - INFO -   → New best validation loss: 0.0064
2025-11-23 02:25:13,086 - INFO - Epoch: 4, Training Loss: 0.0083, Validation Loss: 0.0061
2025-11-23 02:25:13,087 - INFO -   → New best validation loss: 0.0061
2025-11-23 02:25:22,218 - INFO - Epoch: 5, Training Loss: 0.0077, Validation Loss: 0.0075
2025-11-23 02:25:31,938 - INFO - Epoch: 6, Training Loss: 0.0077, Validation Loss: 0.0055
2025-11-23 02:25:31,939 - INFO -   → New best validation loss: 0.0055
2025-11-23 02:25:38,829 - INFO - Epoch: 7, Training Loss: 0.0075, Validation Loss: 0.0066
2025-11-23 02:25:47,567 - INFO - Epoch: 8, Training Loss: 0.0062, Validation Loss: 0.0067
2025-11-23 02:25:55,966 - INFO - Epoch: 9, Training Loss: 0.0066, Validation Loss: 0.0049
2025-11-23 02:25:55,969 - INFO -   → New best validation loss: 0.0049
2025-11-23 02:26:02,782 - INFO - Epoch: 10, Training Loss: 0.0070, Validation Loss: 0.0068
2025-11-23 02:26:12,833 - INFO - Epoch: 11, Training Loss: 0.0063, Validation Loss: 0.0047
2025-11-23 02:26:12,835 - INFO -   → New best validation loss: 0.0047
2025-11-23 02:26:24,185 - INFO - Epoch: 12, Training Loss: 0.0061, Validation Loss: 0.0052
2025-11-23 02:26:32,830 - INFO - Epoch: 13, Training Loss: 0.0052, Validation Loss: 0.0040
2025-11-23 02:26:32,833 - INFO -   → New best validation loss: 0.0040
2025-11-23 02:26:40,536 - INFO - Epoch: 14, Training Loss: 0.0042, Validation Loss: 0.0045
2025-11-23 02:26:51,291 - INFO - Epoch: 15, Training Loss: 0.0051, Validation Loss: 0.0034
2025-11-23 02:26:51,292 - INFO -   → New best validation loss: 0.0034
2025-11-23 02:26:57,491 - INFO - Epoch: 16, Training Loss: 0.0041, Validation Loss: 0.0035
2025-11-23 02:27:04,678 - INFO - Epoch: 17, Training Loss: 0.0038, Validation Loss: 0.0032
2025-11-23 02:27:04,679 - INFO -   → New best validation loss: 0.0032
2025-11-23 02:27:14,888 - INFO - Epoch: 18, Training Loss: 0.0039, Validation Loss: 0.0036
2025-11-23 02:27:22,118 - INFO - Epoch: 19, Training Loss: 0.0036, Validation Loss: 0.0030
2025-11-23 02:27:22,123 - INFO -   → New best validation loss: 0.0030
2025-11-23 02:27:31,939 - INFO - Epoch: 20, Training Loss: 0.0032, Validation Loss: 0.0032
2025-11-23 02:27:43,067 - INFO - Epoch: 21, Training Loss: 0.0028, Validation Loss: 0.0029
2025-11-23 02:27:43,073 - INFO -   → New best validation loss: 0.0029
2025-11-23 02:27:54,841 - INFO - Epoch: 22, Training Loss: 0.0030, Validation Loss: 0.0032
2025-11-23 02:28:05,970 - INFO - Epoch: 23, Training Loss: 0.0025, Validation Loss: 0.0028
2025-11-23 02:28:05,976 - INFO -   → New best validation loss: 0.0028
2025-11-23 02:28:16,771 - INFO - Epoch: 24, Training Loss: 0.0028, Validation Loss: 0.0038
2025-11-23 02:28:28,889 - INFO - Epoch: 25, Training Loss: 0.0022, Validation Loss: 0.0026
2025-11-23 02:28:28,892 - INFO -   → New best validation loss: 0.0026
2025-11-23 02:28:41,222 - INFO - Epoch: 26, Training Loss: 0.0023, Validation Loss: 0.0021
2025-11-23 02:28:41,227 - INFO -   → New best validation loss: 0.0021
2025-11-23 02:28:53,427 - INFO - Epoch: 27, Training Loss: 0.0019, Validation Loss: 0.0019
2025-11-23 02:28:53,431 - INFO -   → New best validation loss: 0.0019
2025-11-23 02:29:01,224 - INFO - Epoch: 28, Training Loss: 0.0020, Validation Loss: 0.0027
2025-11-23 02:29:09,084 - INFO - Epoch: 29, Training Loss: 0.0019, Validation Loss: 0.0013
2025-11-23 02:29:09,085 - INFO -   → New best validation loss: 0.0013
2025-11-23 02:29:15,535 - INFO - Epoch: 30, Training Loss: 0.0016, Validation Loss: 0.0013
2025-11-23 02:29:15,536 - INFO -   → New best validation loss: 0.0013
2025-11-23 02:29:24,481 - INFO - Epoch: 31, Training Loss: 0.0016, Validation Loss: 0.0017
2025-11-23 02:29:32,421 - INFO - Epoch: 32, Training Loss: 0.0013, Validation Loss: 0.0011
2025-11-23 02:29:32,422 - INFO -   → New best validation loss: 0.0011
2025-11-23 02:29:43,409 - INFO - Epoch: 33, Training Loss: 0.0013, Validation Loss: 0.0026
2025-11-23 02:29:53,541 - INFO - Epoch: 34, Training Loss: 0.0018, Validation Loss: 0.0016
2025-11-23 02:30:00,689 - INFO - Epoch: 35, Training Loss: 0.0014, Validation Loss: 0.0016
2025-11-23 02:30:06,784 - INFO - Epoch: 36, Training Loss: 0.0014, Validation Loss: 0.0011
2025-11-23 02:30:16,865 - INFO - Epoch: 37, Training Loss: 0.0013, Validation Loss: 0.0027
2025-11-23 02:30:25,728 - INFO - Epoch: 38, Training Loss: 0.0012, Validation Loss: 0.0010
2025-11-23 02:30:25,729 - INFO -   → New best validation loss: 0.0010
2025-11-23 02:30:30,633 - INFO - Epoch: 39, Training Loss: 0.0014, Validation Loss: 0.0013
2025-11-23 02:30:40,428 - INFO - Epoch: 40, Training Loss: 0.0011, Validation Loss: 0.0021
2025-11-23 02:30:52,007 - INFO - Epoch: 41, Training Loss: 0.0012, Validation Loss: 0.0011
2025-11-23 02:31:02,980 - INFO - Epoch: 42, Training Loss: 0.0009, Validation Loss: 0.0007
2025-11-23 02:31:02,981 - INFO -   → New best validation loss: 0.0007
2025-11-23 02:31:12,327 - INFO - Epoch: 43, Training Loss: 0.0010, Validation Loss: 0.0008
2025-11-23 02:31:23,428 - INFO - Epoch: 44, Training Loss: 0.0010, Validation Loss: 0.0008
2025-11-23 02:31:31,625 - INFO - Epoch: 45, Training Loss: 0.0010, Validation Loss: 0.0009
2025-11-23 02:31:41,550 - INFO - Epoch: 46, Training Loss: 0.0009, Validation Loss: 0.0013
2025-11-23 02:31:48,066 - INFO - Epoch: 47, Training Loss: 0.0008, Validation Loss: 0.0009
2025-11-23 02:31:55,243 - INFO - Epoch: 48, Training Loss: 0.0008, Validation Loss: 0.0010
2025-11-23 02:32:05,047 - INFO - Epoch: 49, Training Loss: 0.0008, Validation Loss: 0.0008
2025-11-23 02:32:13,316 - INFO - Epoch: 50, Training Loss: 0.0009, Validation Loss: 0.0008
2025-11-23 02:32:21,879 - INFO - Epoch: 51, Training Loss: 0.0009, Validation Loss: 0.0011
2025-11-23 02:32:32,725 - INFO - Epoch: 52, Training Loss: 0.0008, Validation Loss: 0.0011
2025-11-23 02:32:41,215 - INFO - Epoch: 53, Training Loss: 0.0010, Validation Loss: 0.0010
2025-11-23 02:32:48,417 - INFO - Epoch: 54, Training Loss: 0.0009, Validation Loss: 0.0008
2025-11-23 02:32:58,911 - INFO - Epoch: 55, Training Loss: 0.0008, Validation Loss: 0.0011
2025-11-23 02:33:07,958 - INFO - Epoch: 56, Training Loss: 0.0008, Validation Loss: 0.0008
2025-11-23 02:33:15,643 - INFO - Epoch: 57, Training Loss: 0.0010, Validation Loss: 0.0009
2025-11-23 02:33:23,310 - INFO - Epoch: 58, Training Loss: 0.0010, Validation Loss: 0.0011
2025-11-23 02:33:32,734 - INFO - Epoch: 59, Training Loss: 0.0008, Validation Loss: 0.0010
2025-11-23 02:33:39,570 - INFO - Epoch: 60, Training Loss: 0.0006, Validation Loss: 0.0008
2025-11-23 02:33:47,359 - INFO - Epoch: 61, Training Loss: 0.0006, Validation Loss: 0.0009
2025-11-23 02:33:57,516 - INFO - Epoch: 62, Training Loss: 0.0007, Validation Loss: 0.0006
2025-11-23 02:33:57,518 - INFO -   → New best validation loss: 0.0006
2025-11-23 02:34:04,075 - INFO - Epoch: 63, Training Loss: 0.0007, Validation Loss: 0.0005
2025-11-23 02:34:04,080 - INFO -   → New best validation loss: 0.0005
2025-11-23 02:34:11,598 - INFO - Epoch: 64, Training Loss: 0.0009, Validation Loss: 0.0010
2025-11-23 02:34:24,329 - INFO - Epoch: 65, Training Loss: 0.0009, Validation Loss: 0.0008
2025-11-23 02:34:33,099 - INFO - Epoch: 66, Training Loss: 0.0010, Validation Loss: 0.0007
2025-11-23 02:34:41,824 - INFO - Epoch: 67, Training Loss: 0.0007, Validation Loss: 0.0008
2025-11-23 02:34:50,415 - INFO - Epoch: 68, Training Loss: 0.0008, Validation Loss: 0.0011
2025-11-23 02:35:02,728 - INFO - Epoch: 69, Training Loss: 0.0007, Validation Loss: 0.0007
2025-11-23 02:35:11,977 - INFO - Epoch: 70, Training Loss: 0.0008, Validation Loss: 0.0007
2025-11-23 02:35:19,006 - INFO - Epoch: 71, Training Loss: 0.0007, Validation Loss: 0.0006
2025-11-23 02:35:25,724 - INFO - Epoch: 72, Training Loss: 0.0007, Validation Loss: 0.0006
2025-11-23 02:35:34,057 - INFO - Epoch: 73, Training Loss: 0.0010, Validation Loss: 0.0007
2025-11-23 02:35:44,331 - INFO - Epoch: 74, Training Loss: 0.0007, Validation Loss: 0.0006
2025-11-23 02:35:55,357 - INFO - Epoch: 75, Training Loss: 0.0008, Validation Loss: 0.0005
2025-11-23 02:35:55,361 - INFO -   → New best validation loss: 0.0005
2025-11-23 02:36:02,973 - INFO - Epoch: 76, Training Loss: 0.0008, Validation Loss: 0.0005
2025-11-23 02:36:02,974 - INFO -   → New best validation loss: 0.0005
2025-11-23 02:36:09,130 - INFO - Epoch: 77, Training Loss: 0.0006, Validation Loss: 0.0005
2025-11-23 02:36:09,131 - INFO -   → New best validation loss: 0.0005
2025-11-23 02:36:18,744 - INFO - Epoch: 78, Training Loss: 0.0008, Validation Loss: 0.0007
2025-11-23 02:36:27,316 - INFO - Epoch: 79, Training Loss: 0.0006, Validation Loss: 0.0006
2025-11-23 02:36:33,217 - INFO - Epoch: 80, Training Loss: 0.0006, Validation Loss: 0.0004
2025-11-23 02:36:33,218 - INFO -   → New best validation loss: 0.0004
2025-11-23 02:36:40,351 - INFO - Epoch: 81, Training Loss: 0.0007, Validation Loss: 0.0014
2025-11-23 02:36:50,690 - INFO - Epoch: 82, Training Loss: 0.0008, Validation Loss: 0.0005
2025-11-23 02:37:02,496 - INFO - Epoch: 83, Training Loss: 0.0007, Validation Loss: 0.0008
2025-11-23 02:37:14,563 - INFO - Epoch: 84, Training Loss: 0.0006, Validation Loss: 0.0008
2025-11-23 02:37:26,146 - INFO - Epoch: 85, Training Loss: 0.0007, Validation Loss: 0.0007
2025-11-23 02:37:36,041 - INFO - Epoch: 86, Training Loss: 0.0006, Validation Loss: 0.0008
2025-11-23 02:37:42,753 - INFO - Epoch: 87, Training Loss: 0.0008, Validation Loss: 0.0011
2025-11-23 02:37:51,477 - INFO - Epoch: 88, Training Loss: 0.0008, Validation Loss: 0.0005
2025-11-23 02:38:01,036 - INFO - Epoch: 89, Training Loss: 0.0008, Validation Loss: 0.0007
2025-11-23 02:38:09,759 - INFO - Epoch: 90, Training Loss: 0.0007, Validation Loss: 0.0012
2025-11-23 02:38:19,150 - INFO - Epoch: 91, Training Loss: 0.0007, Validation Loss: 0.0009
2025-11-23 02:38:28,215 - INFO - Epoch: 92, Training Loss: 0.0006, Validation Loss: 0.0012
2025-11-23 02:38:37,355 - INFO - Epoch: 93, Training Loss: 0.0005, Validation Loss: 0.0006
2025-11-23 02:38:46,400 - INFO - Epoch: 94, Training Loss: 0.0004, Validation Loss: 0.0006
2025-11-23 02:38:55,063 - INFO - Epoch: 95, Training Loss: 0.0009, Validation Loss: 0.0009
2025-11-23 02:39:05,281 - INFO - Epoch: 96, Training Loss: 0.0007, Validation Loss: 0.0006
2025-11-23 02:39:12,254 - INFO - Epoch: 97, Training Loss: 0.0009, Validation Loss: 0.0007
2025-11-23 02:39:19,974 - INFO - Epoch: 98, Training Loss: 0.0007, Validation Loss: 0.0005
2025-11-23 02:39:28,372 - INFO - Epoch: 99, Training Loss: 0.0007, Validation Loss: 0.0008
2025-11-23 02:39:37,562 - INFO - Epoch: 100, Training Loss: 0.0006, Validation Loss: 0.0008
2025-11-23 02:39:37,562 - INFO - Early stopping triggered at epoch 100
2025-11-23 02:39:37,562 - INFO - Best validation loss: 0.0004
2025-11-23 02:39:37,581 - INFO - Restored best model weights
2025-11-23 02:39:37,581 - INFO - Starting model save process...
2025-11-23 02:39:37,581 - INFO - Creating models directory: ./logs_fp_no_cv/models
2025-11-23 02:39:37,581 - INFO - Models directory created/verified: ./logs_fp_no_cv/models
2025-11-23 02:39:37,581 - INFO - Attempting to save model to: ./logs_fp_no_cv/models/trial19_best_model
2025-11-23 02:39:37,786 - WARNING - Failed to save model in SavedModel format: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_18' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_18' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False

2025-11-23 02:39:37,786 - WARNING - Traceback (most recent call last):
  File "experiment_fp_no_cv.py", line 261, in _save_model
    model.save(model_save_path, save_format='tf')
  File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileu3w_yla6.py", line 14, in tf___wrapped_model
    outputs = ag__.converted_call(ag__.ld(model), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
    att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
  File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
  File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
    tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)
ValueError: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_18' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_18' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False


2025-11-23 02:39:37,786 - INFO - Attempting to save model weights to: ./logs_fp_no_cv/models/trial19_best_weights.h5
2025-11-23 02:39:37,796 - INFO - ✓ Saved model weights to: ./logs_fp_no_cv/models/trial19_best_weights.h5
2025-11-23 02:39:37,796 - INFO - Attempting to save scaler to: ./logs_fp_no_cv/models/trial19_scaler.pkl
2025-11-23 02:39:37,797 - INFO - ✓ Saved scaler to: ./logs_fp_no_cv/models/trial19_scaler.pkl
2025-11-23 02:39:37,797 - INFO - Attempting to save metadata to: ./logs_fp_no_cv/models/trial19_metadata.pkl
2025-11-23 02:39:37,797 - INFO - ✓ Saved model metadata to: ./logs_fp_no_cv/models/trial19_metadata.pkl
2025-11-23 02:39:37,797 - INFO - Model save process completed
2025-11-23 02:39:37,797 - INFO - 
============================================================
2025-11-23 02:39:37,797 - INFO - EVALUATION RESULTS
2025-11-23 02:39:37,797 - INFO - ============================================================
2025-11-23 02:39:37,975 - INFO - Validation Prediction Stats:
2025-11-23 02:39:37,975 - INFO -   Std: 0.116824, Range: 0.494561, Unique ratio: 0.7054
2025-11-23 02:39:37,976 - INFO - Validation Set - MSE: 0.000433, MAE: 0.016282, RMSE: 0.020811, Pearson Correlation: 0.984028 (p=0.000000)
2025-11-23 02:39:38,071 - INFO - Test Prediction Stats:
2025-11-23 02:39:38,071 - INFO -   Std: 0.113998, Range: 0.484436, Unique ratio: 0.6619
2025-11-23 02:39:38,071 - INFO - Test Set - MSE: 0.000311, MAE: 0.013825, RMSE: 0.017627, Pearson Correlation: 0.988781 (p=0.000000)
2025-11-23 02:39:38,071 - INFO - ============================================================

2025-11-23 02:39:38,072 - INFO - Trial completed successfully
2025-11-23 02:39:38,072 - INFO - ================================================================================
2025-11-23 02:39:38,072 - INFO - Trial 19 completed. End time: 2025-11-23 02:39:38
2025-11-23 02:39:38,072 - INFO - ================================================================================
