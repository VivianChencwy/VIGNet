2025-11-23 01:03:53,947 - INFO - ================================================================================
2025-11-23 01:03:53,947 - INFO - TRIAL 14 - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 01:03:53,947 - INFO - Log file: ./logs_fp_no_cv/trial14_RGS_20251122_213534.log
2025-11-23 01:03:53,947 - INFO - Start time: 2025-11-23 01:03:53
2025-11-23 01:03:53,947 - INFO - ================================================================================
2025-11-23 01:03:53,949 - INFO - START TRAINING - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 01:03:53,949 - INFO - Learning rate: 0.005, Epochs: 200, Batches: 8
2025-11-23 01:03:53,949 - INFO - Data split: 70% train / 15% validation / 15% test
2025-11-23 01:03:53,949 - INFO - Loading dataset (FP1/FP2 channels only, fixed split)...
2025-11-23 01:03:53,961 - INFO - Dataset shapes - Train: (618, 2, 25, 1), Valid: (131, 2, 25, 1), Test: (136, 2, 25, 1)
2025-11-23 01:03:53,961 - INFO - Applied feature normalization (StandardScaler)
2025-11-23 01:03:53,962 - INFO - Initializing VIGNet-FP model (2 channels)...
2025-11-23 01:03:53,966 - INFO - Number of batch iterations per epoch: 77
2025-11-23 01:04:01,452 - INFO - Epoch: 1, Training Loss: 0.0771, Validation Loss: 0.0536
2025-11-23 01:04:01,453 - INFO -   → New best validation loss: 0.0536
2025-11-23 01:04:09,513 - INFO - Epoch: 2, Training Loss: 0.0316, Validation Loss: 0.0265
2025-11-23 01:04:09,514 - INFO -   → New best validation loss: 0.0265
2025-11-23 01:04:20,228 - INFO - Epoch: 3, Training Loss: 0.0293, Validation Loss: 0.0334
2025-11-23 01:04:28,505 - INFO - Epoch: 4, Training Loss: 0.0257, Validation Loss: 0.0199
2025-11-23 01:04:28,506 - INFO -   → New best validation loss: 0.0199
2025-11-23 01:04:38,085 - INFO - Epoch: 5, Training Loss: 0.0261, Validation Loss: 0.0212
2025-11-23 01:04:45,947 - INFO - Epoch: 6, Training Loss: 0.0258, Validation Loss: 0.0207
2025-11-23 01:04:56,331 - INFO - Epoch: 7, Training Loss: 0.0260, Validation Loss: 0.0204
2025-11-23 01:05:07,158 - INFO - Epoch: 8, Training Loss: 0.0234, Validation Loss: 0.0207
2025-11-23 01:05:16,606 - INFO - Epoch: 9, Training Loss: 0.0215, Validation Loss: 0.0289
2025-11-23 01:05:25,902 - INFO - Epoch: 10, Training Loss: 0.0229, Validation Loss: 0.0199
2025-11-23 01:05:32,950 - INFO - Epoch: 11, Training Loss: 0.0211, Validation Loss: 0.0233
2025-11-23 01:05:40,544 - INFO - Epoch: 12, Training Loss: 0.0216, Validation Loss: 0.0173
2025-11-23 01:05:40,545 - INFO -   → New best validation loss: 0.0173
2025-11-23 01:05:51,454 - INFO - Epoch: 13, Training Loss: 0.0168, Validation Loss: 0.0204
2025-11-23 01:05:59,619 - INFO - Epoch: 14, Training Loss: 0.0168, Validation Loss: 0.0166
2025-11-23 01:05:59,620 - INFO -   → New best validation loss: 0.0166
2025-11-23 01:06:07,996 - INFO - Epoch: 15, Training Loss: 0.0157, Validation Loss: 0.0137
2025-11-23 01:06:07,997 - INFO -   → New best validation loss: 0.0137
2025-11-23 01:06:13,062 - INFO - Epoch: 16, Training Loss: 0.0142, Validation Loss: 0.0209
2025-11-23 01:06:23,285 - INFO - Epoch: 17, Training Loss: 0.0148, Validation Loss: 0.0185
2025-11-23 01:06:34,424 - INFO - Epoch: 18, Training Loss: 0.0144, Validation Loss: 0.0141
2025-11-23 01:06:43,721 - INFO - Epoch: 19, Training Loss: 0.0135, Validation Loss: 0.0135
2025-11-23 01:06:43,722 - INFO -   → New best validation loss: 0.0135
2025-11-23 01:06:55,862 - INFO - Epoch: 20, Training Loss: 0.0123, Validation Loss: 0.0135
2025-11-23 01:07:05,012 - INFO - Epoch: 21, Training Loss: 0.0127, Validation Loss: 0.0162
2025-11-23 01:07:12,514 - INFO - Epoch: 22, Training Loss: 0.0114, Validation Loss: 0.0131
2025-11-23 01:07:12,515 - INFO -   → New best validation loss: 0.0131
2025-11-23 01:07:23,755 - INFO - Epoch: 23, Training Loss: 0.0118, Validation Loss: 0.0136
2025-11-23 01:07:30,563 - INFO - Epoch: 24, Training Loss: 0.0109, Validation Loss: 0.0124
2025-11-23 01:07:30,564 - INFO -   → New best validation loss: 0.0124
2025-11-23 01:07:39,239 - INFO - Epoch: 25, Training Loss: 0.0105, Validation Loss: 0.0138
2025-11-23 01:07:51,014 - INFO - Epoch: 26, Training Loss: 0.0113, Validation Loss: 0.0108
2025-11-23 01:07:51,021 - INFO -   → New best validation loss: 0.0108
2025-11-23 01:08:00,306 - INFO - Epoch: 27, Training Loss: 0.0105, Validation Loss: 0.0134
2025-11-23 01:08:09,689 - INFO - Epoch: 28, Training Loss: 0.0105, Validation Loss: 0.0116
2025-11-23 01:08:19,294 - INFO - Epoch: 29, Training Loss: 0.0098, Validation Loss: 0.0102
2025-11-23 01:08:19,295 - INFO -   → New best validation loss: 0.0102
2025-11-23 01:08:28,761 - INFO - Epoch: 30, Training Loss: 0.0090, Validation Loss: 0.0086
2025-11-23 01:08:28,762 - INFO -   → New best validation loss: 0.0086
2025-11-23 01:08:36,449 - INFO - Epoch: 31, Training Loss: 0.0091, Validation Loss: 0.0103
2025-11-23 01:08:44,636 - INFO - Epoch: 32, Training Loss: 0.0076, Validation Loss: 0.0079
2025-11-23 01:08:44,637 - INFO -   → New best validation loss: 0.0079
2025-11-23 01:08:53,034 - INFO - Epoch: 33, Training Loss: 0.0086, Validation Loss: 0.0077
2025-11-23 01:08:53,040 - INFO -   → New best validation loss: 0.0077
2025-11-23 01:08:59,856 - INFO - Epoch: 34, Training Loss: 0.0084, Validation Loss: 0.0085
2025-11-23 01:09:10,559 - INFO - Epoch: 35, Training Loss: 0.0071, Validation Loss: 0.0101
2025-11-23 01:09:18,338 - INFO - Epoch: 36, Training Loss: 0.0075, Validation Loss: 0.0084
2025-11-23 01:09:29,292 - INFO - Epoch: 37, Training Loss: 0.0074, Validation Loss: 0.0127
2025-11-23 01:09:35,627 - INFO - Epoch: 38, Training Loss: 0.0078, Validation Loss: 0.0094
2025-11-23 01:09:46,313 - INFO - Epoch: 39, Training Loss: 0.0068, Validation Loss: 0.0077
2025-11-23 01:09:46,315 - INFO -   → New best validation loss: 0.0077
2025-11-23 01:09:54,825 - INFO - Epoch: 40, Training Loss: 0.0069, Validation Loss: 0.0085
2025-11-23 01:10:03,323 - INFO - Epoch: 41, Training Loss: 0.0057, Validation Loss: 0.0069
2025-11-23 01:10:03,327 - INFO -   → New best validation loss: 0.0069
2025-11-23 01:10:13,591 - INFO - Epoch: 42, Training Loss: 0.0066, Validation Loss: 0.0083
2025-11-23 01:10:23,748 - INFO - Epoch: 43, Training Loss: 0.0059, Validation Loss: 0.0078
2025-11-23 01:10:32,440 - INFO - Epoch: 44, Training Loss: 0.0051, Validation Loss: 0.0062
2025-11-23 01:10:32,441 - INFO -   → New best validation loss: 0.0062
2025-11-23 01:10:40,245 - INFO - Epoch: 45, Training Loss: 0.0054, Validation Loss: 0.0062
2025-11-23 01:10:48,642 - INFO - Epoch: 46, Training Loss: 0.0049, Validation Loss: 0.0067
2025-11-23 01:10:58,836 - INFO - Epoch: 47, Training Loss: 0.0059, Validation Loss: 0.0063
2025-11-23 01:11:10,452 - INFO - Epoch: 48, Training Loss: 0.0043, Validation Loss: 0.0063
2025-11-23 01:11:18,626 - INFO - Epoch: 49, Training Loss: 0.0044, Validation Loss: 0.0065
2025-11-23 01:11:27,780 - INFO - Epoch: 50, Training Loss: 0.0045, Validation Loss: 0.0055
2025-11-23 01:11:27,785 - INFO -   → New best validation loss: 0.0055
2025-11-23 01:11:37,315 - INFO - Epoch: 51, Training Loss: 0.0048, Validation Loss: 0.0063
2025-11-23 01:11:44,636 - INFO - Epoch: 52, Training Loss: 0.0043, Validation Loss: 0.0042
2025-11-23 01:11:44,639 - INFO -   → New best validation loss: 0.0042
2025-11-23 01:11:55,090 - INFO - Epoch: 53, Training Loss: 0.0043, Validation Loss: 0.0048
2025-11-23 01:12:05,786 - INFO - Epoch: 54, Training Loss: 0.0043, Validation Loss: 0.0043
2025-11-23 01:12:13,707 - INFO - Epoch: 55, Training Loss: 0.0038, Validation Loss: 0.0051
2025-11-23 01:12:23,947 - INFO - Epoch: 56, Training Loss: 0.0037, Validation Loss: 0.0038
2025-11-23 01:12:23,948 - INFO -   → New best validation loss: 0.0038
2025-11-23 01:12:31,476 - INFO - Epoch: 57, Training Loss: 0.0039, Validation Loss: 0.0045
2025-11-23 01:12:43,078 - INFO - Epoch: 58, Training Loss: 0.0036, Validation Loss: 0.0030
2025-11-23 01:12:43,080 - INFO -   → New best validation loss: 0.0030
2025-11-23 01:12:53,062 - INFO - Epoch: 59, Training Loss: 0.0031, Validation Loss: 0.0039
2025-11-23 01:13:02,282 - INFO - Epoch: 60, Training Loss: 0.0033, Validation Loss: 0.0051
2025-11-23 01:13:08,829 - INFO - Epoch: 61, Training Loss: 0.0031, Validation Loss: 0.0039
2025-11-23 01:13:18,539 - INFO - Epoch: 62, Training Loss: 0.0034, Validation Loss: 0.0036
2025-11-23 01:13:28,856 - INFO - Epoch: 63, Training Loss: 0.0026, Validation Loss: 0.0034
2025-11-23 01:13:37,376 - INFO - Epoch: 64, Training Loss: 0.0030, Validation Loss: 0.0032
2025-11-23 01:13:48,686 - INFO - Epoch: 65, Training Loss: 0.0030, Validation Loss: 0.0046
2025-11-23 01:13:58,343 - INFO - Epoch: 66, Training Loss: 0.0029, Validation Loss: 0.0037
2025-11-23 01:14:08,537 - INFO - Epoch: 67, Training Loss: 0.0029, Validation Loss: 0.0042
2025-11-23 01:14:16,874 - INFO - Epoch: 68, Training Loss: 0.0031, Validation Loss: 0.0022
2025-11-23 01:14:16,875 - INFO -   → New best validation loss: 0.0022
2025-11-23 01:14:25,733 - INFO - Epoch: 69, Training Loss: 0.0034, Validation Loss: 0.0038
2025-11-23 01:14:34,420 - INFO - Epoch: 70, Training Loss: 0.0033, Validation Loss: 0.0025
2025-11-23 01:14:40,287 - INFO - Epoch: 71, Training Loss: 0.0023, Validation Loss: 0.0031
2025-11-23 01:14:48,978 - INFO - Epoch: 72, Training Loss: 0.0029, Validation Loss: 0.0055
2025-11-23 01:14:59,747 - INFO - Epoch: 73, Training Loss: 0.0027, Validation Loss: 0.0037
2025-11-23 01:15:07,616 - INFO - Epoch: 74, Training Loss: 0.0024, Validation Loss: 0.0029
2025-11-23 01:15:15,142 - INFO - Epoch: 75, Training Loss: 0.0029, Validation Loss: 0.0029
2025-11-23 01:15:22,647 - INFO - Epoch: 76, Training Loss: 0.0022, Validation Loss: 0.0033
2025-11-23 01:15:28,106 - INFO - Epoch: 77, Training Loss: 0.0023, Validation Loss: 0.0027
2025-11-23 01:15:38,268 - INFO - Epoch: 78, Training Loss: 0.0026, Validation Loss: 0.0025
2025-11-23 01:15:47,076 - INFO - Epoch: 79, Training Loss: 0.0021, Validation Loss: 0.0037
2025-11-23 01:15:58,584 - INFO - Epoch: 80, Training Loss: 0.0025, Validation Loss: 0.0031
2025-11-23 01:16:10,271 - INFO - Epoch: 81, Training Loss: 0.0023, Validation Loss: 0.0019
2025-11-23 01:16:10,272 - INFO -   → New best validation loss: 0.0019
2025-11-23 01:16:20,718 - INFO - Epoch: 82, Training Loss: 0.0022, Validation Loss: 0.0036
2025-11-23 01:16:30,572 - INFO - Epoch: 83, Training Loss: 0.0029, Validation Loss: 0.0037
2025-11-23 01:16:39,595 - INFO - Epoch: 84, Training Loss: 0.0023, Validation Loss: 0.0023
2025-11-23 01:16:47,837 - INFO - Epoch: 85, Training Loss: 0.0024, Validation Loss: 0.0036
2025-11-23 01:16:56,000 - INFO - Epoch: 86, Training Loss: 0.0024, Validation Loss: 0.0041
2025-11-23 01:17:07,270 - INFO - Epoch: 87, Training Loss: 0.0024, Validation Loss: 0.0033
2025-11-23 01:17:17,109 - INFO - Epoch: 88, Training Loss: 0.0025, Validation Loss: 0.0029
2025-11-23 01:17:26,975 - INFO - Epoch: 89, Training Loss: 0.0025, Validation Loss: 0.0018
2025-11-23 01:17:26,976 - INFO -   → New best validation loss: 0.0018
2025-11-23 01:17:34,152 - INFO - Epoch: 90, Training Loss: 0.0026, Validation Loss: 0.0022
2025-11-23 01:17:39,147 - INFO - Epoch: 91, Training Loss: 0.0024, Validation Loss: 0.0024
2025-11-23 01:17:46,576 - INFO - Epoch: 92, Training Loss: 0.0020, Validation Loss: 0.0027
2025-11-23 01:17:56,801 - INFO - Epoch: 93, Training Loss: 0.0021, Validation Loss: 0.0028
2025-11-23 01:18:07,135 - INFO - Epoch: 94, Training Loss: 0.0021, Validation Loss: 0.0032
2025-11-23 01:18:16,914 - INFO - Epoch: 95, Training Loss: 0.0029, Validation Loss: 0.0022
2025-11-23 01:18:26,038 - INFO - Epoch: 96, Training Loss: 0.0021, Validation Loss: 0.0046
2025-11-23 01:18:34,553 - INFO - Epoch: 97, Training Loss: 0.0022, Validation Loss: 0.0056
2025-11-23 01:18:44,319 - INFO - Epoch: 98, Training Loss: 0.0024, Validation Loss: 0.0026
2025-11-23 01:18:52,861 - INFO - Epoch: 99, Training Loss: 0.0019, Validation Loss: 0.0020
2025-11-23 01:19:01,567 - INFO - Epoch: 100, Training Loss: 0.0019, Validation Loss: 0.0019
2025-11-23 01:19:11,330 - INFO - Epoch: 101, Training Loss: 0.0017, Validation Loss: 0.0021
2025-11-23 01:19:21,499 - INFO - Epoch: 102, Training Loss: 0.0024, Validation Loss: 0.0032
2025-11-23 01:19:30,948 - INFO - Epoch: 103, Training Loss: 0.0028, Validation Loss: 0.0041
2025-11-23 01:19:40,930 - INFO - Epoch: 104, Training Loss: 0.0024, Validation Loss: 0.0041
2025-11-23 01:19:49,782 - INFO - Epoch: 105, Training Loss: 0.0023, Validation Loss: 0.0017
2025-11-23 01:19:49,787 - INFO -   → New best validation loss: 0.0017
2025-11-23 01:19:57,633 - INFO - Epoch: 106, Training Loss: 0.0019, Validation Loss: 0.0025
2025-11-23 01:20:07,951 - INFO - Epoch: 107, Training Loss: 0.0024, Validation Loss: 0.0020
2025-11-23 01:20:17,960 - INFO - Epoch: 108, Training Loss: 0.0017, Validation Loss: 0.0014
2025-11-23 01:20:17,961 - INFO -   → New best validation loss: 0.0014
2025-11-23 01:20:29,053 - INFO - Epoch: 109, Training Loss: 0.0022, Validation Loss: 0.0025
2025-11-23 01:20:35,831 - INFO - Epoch: 110, Training Loss: 0.0027, Validation Loss: 0.0040
2025-11-23 01:20:41,123 - INFO - Epoch: 111, Training Loss: 0.0021, Validation Loss: 0.0037
2025-11-23 01:20:49,143 - INFO - Epoch: 112, Training Loss: 0.0021, Validation Loss: 0.0030
2025-11-23 01:20:57,013 - INFO - Epoch: 113, Training Loss: 0.0018, Validation Loss: 0.0023
2025-11-23 01:21:07,413 - INFO - Epoch: 114, Training Loss: 0.0025, Validation Loss: 0.0028
2025-11-23 01:21:16,812 - INFO - Epoch: 115, Training Loss: 0.0024, Validation Loss: 0.0023
2025-11-23 01:21:28,993 - INFO - Epoch: 116, Training Loss: 0.0026, Validation Loss: 0.0024
2025-11-23 01:21:35,212 - INFO - Epoch: 117, Training Loss: 0.0023, Validation Loss: 0.0033
2025-11-23 01:21:44,655 - INFO - Epoch: 118, Training Loss: 0.0021, Validation Loss: 0.0028
2025-11-23 01:21:54,881 - INFO - Epoch: 119, Training Loss: 0.0017, Validation Loss: 0.0022
2025-11-23 01:22:03,036 - INFO - Epoch: 120, Training Loss: 0.0018, Validation Loss: 0.0027
2025-11-23 01:22:10,457 - INFO - Epoch: 121, Training Loss: 0.0017, Validation Loss: 0.0025
2025-11-23 01:22:18,229 - INFO - Epoch: 122, Training Loss: 0.0019, Validation Loss: 0.0031
2025-11-23 01:22:28,761 - INFO - Epoch: 123, Training Loss: 0.0019, Validation Loss: 0.0020
2025-11-23 01:22:38,900 - INFO - Epoch: 124, Training Loss: 0.0017, Validation Loss: 0.0037
2025-11-23 01:22:48,455 - INFO - Epoch: 125, Training Loss: 0.0020, Validation Loss: 0.0036
2025-11-23 01:22:56,466 - INFO - Epoch: 126, Training Loss: 0.0021, Validation Loss: 0.0029
2025-11-23 01:23:05,599 - INFO - Epoch: 127, Training Loss: 0.0022, Validation Loss: 0.0026
2025-11-23 01:23:11,843 - INFO - Epoch: 128, Training Loss: 0.0023, Validation Loss: 0.0030
2025-11-23 01:23:11,843 - INFO - Early stopping triggered at epoch 128
2025-11-23 01:23:11,843 - INFO - Best validation loss: 0.0014
2025-11-23 01:23:11,848 - INFO - Restored best model weights
2025-11-23 01:23:11,848 - INFO - Starting model save process...
2025-11-23 01:23:11,848 - INFO - Creating models directory: ./logs_fp_no_cv/models
2025-11-23 01:23:11,848 - INFO - Models directory created/verified: ./logs_fp_no_cv/models
2025-11-23 01:23:11,848 - INFO - Attempting to save model to: ./logs_fp_no_cv/models/trial14_best_model
2025-11-23 01:23:12,002 - WARNING - Failed to save model in SavedModel format: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_13' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_13' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False

2025-11-23 01:23:12,002 - WARNING - Traceback (most recent call last):
  File "experiment_fp_no_cv.py", line 261, in _save_model
    model.save(model_save_path, save_format='tf')
  File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileu3w_yla6.py", line 14, in tf___wrapped_model
    outputs = ag__.converted_call(ag__.ld(model), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
    att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
  File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
  File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
    tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)
ValueError: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_13' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_13' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False


2025-11-23 01:23:12,003 - INFO - Attempting to save model weights to: ./logs_fp_no_cv/models/trial14_best_weights.h5
2025-11-23 01:23:12,011 - INFO - ✓ Saved model weights to: ./logs_fp_no_cv/models/trial14_best_weights.h5
2025-11-23 01:23:12,012 - INFO - Attempting to save scaler to: ./logs_fp_no_cv/models/trial14_scaler.pkl
2025-11-23 01:23:12,012 - INFO - ✓ Saved scaler to: ./logs_fp_no_cv/models/trial14_scaler.pkl
2025-11-23 01:23:12,012 - INFO - Attempting to save metadata to: ./logs_fp_no_cv/models/trial14_metadata.pkl
2025-11-23 01:23:12,012 - INFO - ✓ Saved model metadata to: ./logs_fp_no_cv/models/trial14_metadata.pkl
2025-11-23 01:23:12,012 - INFO - Model save process completed
2025-11-23 01:23:12,012 - INFO - 
============================================================
2025-11-23 01:23:12,012 - INFO - EVALUATION RESULTS
2025-11-23 01:23:12,012 - INFO - ============================================================
2025-11-23 01:23:12,149 - INFO - Validation Prediction Stats:
2025-11-23 01:23:12,149 - INFO -   Std: 0.216636, Range: 0.842564, Unique ratio: 0.7481
2025-11-23 01:23:12,151 - INFO - Validation Set - MSE: 0.002120, MAE: 0.034047, RMSE: 0.046039, Pearson Correlation: 0.978797 (p=0.000000)
2025-11-23 01:23:12,251 - INFO - Test Prediction Stats:
2025-11-23 01:23:12,251 - INFO -   Std: 0.233143, Range: 0.836613, Unique ratio: 0.8088
2025-11-23 01:23:12,251 - INFO - Test Set - MSE: 0.002058, MAE: 0.035118, RMSE: 0.045363, Pearson Correlation: 0.981387 (p=0.000000)
2025-11-23 01:23:12,251 - INFO - ============================================================

2025-11-23 01:23:12,252 - INFO - Trial completed successfully
2025-11-23 01:23:12,252 - INFO - ================================================================================
2025-11-23 01:23:12,252 - INFO - Trial 14 completed. End time: 2025-11-23 01:23:12
2025-11-23 01:23:12,252 - INFO - ================================================================================
