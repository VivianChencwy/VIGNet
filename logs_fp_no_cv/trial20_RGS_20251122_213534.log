2025-11-23 02:39:38,072 - INFO - ================================================================================
2025-11-23 02:39:38,072 - INFO - TRIAL 20 - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 02:39:38,072 - INFO - Log file: ./logs_fp_no_cv/trial20_RGS_20251122_213534.log
2025-11-23 02:39:38,072 - INFO - Start time: 2025-11-23 02:39:38
2025-11-23 02:39:38,072 - INFO - ================================================================================
2025-11-23 02:39:38,074 - INFO - START TRAINING - Task: RGS (FP1/FP2 only, no CV)
2025-11-23 02:39:38,074 - INFO - Learning rate: 0.005, Epochs: 200, Batches: 8
2025-11-23 02:39:38,074 - INFO - Data split: 70% train / 15% validation / 15% test
2025-11-23 02:39:38,074 - INFO - Loading dataset (FP1/FP2 channels only, fixed split)...
2025-11-23 02:39:38,086 - INFO - Dataset shapes - Train: (617, 2, 25, 1), Valid: (130, 2, 25, 1), Test: (138, 2, 25, 1)
2025-11-23 02:39:38,086 - INFO - Applied feature normalization (StandardScaler)
2025-11-23 02:39:38,088 - INFO - Initializing VIGNet-FP model (2 channels)...
2025-11-23 02:39:38,092 - INFO - Number of batch iterations per epoch: 77
2025-11-23 02:39:46,583 - INFO - Epoch: 1, Training Loss: 0.1035, Validation Loss: 0.0453
2025-11-23 02:39:46,584 - INFO -   → New best validation loss: 0.0453
2025-11-23 02:39:53,348 - INFO - Epoch: 2, Training Loss: 0.0452, Validation Loss: 0.0414
2025-11-23 02:39:53,349 - INFO -   → New best validation loss: 0.0414
2025-11-23 02:39:59,253 - INFO - Epoch: 3, Training Loss: 0.0439, Validation Loss: 0.0369
2025-11-23 02:39:59,254 - INFO -   → New best validation loss: 0.0369
2025-11-23 02:40:06,717 - INFO - Epoch: 4, Training Loss: 0.0360, Validation Loss: 0.0386
2025-11-23 02:40:14,655 - INFO - Epoch: 5, Training Loss: 0.0356, Validation Loss: 0.0343
2025-11-23 02:40:14,656 - INFO -   → New best validation loss: 0.0343
2025-11-23 02:40:22,166 - INFO - Epoch: 6, Training Loss: 0.0319, Validation Loss: 0.0299
2025-11-23 02:40:22,169 - INFO -   → New best validation loss: 0.0299
2025-11-23 02:40:30,949 - INFO - Epoch: 7, Training Loss: 0.0329, Validation Loss: 0.0279
2025-11-23 02:40:30,950 - INFO -   → New best validation loss: 0.0279
2025-11-23 02:40:36,107 - INFO - Epoch: 8, Training Loss: 0.0252, Validation Loss: 0.0280
2025-11-23 02:40:43,777 - INFO - Epoch: 9, Training Loss: 0.0215, Validation Loss: 0.0293
2025-11-23 02:40:55,624 - INFO - Epoch: 10, Training Loss: 0.0190, Validation Loss: 0.0197
2025-11-23 02:40:55,625 - INFO -   → New best validation loss: 0.0197
2025-11-23 02:41:03,874 - INFO - Epoch: 11, Training Loss: 0.0179, Validation Loss: 0.0264
2025-11-23 02:41:14,199 - INFO - Epoch: 12, Training Loss: 0.0176, Validation Loss: 0.0163
2025-11-23 02:41:14,200 - INFO -   → New best validation loss: 0.0163
2025-11-23 02:41:24,969 - INFO - Epoch: 13, Training Loss: 0.0144, Validation Loss: 0.0165
2025-11-23 02:41:31,944 - INFO - Epoch: 14, Training Loss: 0.0161, Validation Loss: 0.0154
2025-11-23 02:41:31,950 - INFO -   → New best validation loss: 0.0154
2025-11-23 02:41:41,962 - INFO - Epoch: 15, Training Loss: 0.0156, Validation Loss: 0.0158
2025-11-23 02:41:48,979 - INFO - Epoch: 16, Training Loss: 0.0137, Validation Loss: 0.0149
2025-11-23 02:41:48,980 - INFO -   → New best validation loss: 0.0149
2025-11-23 02:41:55,464 - INFO - Epoch: 17, Training Loss: 0.0125, Validation Loss: 0.0115
2025-11-23 02:41:55,466 - INFO -   → New best validation loss: 0.0115
2025-11-23 02:42:02,703 - INFO - Epoch: 18, Training Loss: 0.0127, Validation Loss: 0.0139
2025-11-23 02:42:12,428 - INFO - Epoch: 19, Training Loss: 0.0118, Validation Loss: 0.0094
2025-11-23 02:42:12,431 - INFO -   → New best validation loss: 0.0094
2025-11-23 02:42:24,883 - INFO - Epoch: 20, Training Loss: 0.0113, Validation Loss: 0.0124
2025-11-23 02:42:33,928 - INFO - Epoch: 21, Training Loss: 0.0104, Validation Loss: 0.0117
2025-11-23 02:42:44,864 - INFO - Epoch: 22, Training Loss: 0.0091, Validation Loss: 0.0134
2025-11-23 02:42:55,064 - INFO - Epoch: 23, Training Loss: 0.0088, Validation Loss: 0.0069
2025-11-23 02:42:55,065 - INFO -   → New best validation loss: 0.0069
2025-11-23 02:43:04,637 - INFO - Epoch: 24, Training Loss: 0.0098, Validation Loss: 0.0098
2025-11-23 02:43:15,291 - INFO - Epoch: 25, Training Loss: 0.0083, Validation Loss: 0.0074
2025-11-23 02:43:26,250 - INFO - Epoch: 26, Training Loss: 0.0080, Validation Loss: 0.0076
2025-11-23 02:43:35,883 - INFO - Epoch: 27, Training Loss: 0.0074, Validation Loss: 0.0061
2025-11-23 02:43:35,884 - INFO -   → New best validation loss: 0.0061
2025-11-23 02:43:43,582 - INFO - Epoch: 28, Training Loss: 0.0068, Validation Loss: 0.0057
2025-11-23 02:43:43,583 - INFO -   → New best validation loss: 0.0057
2025-11-23 02:43:50,491 - INFO - Epoch: 29, Training Loss: 0.0069, Validation Loss: 0.0075
2025-11-23 02:43:59,980 - INFO - Epoch: 30, Training Loss: 0.0068, Validation Loss: 0.0097
2025-11-23 02:44:08,745 - INFO - Epoch: 31, Training Loss: 0.0074, Validation Loss: 0.0064
2025-11-23 02:44:17,896 - INFO - Epoch: 32, Training Loss: 0.0056, Validation Loss: 0.0057
2025-11-23 02:44:24,837 - INFO - Epoch: 33, Training Loss: 0.0070, Validation Loss: 0.0056
2025-11-23 02:44:24,840 - INFO -   → New best validation loss: 0.0056
2025-11-23 02:44:33,138 - INFO - Epoch: 34, Training Loss: 0.0061, Validation Loss: 0.0060
2025-11-23 02:44:41,363 - INFO - Epoch: 35, Training Loss: 0.0064, Validation Loss: 0.0077
2025-11-23 02:44:51,357 - INFO - Epoch: 36, Training Loss: 0.0052, Validation Loss: 0.0070
2025-11-23 02:44:59,724 - INFO - Epoch: 37, Training Loss: 0.0049, Validation Loss: 0.0050
2025-11-23 02:44:59,726 - INFO -   → New best validation loss: 0.0050
2025-11-23 02:45:11,079 - INFO - Epoch: 38, Training Loss: 0.0050, Validation Loss: 0.0084
2025-11-23 02:45:19,263 - INFO - Epoch: 39, Training Loss: 0.0049, Validation Loss: 0.0051
2025-11-23 02:45:29,088 - INFO - Epoch: 40, Training Loss: 0.0036, Validation Loss: 0.0050
2025-11-23 02:45:29,089 - INFO -   → New best validation loss: 0.0050
2025-11-23 02:45:36,387 - INFO - Epoch: 41, Training Loss: 0.0049, Validation Loss: 0.0030
2025-11-23 02:45:36,391 - INFO -   → New best validation loss: 0.0030
2025-11-23 02:45:45,406 - INFO - Epoch: 42, Training Loss: 0.0041, Validation Loss: 0.0044
2025-11-23 02:45:56,997 - INFO - Epoch: 43, Training Loss: 0.0047, Validation Loss: 0.0112
2025-11-23 02:46:07,478 - INFO - Epoch: 44, Training Loss: 0.0058, Validation Loss: 0.0041
2025-11-23 02:46:17,811 - INFO - Epoch: 45, Training Loss: 0.0036, Validation Loss: 0.0039
2025-11-23 02:46:25,827 - INFO - Epoch: 46, Training Loss: 0.0035, Validation Loss: 0.0035
2025-11-23 02:46:36,803 - INFO - Epoch: 47, Training Loss: 0.0037, Validation Loss: 0.0054
2025-11-23 02:46:45,341 - INFO - Epoch: 48, Training Loss: 0.0039, Validation Loss: 0.0042
2025-11-23 02:46:55,112 - INFO - Epoch: 49, Training Loss: 0.0039, Validation Loss: 0.0050
2025-11-23 02:47:04,897 - INFO - Epoch: 50, Training Loss: 0.0037, Validation Loss: 0.0054
2025-11-23 02:47:15,057 - INFO - Epoch: 51, Training Loss: 0.0028, Validation Loss: 0.0040
2025-11-23 02:47:22,755 - INFO - Epoch: 52, Training Loss: 0.0032, Validation Loss: 0.0026
2025-11-23 02:47:22,756 - INFO -   → New best validation loss: 0.0026
2025-11-23 02:47:30,535 - INFO - Epoch: 53, Training Loss: 0.0028, Validation Loss: 0.0027
2025-11-23 02:47:40,233 - INFO - Epoch: 54, Training Loss: 0.0026, Validation Loss: 0.0024
2025-11-23 02:47:40,234 - INFO -   → New best validation loss: 0.0024
2025-11-23 02:47:48,067 - INFO - Epoch: 55, Training Loss: 0.0026, Validation Loss: 0.0029
2025-11-23 02:47:58,012 - INFO - Epoch: 56, Training Loss: 0.0032, Validation Loss: 0.0041
2025-11-23 02:48:07,132 - INFO - Epoch: 57, Training Loss: 0.0030, Validation Loss: 0.0059
2025-11-23 02:48:15,924 - INFO - Epoch: 58, Training Loss: 0.0024, Validation Loss: 0.0029
2025-11-23 02:48:23,233 - INFO - Epoch: 59, Training Loss: 0.0027, Validation Loss: 0.0037
2025-11-23 02:48:32,345 - INFO - Epoch: 60, Training Loss: 0.0021, Validation Loss: 0.0026
2025-11-23 02:48:40,715 - INFO - Epoch: 61, Training Loss: 0.0029, Validation Loss: 0.0038
2025-11-23 02:48:49,655 - INFO - Epoch: 62, Training Loss: 0.0029, Validation Loss: 0.0025
2025-11-23 02:48:56,551 - INFO - Epoch: 63, Training Loss: 0.0021, Validation Loss: 0.0013
2025-11-23 02:48:56,556 - INFO -   → New best validation loss: 0.0013
2025-11-23 02:49:08,242 - INFO - Epoch: 64, Training Loss: 0.0024, Validation Loss: 0.0035
2025-11-23 02:49:16,618 - INFO - Epoch: 65, Training Loss: 0.0032, Validation Loss: 0.0037
2025-11-23 02:49:25,915 - INFO - Epoch: 66, Training Loss: 0.0022, Validation Loss: 0.0016
2025-11-23 02:49:35,759 - INFO - Epoch: 67, Training Loss: 0.0021, Validation Loss: 0.0031
2025-11-23 02:49:45,782 - INFO - Epoch: 68, Training Loss: 0.0021, Validation Loss: 0.0019
2025-11-23 02:49:53,826 - INFO - Epoch: 69, Training Loss: 0.0022, Validation Loss: 0.0023
2025-11-23 02:50:02,366 - INFO - Epoch: 70, Training Loss: 0.0019, Validation Loss: 0.0019
2025-11-23 02:50:11,436 - INFO - Epoch: 71, Training Loss: 0.0020, Validation Loss: 0.0019
2025-11-23 02:50:18,449 - INFO - Epoch: 72, Training Loss: 0.0021, Validation Loss: 0.0026
2025-11-23 02:50:25,287 - INFO - Epoch: 73, Training Loss: 0.0019, Validation Loss: 0.0044
2025-11-23 02:50:31,639 - INFO - Epoch: 74, Training Loss: 0.0019, Validation Loss: 0.0014
2025-11-23 02:50:39,998 - INFO - Epoch: 75, Training Loss: 0.0015, Validation Loss: 0.0014
2025-11-23 02:50:48,311 - INFO - Epoch: 76, Training Loss: 0.0016, Validation Loss: 0.0024
2025-11-23 02:50:55,278 - INFO - Epoch: 77, Training Loss: 0.0016, Validation Loss: 0.0012
2025-11-23 02:50:55,279 - INFO -   → New best validation loss: 0.0012
2025-11-23 02:51:04,818 - INFO - Epoch: 78, Training Loss: 0.0021, Validation Loss: 0.0029
2025-11-23 02:51:13,100 - INFO - Epoch: 79, Training Loss: 0.0018, Validation Loss: 0.0026
2025-11-23 02:51:22,202 - INFO - Epoch: 80, Training Loss: 0.0015, Validation Loss: 0.0020
2025-11-23 02:51:32,022 - INFO - Epoch: 81, Training Loss: 0.0014, Validation Loss: 0.0028
2025-11-23 02:51:41,886 - INFO - Epoch: 82, Training Loss: 0.0015, Validation Loss: 0.0023
2025-11-23 02:51:51,686 - INFO - Epoch: 83, Training Loss: 0.0015, Validation Loss: 0.0026
2025-11-23 02:51:58,290 - INFO - Epoch: 84, Training Loss: 0.0018, Validation Loss: 0.0029
2025-11-23 02:52:06,662 - INFO - Epoch: 85, Training Loss: 0.0016, Validation Loss: 0.0016
2025-11-23 02:52:16,763 - INFO - Epoch: 86, Training Loss: 0.0017, Validation Loss: 0.0027
2025-11-23 02:52:26,060 - INFO - Epoch: 87, Training Loss: 0.0021, Validation Loss: 0.0030
2025-11-23 02:52:34,837 - INFO - Epoch: 88, Training Loss: 0.0019, Validation Loss: 0.0018
2025-11-23 02:52:43,990 - INFO - Epoch: 89, Training Loss: 0.0013, Validation Loss: 0.0012
2025-11-23 02:52:50,883 - INFO - Epoch: 90, Training Loss: 0.0013, Validation Loss: 0.0023
2025-11-23 02:52:59,289 - INFO - Epoch: 91, Training Loss: 0.0013, Validation Loss: 0.0015
2025-11-23 02:53:08,799 - INFO - Epoch: 92, Training Loss: 0.0017, Validation Loss: 0.0013
2025-11-23 02:53:18,773 - INFO - Epoch: 93, Training Loss: 0.0014, Validation Loss: 0.0025
2025-11-23 02:53:27,361 - INFO - Epoch: 94, Training Loss: 0.0018, Validation Loss: 0.0013
2025-11-23 02:53:37,747 - INFO - Epoch: 95, Training Loss: 0.0015, Validation Loss: 0.0014
2025-11-23 02:53:48,468 - INFO - Epoch: 96, Training Loss: 0.0019, Validation Loss: 0.0026
2025-11-23 02:53:56,746 - INFO - Epoch: 97, Training Loss: 0.0014, Validation Loss: 0.0011
2025-11-23 02:53:56,747 - INFO -   → New best validation loss: 0.0011
2025-11-23 02:54:04,845 - INFO - Epoch: 98, Training Loss: 0.0015, Validation Loss: 0.0012
2025-11-23 02:54:11,561 - INFO - Epoch: 99, Training Loss: 0.0018, Validation Loss: 0.0018
2025-11-23 02:54:19,359 - INFO - Epoch: 100, Training Loss: 0.0016, Validation Loss: 0.0022
2025-11-23 02:54:28,948 - INFO - Epoch: 101, Training Loss: 0.0016, Validation Loss: 0.0013
2025-11-23 02:54:39,251 - INFO - Epoch: 102, Training Loss: 0.0013, Validation Loss: 0.0020
2025-11-23 02:54:49,607 - INFO - Epoch: 103, Training Loss: 0.0014, Validation Loss: 0.0015
2025-11-23 02:54:57,718 - INFO - Epoch: 104, Training Loss: 0.0019, Validation Loss: 0.0013
2025-11-23 02:55:06,528 - INFO - Epoch: 105, Training Loss: 0.0015, Validation Loss: 0.0024
2025-11-23 02:55:15,281 - INFO - Epoch: 106, Training Loss: 0.0016, Validation Loss: 0.0014
2025-11-23 02:55:22,797 - INFO - Epoch: 107, Training Loss: 0.0017, Validation Loss: 0.0009
2025-11-23 02:55:22,798 - INFO -   → New best validation loss: 0.0009
2025-11-23 02:55:30,749 - INFO - Epoch: 108, Training Loss: 0.0018, Validation Loss: 0.0013
2025-11-23 02:55:37,851 - INFO - Epoch: 109, Training Loss: 0.0014, Validation Loss: 0.0013
2025-11-23 02:55:47,244 - INFO - Epoch: 110, Training Loss: 0.0013, Validation Loss: 0.0016
2025-11-23 02:55:55,903 - INFO - Epoch: 111, Training Loss: 0.0016, Validation Loss: 0.0033
2025-11-23 02:56:05,746 - INFO - Epoch: 112, Training Loss: 0.0019, Validation Loss: 0.0022
2025-11-23 02:56:13,180 - INFO - Epoch: 113, Training Loss: 0.0013, Validation Loss: 0.0019
2025-11-23 02:56:22,785 - INFO - Epoch: 114, Training Loss: 0.0014, Validation Loss: 0.0026
2025-11-23 02:56:30,961 - INFO - Epoch: 115, Training Loss: 0.0015, Validation Loss: 0.0011
2025-11-23 02:56:40,396 - INFO - Epoch: 116, Training Loss: 0.0014, Validation Loss: 0.0019
2025-11-23 02:56:52,433 - INFO - Epoch: 117, Training Loss: 0.0017, Validation Loss: 0.0013
2025-11-23 02:57:01,154 - INFO - Epoch: 118, Training Loss: 0.0015, Validation Loss: 0.0015
2025-11-23 02:57:11,055 - INFO - Epoch: 119, Training Loss: 0.0014, Validation Loss: 0.0019
2025-11-23 02:57:19,898 - INFO - Epoch: 120, Training Loss: 0.0017, Validation Loss: 0.0021
2025-11-23 02:57:28,896 - INFO - Epoch: 121, Training Loss: 0.0015, Validation Loss: 0.0018
2025-11-23 02:57:39,311 - INFO - Epoch: 122, Training Loss: 0.0015, Validation Loss: 0.0013
2025-11-23 02:57:50,197 - INFO - Epoch: 123, Training Loss: 0.0012, Validation Loss: 0.0013
2025-11-23 02:58:00,221 - INFO - Epoch: 124, Training Loss: 0.0012, Validation Loss: 0.0019
2025-11-23 02:58:12,548 - INFO - Epoch: 125, Training Loss: 0.0019, Validation Loss: 0.0026
2025-11-23 02:58:23,443 - INFO - Epoch: 126, Training Loss: 0.0019, Validation Loss: 0.0026
2025-11-23 02:58:33,616 - INFO - Epoch: 127, Training Loss: 0.0021, Validation Loss: 0.0028
2025-11-23 02:58:33,616 - INFO - Early stopping triggered at epoch 127
2025-11-23 02:58:33,616 - INFO - Best validation loss: 0.0009
2025-11-23 02:58:33,620 - INFO - Restored best model weights
2025-11-23 02:58:33,620 - INFO - Starting model save process...
2025-11-23 02:58:33,620 - INFO - Creating models directory: ./logs_fp_no_cv/models
2025-11-23 02:58:33,620 - INFO - Models directory created/verified: ./logs_fp_no_cv/models
2025-11-23 02:58:33,620 - INFO - Attempting to save model to: ./logs_fp_no_cv/models/trial20_best_model
2025-11-23 02:58:34,016 - WARNING - Failed to save model in SavedModel format: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_19' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_19' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False

2025-11-23 02:58:34,016 - WARNING - Traceback (most recent call last):
  File "experiment_fp_no_cv.py", line 261, in _save_model
    model.save(model_save_path, save_format='tf')
  File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileu3w_yla6.py", line 14, in tf___wrapped_model
    outputs = ag__.converted_call(ag__.ld(model), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
    att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
  File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
  File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
    tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)
ValueError: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_19' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_19' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False


2025-11-23 02:58:34,016 - INFO - Attempting to save model weights to: ./logs_fp_no_cv/models/trial20_best_weights.h5
2025-11-23 02:58:34,028 - INFO - ✓ Saved model weights to: ./logs_fp_no_cv/models/trial20_best_weights.h5
2025-11-23 02:58:34,028 - INFO - Attempting to save scaler to: ./logs_fp_no_cv/models/trial20_scaler.pkl
2025-11-23 02:58:34,028 - INFO - ✓ Saved scaler to: ./logs_fp_no_cv/models/trial20_scaler.pkl
2025-11-23 02:58:34,028 - INFO - Attempting to save metadata to: ./logs_fp_no_cv/models/trial20_metadata.pkl
2025-11-23 02:58:34,028 - INFO - ✓ Saved model metadata to: ./logs_fp_no_cv/models/trial20_metadata.pkl
2025-11-23 02:58:34,028 - INFO - Model save process completed
2025-11-23 02:58:34,028 - INFO - 
============================================================
2025-11-23 02:58:34,028 - INFO - EVALUATION RESULTS
2025-11-23 02:58:34,028 - INFO - ============================================================
2025-11-23 02:58:34,211 - INFO - Validation Prediction Stats:
2025-11-23 02:58:34,212 - INFO -   Std: 0.352064, Range: 0.947048, Unique ratio: 0.6615
2025-11-23 02:58:34,213 - INFO - Validation Set - MSE: 0.000950, MAE: 0.022915, RMSE: 0.030827, Pearson Correlation: 0.996598 (p=0.000000)
2025-11-23 02:58:34,415 - INFO - Test Prediction Stats:
2025-11-23 02:58:34,415 - INFO -   Std: 0.333679, Range: 0.940939, Unique ratio: 0.6449
2025-11-23 02:58:34,417 - INFO - Test Set - MSE: 0.002341, MAE: 0.031728, RMSE: 0.048383, Pearson Correlation: 0.993388 (p=0.000000)
2025-11-23 02:58:34,417 - INFO - ============================================================

2025-11-23 02:58:34,418 - INFO - Trial completed successfully
2025-11-23 02:58:34,418 - INFO - ================================================================================
2025-11-23 02:58:34,418 - INFO - Trial 20 completed. End time: 2025-11-23 02:58:34
2025-11-23 02:58:34,418 - INFO - ================================================================================
