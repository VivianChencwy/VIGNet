2025-11-22 22:36:11,462 - INFO - ================================================================================
2025-11-22 22:36:11,462 - INFO - TRIAL 5 - Task: RGS (FP1/FP2 only, no CV)
2025-11-22 22:36:11,462 - INFO - Log file: ./logs_fp_no_cv/trial5_RGS_20251122_213534.log
2025-11-22 22:36:11,462 - INFO - Start time: 2025-11-22 22:36:11
2025-11-22 22:36:11,462 - INFO - ================================================================================
2025-11-22 22:36:11,464 - INFO - START TRAINING - Task: RGS (FP1/FP2 only, no CV)
2025-11-22 22:36:11,464 - INFO - Learning rate: 0.005, Epochs: 200, Batches: 8
2025-11-22 22:36:11,464 - INFO - Data split: 70% train / 15% validation / 15% test
2025-11-22 22:36:11,465 - INFO - Loading dataset (FP1/FP2 channels only, fixed split)...
2025-11-22 22:36:11,477 - INFO - Dataset shapes - Train: (617, 2, 25, 1), Valid: (130, 2, 25, 1), Test: (138, 2, 25, 1)
2025-11-22 22:36:11,477 - INFO - Applied feature normalization (StandardScaler)
2025-11-22 22:36:11,478 - INFO - Initializing VIGNet-FP model (2 channels)...
2025-11-22 22:36:11,482 - INFO - Number of batch iterations per epoch: 77
2025-11-22 22:36:18,785 - INFO - Epoch: 1, Training Loss: 0.0745, Validation Loss: 0.0303
2025-11-22 22:36:18,786 - INFO -   → New best validation loss: 0.0303
2025-11-22 22:36:27,642 - INFO - Epoch: 2, Training Loss: 0.0284, Validation Loss: 0.0304
2025-11-22 22:36:38,946 - INFO - Epoch: 3, Training Loss: 0.0214, Validation Loss: 0.0303
2025-11-22 22:36:46,283 - INFO - Epoch: 4, Training Loss: 0.0260, Validation Loss: 0.0229
2025-11-22 22:36:46,286 - INFO -   → New best validation loss: 0.0229
2025-11-22 22:36:54,537 - INFO - Epoch: 5, Training Loss: 0.0190, Validation Loss: 0.0193
2025-11-22 22:36:54,538 - INFO -   → New best validation loss: 0.0193
2025-11-22 22:37:05,032 - INFO - Epoch: 6, Training Loss: 0.0188, Validation Loss: 0.0188
2025-11-22 22:37:05,037 - INFO -   → New best validation loss: 0.0188
2025-11-22 22:37:13,620 - INFO - Epoch: 7, Training Loss: 0.0194, Validation Loss: 0.0202
2025-11-22 22:37:21,740 - INFO - Epoch: 8, Training Loss: 0.0189, Validation Loss: 0.0183
2025-11-22 22:37:21,741 - INFO -   → New best validation loss: 0.0183
2025-11-22 22:37:31,739 - INFO - Epoch: 9, Training Loss: 0.0185, Validation Loss: 0.0190
2025-11-22 22:37:38,735 - INFO - Epoch: 10, Training Loss: 0.0199, Validation Loss: 0.0207
2025-11-22 22:37:48,857 - INFO - Epoch: 11, Training Loss: 0.0182, Validation Loss: 0.0177
2025-11-22 22:37:48,858 - INFO -   → New best validation loss: 0.0177
2025-11-22 22:37:59,067 - INFO - Epoch: 12, Training Loss: 0.0180, Validation Loss: 0.0181
2025-11-22 22:38:10,344 - INFO - Epoch: 13, Training Loss: 0.0211, Validation Loss: 0.0188
2025-11-22 22:38:19,750 - INFO - Epoch: 14, Training Loss: 0.0186, Validation Loss: 0.0176
2025-11-22 22:38:19,751 - INFO -   → New best validation loss: 0.0176
2025-11-22 22:38:29,566 - INFO - Epoch: 15, Training Loss: 0.0167, Validation Loss: 0.0173
2025-11-22 22:38:29,572 - INFO -   → New best validation loss: 0.0173
2025-11-22 22:38:39,405 - INFO - Epoch: 16, Training Loss: 0.0160, Validation Loss: 0.0210
2025-11-22 22:38:49,162 - INFO - Epoch: 17, Training Loss: 0.0163, Validation Loss: 0.0189
2025-11-22 22:38:57,347 - INFO - Epoch: 18, Training Loss: 0.0148, Validation Loss: 0.0184
2025-11-22 22:39:07,243 - INFO - Epoch: 19, Training Loss: 0.0189, Validation Loss: 0.0179
2025-11-22 22:39:14,763 - INFO - Epoch: 20, Training Loss: 0.0151, Validation Loss: 0.0171
2025-11-22 22:39:14,765 - INFO -   → New best validation loss: 0.0171
2025-11-22 22:39:22,790 - INFO - Epoch: 21, Training Loss: 0.0151, Validation Loss: 0.0165
2025-11-22 22:39:22,791 - INFO -   → New best validation loss: 0.0165
2025-11-22 22:39:31,035 - INFO - Epoch: 22, Training Loss: 0.0150, Validation Loss: 0.0172
2025-11-22 22:39:39,740 - INFO - Epoch: 23, Training Loss: 0.0145, Validation Loss: 0.0159
2025-11-22 22:39:39,741 - INFO -   → New best validation loss: 0.0159
2025-11-22 22:39:48,393 - INFO - Epoch: 24, Training Loss: 0.0129, Validation Loss: 0.0154
2025-11-22 22:39:48,394 - INFO -   → New best validation loss: 0.0154
2025-11-22 22:39:57,711 - INFO - Epoch: 25, Training Loss: 0.0134, Validation Loss: 0.0158
2025-11-22 22:40:06,693 - INFO - Epoch: 26, Training Loss: 0.0121, Validation Loss: 0.0141
2025-11-22 22:40:06,694 - INFO -   → New best validation loss: 0.0141
2025-11-22 22:40:14,556 - INFO - Epoch: 27, Training Loss: 0.0121, Validation Loss: 0.0138
2025-11-22 22:40:14,557 - INFO -   → New best validation loss: 0.0138
2025-11-22 22:40:24,124 - INFO - Epoch: 28, Training Loss: 0.0127, Validation Loss: 0.0121
2025-11-22 22:40:24,125 - INFO -   → New best validation loss: 0.0121
2025-11-22 22:40:32,317 - INFO - Epoch: 29, Training Loss: 0.0119, Validation Loss: 0.0191
2025-11-22 22:40:41,049 - INFO - Epoch: 30, Training Loss: 0.0118, Validation Loss: 0.0124
2025-11-22 22:40:50,137 - INFO - Epoch: 31, Training Loss: 0.0108, Validation Loss: 0.0140
2025-11-22 22:40:59,427 - INFO - Epoch: 32, Training Loss: 0.0108, Validation Loss: 0.0146
2025-11-22 22:41:07,733 - INFO - Epoch: 33, Training Loss: 0.0101, Validation Loss: 0.0142
2025-11-22 22:41:15,902 - INFO - Epoch: 34, Training Loss: 0.0096, Validation Loss: 0.0274
2025-11-22 22:41:24,060 - INFO - Epoch: 35, Training Loss: 0.0109, Validation Loss: 0.0123
2025-11-22 22:41:32,722 - INFO - Epoch: 36, Training Loss: 0.0094, Validation Loss: 0.0195
2025-11-22 22:41:43,913 - INFO - Epoch: 37, Training Loss: 0.0102, Validation Loss: 0.0113
2025-11-22 22:41:43,917 - INFO -   → New best validation loss: 0.0113
2025-11-22 22:41:53,396 - INFO - Epoch: 38, Training Loss: 0.0099, Validation Loss: 0.0117
2025-11-22 22:41:59,686 - INFO - Epoch: 39, Training Loss: 0.0087, Validation Loss: 0.0111
2025-11-22 22:41:59,691 - INFO -   → New best validation loss: 0.0111
2025-11-22 22:42:09,236 - INFO - Epoch: 40, Training Loss: 0.0090, Validation Loss: 0.0142
2025-11-22 22:42:19,705 - INFO - Epoch: 41, Training Loss: 0.0091, Validation Loss: 0.0117
2025-11-22 22:42:27,888 - INFO - Epoch: 42, Training Loss: 0.0096, Validation Loss: 0.0140
2025-11-22 22:42:35,687 - INFO - Epoch: 43, Training Loss: 0.0092, Validation Loss: 0.0095
2025-11-22 22:42:35,688 - INFO -   → New best validation loss: 0.0095
2025-11-22 22:42:44,820 - INFO - Epoch: 44, Training Loss: 0.0086, Validation Loss: 0.0105
2025-11-22 22:42:53,432 - INFO - Epoch: 45, Training Loss: 0.0087, Validation Loss: 0.0117
2025-11-22 22:43:03,378 - INFO - Epoch: 46, Training Loss: 0.0081, Validation Loss: 0.0104
2025-11-22 22:43:12,660 - INFO - Epoch: 47, Training Loss: 0.0081, Validation Loss: 0.0106
2025-11-22 22:43:23,817 - INFO - Epoch: 48, Training Loss: 0.0072, Validation Loss: 0.0089
2025-11-22 22:43:23,818 - INFO -   → New best validation loss: 0.0089
2025-11-22 22:43:31,575 - INFO - Epoch: 49, Training Loss: 0.0078, Validation Loss: 0.0097
2025-11-22 22:43:39,223 - INFO - Epoch: 50, Training Loss: 0.0080, Validation Loss: 0.0094
2025-11-22 22:43:47,753 - INFO - Epoch: 51, Training Loss: 0.0085, Validation Loss: 0.0112
2025-11-22 22:43:56,371 - INFO - Epoch: 52, Training Loss: 0.0079, Validation Loss: 0.0095
2025-11-22 22:44:07,274 - INFO - Epoch: 53, Training Loss: 0.0082, Validation Loss: 0.0084
2025-11-22 22:44:07,275 - INFO -   → New best validation loss: 0.0084
2025-11-22 22:44:16,677 - INFO - Epoch: 54, Training Loss: 0.0081, Validation Loss: 0.0089
2025-11-22 22:44:25,528 - INFO - Epoch: 55, Training Loss: 0.0077, Validation Loss: 0.0089
2025-11-22 22:44:32,934 - INFO - Epoch: 56, Training Loss: 0.0075, Validation Loss: 0.0088
2025-11-22 22:44:41,590 - INFO - Epoch: 57, Training Loss: 0.0076, Validation Loss: 0.0092
2025-11-22 22:44:51,052 - INFO - Epoch: 58, Training Loss: 0.0071, Validation Loss: 0.0093
2025-11-22 22:45:00,035 - INFO - Epoch: 59, Training Loss: 0.0073, Validation Loss: 0.0103
2025-11-22 22:45:08,743 - INFO - Epoch: 60, Training Loss: 0.0075, Validation Loss: 0.0081
2025-11-22 22:45:08,744 - INFO -   → New best validation loss: 0.0081
2025-11-22 22:45:17,669 - INFO - Epoch: 61, Training Loss: 0.0067, Validation Loss: 0.0083
2025-11-22 22:45:26,260 - INFO - Epoch: 62, Training Loss: 0.0069, Validation Loss: 0.0089
2025-11-22 22:45:33,074 - INFO - Epoch: 63, Training Loss: 0.0070, Validation Loss: 0.0087
2025-11-22 22:45:41,141 - INFO - Epoch: 64, Training Loss: 0.0066, Validation Loss: 0.0082
2025-11-22 22:45:50,638 - INFO - Epoch: 65, Training Loss: 0.0061, Validation Loss: 0.0070
2025-11-22 22:45:50,639 - INFO -   → New best validation loss: 0.0070
2025-11-22 22:46:01,724 - INFO - Epoch: 66, Training Loss: 0.0064, Validation Loss: 0.0075
2025-11-22 22:46:11,173 - INFO - Epoch: 67, Training Loss: 0.0066, Validation Loss: 0.0085
2025-11-22 22:46:18,595 - INFO - Epoch: 68, Training Loss: 0.0059, Validation Loss: 0.0058
2025-11-22 22:46:18,598 - INFO -   → New best validation loss: 0.0058
2025-11-22 22:46:25,445 - INFO - Epoch: 69, Training Loss: 0.0066, Validation Loss: 0.0101
2025-11-22 22:46:34,214 - INFO - Epoch: 70, Training Loss: 0.0067, Validation Loss: 0.0076
2025-11-22 22:46:43,182 - INFO - Epoch: 71, Training Loss: 0.0058, Validation Loss: 0.0063
2025-11-22 22:46:51,382 - INFO - Epoch: 72, Training Loss: 0.0064, Validation Loss: 0.0076
2025-11-22 22:47:00,451 - INFO - Epoch: 73, Training Loss: 0.0069, Validation Loss: 0.0079
2025-11-22 22:47:11,997 - INFO - Epoch: 74, Training Loss: 0.0061, Validation Loss: 0.0064
2025-11-22 22:47:21,184 - INFO - Epoch: 75, Training Loss: 0.0058, Validation Loss: 0.0063
2025-11-22 22:47:31,423 - INFO - Epoch: 76, Training Loss: 0.0059, Validation Loss: 0.0093
2025-11-22 22:47:39,053 - INFO - Epoch: 77, Training Loss: 0.0051, Validation Loss: 0.0061
2025-11-22 22:47:45,801 - INFO - Epoch: 78, Training Loss: 0.0055, Validation Loss: 0.0067
2025-11-22 22:47:52,293 - INFO - Epoch: 79, Training Loss: 0.0051, Validation Loss: 0.0055
2025-11-22 22:47:52,294 - INFO -   → New best validation loss: 0.0055
2025-11-22 22:48:01,589 - INFO - Epoch: 80, Training Loss: 0.0052, Validation Loss: 0.0052
2025-11-22 22:48:01,590 - INFO -   → New best validation loss: 0.0052
2025-11-22 22:48:10,606 - INFO - Epoch: 81, Training Loss: 0.0047, Validation Loss: 0.0053
2025-11-22 22:48:21,289 - INFO - Epoch: 82, Training Loss: 0.0054, Validation Loss: 0.0063
2025-11-22 22:48:31,592 - INFO - Epoch: 83, Training Loss: 0.0052, Validation Loss: 0.0055
2025-11-22 22:48:38,702 - INFO - Epoch: 84, Training Loss: 0.0047, Validation Loss: 0.0069
2025-11-22 22:48:45,834 - INFO - Epoch: 85, Training Loss: 0.0056, Validation Loss: 0.0055
2025-11-22 22:48:53,414 - INFO - Epoch: 86, Training Loss: 0.0045, Validation Loss: 0.0048
2025-11-22 22:48:53,415 - INFO -   → New best validation loss: 0.0048
2025-11-22 22:49:01,046 - INFO - Epoch: 87, Training Loss: 0.0046, Validation Loss: 0.0053
2025-11-22 22:49:10,179 - INFO - Epoch: 88, Training Loss: 0.0046, Validation Loss: 0.0042
2025-11-22 22:49:10,180 - INFO -   → New best validation loss: 0.0042
2025-11-22 22:49:19,107 - INFO - Epoch: 89, Training Loss: 0.0042, Validation Loss: 0.0047
2025-11-22 22:49:25,819 - INFO - Epoch: 90, Training Loss: 0.0051, Validation Loss: 0.0050
2025-11-22 22:49:34,368 - INFO - Epoch: 91, Training Loss: 0.0047, Validation Loss: 0.0049
2025-11-22 22:49:40,315 - INFO - Epoch: 92, Training Loss: 0.0041, Validation Loss: 0.0042
2025-11-22 22:49:40,320 - INFO -   → New best validation loss: 0.0042
2025-11-22 22:49:49,079 - INFO - Epoch: 93, Training Loss: 0.0045, Validation Loss: 0.0058
2025-11-22 22:49:58,273 - INFO - Epoch: 94, Training Loss: 0.0048, Validation Loss: 0.0043
2025-11-22 22:50:07,088 - INFO - Epoch: 95, Training Loss: 0.0040, Validation Loss: 0.0041
2025-11-22 22:50:07,089 - INFO -   → New best validation loss: 0.0041
2025-11-22 22:50:15,944 - INFO - Epoch: 96, Training Loss: 0.0037, Validation Loss: 0.0048
2025-11-22 22:50:25,104 - INFO - Epoch: 97, Training Loss: 0.0040, Validation Loss: 0.0053
2025-11-22 22:50:33,880 - INFO - Epoch: 98, Training Loss: 0.0039, Validation Loss: 0.0049
2025-11-22 22:50:40,000 - INFO - Epoch: 99, Training Loss: 0.0042, Validation Loss: 0.0041
2025-11-22 22:50:46,568 - INFO - Epoch: 100, Training Loss: 0.0037, Validation Loss: 0.0047
2025-11-22 22:50:54,119 - INFO - Epoch: 101, Training Loss: 0.0042, Validation Loss: 0.0030
2025-11-22 22:50:54,120 - INFO -   → New best validation loss: 0.0030
2025-11-22 22:51:01,177 - INFO - Epoch: 102, Training Loss: 0.0040, Validation Loss: 0.0047
2025-11-22 22:51:10,559 - INFO - Epoch: 103, Training Loss: 0.0038, Validation Loss: 0.0047
2025-11-22 22:51:22,018 - INFO - Epoch: 104, Training Loss: 0.0045, Validation Loss: 0.0059
2025-11-22 22:51:30,402 - INFO - Epoch: 105, Training Loss: 0.0042, Validation Loss: 0.0034
2025-11-22 22:51:39,197 - INFO - Epoch: 106, Training Loss: 0.0040, Validation Loss: 0.0045
2025-11-22 22:51:47,632 - INFO - Epoch: 107, Training Loss: 0.0039, Validation Loss: 0.0054
2025-11-22 22:51:57,597 - INFO - Epoch: 108, Training Loss: 0.0031, Validation Loss: 0.0041
2025-11-22 22:52:04,962 - INFO - Epoch: 109, Training Loss: 0.0041, Validation Loss: 0.0047
2025-11-22 22:52:15,521 - INFO - Epoch: 110, Training Loss: 0.0034, Validation Loss: 0.0033
2025-11-22 22:52:26,715 - INFO - Epoch: 111, Training Loss: 0.0034, Validation Loss: 0.0032
2025-11-22 22:52:35,382 - INFO - Epoch: 112, Training Loss: 0.0035, Validation Loss: 0.0039
2025-11-22 22:52:46,851 - INFO - Epoch: 113, Training Loss: 0.0044, Validation Loss: 0.0073
2025-11-22 22:52:55,591 - INFO - Epoch: 114, Training Loss: 0.0036, Validation Loss: 0.0060
2025-11-22 22:53:04,702 - INFO - Epoch: 115, Training Loss: 0.0032, Validation Loss: 0.0031
2025-11-22 22:53:15,951 - INFO - Epoch: 116, Training Loss: 0.0031, Validation Loss: 0.0043
2025-11-22 22:53:25,376 - INFO - Epoch: 117, Training Loss: 0.0038, Validation Loss: 0.0038
2025-11-22 22:53:33,156 - INFO - Epoch: 118, Training Loss: 0.0036, Validation Loss: 0.0039
2025-11-22 22:53:43,054 - INFO - Epoch: 119, Training Loss: 0.0036, Validation Loss: 0.0051
2025-11-22 22:53:52,697 - INFO - Epoch: 120, Training Loss: 0.0034, Validation Loss: 0.0054
2025-11-22 22:54:03,547 - INFO - Epoch: 121, Training Loss: 0.0028, Validation Loss: 0.0038
2025-11-22 22:54:03,548 - INFO - Early stopping triggered at epoch 121
2025-11-22 22:54:03,548 - INFO - Best validation loss: 0.0030
2025-11-22 22:54:03,552 - INFO - Restored best model weights
2025-11-22 22:54:03,552 - INFO - Starting model save process...
2025-11-22 22:54:03,552 - INFO - Creating models directory: ./logs_fp_no_cv/models
2025-11-22 22:54:03,552 - INFO - Models directory created/verified: ./logs_fp_no_cv/models
2025-11-22 22:54:03,552 - INFO - Attempting to save model to: ./logs_fp_no_cv/models/trial5_best_model
2025-11-22 22:54:03,659 - WARNING - Failed to save model in SavedModel format: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_4' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_4' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False

2025-11-22 22:54:03,659 - WARNING - Traceback (most recent call last):
  File "experiment_fp_no_cv.py", line 261, in _save_model
    model.save(model_save_path, save_format='tf')
  File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileu3w_yla6.py", line 14, in tf___wrapped_model
    outputs = ag__.converted_call(ag__.ld(model), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
    att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
  File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
  File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
    tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)
ValueError: in user code:

    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/saving/legacy/saving_utils.py", line 147, in _wrapped_model  *
        outputs = model(*args, **kwargs)
    File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
        raise e.with_traceback(filtered_tb) from None
    File "/tmp/__autograph_generated_file3t0ck_8q.py", line 10, in tf__call
        att1 = ag__.converted_call(ag__.ld(self).MHRSSA, (ag__.ld(x), 10), None, fscope)
    File "/tmp/__autograph_generated_file2szops_9.py", line 41, in tf__MHRSSA
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(out_filter),), None, fscope), None, loop_body, get_state_1, set_state_1, ('MHRSSA',), {'iterate_names': 'i'})
    File "/tmp/__autograph_generated_file2szops_9.py", line 21, in loop_body
        tmp = ag__.converted_call(ag__.converted_call(ag__.ld(tf).keras.layers.Conv2D, (ag__.ld(num_channel), (ag__.ld(num_channel), 1)), dict(kernel_regularizer=ag__.ld(self).regularizer, activation=None), fscope), (ag__.ld(x),), None, fscope)

    ValueError: Exception encountered when calling layer 'vignet_fp_4' (type vignet_fp).
    
    in user code:
    
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 56, in call  *
            att1 = self.MHRSSA(x, 10)
        File "/home/vivian/eeg/SEED_VIG/VIGNet/network_fp.py", line 44, in MHRSSA  *
            tmp = tf.keras.layers.Conv2D(num_channel, (num_channel, 1), kernel_regularizer=self.regularizer, activation=None)(x)
        File "/home/vivian/miniconda3/envs/seed/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler  **
            raise e.with_traceback(filtered_tb) from None
    
        ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
    
    
    Call arguments received by layer 'vignet_fp_4' (type vignet_fp):
      • x=tf.Tensor(shape=(None, 2, 25, 1), dtype=float64)
      • training=False


2025-11-22 22:54:03,659 - INFO - Attempting to save model weights to: ./logs_fp_no_cv/models/trial5_best_weights.h5
2025-11-22 22:54:03,665 - INFO - ✓ Saved model weights to: ./logs_fp_no_cv/models/trial5_best_weights.h5
2025-11-22 22:54:03,665 - INFO - Attempting to save scaler to: ./logs_fp_no_cv/models/trial5_scaler.pkl
2025-11-22 22:54:03,665 - INFO - ✓ Saved scaler to: ./logs_fp_no_cv/models/trial5_scaler.pkl
2025-11-22 22:54:03,665 - INFO - Attempting to save metadata to: ./logs_fp_no_cv/models/trial5_metadata.pkl
2025-11-22 22:54:03,665 - INFO - ✓ Saved model metadata to: ./logs_fp_no_cv/models/trial5_metadata.pkl
2025-11-22 22:54:03,665 - INFO - Model save process completed
2025-11-22 22:54:03,665 - INFO - 
============================================================
2025-11-22 22:54:03,665 - INFO - EVALUATION RESULTS
2025-11-22 22:54:03,665 - INFO - ============================================================
2025-11-22 22:54:03,712 - INFO - Validation Prediction Stats:
2025-11-22 22:54:03,712 - INFO -   Std: 0.321580, Range: 0.996583, Unique ratio: 0.8154
2025-11-22 22:54:03,713 - INFO - Validation Set - MSE: 0.003501, MAE: 0.044172, RMSE: 0.059166, Pearson Correlation: 0.983503 (p=0.000000)
2025-11-22 22:54:03,784 - INFO - Test Prediction Stats:
2025-11-22 22:54:03,784 - INFO -   Std: 0.329565, Range: 0.947122, Unique ratio: 0.7246
2025-11-22 22:54:03,786 - INFO - Test Set - MSE: 0.002645, MAE: 0.037750, RMSE: 0.051432, Pearson Correlation: 0.988604 (p=0.000000)
2025-11-22 22:54:03,786 - INFO - ============================================================

2025-11-22 22:54:03,787 - INFO - Trial completed successfully
2025-11-22 22:54:03,787 - INFO - ================================================================================
2025-11-22 22:54:03,787 - INFO - Trial 5 completed. End time: 2025-11-22 22:54:03
2025-11-22 22:54:03,787 - INFO - ================================================================================
